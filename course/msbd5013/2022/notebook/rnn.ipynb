{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of a character-based RNN to generate sonnets\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.callbacks import LambdaCallback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename=\"shakespeare.txt\", seq_length=40, step=5):\n",
    "    '''\n",
    "    returns semi-redundant sequences their outputs \n",
    "    seq_length: number of characters in each sequence\n",
    "    step: gets every [step] sequence  \n",
    "    '''\n",
    "\n",
    "    # puts all data into text string  \n",
    "    file = open(filename, \"r\")\n",
    "    text = \"\"\n",
    "    for line in file:\n",
    "        line = line.lstrip(' ').rstrip(' ')\n",
    "        if line != '\\n' and not line[0].isdigit():\n",
    "            line.translate(str.maketrans('', '', string.punctuation))\n",
    "            text += line.lower()\n",
    "\n",
    "    # make char to index and index to char dictionary \n",
    "    characters = sorted(list(set(text)))\n",
    "    char_indices_dict = dict((c, i) for i, c in enumerate(characters))\n",
    "    indices_char_dict = dict((i, c) for i, c in enumerate(characters))\n",
    "    #print(char_indices_dict)\n",
    "\n",
    "    # makes every [step] char sequences of length seq_length and their outputs\n",
    "    sequences = []\n",
    "    next_chars = [] # next char that seq in sequences generates\n",
    "    #print(repr(text[len(text) - 200:]))\n",
    "    for i in range(0, len(text) - seq_length, step):\n",
    "        #print(i, seq, text[i : i + seq_length])\n",
    "        sequences.append(text[i : i + seq_length])\n",
    "        next_chars.append(text[i + seq_length])\n",
    "\n",
    "    # put sequences and outputs into np array\n",
    "    x = np.zeros((len(sequences), seq_length, len(characters)))\n",
    "    y = np.zeros((len(sequences), len(characters)), dtype=np.bool)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for t, char in enumerate(sequence):\n",
    "            x[i, t, char_indices_dict[char]] = 1\n",
    "        y[i, char_indices_dict[next_chars[i]]] = 1\n",
    "\n",
    "    return x, y, sequences, indices_char_dict, char_indices_dict, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_length: number of characters in each sequence\n",
    "#step: gets every [step] sequence  \n",
    "\n",
    "seq_length=40\n",
    "step=5    \n",
    "filename=\"shakespeare.txt\"\n",
    "# puts all data into text string  \n",
    "file = open(filename, \"r\")\n",
    "text = \"\"\n",
    "for line in file:\n",
    "    line = line.lstrip(' ').rstrip(' ')\n",
    "    if line != '\\n' and not line[0].isdigit():\n",
    "        line.translate(str.maketrans('', '', string.punctuation))\n",
    "        text += line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37}\n"
     ]
    }
   ],
   "source": [
    "# make char to index and index to char dictionary \n",
    "characters = sorted(list(set(text)))\n",
    "char_indices_dict = dict((c, i) for i, c in enumerate(characters))\n",
    "indices_char_dict = dict((i, c) for i, c in enumerate(characters))\n",
    "print(char_indices_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fire took heat perpetual,\\ngrowing a bath and healthful remedy,\\nfor men discased, but i my mistress' thrall,\\ncame there for cure and this by that i prove,\\nlove's fire heats water, water cools not love.\"\n"
     ]
    }
   ],
   "source": [
    "# makes every [step] char sequences of length seq_length and their outputs\n",
    "sequences = []\n",
    "next_chars = [] # next char that seq in sequences generates\n",
    "print(repr(text[len(text) - 200:]))\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    sequences.append(text[i : i + seq_length])\n",
    "    next_chars.append(text[i + seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# put sequences and outputs into np array\n",
    "x = np.zeros((len(sequences), seq_length, len(characters)))\n",
    "y = np.zeros((len(sequences), len(characters)), dtype=np.bool)\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i, t, char_indices_dict[char]] = 1\n",
    "    y[i, char_indices_dict[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using rnn to build model\n",
    "def make_model(temperature=1.0):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(100))\n",
    "    # add temperature (controls variance)\n",
    "    model.add(Lambda(lambda x: x / temperature))\n",
    "    model.add(Dense(len(indices_char_dict), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    earlyStopping = EarlyStopping(monitor='loss', patience=3, verbose=1, mode='auto')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_7 (SimpleRNN)     (18727, 100)              13900     \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (18727, 100)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (18727, 38)               3838      \n",
      "=================================================================\n",
      "Total params: 17,738\n",
      "Trainable params: 17,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x, y, sequences, indices_char_dict, char_indices_dict, text = preprocess()\n",
    "model=make_model(0.2)\n",
    "model.build(x.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18727, 40, 38)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 19s 29ms/step - loss: 3.0394 - accuracy: 0.1954\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 17s 30ms/step - loss: 2.3190 - accuracy: 0.3335\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 2.1923 - accuracy: 0.3595\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 17s 30ms/step - loss: 2.1426 - accuracy: 0.3618\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 2.1284 - accuracy: 0.3644\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 2.0892 - accuracy: 0.3721\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 2.0713 - accuracy: 0.3767\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 17s 30ms/step - loss: 2.0547 - accuracy: 0.3854\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 2.0704 - accuracy: 0.3764\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 18s 31ms/step - loss: 2.0610 - accuracy: 0.3752\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 2.0522 - accuracy: 0.3847\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 2.0330 - accuracy: 0.3937\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 2.0253 - accuracy: 0.3926\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 2.0476 - accuracy: 0.3805\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 2.0220 - accuracy: 0.3889\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 2.0235 - accuracy: 0.3963\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 17s 30ms/step - loss: 2.0051 - accuracy: 0.4014\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 1.9886 - accuracy: 0.4004\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.9809 - accuracy: 0.4037\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 17s 28ms/step - loss: 1.9873 - accuracy: 0.4019\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 18s 30ms/step - loss: 1.9673 - accuracy: 0.4044\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.9718 - accuracy: 0.4028\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 16s 28ms/step - loss: 1.9572 - accuracy: 0.4124\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.9174 - accuracy: 0.4227\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.9431 - accuracy: 0.4043\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.9092 - accuracy: 0.4291\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.9009 - accuracy: 0.4228\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.9103 - accuracy: 0.4222\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 17s 28ms/step - loss: 1.8895 - accuracy: 0.4289\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.8702 - accuracy: 0.4322\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.8771 - accuracy: 0.4340\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.8434 - accuracy: 0.4442\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 17s 30ms/step - loss: 1.8403 - accuracy: 0.4424\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 17s 28ms/step - loss: 1.8350 - accuracy: 0.4464\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.8209 - accuracy: 0.4481\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 18s 31ms/step - loss: 1.7927 - accuracy: 0.4562\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 17s 30ms/step - loss: 1.7848 - accuracy: 0.4549\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.7838 - accuracy: 0.4606\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 16s 28ms/step - loss: 1.7553 - accuracy: 0.4625\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 17s 30ms/step - loss: 1.7464 - accuracy: 0.4674\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 17s 28ms/step - loss: 1.7302 - accuracy: 0.4736\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.7146 - accuracy: 0.4731\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.7056 - accuracy: 0.4823\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 16s 27ms/step - loss: 1.6852 - accuracy: 0.4836\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.6834 - accuracy: 0.4880\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.6725 - accuracy: 0.4830\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 17s 29ms/step - loss: 1.6504 - accuracy: 0.4897\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 16s 28ms/step - loss: 1.6442 - accuracy: 0.4981\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 17s 28ms/step - loss: 1.6185 - accuracy: 0.5034\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 16s 28ms/step - loss: 1.6204 - accuracy: 0.5060\n"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, epochs=50, verbose=1, callbacks=[earlyStopping])\n",
    "model.save('rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sonnet():\n",
    "    x, y, sequences, indices_char_dict, char_indices_dict, text = preprocess()\n",
    "\n",
    "    model = load_model('rnn.h5')\n",
    "    sonnet = []\n",
    "\n",
    "\n",
    "    seq = \"shall i compare thee to a summer's day?\\n\"\n",
    "    sonnet.append(seq)\n",
    "    for _ in range(13):\n",
    "        line = \"\"\n",
    "        for i in range(40):\n",
    "            x = np.zeros((1, len(seq), len(indices_char_dict)))\n",
    "            for t, index in enumerate(seq):\n",
    "                x[0, t, char_indices_dict[index]] = 1.\n",
    "\n",
    "            prediction = model.predict(x, verbose=0)[0]\n",
    "            index = np.argmax(prediction)\n",
    "            char = indices_char_dict[index]\n",
    "            line += char\n",
    "            seq = seq[1:] + char\n",
    "\n",
    "        sonnet.append(line)\n",
    "    return sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "\n",
      "whing and the sunder sweet is in heresse\n",
      ",\n",
      "and them fores as poong asthough as wo\n",
      "ll.\n",
      "the sunder it deme dind on hath sene\n",
      " thee,\n",
      "as as whel bear beare the sued al\n",
      "l abe ther faire,\n",
      "and beauty sall the fr\n",
      "emedin the sheme,\n",
      "and the thee for the a\n",
      "re as but tome,\n",
      "and the thee for the are\n",
      " as but to hand allest to buldear byend,\n",
      "\n",
      "and all the the arof the sweet be all a\n",
      "s but the,\n",
      "and there ain the mane thee f\n",
      "airt i ain thee,\n",
      "where bet a din the wit\n",
      "h the hored and have with hemesere,\n",
      "and \n",
      "there ain the mand are my hath abe thee,\n"
     ]
    }
   ],
   "source": [
    "sonnet=generate_sonnet()\n",
    "\n",
    "for line in sonnet:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "772508630a427619dd49b8cfe9c2ae7d9dbaeae5c7cd5fb2ab9db30424e7636a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('python36': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
