{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data from preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"train_scale.csv\")\n",
    "x_train.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "\n",
    "x_test = pd.read_csv(\"test_scale.csv\")\n",
    "x_test.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "\n",
    "y_train = pd.read_csv(\"train.csv\")['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 275)\n",
      "(307511,)\n",
      "0    282686\n",
      "1     24825\n",
      "Name: TARGET, dtype: int64\n",
      "(48744, 275)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train.value_counts())\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we found that the class is heavily skewed, we take both desample and oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### desample\n",
    "import random\n",
    "\n",
    "desample_cnt = 25000\n",
    "y_train[y_train == [0]]\n",
    "desample_index = random.sample(y_train[y_train == [0]].index.tolist(), desample_cnt)\n",
    "\n",
    "negative_index = y_train[y_train == [1]].index.tolist()\n",
    "\n",
    "desample_y_train = y_train[negative_index + desample_index]\n",
    "desample_x_train = x_train.iloc[negative_index + desample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25000\n",
       "1    24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desample_y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### oversample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smo = SMOTE(sampling_strategy=1,random_state=42)\n",
    "X_smo, y_smo = smo.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    282686\n",
       "0    282686\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smo.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale each feature to 0-1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "scaler.fit(x_test)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_train)\n",
    "x_test  = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.7053101374740215\n",
      "AUC for train:0.7216436322279355\n",
      "-----\n",
      "accuracy for test:0.9194307864408543\n",
      "accuracy for train:0.9192916885267937\n",
      "-----\n",
      "F1 for test:0.02395209580838323\n",
      "F1 for train:0.023604699958036095\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr = LogisticRegression(random_state=0, n_jobs=-1, penalty = 'l2')\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "pred = lr.predict(X_valid)\n",
    "pred2 = lr.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.6851585676384504\n",
      "AUC for train:0.6842624735636281\n",
      "-----\n",
      "accuracy for test:0.6851569398731637\n",
      "accuracy for train:0.6842485549132948\n",
      "-----\n",
      "F1 for test:0.6826347305389222\n",
      "F1 for train:0.6814438834741758\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr = LogisticRegression(random_state=0, n_jobs=-1, penalty = 'l2')\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(desample_x_train, desample_y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "pred = lr.predict(X_valid)\n",
    "pred2 = lr.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.708298608381162\n",
      "AUC for train:0.7104024900875925\n",
      "-----\n",
      "accuracy for test:0.7081284534784178\n",
      "accuracy for train:0.710243874829316\n",
      "-----\n",
      "F1 for test:0.7121987972820248\n",
      "F1 for train:0.7141816963693758\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr = LogisticRegression(random_state=0, n_jobs=-1, penalty = 'l2')\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_smo, y_smo, test_size = 0.25, random_state = 42)\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "pred = lr.predict(X_valid)\n",
    "pred2 = lr.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold is used for hyperparameters selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments 1: n_estimator = 10, lr = 0.01, mean AUC for kfold = 0.656650809802559, all AUCs are:\n",
      "  [0.6628165493523377, 0.6509760736753093, 0.6594849922527997, 0.6523161657405729, 0.657660267991775]\n",
      "Experiments 2: n_estimator = 10, lr = 0.05, mean AUC for kfold = 0.6599237731157599, all AUCs are:\n",
      "  [0.6621228884777692, 0.659179851091184, 0.6532554658332459, 0.6623362703374074, 0.662724389839193]\n",
      "Experiments 3: n_estimator = 10, lr = 0.1, mean AUC for kfold = 0.6657619712509179, all AUCs are:\n",
      "  [0.6728343302441296, 0.6652958989121088, 0.6708674170637635, 0.6559672437613224, 0.6638449662732647]\n",
      "Experiments 4: n_estimator = 25, lr = 0.01, mean AUC for kfold = 0.6578701540072116, all AUCs are:\n",
      "  [0.663426333199776, 0.6493989185124358, 0.6588661624659075, 0.6569903440327567, 0.6606690118251819]\n",
      "Experiments 5: n_estimator = 25, lr = 0.05, mean AUC for kfold = 0.6691756412938114, all AUCs are:\n",
      "  [0.6713330143798362, 0.6696847391396371, 0.6661615588767488, 0.6733086664010302, 0.6653902276718042]\n",
      "Experiments 6: n_estimator = 25, lr = 0.1, mean AUC for kfold = 0.6744983422313027, all AUCs are:\n",
      "  [0.6689810523940393, 0.6738778164768792, 0.6781746785591484, 0.6711561559782661, 0.6803020077481803]\n",
      "Experiments 7: n_estimator = 50, lr = 0.01, mean AUC for kfold = 0.6600387363229212, all AUCs are:\n",
      "  [0.662296520265511, 0.6566809273582225, 0.6618239700680161, 0.6623158956202794, 0.6570763683025773]\n",
      "Experiments 8: n_estimator = 50, lr = 0.05, mean AUC for kfold = 0.6758252988622029, all AUCs are:\n",
      "  [0.675992928560966, 0.6797434094432719, 0.677572201711612, 0.6748623964594838, 0.6709555581356805]\n",
      "Experiments 9: n_estimator = 50, lr = 0.1, mean AUC for kfold = 0.6819363245761874, all AUCs are:\n",
      "  [0.6794093477144325, 0.6799034728316516, 0.6855035224971829, 0.6892004763504543, 0.6756648034872159]\n",
      "Experiments 10: n_estimator = 100, lr = 0.01, mean AUC for kfold = 0.6647802805968032, all AUCs are:\n",
      "  [0.6635750592753993, 0.665822584167297, 0.6640357343679281, 0.6682191347895909, 0.6622488903838009]\n",
      "Experiments 11: n_estimator = 100, lr = 0.05, mean AUC for kfold = 0.6825042885751683, all AUCs are:\n",
      "  [0.6794558959537152, 0.677215409372139, 0.6919881330980966, 0.681634796654958, 0.6822272077969328]\n",
      "Experiments 12: n_estimator = 100, lr = 0.1, mean AUC for kfold = 0.6868560567822949, all AUCs are:\n",
      "  [0.6869798426420877, 0.6850552461146421, 0.6839254445619868, 0.6901145645873605, 0.6882051860053973]\n"
     ]
    }
   ],
   "source": [
    "# sklearn version\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "n_estimators = [15,25,50]\n",
    "learning_rate = [ 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "group_cnt = len(n_estimators) * len(learning_rate) \n",
    "results = []\n",
    "index = 0\n",
    "for n in n_estimators:\n",
    "    for lr in learning_rate:\n",
    "        index += 1\n",
    "        gbm = GradientBoostingClassifier(n_estimators=n, learning_rate = lr, random_state=42, max_depth=5)\n",
    "        AUC = []\n",
    "        for train_index, test_index in kf.split(desample_x_train):     ### 获得 train 的 index    ### 获得 test  的 index\n",
    "            X_train, X_valid = desample_x_train.iloc[train_index], desample_x_train.iloc[test_index]\n",
    "            Y_train, Y_valid = desample_y_train.iloc[train_index], desample_y_train.iloc[test_index]\n",
    "            gbm.fit(X_train,Y_train)\n",
    "    \n",
    "            AUC.append(roc_auc_score(gbm.predict(X_valid),Y_valid))\n",
    "        \n",
    "        print(\"Experiments {}: n_estimator = {}, lr = {}, mean AUC for kfold = {}, all AUCs are:\\n\".format(index,n, lr, sum(AUC) / len(AUC)), end=\"  \")\n",
    "        print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can learn that     \n",
    "n_estimator : 100 > 50 > 25 > 10  ； lr: 0.1 > 0.05 > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments 1: n_estimator = 100, lr = 0.1, mean AUC for kfold = 0.6899266388205039, all AUCs are:\n",
      "  [0.6883032494232421, 0.6915643572335154, 0.6912852993427447, 0.6895777266868184, 0.6889025614161988]\n",
      "Experiments 2: n_estimator = 100, lr = 0.2, mean AUC for kfold = 0.6856045973162752, all AUCs are:\n",
      "  [0.6873897647552081, 0.6821767315107506, 0.6863681256645642, 0.6823245393200594, 0.6897638253307942]\n",
      "Experiments 3: n_estimator = 100, lr = 0.5, mean AUC for kfold = 0.6706089869574089, all AUCs are:\n",
      "  [0.6608148685711965, 0.6719504711605833, 0.6773656761386447, 0.6704461778911031, 0.672467741025517]\n",
      "Experiments 4: n_estimator = 125, lr = 0.1, mean AUC for kfold = 0.6902442082918798, all AUCs are:\n",
      "  [0.6941392578926681, 0.6820064964149402, 0.6877022460080249, 0.6976600314021725, 0.6897130097415939]\n",
      "Experiments 5: n_estimator = 125, lr = 0.2, mean AUC for kfold = 0.6875068675370389, all AUCs are:\n",
      "  [0.6903293088883414, 0.6800997034493321, 0.6884387068051666, 0.686036037088477, 0.6926305814538773]\n",
      "Experiments 6: n_estimator = 125, lr = 0.5, mean AUC for kfold = 0.6671509691840329, all AUCs are:\n",
      "  [0.6628139696478385, 0.6649203218115894, 0.6713598735894835, 0.6668328617033061, 0.6698278191679475]\n",
      "Experiments 7: n_estimator = 150, lr = 0.1, mean AUC for kfold = 0.6910039714169722, all AUCs are:\n",
      "  [0.6894393337069592, 0.6890051765464178, 0.6924467915833318, 0.6853014583276914, 0.6988270969204616]\n",
      "Experiments 8: n_estimator = 150, lr = 0.2, mean AUC for kfold = 0.6860192539165073, all AUCs are:\n",
      "  [0.6863172690889247, 0.6847904767475135, 0.6813406233308932, 0.689237628561631, 0.6884102718535738]\n",
      "Experiments 9: n_estimator = 150, lr = 0.5, mean AUC for kfold = 0.6659292433218826, all AUCs are:\n",
      "  [0.6629793620257244, 0.6672301759705556, 0.6620163389196897, 0.6672721952691056, 0.6701481444243386]\n"
     ]
    }
   ],
   "source": [
    "# sklearn version\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "n_estimators = [100, 125, 150]\n",
    "learning_rate = [ 0.1, 0.2, 0.5]\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "group_cnt = len(n_estimators) * len(learning_rate) \n",
    "results = []\n",
    "index = 0\n",
    "for n in n_estimators:\n",
    "    for lr in learning_rate:\n",
    "        index += 1\n",
    "        gbm = GradientBoostingClassifier(n_estimators=n, learning_rate = lr, random_state=42, max_depth=5)\n",
    "        AUC = []\n",
    "        for train_index, test_index in kf.split(desample_x_train):     ### 获得 train 的 index    ### 获得 test  的 index\n",
    "            X_train, X_valid = desample_x_train.iloc[train_index], desample_x_train.iloc[test_index]\n",
    "            Y_train, Y_valid = desample_y_train.iloc[train_index], desample_y_train.iloc[test_index]\n",
    "            gbm.fit(X_train,Y_train)\n",
    "    \n",
    "            AUC.append(roc_auc_score(gbm.predict(X_valid),Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments 1: n_estimator = 100, lr = 0.1, mean AUC for kfold = 0.6903831771509621, all AUCs are:\n",
      "  [0.6898373880215225, 0.6890156741700985, 0.6823933201795314, 0.7000498765292058, 0.6906196268544527]\n",
      "Experiments 2: n_estimator = 100, lr = 0.15, mean AUC for kfold = 0.6897723596129024, all AUCs are:\n",
      "  [0.6919766700927956, 0.6873844359669512, 0.6849672426667629, 0.6976230835226116, 0.6869103658153906]\n",
      "Experiments 3: n_estimator = 125, lr = 0.1, mean AUC for kfold = 0.6874916010961658, all AUCs are:\n",
      "  [0.6909980694971362, 0.6878880259755474, 0.6881691355330248, 0.6798934867874352, 0.6905092876876854]\n",
      "Experiments 4: n_estimator = 125, lr = 0.15, mean AUC for kfold = 0.6884227824827844, all AUCs are:\n",
      "  [0.6872919305996066, 0.6862654089857226, 0.6887569597453839, 0.6860724385841579, 0.6937271744990514]\n",
      "Experiments 5: n_estimator = 150, lr = 0.1, mean AUC for kfold = 0.6891550538361396, all AUCs are:\n",
      "  [0.6895976116849247, 0.6850358961363584, 0.6932158087122806, 0.6847991063300041, 0.69312684631713]\n",
      "Experiments 6: n_estimator = 150, lr = 0.15, mean AUC for kfold = 0.6908113115697839, all AUCs are:\n",
      "  [0.6922107032782292, 0.6911079055072741, 0.6916990220916345, 0.6877042934892159, 0.6913346334825653]\n",
      "Experiments 7: n_estimator = 175, lr = 0.1, mean AUC for kfold = 0.6900822382274018, all AUCs are:\n",
      "  [0.6948089488784008, 0.685722947385384, 0.6881024202390706, 0.6891420150903289, 0.6926348595438246]\n",
      "Experiments 8: n_estimator = 175, lr = 0.15, mean AUC for kfold = 0.690178092696842, all AUCs are:\n",
      "  [0.6862799559976003, 0.6879832523289663, 0.6869744810906881, 0.7015049082562856, 0.6881478658106694]\n",
      "Experiments 9: n_estimator = 200, lr = 0.1, mean AUC for kfold = 0.6898616470241166, all AUCs are:\n",
      "  [0.699245429750925, 0.6905629196177715, 0.6844230463218662, 0.6898321948095821, 0.685244644620438]\n",
      "Experiments 10: n_estimator = 200, lr = 0.15, mean AUC for kfold = 0.690490730742517, all AUCs are:\n",
      "  [0.6861086586333889, 0.6952525375398215, 0.6935792836839572, 0.6903159451437286, 0.687197228711689]\n",
      "Experiments 11: n_estimator = 225, lr = 0.1, mean AUC for kfold = 0.6911867494322126, all AUCs are:\n",
      "  [0.6935244092592588, 0.6905147190512725, 0.6920862601440071, 0.6890990030547144, 0.6907093556518099]\n",
      "Experiments 12: n_estimator = 225, lr = 0.15, mean AUC for kfold = 0.6872868513916818, all AUCs are:\n",
      "  [0.6839794445075097, 0.6898085915564692, 0.689750905159988, 0.6884029195541924, 0.6844923961802495]\n",
      "Experiments 13: n_estimator = 250, lr = 0.1, mean AUC for kfold = 0.6906759333389444, all AUCs are:\n",
      "  [0.6944445876961536, 0.6901527071039183, 0.6907247401349939, 0.6873288404975338, 0.690728791262123]\n",
      "Experiments 14: n_estimator = 250, lr = 0.15, mean AUC for kfold = 0.6893041396892958, all AUCs are:\n",
      "  [0.6922126679582565, 0.6884696547149248, 0.6879061596080372, 0.6863941888763425, 0.691538027288918]\n"
     ]
    }
   ],
   "source": [
    "# sklearn version\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "n_estimators = [100, 125, 150, 175,200, 225, 250]\n",
    "learning_rate = [ 0.1, 0.15]\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "group_cnt = len(n_estimators) * len(learning_rate) \n",
    "results = []\n",
    "index = 0\n",
    "for n in n_estimators:\n",
    "    for lr in learning_rate:\n",
    "        index += 1\n",
    "        gbm = GradientBoostingClassifier(n_estimators=n, learning_rate = lr, random_state=42, max_depth=5)\n",
    "        AUC = []\n",
    "        for train_index, test_index in kf.split(desample_x_train):     ### 获得 train 的 index    ### 获得 test  的 index\n",
    "            X_train, X_valid = desample_x_train.iloc[train_index], desample_x_train.iloc[test_index]\n",
    "            Y_train, Y_valid = desample_y_train.iloc[train_index], desample_y_train.iloc[test_index]\n",
    "            gbm.fit(X_train,Y_train)\n",
    "    \n",
    "            AUC.append(roc_auc_score(gbm.predict(X_valid),Y_valid))\n",
    "        \n",
    "        print(\"Experiments {}: n_estimator = {}, lr = {}, mean AUC for kfold = {}, all AUCs are:\\n\".format(index,n, lr, sum(AUC) / len(AUC)), end=\"  \")\n",
    "        print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally we confirm the hyperparaters:       \n",
    "n_estimator = 100, lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after determining hyperparameter, we apply it to different sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.723511042958193\n",
      "AUC for train:0.8823032018715535\n",
      "-----\n",
      "accuracy for test:0.9196389084003226\n",
      "accuracy for train:0.9216417425086609\n",
      "-----\n",
      "F1 for test:0.040683229813664595\n",
      "F1 for train:0.07103937493574586\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1, random_state=42, max_depth=5)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "gbm.fit(X_train,Y_train)\n",
    "pred = gbm.predict(X_valid)\n",
    "pred2 = gbm.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.6921661737575615\n",
      "AUC for train:0.7316151976676741\n",
      "-----\n",
      "accuracy for test:0.6921409649193224\n",
      "accuracy for train:0.7316152858060373\n",
      "-----\n",
      "F1 for test:0.6926344473831851\n",
      "F1 for train:0.7311620426216324\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1, random_state=42, max_depth=5)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(desample_x_train, desample_y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "gbm.fit(X_train,Y_train)\n",
    "pred = gbm.predict(X_valid)\n",
    "pred2 = gbm.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.956194270802831\n",
      "AUC for train:0.9563357907505107\n",
      "-----\n",
      "accuracy for test:0.9524631570010542\n",
      "accuracy for train:0.952614090074028\n",
      "-----\n",
      "F1 for test:0.9502063926128489\n",
      "F1 for train:0.9503750336505332\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1, random_state=42, max_depth=5)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_smo, y_smo, test_size = 0.25, random_state = 42)\n",
    "\n",
    "gbm.fit(X_train,Y_train)\n",
    "pred = gbm.predict(X_valid)\n",
    "pred2 = gbm.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments 1: n_estimator = 100, criterion = gini, mean AUC for kfold = 0.688294676154255, all AUCs are:\n",
      "  [0.6878509546563139, 0.6873880547874367, 0.6920201004231529, 0.6856053199582706, 0.6886089509461006]\n",
      "Experiments 2: n_estimator = 100, criterion = entropy, mean AUC for kfold = 0.6909257060819682, all AUCs are:\n",
      "  [0.6951235649546827, 0.6863428809319927, 0.690625656786026, 0.6880105263098502, 0.6945259014272891]\n",
      "Experiments 3: n_estimator = 125, criterion = gini, mean AUC for kfold = 0.6882427826141599, all AUCs are:\n",
      "  [0.6851728164339529, 0.6798688112039554, 0.6919211449609873, 0.6956134596067192, 0.6886376808651848]\n",
      "Experiments 4: n_estimator = 125, criterion = entropy, mean AUC for kfold = 0.6871917363587712, all AUCs are:\n",
      "  [0.687092411130871, 0.6864973862594805, 0.6858028591668407, 0.6871940518588526, 0.6893719733778111]\n",
      "Experiments 5: n_estimator = 150, criterion = gini, mean AUC for kfold = 0.6857633294214991, all AUCs are:\n",
      "  [0.6856925478348439, 0.6855082245988443, 0.6840988754487262, 0.6860071755718917, 0.6875098236531897]\n",
      "Experiments 6: n_estimator = 150, criterion = entropy, mean AUC for kfold = 0.6892685094274528, all AUCs are:\n",
      "  [0.6850793219450856, 0.6895504444891954, 0.6926552669537207, 0.6905657792341253, 0.6884917345151366]\n",
      "Experiments 7: n_estimator = 175, criterion = gini, mean AUC for kfold = 0.6877683710538449, all AUCs are:\n",
      "  [0.6881160029073959, 0.6861272045888953, 0.6833410395140931, 0.6921180089211056, 0.6891395993377348]\n",
      "Experiments 8: n_estimator = 175, criterion = entropy, mean AUC for kfold = 0.6866110354862519, all AUCs are:\n",
      "  [0.6877991458982748, 0.6895680400146418, 0.6784660973717886, 0.6884204150375707, 0.6888014791089834]\n",
      "Experiments 9: n_estimator = 200, criterion = gini, mean AUC for kfold = 0.6859619539428761, all AUCs are:\n",
      "  [0.6854883915205611, 0.6838749408340635, 0.6841528623020167, 0.6822651957879426, 0.6940283792697967]\n",
      "Experiments 10: n_estimator = 200, criterion = entropy, mean AUC for kfold = 0.6876869714427285, all AUCs are:\n",
      "  [0.6851756980061088, 0.6936064943121395, 0.6866779469825155, 0.6876839149721891, 0.6852908029406899]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "n_estimators = [100, 125, 150, 175,200]\n",
    "criterion = {\"gini\",\"entropy\"}\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "group_cnt = len(n_estimators) * len(criterion) \n",
    "results = []\n",
    "index = 0\n",
    "for n in n_estimators:\n",
    "    for c in criterion:\n",
    "        index += 1\n",
    "        rfc = RandomForestClassifier(n_estimators=n, criterion = c, random_state=42, n_jobs=-1)\n",
    "        AUC = []\n",
    "        for train_index, test_index in kf.split(desample_x_train):     ### 获得 train 的 index    ### 获得 test  的 index\n",
    "            X_train, X_valid = desample_x_train.iloc[train_index], desample_x_train.iloc[test_index]\n",
    "            Y_train, Y_valid = desample_y_train.iloc[train_index], desample_y_train.iloc[test_index]\n",
    "            gbm.fit(X_train,Y_train)\n",
    "    \n",
    "            AUC.append(roc_auc_score(gbm.predict(X_valid),Y_valid))\n",
    "        \n",
    "        print(\"Experiments {}: n_estimator = {}, criterion = {}, mean AUC for kfold = {}, all AUCs are:\\n\".format(index,n, c, sum(AUC) / len(AUC)), end=\"  \")\n",
    "        print(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimator= 50, max_depth=10, criterion = \"entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.9597468650814298\n",
      "AUC for train:0.9596861976399772\n",
      "-----\n",
      "accuracy for test:0.9194958245531881\n",
      "accuracy for train:0.9193870781718141\n",
      "-----\n",
      "F1 for test:0.0006458905215565962\n",
      "F1 for train:0.004497751124437781\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, criterion = \"entropy\", max_depth=10, max_features=20,random_state=42, n_jobs=-1)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "rfc.fit(X_train,Y_train)\n",
    "pred = rfc.predict(X_valid)\n",
    "pred2 = rfc.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.6788213256430664\n",
      "AUC for train:0.7356646248496366\n",
      "-----\n",
      "accuracy for test:0.6788151240266517\n",
      "accuracy for train:0.7356561764076215\n",
      "-----\n",
      "F1 for test:0.6785570820277979\n",
      "F1 for train:0.7356703237891355\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, criterion = \"entropy\", random_state=42, max_depth = 10,max_features=20,n_jobs=-1)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(desample_x_train, desample_y_train, test_size = 0.25, random_state = 42)\n",
    "\n",
    "rfc.fit(X_train,Y_train)\n",
    "pred = rfc.predict(X_valid)\n",
    "pred2 = rfc.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for test:0.9538392342836036\n",
      "AUC for train:0.9999528357505012\n",
      "-----\n",
      "accuracy for test:0.9512604090757943\n",
      "accuracy for train:0.9999528334146957\n",
      "-----\n",
      "F1 for test:0.9493459606914655\n",
      "F1 for train:0.9999528333034612\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, criterion = \"entropy\", random_state=42,n_jobs=-1)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_smo, y_smo, test_size = 0.25, random_state = 42)\n",
    "\n",
    "rfc.fit(X_train,Y_train)\n",
    "pred = rfc.predict(X_valid)\n",
    "pred2 = rfc.predict(X_train)\n",
    "\n",
    "print(\"AUC for test:{}\".format(roc_auc_score(pred,Y_valid)))\n",
    "print(\"AUC for train:{}\".format(roc_auc_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"accuracy for test:{}\".format(accuracy_score(pred,Y_valid)))\n",
    "print(\"accuracy for train:{}\".format(accuracy_score(pred2,Y_train)))\n",
    "print(\"-----\")\n",
    "print(\"F1 for test:{}\".format(f1_score(pred,Y_valid)))\n",
    "print(\"F1 for train:{}\".format(f1_score(pred2,Y_train)))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results visulization for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([],columns=[\"model\",\"data\",\"f1-score\",\"AUC-score\"])\n",
    "results[\"model\"] = [\"logistic Regression\"] * 3 + [\"GBDT\"] * 3 + [\"Random Forest\"] * 3\n",
    "results[\"data\"] = ([\"Original\",\"desample\",\"overSample\"]  ) * 3\n",
    "results[\"f1-score\"] = [0.0339,0.6826,0.7121,   0.0506, 0.6926, 0.8502,    0.0125, 0.6785, 0.8493]\n",
    "results['AUC-score'] = [0.6053, 0.6851, 0.7082,  0.6235, 0.6921, 0.8561,   0.8597, 0.6788,  0.8538]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic Regression</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.6053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic Regression</td>\n",
       "      <td>desample</td>\n",
       "      <td>0.6826</td>\n",
       "      <td>0.6851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic Regression</td>\n",
       "      <td>overSample</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.7082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.6235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>desample</td>\n",
       "      <td>0.6926</td>\n",
       "      <td>0.6921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>overSample</td>\n",
       "      <td>0.8502</td>\n",
       "      <td>0.8561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Original</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.8597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>desample</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>0.6788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>overSample</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.8538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model        data  f1-score  AUC-score\n",
       "0  logistic Regression    Original    0.0339     0.6053\n",
       "1  logistic Regression    desample    0.6826     0.6851\n",
       "2  logistic Regression  overSample    0.7121     0.7082\n",
       "3                 GBDT    Original    0.0506     0.6235\n",
       "4                 GBDT    desample    0.6926     0.6921\n",
       "5                 GBDT  overSample    0.8502     0.8561\n",
       "6        Random Forest    Original    0.0125     0.8597\n",
       "7        Random Forest    desample    0.6785     0.6788\n",
       "8        Random Forest  overSample    0.8493     0.8538"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e787825898>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3de3gV5bn38e9NAEFARAliQST4opxJMJwxnF4RLYJCbUUqoiLSAnbjW5UerHTX12qlaikoG6lgd7XQirKpm6oFBYRiBSRyVhEBg24N4AEEioF7/zFDulhZJAHWJCTr97mudWUOz8zcWbPWuueZeeYZc3dERCR1VSnvAEREpHwpEYiIpDglAhGRFKdEICKS4pQIRERSXNXyDuBE1a9f35s2bVreYYiIVCirV6/e5e7pieZVuETQtGlTVq1aVd5hiIhUKGa2/XjzdGpIRCTFKRGIiKQ4JQIRkRRX4a4RJPL111+Tl5fHwYMHyzsUKSc1atSgcePGVKtWrbxDEalwKkUiyMvLo06dOjRt2hQzK+9wpIy5O7t37yYvL4+MjIzyDkekwqkUp4YOHjzIueeeqySQosyMc889VzVCkZNUKRIBoCSQ4rT/RU5epUkEIiJycpQIKqmmTZuya9euUy4jIpVfpbhYLCICsOPf25bLdofWO6tctrt83PKkrEc1gtPItm3baNGiBSNHjqRNmzYMGzaMhQsX0r17d5o3b86bb77Jnj17uOaaa2jXrh1dunRh7dq1AOzevZt+/fqRlZXF7bffTuyT5/7whz/QqVMnMjMzuf322zl8+HB5/YsichpSIjjNbNmyhR/84AesXbuWzZs38+yzz7Js2TImTZrEAw88wH333UdWVhZr167lgQceYPjw4QD8/Oc/p0ePHqxZs4aBAweyY8cOADZt2sScOXNYvnw5ubm5pKWl8cwzz5TnvygipxmdGjrNZGRk0LZtUL1t3bo1ffv2xcxo27Yt27ZtY/v27cydOxeAPn36sHv3br744guWLl3K888/D8A3v/lN6tWrB8CiRYtYvXo1HTt2BODAgQM0aNCgHP4zETldKRGcZs4444zC4SpVqhSOV6lShYKCAqpWLbrLjjadTNSE0t256aab+OUvfxlRxCJS0enUUAWTk5NTeGpn8eLF1K9fn7POOuuY6X/961/57LPPAOjbty/PPfccn376KQB79uxh+/bj9kYrIilINYIKZuLEidx88820a9eOM888k6effhqA++67j6FDh9KhQwd69uxJkyZNAGjVqhX3338//fr148iRI1SrVo2pU6dy4YUXlue/ISKnEYttXVIRZGdne/yDaTZt2kTLli3LKSI5XehzIGo+enxmttrdsxPN06khEZEUF2kiMLP+ZvaOmW0xswkJ5tc1s7+Y2dtmtsHMbo4yHhERKSqyRGBmacBU4EqgFTDUzFrFFRsDbHT39kAv4NdmVj2qmEREpKgoawSdgC3uvtXdDwGzgUFxZRyoY0G7x9rAHqAgwphERCROlImgEfBhzHheOC3WFKAl8BGwDviBux+JX5GZjTKzVWa2Kj8/P6p4RURSUpSJIFEH8fFNlK4AcoFvAJnAFDMrcvnd3ae7e7a7Z6enpyc/UhGRFBblfQR5wAUx440Jjvxj3Qw86EEb1i1m9gHQAnjzVDZ86V2/P5XFi1j98PASy9SuXZt9+/ad1PpHjhzJnXfeSatW8ZdQArNmzaJfv3584xvfKFX5WIsXL2bQoEE0a9aMAwcOMGDAACZNmnRScUbhqquu4tlnn+Xss88u71BEUlaUNYKVQHMzywgvAF8PzI8rswPoC2Bm5wGXAFsjjOm0NGPGjGJ/1GfNmsVHH31U6vLxLrvsMtasWcOaNWt48cUXWb781LuuLShIzqWcBQsWKAmIlLPIEoG7FwBjgZeBTcCf3H2DmY02s9FhsV8A3cxsHbAIuMfdK/STUtydu+66izZt2tC2bVvmzJkDwJEjR/j+979P69atGTBgAFdddRXPPfccAL169WLVqlUcPnyYESNGFC776KOP8txzz7Fq1SqGDRtGZmYmBw4cKCwP8NJLL9GhQwfat29P3759i42tZs2aZGZmsnPnTgBeeeUVunbtSocOHbjuuusKazQLFiygRYsW9OjRgzvuuIMBAwYAwV3No0aNol+/fgwfPpz8/HyGDBlCx44d6dixY2GCWbJkCZmZmWRmZpKVlcXevXv5+OOPycnJITMzkzZt2vD6668Dxz4c55FHHqFNmza0adOGxx57DAi65m7ZsiW33XYbrVu3pl+/fhw4cCBp+0tEIu5iwt0XAAvipk2LGf4I6BdlDGXt+eefJzc3l7fffptdu3bRsWNHcnJyWL58Odu2bWPdunV8+umntGzZkltuueWYZXNzc9m5cyfr168H4PPPP+fss89mypQpTJo0iezsY28KzM/P57bbbmPp0qVkZGSwZ8+eYmP77LPPeO+998jJyWHXrl3cf//9LFy4kFq1avHQQw/xyCOPcPfdd3P77bcXrnPo0KHHrGP16tUsW7aMmjVrcsMNNzB+/Hh69OjBjh07uOKKK9i0aROTJk1i6tSpdO/enX379lGjRg2mT5/OFVdcwU9+8hMOHz7M/v37i6x35syZ/OMf/8Dd6dy5Mz179qRevXq89957/PGPf+TJJ5/k29/+NnPnzuW73/3uye4iEYmjO4uTbNmyZQwdOpS0tDTOO+88evbsycqVK1m2bBnXXXcdVapUoWHDhvTu3bvIss2aNWPr1q2MGzeOl156ibPOKv629TfeeIOcnBwyMjIAOOeccxKWe/3112nXrh0NGzZkwIABNGzYkDfeeIONGzfSvXt3MjMzefrpp9m+fTubN2+mWbNmheuMTwQDBw6kZs2aACxcuJCxY8eSmZnJwIED+fLLL9m7dy/du3fnzjvvZPLkyXz++edUrVqVjh07MnPmTCZOnMi6deuoU6dOkfft2muvpVatWtSuXZvBgwcX1hoyMjLIzMwE4NJLL2Xbtm0l7AURORFKBEl2vL6bStOnU7169Xj77bfp1asXU6dOZeTIkSVuK1HX0/Euu+wy1q5dy7p163jiiSfIzc3F3bn88svJzc0lNzeXjRs38rvf/a7EOGvVqlU4fOTIEVasWFG4jp07d1KnTh0mTJjAjBkzOHDgAF26dGHz5s3k5OSwdOlSGjVqxI033sjvf3/sBf3ithvbNXdaWlrSrk+ISECJIMlycnKYM2cOhw8fJj8/n6VLl9KpUyd69OjB3LlzOXLkCJ988gmLFy8usuyuXbs4cuQIQ4YM4Re/+AVvvfUWAHXq1GHv3r1Fynft2pUlS5bwwQcfAJR4aujiiy/mRz/6EQ899BBdunRh+fLlbNmyBYD9+/fz7rvv0qJFC7Zu3Vp41H30Gkci/fr1Y8qUKYXjubm5ALz//vu0bduWe+65h+zsbDZv3sz27dtp0KABt912G7feemvh/xb7vs2bN4/9+/fz1Vdf8cILL3DZZZcV+/+ISHJUym6oS9PcMyrXXnstK1asoH379pgZv/rVr2jYsCFDhgxh0aJFtGnThosvvpjOnTtTt27dY5bduXMnN998M0eOBPfUHX2YzIgRIxg9ejQ1a9ZkxYoVheXT09OZPn06gwcP5siRIzRo0IC//e1vxcY3evRoJk2axL59+5g1axZDhw7ln//8JwD3338/F198MY8//jj9+/enfv36dOrU6bjrmjx5MmPGjKFdu3YUFBSQk5PDtGnTeOyxx3jttddIS0ujVatWXHnllcyePZuHH36YatWqUbt27SI1gg4dOjBixIjC7Y0cOZKsrCydBhIpA+qGugzt27eP2rVrs3v3bjp16sTy5ctp2LBheYdVxNE43Z0xY8bQvHlzxo8fX95hlaiifA4kOuqG+viK64a6UtYITlcDBgzg888/59ChQ9x7772nZRIAePLJJ3n66ac5dOgQWVlZ3H777eUdkohESImgDCW6LnA6Gj9+fIWoAYhIcuhisYhIilMiEBFJcUoEIiIpTolARCTFVcqLxcluQtbkZ+tKVe6TTz5h/PjxvPHGG9SrV4/q1atz9913U69ePQYNGkRGRkZhe/9nn32WBg0aMGvWLO666y4aN27Mvn37aNasGffddx/dunVjzJgxLF++nEOHDvHBBx9wySWXAPDTn/6Ub33rW0n9H0UkdalGkCTuzjXXXENOTg5bt25l9erVzJ49m7y8PCDo5iE3N5e1a9fSsWNHpk6dWrjsd77zHdasWcN7773HhAkTGDx4MJs2bWLq1Knk5uayYMECLrroosKuHJQERCSZlAiS5NVXX6V69eqMHj26cNqFF17IuHHjjinn7uzdu5d69eolXE/v3r0ZNWoU06dPjzReEZGjlAiSZMOGDXTo0OG4819//XUyMzNp0qQJCxcuLNIFdawOHTqwefPmKMIUESki0msEZtYf+A2QBsxw9wfj5t8FDIuJpSWQ7u7F955WAYwZM4Zly5ZRvXp1Hn74YS677DJefPFFAB566CHuvvtupk2blnDZitbth0giyX5kbGm8UKfkMlJUZDUCM0sDpgJXAq2AoWZ2zPMV3f1hd89090zgR8CSipoEWrdufUyPmlOnTmXRokXk5+cXKTtw4ECWLl163HWtWbNGfeaISJmJ8tRQJ2CLu29190PAbGBQMeWHAn+MMJ5I9enTh4MHD/LEE08UTot/CtdRy5Yt46KLLko4b8mSJUyfPp3bbrstkjhFROJFeWqoEfBhzHge0DlRQTM7E+hP8IzjRPNHAaMAmjRpUuKGS9vcM5nMjHnz5jF+/Hh+9atfkZ6eXvgISPjXNQJ3p27dusyYMaNw2Tlz5rBs2TL2799PRkYGc+fOVY1ARMpMlIkg0aOzjnfy+2pg+fFOC7n7dGA6BN1QJye85Dv//POZPXt2wnlffPFFwukjRoxgxIgRxa63adOmhc8xFhFJtigTQR5wQcx4Y+Cj45S9ngp8Wkgql/Lo0748arEiR0V5jWAl0NzMMsysOsGP/fz4QmZWF+gJ/FeEsYiIyHFEViNw9wIzGwu8TNB89Cl332Bmo8P5R9tOXgu84u5fRRWLiIgcX6T3Ebj7AmBB3LRpceOzgFlRxiEV08YPd51Q+f/5bB/fTULbdbVFl1RTKTudE6louv+2e7ls90SeeSuVl7qYEBFJcZWyRpDso6vSHDWlpaXRtm1bCgoKyMjI4D//8z85++yzT3nbs2bNYtWqVUyZMuWU1xWrV69efPzxx9SsWROIrmvrbdu28fe//50bbrgh6esWkeRQjSBJatasSW5uLuvXr+ecc845ppvp09Uzzzxzwl1bFxQUnNA2tm3bxrPPPnsy4YlIGVEiiEDXrl3ZuXMnAG+++SbdunUjKyuLbt268c477wDBkf7gwYPp378/zZs35+677y5cfubMmVx88cX07NmT5cv/VRvZvn07ffv2pV27dvTt25cdO3YAwU1p3/ve9+jduzfNmjVjyZIl3HLLLbRs2bLEm9Vi7dmzh2uuuYZ27drRpUsX1q5dC8DEiRMZNWoU/fr1Y/jw4eTn5zNkyBA6duxIx44dC2NcsmQJmZmZZGZmkpWVxd69e5kwYULhXdWPPvroKb2vIhKNSnlqqDwdPnyYRYsWceuttwLQokULli5dStWqVVm4cCE//vGPmTt3LgC5ubmsWbOGM844g0suuYRx48ZRtWpV7rvvPlavXk3dunXp3bs3WVlZAIwdO5bhw4dz00038dRTT3HHHXcwb948AD777DNeffVV5s+fz9VXX83y5cuZMWMGHTt2JDc3l8zMzCKxDhs2rPDU0KJFi5g4cSJZWVnMmzePV199leHDh5ObmwvA6tWrWbZsGTVr1uSGG25g/Pjx9OjRgx07dnDFFVewadMmJk2axNSpU+nevTv79u2jRo0aPPjgg0yaNKmw51UROf0oESTJgQMHyMzMZNu2bVx66aVcfvnlQNC1xE033cR7772HmfH1118XLtO3b1/q1q0LQKtWrdi+fTu7du2iV69epKenA8HTy959910AVqxYwfPPPw/AjTfeeEwt4uqrr8bMaNu2Leeddx5t2wZ3x7Zu3Zpt27YlTATPPPMM2dnZhePLli0rTFJ9+vRh9+7dhV1jDBw4sDBpLFy4kI0bNxYu9+WXX7J37166d+/OnXfeybBhwxg8eDCNGzc+lbdURMqITg0lydFrBNu3b+fQoUOF1wjuvfdeevfuzfr16/nLX/7CwYMHC5c544wzCofT0tIKz7+bJeqmqajYckfXVaVKlWPWW6VKlVKf10/0HISj26hVq1bhtCNHjrBixYrC6ws7d+6kTp06TJgwgRkzZnDgwAG6dOmih+uIVBBKBElWt25dJk+ezKRJk/j666/54osvaNSoERBcFyhJ586dWbx4Mbt37+brr7/mz3/+c+G8bt26FXZq98wzz9CjR4+kxp6Tk8MzzzwDwOLFi6lfvz5nnXVWkXL9+vU7phXT0dNH77//Pm3btuWee+4hOzubzZs3U6dOHfbu3ZvUOEUkuSrlqaHyvkkmKyuL9u3bM3v2bO6++25uuukmHnnkEfr06VPisueffz4TJ06ka9eunH/++XTo0IHDhw8DMHnyZG655RYefvhh0tPTmTlzZlLjnjhxIjfffDPt2rXjzDPP5Omnn05YbvLkyYwZM4Z27dpRUFBATk4O06ZN47HHHuO1114jLS2NVq1aceWVV1KlShWqVq1K+/btGTFiBOPHj09qzCJy6qyiPRYxOzvbV61adcy0TZs2qf/+SuiEu5j48APuemHTKW/3hToPn/I6TtTQekVrXmUhyoOm8nlUZdnvO6gY+8/MVrt7dqJ5OjUkIpLilAhERFJcpUkEFe0UlySXu6OPgMjJqRSJoEaNGuzevVvJIEW5O4f27yXv84MlFxaRIiJtNWRm/YHfEDyYZoa7P5igTC/gMaAasMvde57odho3bkxeXh75+fmnGLGcTv7ns32lKucOeZ8fZOaKHRFHJFI5RZYIzCwNmApcTvD84pVmNt/dN8aUORt4HOjv7jvMrMHJbKtatWpkZGQkI2w5jSTjITMiUrIoTw11Ara4+1Z3PwTMBgbFlbkBeN7ddwC4+6cRxiMiIglEmQgaAR/GjOeF02JdDNQzs8VmttrMhkcYj4iIJBDlNYJEHebEX82tClwK9AVqAivM7A13f/eYFZmNAkYBNGnSJIJQRURSV5Q1gjzggpjxxsBHCcq85O5fufsuYCnQPn5F7j7d3bPdPftor5wiIpIcUSaClUBzM8sws+rA9cD8uDL/BVxmZlXN7EygM3DqfQSIiEipRXZqyN0LzGws8DJB89Gn3H2DmY0O509z901m9hKwFjhC0MR0fVQxiYhIUZHeR+DuC4AFcdOmxY0/DJRPT1EiIlI57iwWEZGTp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEQkxSkRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEQkxZWYCMzsPDP7nZn9NRxvZWa3Rh+aiIiUhdLUCGYRPGXsG+H4u8C/lWblZtbfzN4xsy1mNiHB/F5m9oWZ5Yavn5U2cBERSY7SJIL67v4ngkdJ4u4FwOGSFjKzNGAqcCXQChhqZq0SFH3d3TPD17+XPnQREUmG0iSCr8zsXMABzKwL8EUplusEbHH3re5+CJgNDDrpSEVEJBKlSQR3AvOBi8xsOfB7YFwplmsEfBgznhdOi9fVzN42s7+aWetEKzKzUWa2ysxW5efnl2LTIiJSWsU+vD48vdMzfF0CGPCOu39dinVbgmkeN/4WcKG77zOzq4B5QPMiC7lPB6YDZGdnx69DREROQbE1Anc/DAxy9wJ33+Du60uZBCCoAVwQM94Y+Chu/V+6+75weAFQzczqlz58ERE5VcXWCELLzWwKMAf46uhEd3+rhOVWAs3NLAPYCVwP3BBbwMwaAp+4u5tZJ4LEtPsE4hcRkVNUmkTQLfwb26LHgT7FLeTuBWY2lqDpaRrwlLtvMLPR4fxpwLeA75lZAXAAuN7ddepHRKQMlZgI3L33ya48PN2zIG7atJjhKcCUk12/iIicutLcWVzXzB452mrHzH5tZnXLIjgREYleaZqPPgXsBb4dvr4EZkYZlIiIlJ3SXCO4yN2HxIz/3MxyowpIRETKVmlqBAfMrMfRETPrTnBhV0REKoHS1Ai+Bzwdc13gM2BEZBGJiEiZKk2roVygvZmdFY5/GXlUIiJSZkrTaugBMzs7vAv4SzOrZ2b3l0VwIiISvdJcI7jS3T8/OuLunwFXRReSiIiUpdIkgjQzO+PoiJnVBM4opryIiFQgpblY/AdgkZnNJOha4hbg6UijEhGRMlOai8W/MrO1wP8l6Fr6F+7+cuSRiYhImSgxEZhZLeAVd3/JzC4BLjGzaifQHbWIiJzGSnONYClQw8waAQuBmwkeaC8iIpVAaRKBuft+YDDwW3e/luBh9CIiUgmUKhGYWVdgGPDf4bTSXGQWEZEKoDSJ4AfAj4AXwgfLNANeK83Kzay/mb1jZlvMbEIx5Tqa2WEz+1bpwhYRkWQpTauhpQTXCTCzhu6+FbijpOXCB99PBS4neH7xSjOb7+4bE5R7iOBJZiIiUsZKUyOItaDkIoU6AVvcfau7HwJmA4MSlBsHzAU+PcFYREQkCU40EdgJlG0EfBgznhdO+9fKgpZI1wLTKIaZjTr6hLT8/PwTCEFEREpyoongyRMomyhpxD+Y/jHgHnc/XNyK3H26u2e7e3Z6evoJhCAiIiU5odY/7v44gJnVdvd9JRTPAy6IGW8MfBRXJhuYbWYA9YGrzKzA3eedSFwiInLyTrYZ6EagSQllVgLNzSwD2AlcD9wQW8DdM44Om9ks4EUlARGRsnXcRGBmdx5vFlC7pBW7e4GZjSVoDZQGPBU2Px0dzi/2uoCIiJSN4moEDwAPAwUJ5pXq2oK7LyCupdHxEoC7jyjNOkVEJLmKSwRvAfPcfXX8DDMbGV1IIiJSloo7st8JbDezHySYlx1RPCIiUsaKSwStgFrALeFzis85+gLUBbWISCVR3Kmh/wBeApoBqzn2vgAPp4uISAV33BqBu09295YErX2auXtGzEtJQESkkiix9Y+7f68sAhERkfJxol1MiIhIJaNEICKS4pQIRERSnBKBiEiKUyIQEUlxSgQiIilOiUBEJMUpEYiIpDglAhGRFKdEICKS4iJNBGbW38zeMbMtZjYhwfxBZrbWzHLNbJWZ9YgyHhERKepkn1lcIjNLA6YClxM8yH6lmc13940xxRYB893dzawd8CegRVQxiYhIUVHWCDoBW9x9q7sfAmYDg2ILuPs+d/dwtBZB99YiIlKGokwEjYAPY8bzwmnHMLNrzWwz8N/ALYlWZGajwlNHq/Lz8yMJVkQkVUWZCCzBtCJH/O7+gru3AK4BfpFoRe4+3d2z3T07PT09yWGKiKS2KBNBHnBBzHhj4KPjFXb3pcBFZlY/wphERCROlIlgJdDczDLMrDpwPTA/toCZ/R8zs3C4A1Ad2B1hTCIiEieyVkPuXmBmY4GXgTSCR15uMLPR4fxpwBBguJl9DRwAvhNz8VhERMpAZIkAwN0XAAvipk2LGX4IeCjKGEREpHi6s1hEJMUpEYiIpDglAhGRFKdEICKS4pQIRERSnBKBiEiKUyIQEUlxSgQiIilOiUBEJMUpEYiIpDglAhGRFKdEICKS4pQIRERSnBKBiEiKUyIQEUlxkSYCM+tvZu+Y2RYzm5Bg/jAzWxu+/m5m7aOMR0REioosEZhZGjAVuBJoBQw1s1ZxxT4Aerp7O4IH10+PKh4REUksyhpBJ2CLu29190PAbGBQbAF3/7u7fxaOvkHwgHsRESlDUSaCRsCHMeN54bTjuRX4a6IZZjbKzFaZ2ar8/PwkhigiIlEmAkswLeGD6c2sN0EiuCfRfHef7u7Z7p6dnp6exBBFRCTKh9fnARfEjDcGPoovZGbtgBnAle6+O8J4REQkgShrBCuB5maWYWbVgeuB+bEFzKwJ8Dxwo7u/G2EsIiJyHJHVCNy9wMzGAi8DacBT7r7BzEaH86cBPwPOBR43M4ACd8+OKiYRESkqylNDuPsCYEHctGkxwyOBkVHGICIixdOdxSIiKU6JQEQkxSkRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEQkxSkRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIqLNBGYWX8ze8fMtpjZhATzW5jZCjP7p5n9MMpYREQkscgeTGNmacBU4HKC5xevNLP57r4xptge4A7gmqjiEBGR4kVZI+gEbHH3re5+CJgNDIot4O6fuvtK4OsI4xARkWJEmQgaAR/GjOeF006YmY0ys1Vmtio/Pz8pwYmISCDKRGAJpvnJrMjdp7t7trtnp6enn2JYIiISK8pEkAdcEDPeGPgowu2JiMhJiDIRrASam1mGmVUHrgfmR7g9ERE5CZG1GnL3AjMbC7wMpAFPufsGMxsdzp9mZg2BVcBZwBEz+zeglbt/GVVcIiJyrMgSAYC7LwAWxE2bFjP8PwSnjEREpJzozmIRkRSnRCAikuKUCEREUpwSgYhIilMiEBFJcUoEIiIpLtLmo6lqx7+3LZftNvnZunLZrohUbKoRiIikOCUCEZEUp0QgIpLilAhERFJcpb5YfOldvy+X7b5Qp1w2KyJyUlQjEBFJcUoEIiIpTolARCTFKRGIiKS4SC8Wm1l/4DcETyib4e4Pxs23cP5VwH5ghLu/FWVMlVn333Yvl+0uH7e8XLYrIskRWY3AzNKAqcCVQCtgqJm1iit2JdA8fI0CnogqHhERSSzKU0OdgC3uvtXdDwGzgUFxZQYBv/fAG8DZZnZ+hDGJiEicKE8NNQI+jBnPAzqXokwj4OPYQmY2iqDGALDPzN5JbqjJdeGpLV4f2JWUQMqI3WHlHUJSpdL+0747RoXad3DC+++4b0+UiSBRhH4SZXD36cD0ZAR1ujOzVe6eXd5xyMnR/qu4UnnfRXlqKA+4IGa8MfDRSZQREZEIRZkIVplNpIgAAAeXSURBVALNzSzDzKoD1wPz48rMB4ZboAvwhbt/HL8iERGJTmSnhty9wMzGAi8TNB99yt03mNnocP40YAFB09EtBM1Hb44qngokJU6BVWLafxVXyu47cy9ySl5ERFKI7iwWEUlxSgQiIilOiSBJzKyxmf2Xmb1nZu+b2W/Ci+Tx5b5hZs+VYn0LzOzsk4xlopn98GSWTTWn03tlZr3M7MXyjqMyM7NbzGydma01s/VmFn+Ta7K3N8vMvhXlNpJBiSAJwj6TngfmuXtz4GKgNvD/48pVdfeP3L3ED4a7X+Xun0cSsEiKCVsmNgF+AvRw93ZAF2Bt+UZ2elAiSI4+wEF3nwng7oeB8cAtZvZ9M/uzmf0FeMXMmprZegAzO9PM/hQencwxs3+YWXY4b5uZ1Q/LbzKzJ81sg5m9YmY1wzK3mdlKM3vbzOaa2Znl8+9XLGb2EzN7x8wWApeE0y4ys5fMbLWZvW5mLcLp14VHjm+b2dJwWtOwzFvhq1s4vZeZLQn36btm9qCZDTOzN8Oj0IvCcrPMbFq4jnfNbECCGGuZ2VPh/l0T9ZHr6cjM7gzf+/Vm9m9m9pCZfT9m/kQz+3/h8F3he7XWzH4eTjv63XkceAvIAPYC+wDcfZ+7fxCWTfhdCvfVE2b2mpltNbOe4X7ZZGazYmLZZ2a/Dj8Pi8wsPcH/c2n4+VhtZi/b6dSdjrvrdYov4A7g0QTT14Tz8oBzwmlNgfXh8A+B/wiH2wAFQHY4vo3glvem4fTMcPqfgO+Gw+fGbOt+YFw4PBH4YXm/L6fjC7gUWAecCZxF0HT5h8AioHlYpjPwaji8DmgUDp8d/j0TqBEONwdWhcO9gM+B84EzgJ3Az8N5PwAeC4dnAS8RHIg1Dz8fNcLlXwzLPBCzn88G3gVqlff7Vw77qRZB7XoDkAUsiSmzEWgC9CNo+mnhe/oikBN+d44AXcLyaQTN2XcAM4GrY9Z1vO/SLIJ+0oygb7QvgbbhdlbHfC8dGBYO/wyYErP8t4BqwN+B9HD6dwia1Jf7e+3ulfuZxWXISNA1Rsz0v7n7ngTzexB0w427rzez41VTP3D33HB4NcEHHKCNmd1P8ENRm+BDLsW7DHjB3fcDmNl8gh/hbsCfg7N8QPBDDrAcmGVmfyI4/QfBl3qKmWUChwlOBR610sObIs3sfeCVcPo6oHdMuT+5+xHgPTPbCrSIi7MfMDDm+kUNgh+9TSf1X1c8PQj201cAZvY8wb5rYGbfANKBz9x9h5ndQfB+rQmXrU2QYHcA2z3o0BJ3P2xB1/gdgb7Ao2Z2qbtPpPjv0l/c3c1sHfCJu68LY9pA8F3MJUg4c8Lyf+Bfn5WjLiE42Ptb+BlLI65PtfKkRJAcG4AhsRPM7CyC7jMOA18dZ7nS9hj1z5jhw0DNcHgWcI27v21mIwiOKKVk8Um7CvC5u2cWKeg+2sw6A98EcsMf/3HAJ0D7cNmDMYvE7qsjMeNHOPb7Fh9Don64hrj7ad3BYoSO9914juAIuyHBkfrRsr909/84ZgVmTYn77nlwOP4m8KaZ/Y2gZjCR4r9Lsfswfv8e7zc00f7c4O5dj1O+XOkaQXIsAs40s+FQ+CyGXxN8uPYXs9wy4NvhMq0Iqpwnog7wsZlVA4ad4LKpailwrZnVNLM6wNUE++gDM7sOCi8stg+HL3L3f7j7zwh6prwAqAt8HB7R30hwdHeirjOzKuF1g2ZA/A/+y8A4Cw8fzSzrJLZRkS0FrrHgOlot4FrgdYIf/+sJksHR1ncvE1yPqw1gZo3MrEH8Ci1osdchZlImsD0cPtXvUpUwJoAbCL7bsd4B0s2saxhLNTNrfRLbiYRqBEkQVhuvBR43s3sJPhQLgB8DQ4tZ9HHg6fCU0BqCFgxfnMCm7wX+QfBhXkfwYZZiuPtbZjaHoDq/neDHBYIv/xNm9lOCUz+zgbeBh82sOcER3aJw2uPA3DBxvMbxa3zFeQdYApwHjHb3gzGnpQB+ATwGrA2TwTagyEXlyircT7MIjt4heMLhGoAwge88egrO3V8xs5bAivA93Ad8l6D2HKsaMCk8tXQQyAdGh/NO9bv0FdDazFYTfIe/E/f/HLKgGelkM6tL8Nv7GMHZhHKnLibKUVhzqBb+CFxE8ENzsQcP8pFKKvyBe9HdS7yfRCoGM9vn7rXLO46TpRpB+ToTeC2sjhrwPSUBESlrqhGIiKQ4XSwWEUlxSgQiIilOiUBEJMUpEYicICuhx1Izuya8L0SkQlAiEEm+awAlAqkw1GpIpBTM7CfAcOBDghuRjt44NAqoTtB53Y0Ed6u+GM77gqDrkT7x5Y72dSRyOlAiECmBmV1K0F1IZ4J7b94CpgEz3X13WOZ+gg7Jfht/w5iZnZuoXJn/IyLHoRvKREqWqMdSKH3vr+olVk5rukYgUjqJqs6zgLHu3hb4OUFX0YmUtpxIuVAiEClZoh5L4fg9Vu7l2E7L1EusnNaUCERK4O5vETx0JBeYy796LD3aY+XfgM0xi8wG7rLgEZMXFVNO5LSgi8UiIilONQIRkRSnRCAikuKUCEREUpwSgYhIilMiEBFJcUoEIiIpTolARCTF/S9nheuzY4zo3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(x=\"data\", y=\"f1-score\",hue=\"model\",data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e787a36fd0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deXgUZbr+8e9DQMMmoEZlQCQuIHuAACoYAfcVwV2UTfEwo7gdUY4buDvCzDAeGDnIDzILDC6AiofRGRklwsAoS2QRVHYCDgICsh5I8vz+6CITQhICdKeT1P25Li66qt6qftLV3XfX9pa5OyIiEl6V4l2AiIjEl4JARCTkFAQiIiGnIBARCTkFgYhIyFWOdwFH69RTT/WGDRvGuwwRkXJl/vz5W9w9qbBp5S4IGjZsyLx58+JdhohIuWJma4uapl1DIiIhpyAQEQk5BYGISMiVu2MEhTlw4ABZWVns27cv3qVInCQmJlK/fn2qVKkS71JEyp0KEQRZWVnUrFmThg0bYmbxLkdKmbuzdetWsrKySE5Ojnc5IuVOhdg1tG/fPk455RSFQEiZGaeccoq2CEWOUYUIAkAhEHJa/yLHrsIEgYiIHBsFQQXVsGFDtmzZctxtRKTiqxAHiyVi+ableY8P5Bzgux++Y0tO0V/0JWlTEueffv5xzS8i8aUgKEPWrFnDVVddRadOnZg7dy6tWrWib9++DBkyhB9++IEJEyZw7rnn0q9fP1atWkW1atUYM2YMLVu2ZOvWrdxz2z1s27qNFq1bkP/Ocx+8+wF/GvsnDhw4QMs2LXn21WdJSEiI418qEhvrnm8Rl+e9o85JcXne2QNnR2U52jVUxqxYsYKHHnqIRYsWsXz5ciZOnMisWbMYPnw4L7/8MkOGDKF169YsWrSIl19+mV69egHw3HPP0aZ9G6Z8MoUuV3Th+w3fA7Dy25X85f2/MGHaBKbOmEqlSpWYNnlaPP9EESljtEVQxiQnJ9OiReRXTbNmzbj00ksxM1q0aMGaNWtYu3YtkydPBqBr165s3bqVHTt2kJGRwbAxwwDofHlnatWuBcDcz+eydNFSbr3qViA41fbUU+Lwl4lIWaUgKGNOPPHEvMeVKlXKG65UqRLZ2dlUrnz4Kjt46qRx+CmU7s6Nt97Io089GqOKRaS8066hciYtLY0JEyYA8Nlnn3Hqqady0kknkZaWxrQpkV0+GTMy2LF9BwAXXHwBH3/4MVs3bwVg+7btbFi/IT7Fi0iZpC2Ccmbo0KH07duXli1bUq1aNX7/+98DMGTIEG646QZ6XN6Ddhe2o269ugCc2/hcHnriIe69/V5yc3OpXKUyz7zyDPXOrBfPP0NEyhDLf3ZJeZCamuoFb0yzbNkymjRpEqeKyo78p4+WprJy+qjeB6KzhopmZvPdPbWwado1JCIScgoCEZGQUxCIiIRcTIPAzK4ys2/MbIWZDS5kei0zm2ZmX5nZUjPrG8t6RETkcDELAjNLAEYBVwNNgTvMrGmBZvcDX7t7K6Az8CszOyFWNYmIyOFiuUXQHljh7qvcfT8wCehWoI0DNS1yRVQN4EcgO4Y1iYhIAbG8jqAesD7fcBbQoUCbkcAHwEagJnCbu+cWXJCZ3QfcB9CgQYMjPnHbQX84toqLMH9YryO2qVGjBrt27Tqm5d977708+uijNG1acIMpIj09nSuuuIKf/exnJWqf3xezv+D+Pvdz5llnsm/fPjpf1pnHhz5+THXGwjXXXMPEiROpXbt2vEsRCa1YbhEUdsuoghctXAlkAj8DUoCRZnbYCbnuPsbdU909NSkpKfqVxtnYsWOL/VJPT09n48aNJW5fUNsObZnyyRSm/G0Kn33yGQu+WHBc9QJkZ0dnw2369OkKAZE4i2UQZAFn5huuT+SXf359gSkesQJYDZSNq5OOkbszaNAgmjdvTosWLXjrrbcAyM3N5Re/+AXNmjXjuuuu45prruHdd98FoHPnzsybN4+cnBz69OmTN+9vfvMb3n33XebNm0fPnj1JSUlh7969ee0BPvroI9q0aRPpsvrm4o+1J1ZN5Pxm57Pp+00AzP5sNrdfezs9Lu/Bw/c+zO7duwGY+clMrul0DT1v6MlLT73EgLsGADBy2EiefexZ7rntHgYPHMyPW37kwXsepF27drRr147ZsyMXt8ycOZOUlBRSUlJo3bo1O3fu5PvvvyctLY2UlBSaN2/O559/Dhx6c5xf//rXNG/enObNmzNixAgg0jV3kyZN6N+/P82aNeOKK65g7969UVtfIhLbXUNfAueZWTKwAbgduLNAm3XApcDnZnY60BhYFcOaYm7KlClkZmby1VdfsWXLFtq1a0daWhqzZ89mzZo1LF68mB9++IEmTZrQr1+/Q+bNzMxkw4YNLFmyBIDt27dTu3ZtRo4cyfDhw0lNPfSiwM2bN9O/f38yMjJITk5m7vK5xda2Y/sO1q5eS+qFqWzbuo03RrzBuLfHUa16Nd787zdJH53Ovfffy9DHh/LHqX+k/ln1+c8B/3nIMpYuWsqE9yeQWDWRx37+GL3v603PG3qybt06rrzySpYtW8bw4cMZNWoUHTt2ZNeuXSQmJjJmzBiuvPJKnnrqKXJyctizZ88hy50/fz7jx4/nn//8J+5Ohw4duOSSS6hTpw7fffcdf/7zn3nzzTe59dZbmTx5MnfdddexriIRKSBmWwTung08AHwMLAPedvelZjbAzAYEzV4ALjKzxcAM4Al3L9f3Tpw1axZ33HEHCQkJnH766VxyySV8+eWXzJo1i1tuuYVKlSpxxhln0KVLl8PmPfvss1m1ahUDBw7ko48+4qSTir9sfe7cuaSlpZGcnAxA7TqF72KZ/8/5dOvSjYtbXkznyzqTdFoSmfMzWfntSnre0JPul3bn/bffZ2PWRlatWEX9BvWpf1Z9AK7tfu0hy+p6RVcSqyYCMCdjDi8++SIpKSnccMMN/PTTT+zcuZOOHTvy6KOP8vrrr7N9+3YqV65Mu3btGD9+PEOHDmXx4sXUrFnzsNete/fuVK9enRo1atCjR4+8rYbk5GRSUlIAaNu2LWvWrDnCWhCRoxHTTufcfTowvcC40fkebwSuiGUNpa2ovptK0qdTnTp1+Oqrr/j4448ZNWoUb7/9NuPGjSv2uQ52QV2cth3aMvpPo1m9cjV33XAXl11zGQAXpV3Er0b/6pC2Xy/+uthlVa1WNe9xrufy5w//TErDlEPaDB48mGuvvZbp06dzwQUX8Mknn5CWlkZGRgb/+7//y913382gQYPybqpz8G8pSv6uuRMSErRrSCTKdGVxlKWlpfHWW2+Rk5PD5s2bycjIoH379nTq1InJkyeTm5vLpk2b+Oyzzw6bd8uWLeTm5nLTTTfxwgsvsGBB5KBuzZo12blz52HtL7zwQmbOnMnq1auBSBfTxUk+J5n+D/Zn7MixtGrTioVfLmTt6rUA7N2zl9UrV3P2uWeTtS6LDesiXVX/5f2/FLm8jpd0ZMK4CXnDmZmZAKxcuZIWLVrwxBNPkJqayvLly1m7di2nnXYa/fv355577sn72/K/bu+99x579uxh9+7dTJ06lYsvvrjYv0dEoqNCdkNdktM9Y6V79+7MmTOHVq1aYWa89tprnHHGGdx0003MmDGD5s2b06hRIzp06ECtWrUOmXfDhg307duX3NzIGbSvvPIKAH369GHAgAFUrVqVOXPm5LVPSkpizJgx9OjRg9zcXKrXrs64t4veggC4vdftjH9jPHt27+Hl377MYwMeY//+/QA8NPghks9J5tlXn6X/nf2pc3IdWrQuujfHp158iuf/63latmxJdnY2aWlpjB49mhEjRvDpp5+SkJBA06ZNufrqq5k0aRLDhg2jSpUq1KhRgz/84dBTfNu0aUOfPn1o3749EDlFtnXr1toNJFIK1A11Kdq1axc1atRg69attG/fntmzZ3PGGWdEbfnR6oZ69+7dVK9eHXfn+cHPc9bZZ9HnP/oU2V7dUEtZoW6oi1ZcN9QVcougrLruuuvYvn07+/fv55lnnolqCETTO396h/fffp8D+w/QpEUTbrv7tniXJCIxpCAoRYUdFyiL+vxHn2K3AESkYtHBYhGRkFMQiIiEnIJARCTkFAQiIiFXIQ8WR/sUsgbPLi5Ru02bNvHII48wd+5c6tSpwwknnMDjjz9OnTp16NatG8nJyeTm5nLaaacxceJETjvtNNLT0xk0aBD169dn165dnH322QwZMoSLLrqI+++/n9mzZ7N//35Wr15N48aNAXj66ae5+eabo/o3ikh4aYsgStydG2+8kbS0NFatWsX8+fOZNGkSWVlZAFx88cVkZmayaNEi2rVrx6hRo/Lmve2221i4cCHfffcdgwcPpkePHixbtoxRo0aRmZnJ9OnTOeecc8jMzCQzM1MhICJRpSCIkr///e+ccMIJDBgwIG/cWWedxcCBAw9p5+7s3LmTOnXqFLqcLl26cN999zFmzJiY1isicpCCIEqWLl1KmzZtipz++eefk5KSQoMGDfjkk08O64I6vzZt2rB8eXSuEhYRORIFQYzcf//9tGrVinbt2gH/3jW0fv16+vbty+OPF327yPLW7YeIlG8Kgihp1qzZIT1qjho1ihkzZrB58+bD2t5www1kZGQUuayFCxeqzxwRKTUKgijp2rUr+/bt44033sgbV/AuXAfNmjWLc845p9BpM2fOZMyYMfTv3z8mdYqIFFQhTx8t6eme0WRmvPfeezzyyCO89tprJCUlUb16dX75y18C/z5G4O7UqlWLsWPH5s371ltvMWvWLPbs2UNycjKTJ0/WFoGUe20H/eHIjaJsas0jt5HDVcggiJe6desyadKkQqft2LGj0PF9+vShT58+xS63YcOGefcxFhGJNu0aEhEJOQWBiEjIadeQSAHxuMtVPI5riRykLQIRkZDTFoGUWV+v33JU7f+1bRd3ReFMFZ15ImGjIBApAzr+d8e4PO/R3PxcKq4KGQTR/lCV5MOSkJBAixYtyM7OJjk5mT/+8Y/Url37uJ87PT2defPmMXLkyONeVn69uvdi8w+bSUxMBGDAwwO48voro/ocAGvWrOEf//gHd955Z9SXLSLRoWMEUVK1alUyMzNZsmQJJ5988iHdTJdVw0YNY+qMqUydMbXEIZCdnX1Uz7FmzRomTpx4LOWJSCmpkFsE8XbhhReyaNEiAL744gsefvhh9u7dS9WqVRk/fjyNGzcmPT2dDz74gD179rBy5Uq6d+/Oa6+9BsD48eN55ZVXqFu3Lo0aNeLEE08EYO3atfTr14/NmzeTlJTE+PHjadCgAX369KFq1aosWLSAjVkbeWnES7z/9vtkzs+kZeuWvPL6KyWqe/u27Tz9yNOsX7uexKqJPD/8eRo3bczIYSP5YdMPbFi/gTon1+HJF55k6BND+T7rewBGjxpNx44dmTlzJg899BAQudI6IyODwYMHs2zZMlJSUujduzePPPJItF9uETlOCoIoy8nJYcaMGdxzzz0AnH/++WRkZFC5cmU++eQTnnzySSZPngxAZmYmCxcu5MQTT6Rx48YMHDiQypUrM2TIEObPn0+tWrXo0qULrVu3BuCBBx6gV69e9O7dm3HjxvHggw/y3nvvAbBt2zbSJ6fz94//zi96/YKJ0ybyQuMXuOWqW1i2ZBlNmh/eZcWg+wfl7Roa9844Rg0fRZPmTRiZPpK5s+YyeOBgps6YCsDSRUuZ8P4EEqsm8tjPH6P3fb1p26EtG7M2cu9d97Js2TKGDx/OqFGj6NixI7t27SIxMZFXX32V4cOH8+GHH8b8tReRY6MgiJK9e/eSkpLCmjVraNu2LZdffjkQ6Vqid+/efPfdd5gZBw4cyJvn0ksvpVatWgA0bdqUtWvXsmXLFjp37kxSUhIQuXvZt99+C8CcOXOYMmUKAHffffchXVlff/31mBmNmjTilKRTaNSkEQDnNjqXDes3FBoEw0YNo3lK87zhBV8s4Lf/77cAXNDpArZv287On3YC0PWKriRWjYTGnIw5rPx2Zd58P/30Ezt37qRjx448+uij9OzZkx49elC/fv3jeUlFpJToGEGUHDxGsHbtWvbv3593jOCZZ56hS5cuLFmyhGnTprFv3768eQ7u8oHIweaD+9/NrETPmb/dwWVVskqccMIJeeMrVapETnZOiZZX2H0QDj5H1WpV88blei5//vDPeccXNmzYQM2aNRk8eDBjx45l7969XHDBBbq5jkg5oSCIslq1avH6668zfPhwDhw4wI4dO6hXrx4QOQPoSDp06MBnn33G1q1bOXDgAO+8807etIsuuiivU7sJEybQqVOnqNaeekEq0yZPA+CL2V9Q5+Q61KhZ47B2HS/pyIRxE/KGMzMzAVi5ciUtWrTgiSeeIDU1leXLl1OzZk127twZ1TpFJLoq5K6heJ8b3bp1a1q1asWkSZN4/PHH6d27N7/+9a/p2rXrEeetW7cuQ4cO5cILL6Ru3bq0adOGnJzIL/rXX3+dfv36MWzYsLyDxdF0/2P389TDT9GtSzcSqyYWeZD5qRef4vn/ep5uXbqRk53DZV0vY/To0YwYMYJPP/2UhIQEmjZtytVXX02lSpWoXLkyrVq1ok+fPjpYLFIGWXm7LWJqaqrPmzfvkHHLli1T//3A8k3x2RVz/unnx2S5R31l8frVDJq67Lifd2rNYce9jKN1R52TSv05IbY/muJzP4LSX3dQPtafmc1399TCpmnXkIhIyCkIRERCrsIEQXnbxSXR5e7oLSBybCpEECQmJrJ161aFQUi5O/v37CRr+74jNxaRw1SIs4bq169PVlYWmzdvjncpAGRv3xiX591SKT657j/GJoD/tW1XyZ7fIWv7PsbPWReTOkQqugoRBFWqVCE5OTneZeRZ9/ytcXneAeXgzIWjEY17C4jIkcX0J6SZXWVm35jZCjMbXESbzmaWaWZLzWxmLOsREZHDxWyLwMwSgFHA5UAW8KWZfeDuX+drUxv4HXCVu68zs9NiVY+IiBQulruG2gMr3H0VgJlNAroBX+drcycwxd3XAbj7D9EsIB4XtIBudSgi5Ussdw3VA9bnG84KxuXXCKhjZp+Z2Xwz61XYgszsPjObZ2bzysoBYRGRiiKWQVBYF5oFTy+pDLQFrgWuBJ4xs0aHzeQ+xt1T3T31YPfMIiISHbHcNZQFnJlvuD5Q8LzKLGCLu+8GdptZBtAK+DaGdYmISD6x3CL4EjjPzJLN7ATgduCDAm3eBy42s8pmVg3oABx/r2EiIlJiMdsicPdsM3sA+BhIAMa5+1IzGxBMH+3uy8zsI2ARkAuMdfclsapJREQOF9MLytx9OjC9wLjRBYaHAfHpO1ZERCpGX0MiInLsFAQiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhNwRg8DMGpnZDDNbEgy3NLOnY1+aiIiUhpJsEbwJ/BdwAMDdFxHpN0hERCqAkgRBNXf/osC47FgUIyIipa8kQbDFzM4huJeAmd0MfB/TqkREpNSUpNO5+4ExwPlmtgFYDfSMaVUiIlJqig2C4Ab0P3f3y8ysOlDJ3XeWTmkiIlIaig0Cd88xs7bB492lU5KIiJSmkuwaWmhmHwDvAHlh4O5TYlaViIiUmpIEwcnAVqBrvnEOKAhERCqAIwaBu/ctjUJERCQ+SnJlcX0zm2pmP5jZJjObbGb1S6M4ERGJvZJcRzAe+AD4GVAPmBaMExGRCqAkQZDk7uPdPTv4lw4kxbguEREpJSW9svguM0sI/t1F5OCxiIhUACUJgn7ArcC/iHQtcXMwTkREKoCSnDW0DrihFGoREZE4KMlZQ783s9r5huuY2bjYliUiIqWlJLuGWrr79oMD7r4NaB27kkREpDSVJAgqmVmdgwNmdjIluyJZRETKgZJ8of8K+IeZvRsM3wK8FLuSRESkNJXkYPEfzGwekb6GDOjh7l/HvDIRESkVRwyC4O5kK939azPrDFxmZhvzHzcQEZHyqyTHCCYDOWZ2LjAWSAYmxrQqEREpNSUJglx3zwZ6AL9190eAurEtS0RESktJguCAmd0B9AI+DMZViV1JIiJSmkoSBH2BC4GX3H21mSUDf4ptWSIiUlpKctbQ18CDAGbWxt0XAK/GujARESkdJdkiyG9sTKoQEZG4OdogsJhUISIicXO0QfBcTKoQEZG4KTIIzOxKM7s5/zh3f8/MeprZ5bEvTURESkNxWwTPATMLGT8DeL4kCzezq8zsGzNbYWaDi2nXzsxyCgaPiIjEXnFBUM3dNxcc6e7/AqofacFmlgCMAq4GmgJ3mFnTItr9Evi4pEWLiEj0FBcEiWZ22OmlZlYFqFqCZbcHVrj7KnffD0wCuhXSbiCRbix+KMEyRUQkyooLginAm2aW9+s/eDw6mHYk9YD1+YazgnF5zKwe0D1YZpHM7D4zm2dm8zZvPmwjRUREjkNxQfA0sAlYa2bzzWwBsAbYHEw7ksJONfUCwyOAJ9w9p7gFufsYd09199SkpKQSPLWIiJRUkVcWBx3NDTaz54Bzg9Er3H1vCZedBZyZb7g+sLFAm1RgkpkBnApcY2bZ7v5eCZ9DRESOU5FBYGY9CoxyoLaZZbr7zhIs+0vgvKBvog3A7cCdhyzQPTnf86UDHyoERERKV3F9DV1fyLiTgZZmdo+7/724Bbt7tpk9QORsoARgnLsvNbMBwfRijwuIiEjpKG7XUN/CxpvZWcDbQIcjLdzdpwPTC4wrNADcvc+RliciItF3tF1M4O5r0f0IREQqjKMOAjM7H/i/GNQiIiJxUNzB4mkcfrrnyURuU3lXLIsSEZHSU9zB4uEFhh34kUgY3AXMiVVRIiJSeoo7WJzX4ZyZpRA59fNWYDWRLiFERKQCKG7XUCMi5/7fAWwF3gLM3buUUm0iIlIKits1tBz4HLje3VcAmNkjpVKViIiUmuLOGroJ+BfwqZm9aWaXoltViohUOEUGgbtPdffbgPOBz4BHgNPN7A0zu6KU6hMRkRg74nUE7r7b3Se4+3VEOo7LBIq825iIiJQvR3VBmbv/6O7/4+5dY1WQiIiUrqO+slhERCoWBYGISMgpCEREQk5BICIScgoCEZGQUxCIiIScgkBEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiIiEnIJARCTkFAQiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScjENAjO7ysy+MbMVZja4kOk9zWxR8O8fZtYqlvWIiMjhYhYEZpYAjAKuBpoCd5hZ0wLNVgOXuHtL4AVgTKzqERGRwsVyi6A9sMLdV7n7fmAS0C1/A3f/h7tvCwbnAvVjWI+IiBQilkFQD1ifbzgrGFeUe4C/xLAeEREpROUYLtsKGeeFNjTrQiQIOhUx/T7gPoAGDRpEqz4RESG2WwRZwJn5husDGws2MrOWwFigm7tvLWxB7j7G3VPdPTUpKSkmxYqIhFUsg+BL4DwzSzazE4DbgQ/yNzCzBsAU4G53/zaGtYiISBFitmvI3bPN7AHgYyABGOfuS81sQDB9NPAscArwOzMDyHb31FjVJCIih4vlMQLcfTowvcC40fke3wvcG8saRESkeLqyWEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQUxCIiIScgkBEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiIiEnIJARCTkFAQiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQUxCIiIScgkBEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiIiEXEyDwMyuMrNvzGyFmQ0uZLqZ2evB9EVm1iaW9YiIyOFiFgRmlgCMAq4GmgJ3mFnTAs2uBs4L/t0HvBGrekREpHCx3CJoD6xw91Xuvh+YBHQr0KYb8AePmAvUNrO6MaxJREQKqBzDZdcD1ucbzgI6lKBNPeD7/I3M7D4iWwwAu8zsm+iWGl1nHd/spwJbolJIKbEHLd4lRFWY1p/W3SHK1bqDo15/Rb48sQyCwir0Y2iDu48BxkSjqLLOzOa5e2q865Bjo/VXfoV53cVy11AWcGa+4frAxmNoIyIiMRTLIPgSOM/Mks3sBOB24IMCbT4AegVnD10A7HD37wsuSEREYidmu4bcPdvMHgA+BhKAce6+1MwGBNNHA9OBa4AVwB6gb6zqKUdCsQusAtP6K79Cu+7M/bBd8iIiEiK6slhEJOQUBCIiIacgiBIzq29m75vZd2a20sx+GxwkL9juZ2b2bgmWN93Mah9jLUPN7LFjmTdsytJrZWadzezDeNdRkZlZPzNbHHRps8TMCl7kGu3nSzezm2P5HNGgIIgCMzNgCvCeu58HNAJqAC8VaFfZ3Te6+xHfGO5+jbtvj0nBIiETnJnYAHgK6OTuLYELgEXxraxsUBBER1dgn7uPB3D3HOARoJ+Z/cLM3jGzacBfzayhmS0BMLNqZvZ28OvkLTP7p5mlBtPWmNmpQftlZvammS01s7+aWdWgTX8z+9LMvjKzyWZWLT5/fvliZk8FnSF+AjQOxp1jZh+Z2Xwz+9zMzg/G3xL8cvzKzDKCcQ2DNguCfxcF4zub2cxgnX5rZq+aWU8z+yL4FXpO0C7dzEYHy/jWzK4rpMbqZjYuWL8LY/3LtSwys0eD136JmT1sZr80s1/kmz7UzP4zeDwoeK0WmdlzwbiDn53fAQuAZGAnsAvA3Xe5++qgbaGfpWBdvWFmn5rZKjO7JFgvy8wsPV8tu8zsV8H7YYaZJRXy97QN3h/zzexjK0vd6bi7/h3nP+BB4DeFjF8YTMsCTg7GNQSWBI8fA/4neNwcyAZSg+E1RC55bxiMTwnGvw3cFTw+Jd9zvQgMDB4PBR6L9+tSFv8BbYHFQDXgJCKnLj8GzADOC9p0AP4ePF4M1Ase1w7+rwYkBo/PA2ug9bQAAAUrSURBVOYFjzsD24G6wInABuC5YNpDwIjgcTrwEZEfYucF74/EYP4PgzYv51vPtYFvgerxfv3isJ6qE9m6Xgq0Bmbma/M10AC4gsipnxa8ph8CacFnJxe4IGifQOR09nXAeOD6fMsq6rOUTqSfNCPSN9pPQIvgeebn+1w60DN4/CwwMt/8NwNVgH8AScH424icUh/319rdY9rFRJgYhXSNkW/839z9x0KmdwJ+C+DuS8ysqM3U1e6eGTyeT+QNDtDczF4k8kVRg8ibXIp3MTDV3fcAmNkHRL6ELwLeiezlAyJf5ACzgXQze5vI7j+IfKhHmlkKkENkV+BBX3pwUaSZrQT+GoxfDHTJ1+5td88FvjOzVcD5Beq8Argh3/GLRCJfesuO6a8ufzoRWU+7AcxsCpF1d5qZ/QxIAra5+zoze5DI67UwmLcGkYBdB6z1SIeWuHuOmV0FtAMuBX5jZm3dfSjFf5amubub2WJgk7svDmpaSuSzmEkkcN4K2v+Jf79XDmpM5Mfe34L3WAIF+lSLJwVBdCwFbso/wsxOItJ9Rg6wu4j5Stpj1P/le5wDVA0epwM3uvtXZtaHyC9KObKCoV0J2O7uKYc1dB9gZh2Aa4HM4Mt/ILAJaBXMuy/fLPnXVW6+4VwO/bwVrKGwfrhucvcy3cFiDBX12XiXyC/sM4j8Uj/Y9hV3/59DFmDWkAKfPY/8HP8C+MLM/kZky2AoxX+W8q/Dguu3qO/QwtbnUne/sIj2caVjBNExA6hmZr0g714MvyLy5tpTzHyzgFuDeZoS2eQ8GjWB782sCtDzKOcNqwygu5lVNbOawPVE1tFqM7sF8g4stgoen+Pu/3T3Z4n0THkmUAv4PvhFfzeRX3dH6xYzqxQcNzgbKPiF/zEw0IKfj2bW+hieozzLAG60yHG06kB34HMiX/63EwmDg2fffUzkeFwNADOrZ2anFVygRc7Yy3/zqxRgbfD4eD9LlYKaAO4k8tnO7xsgycwuDGqpYmbNjuF5YkJbBFEQbDZ2B35nZs8QeVNMB54E7ihm1t8Bvw92CS0kcgbDjqN46meAfxJ5My8m8maWYrj7AjN7i8jm/FoiXy4Q+fC/YWZPE9n1Mwn4ChhmZucR+UU3Ixj3O2ByEByfUvQWX3G+AWYCpwMD3H1fvt1SAC8AI4BFQRisAQ47qFxRBespncivd4Cx7r4QIAjwDQd3wbn7X82sCTAneA13AXcR2XrOrwowPNi1tA/YDAwIph3vZ2k30MzM5hP5DN9W4O/Zb5HTSF83s1pEvntHENmbEHfqYiKOgi2HKsGXwDlEvmgaeeRGPlJBBV9wH7r7Ea8nkfLBzHa5e41413GstEUQX9WAT4PNUQN+rhAQkdKmLQIRkZDTwWIRkZBTEIiIhJyCQEQk5BQEIkfJjtBjqZndGFwXIlIuKAhEou9GQEEg5YbOGhIpATN7CugFrCdyIdLBC4fuA04g0nnd3USuVv0wmLaDSNcjXQu2O9jXkUhZoCAQOQIza0uku5AORK69WQCMBsa7+9agzYtEOiT774IXjJnZKYW1K/U/RKQIuqBM5MgK67EUSt77q3qJlTJNxwhESqawTed04AF3bwE8R6Sr6MKUtJ1IXCgIRI6ssB5LoegeK3dyaKdl6iVWyjQFgcgRuPsCIjcdyQQm8+8eSw/2WPk3YHm+WSYBgyxyi8lzimknUiboYLGISMhpi0BEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkPv/RL2sV3A7kCYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"data\", y=\"AUC-score\",hue=\"model\",data=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET\n",
       "0      100001    0.06\n",
       "1      100005    0.34\n",
       "2      100013    0.10\n",
       "3      100028    0.32\n",
       "4      100038    0.90"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_submit = pd.read_csv(\"test.csv\")[['SK_ID_CURR']]\n",
    "rfc_pred = rfc.predict_proba(x_test)[:, 1]\n",
    "rfc_submit['TARGET'] = rfc_pred\n",
    "rfc_submit.to_csv(\"submission.csv\",index=0)\n",
    "rfc_submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
