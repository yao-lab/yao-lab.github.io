{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, tpe, fmin\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"./m5-forecasting-accuracy/sales_train_evaluation.csv\")\n",
    "calendar = pd.read_csv(\"./m5-forecasting-accuracy/calendar.csv\")\n",
    "sell_prices = pd.read_csv(\"./m5-forecasting-accuracy/sell_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Zero sales for dates d_1942 to d_1969\n",
    "for i in range(1942,1970):\n",
    "    col = \"d_\"+ str(i)\n",
    "    train[col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Usage Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downcast in order to save memory\n",
    "def downcast(df):\n",
    "    cols = df.dtypes.index.tolist()\n",
    "    types = df.dtypes.values.tolist()\n",
    "    for i,t in enumerate(types):\n",
    "        if 'int' in str(t):\n",
    "            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int8)\n",
    "            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int16)\n",
    "            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int64)\n",
    "        elif 'float' in str(t):\n",
    "            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float16)\n",
    "            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float64)\n",
    "        elif t == np.object:\n",
    "            if cols[i] == 'date':\n",
    "                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype('category')\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = downcast(train)\n",
    "sell_prices = downcast(sell_prices)\n",
    "calendar = downcast(calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MELT the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_train = pd.melt(train, \n",
    "                  id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], \n",
    "                  var_name = 'd', \n",
    "                  value_name = \"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = pd.merge(sale_train,calendar, on = \"d\")\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del calendar,sale_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = pd.merge(combine, sell_prices, on=['store_id','item_id','wm_yr_wk'], how='left') \n",
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sell_prices\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id = dict(zip(fulldata.id.cat.codes, fulldata.id))\n",
    "new_item_id = dict(zip(fulldata.item_id.cat.codes, fulldata.item_id))\n",
    "new_dept_id = dict(zip(fulldata.dept_id.cat.codes, fulldata.dept_id))\n",
    "new_cat_id = dict(zip(fulldata.cat_id.cat.codes, fulldata.cat_id))\n",
    "new_store_id = dict(zip(fulldata.store_id.cat.codes, fulldata.store_id))\n",
    "new_d_state_id = dict(zip(fulldata.state_id.cat.codes, fulldata.state_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.d = fulldata['d'].apply(lambda x: x.split('_')[1]).astype(np.int16) #change d into int type\n",
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numeric variables into categorical variables\n",
    "cols = fulldata.dtypes.index.tolist()\n",
    "types = fulldata.dtypes.values.tolist()\n",
    "for i,type in enumerate(types):\n",
    "    if type.name == 'category':\n",
    "        fulldata[cols[i]] = fulldata[cols[i]].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata['sell_price'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata.drop('date',1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagdata = fulldata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce lags\n",
    "lags = [1,7,14,28]\n",
    "for lag in lags:\n",
    "    lagdata['lag_'+str(lag)] = lagdata.groupby('id')['sales'].shift(lag).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [7,14]\n",
    "for lag in lags:\n",
    "    for w in windows:\n",
    "        lagdata['lag_'+str(lag)+'_rolling_mean_'+str(w)] = lagdata.groupby('id')['sales'].shift(lag).rolling(w).mean().astype(np.float16)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = lagdata[(lagdata['d']>=1914) & (lagdata['d']<1942)][['id','d','sales']]\n",
    "test = lagdata[lagdata['d']>=1942][['id','d','sales']]\n",
    "eval_preds = test['sales']\n",
    "valid_preds = valid['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valgrid = {'n_estimators':hp.quniform('n_estimators', 800, 1200, 100),\n",
    "           'learning_rate':hp.quniform('learning_rate', 0.1, 0.4, 0.1),\n",
    "           'max_depth':hp.quniform('max_depth', 8,12,1),\n",
    "           'num_leaves':hp.quniform('num_leaves', 50,100,25),\n",
    "           'subsample':hp.quniform('subsample', 0.5, 0.9, 0.1),\n",
    "           'colsample_bytree':hp.quniform('colsample_bytree', 0.5, 0.9, 0.1),\n",
    "           'min_child_weight':hp.quniform('min_child_weight', 100, 500, 100) \n",
    "          }\n",
    "\n",
    "def objective(params):\n",
    "    params = {'n_estimators': int(params['n_estimators']),\n",
    "              'learning_rate': params['learning_rate'],\n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'num_leaves': int(params['num_leaves']),\n",
    "              'subsample': params['subsample'],\n",
    "              'colsample_bytree': params['colsample_bytree'],\n",
    "              'min_child_weight': params['min_child_weight']}\n",
    "    \n",
    "    lgb_a = LGBMRegressor(**params)\n",
    "    score = cross_val_score(lgb_a, X_train, y_train, cv=2, n_jobs=-1).mean()\n",
    "    return score\n",
    "\n",
    "bestP = fmin(fn= objective, space= valgrid, max_evals=20, rstate=np.random.RandomState(123), algo=tpe.suggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = lagdata.cat_id.astype('category').cat.codes.unique().tolist()\n",
    "for cat in cats:\n",
    "    df = lagdata[lagdata['cat_id']==cat]\n",
    "    \n",
    "    # split the data into train,validate and test\n",
    "    X_train, y_train = df[df['d']<1914].drop('sales',axis=1), df[df['d']<1914]['sales']\n",
    "    X_valid, y_valid = df[(df['d']>=1914) & (df['d']<1942)].drop('sales',axis=1), df[(df['d']>=1914) & (df['d']<1942)]['sales']\n",
    "    X_test = df[df['d']>=1942].drop('sales',axis=1)\n",
    "    \n",
    "    #model\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators = int(bestP['n_estimators']),\n",
    "        learning_rate = bestP['learning_rate'],\n",
    "        subsample = bestP['subsample'],\n",
    "        colsample_bytree = bestP['colsample_bytree'],\n",
    "        max_depth = int(bestP['max_depth']),\n",
    "        num_leaves = int(bestP['num_leaves']),\n",
    "        min_child_weight = int(bestP['min_child_weight'])\n",
    "    )\n",
    "    print('Category: {} prediction result'.format(new_cat_id[cat]))\n",
    "    lgbmmodel = model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],\n",
    "             eval_metric='rmse', verbose=20, early_stopping_rounds=20)\n",
    "    \n",
    "    lgb.plot_importance(model, importance_type=\"gain\", precision=0, figsize=(6, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds[X_valid.index] = model.predict(X_valid)\n",
    "eval_preds[X_test.index] = model.predict(X_test)\n",
    "#del model, X_train, y_train, X_valid, y_valid\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['sales'] = valid_preds\n",
    "validation = valid[['id','d','sales']]\n",
    "validation = pd.pivot(validation, index='id', columns='d', values='sales').reset_index()\n",
    "validation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "validation.id = validation.id.map(new_id).str.replace('evaluation','validation')\n",
    "\n",
    "#Get the evaluation results\n",
    "test['sales'] = eval_preds\n",
    "evaluation = test[['id','d','sales']]\n",
    "evaluation = pd.pivot(evaluation, index='id', columns='d', values='sales').reset_index()\n",
    "evaluation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "#Remap the category id to their respective categories\n",
    "evaluation.id = evaluation.id.map(new_id)\n",
    "\n",
    "#Prepare the submission\n",
    "submit = pd.concat([validation,evaluation]).reset_index(drop=True)\n",
    "submit.to_csv('submission4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FER",
   "language": "python",
   "name": "fer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
