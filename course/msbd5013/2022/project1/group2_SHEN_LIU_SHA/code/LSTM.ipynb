{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-20T07:11:42.196309Z","iopub.execute_input":"2022-03-20T07:11:42.19722Z","iopub.status.idle":"2022-03-20T07:11:42.235618Z","shell.execute_reply.started":"2022-03-20T07:11:42.197111Z","shell.execute_reply":"2022-03-20T07:11:42.234376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nimport re\nimport warnings\nfrom tqdm import tqdm\nimport datetime as dt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML/DL imports\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, LabelEncoder\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.model_selection import train_test_split\nfrom fastprogress import master_bar, progress_bar","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:11:42.237507Z","iopub.execute_input":"2022-03-20T07:11:42.238038Z","iopub.status.idle":"2022-03-20T07:11:49.498854Z","shell.execute_reply.started":"2022-03-20T07:11:42.238Z","shell.execute_reply":"2022-03-20T07:11:49.498037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/m5-forecasting-accuracy/'\n\ntrain_data = pd.read_csv(path+'sales_train_validation.csv')\ncalendar = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\nsell_prices = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv')\nsubmission_file = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:11:49.500015Z","iopub.execute_input":"2022-03-20T07:11:49.500256Z","iopub.status.idle":"2022-03-20T07:11:59.113092Z","shell.execute_reply.started":"2022-03-20T07:11:49.500219Z","shell.execute_reply":"2022-03-20T07:11:59.112223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"days = range(1, 1970)\ntime_series_columns = [f'd_{i}' for i in days]\ntransfer_cal = pd.DataFrame(calendar[['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']].values.T, index=['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI'], columns= time_series_columns)\ntransfer_cal = transfer_cal.fillna(0)\nevent_name_1_se = transfer_cal.loc['event_name_1'].apply(lambda x: x if re.search(\"^\\d+$\", str(x)) else np.nan).fillna(10)\nevent_name_2_se = transfer_cal.loc['event_name_2'].apply(lambda x: x if re.search(\"^\\d+$\", str(x)) else np.nan).fillna(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:11:59.114138Z","iopub.execute_input":"2022-03-20T07:11:59.114389Z","iopub.status.idle":"2022-03-20T07:11:59.284522Z","shell.execute_reply.started":"2022-03-20T07:11:59.114364Z","shell.execute_reply":"2022-03-20T07:11:59.283431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform(data):\n    \n    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n    for feature in nan_features:\n        data[feature].fillna('unknown', inplace = True)\n        \n    cat = ['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']\n    for feature in cat:\n        encoder = LabelEncoder()\n        data[feature] = encoder.fit_transform(data[feature])\n    \n    return data\n\ncalendar['date'] = pd.to_datetime(calendar['date'])\ncalendar = calendar[calendar['date']>= '2016-2-01']  # reduce memory\ncalendar= transform(calendar)\n# Attempts to convert events into time series data.\ntransfer_cal = pd.DataFrame(calendar[['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']].values.T,\n                            index=['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI'])\ntransfer_cal","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:11:59.287271Z","iopub.execute_input":"2022-03-20T07:11:59.287605Z","iopub.status.idle":"2022-03-20T07:11:59.328092Z","shell.execute_reply.started":"2022-03-20T07:11:59.287561Z","shell.execute_reply":"2022-03-20T07:11:59.327094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_fea = calendar[['wm_yr_wk','date']].merge(sell_prices, on = ['wm_yr_wk'], how = 'left')\nprice_fea['id'] = price_fea['item_id']+'_'+price_fea['store_id']+'_validation'\n#price_fea.head()\ndf = price_fea.pivot('id','date','sell_price')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:11:59.329356Z","iopub.execute_input":"2022-03-20T07:11:59.329567Z","iopub.status.idle":"2022-03-20T07:12:05.700242Z","shell.execute_reply.started":"2022-03-20T07:11:59.329542Z","shell.execute_reply":"2022-03-20T07:12:05.699123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_df = train_data.merge(df,on=['id'],how= 'left').iloc[:,-140:] # -145: starts dataframe column at 2016-01-27 \nprice_df.index = train_data.id\nprice_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:12:05.701442Z","iopub.execute_input":"2022-03-20T07:12:05.7019Z","iopub.status.idle":"2022-03-20T07:12:06.006668Z","shell.execute_reply.started":"2022-03-20T07:12:05.701832Z","shell.execute_reply":"2022-03-20T07:12:06.005728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:12:06.00777Z","iopub.execute_input":"2022-03-20T07:12:06.008001Z","iopub.status.idle":"2022-03-20T07:12:06.103012Z","shell.execute_reply.started":"2022-03-20T07:12:06.007973Z","shell.execute_reply":"2022-03-20T07:12:06.101959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\n\ntrain_data = downcast_dtypes(train_data)\ntrain_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:12:06.104219Z","iopub.execute_input":"2022-03-20T07:12:06.104558Z","iopub.status.idle":"2022-03-20T07:14:26.329884Z","shell.execute_reply.started":"2022-03-20T07:12:06.104524Z","shell.execute_reply":"2022-03-20T07:14:26.328956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:14:26.330954Z","iopub.execute_input":"2022-03-20T07:14:26.331177Z","iopub.status.idle":"2022-03-20T07:14:26.33612Z","shell.execute_reply.started":"2022-03-20T07:14:26.331143Z","shell.execute_reply":"2022-03-20T07:14:26.335413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.iloc[:, -140:]\ntrain_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:14:26.33709Z","iopub.execute_input":"2022-03-20T07:14:26.337828Z","iopub.status.idle":"2022-03-20T07:14:26.388976Z","shell.execute_reply.started":"2022-03-20T07:14:26.337788Z","shell.execute_reply":"2022-03-20T07:14:26.387963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_series_col1 = train_data.columns\ntime_series_col2 = price_df.columns\ntime_series_col3 = transfer_cal.columns\n\nprint(len(time_series_col1),len(time_series_col2),len(time_series_col3))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:14:26.390111Z","iopub.execute_input":"2022-03-20T07:14:26.39033Z","iopub.status.idle":"2022-03-20T07:14:26.395527Z","shell.execute_reply.started":"2022-03-20T07:14:26.390299Z","shell.execute_reply":"2022-03-20T07:14:26.394618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_df.columns = time_series_col1\ntransfer_cal.columns = time_series_col1\n\ntrain_data.shape, price_df.shape, transfer_cal.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:14:26.397145Z","iopub.execute_input":"2022-03-20T07:14:26.397577Z","iopub.status.idle":"2022-03-20T07:14:26.409722Z","shell.execute_reply.started":"2022-03-20T07:14:26.397547Z","shell.execute_reply":"2022-03-20T07:14:26.408742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_train_data = pd.concat([train_data, transfer_cal, price_df], axis=0)\nfull_train_data.tail(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:14:26.412215Z","iopub.execute_input":"2022-03-20T07:14:26.412773Z","iopub.status.idle":"2022-03-20T07:14:26.496764Z","shell.execute_reply.started":"2022-03-20T07:14:26.412701Z","shell.execute_reply":"2022-03-20T07:14:26.496121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_train_data_transposed = full_train_data.T\nfull_train_data_transposed.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:14:26.497904Z","iopub.execute_input":"2022-03-20T07:14:26.498315Z","iopub.status.idle":"2022-03-20T07:14:26.578036Z","shell.execute_reply.started":"2022-03-20T07:14:26.498285Z","shell.execute_reply":"2022-03-20T07:14:26.57706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timesteps = 28\nhorizon = 28\n\nfull_train_data_sequenced = []   \n\nfor i in tqdm(range(train_data.shape[0])):      # Using tqdm to visualize the progress\n\n    full_train_data_sequenced.append([list(t) for t in zip(full_train_data_transposed['event_name_1'][-(100+14):-(14)],\n                                       full_train_data_transposed['event_type_1'][-(100+14):-(14)],\n                                       full_train_data_transposed['event_name_2'][-(100+14):-(14)],     \n                                       full_train_data_transposed['event_type_2'][-(100+14):-(14)],\n                                       full_train_data_transposed['snap_CA'][-(100+14):-(14)],\n                                       full_train_data_transposed['snap_TX'][-(100+14):-(14)],\n                                       full_train_data_transposed['snap_WI'][-(100+14):-(14)],\n                                       price_df.iloc[i][-100:],\n                                       train_data.iloc[i][-100:])]) \n\nfull_train_data_sequenced = np.asarray(full_train_data_sequenced, dtype=np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:14:26.579309Z","iopub.execute_input":"2022-03-20T07:14:26.579557Z","iopub.status.idle":"2022-03-20T07:15:04.931146Z","shell.execute_reply.started":"2022-03-20T07:14:26.579526Z","shell.execute_reply":"2022-03-20T07:15:04.930062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Normalize(list):\n    list = np.array(list)\n    low, high = np.percentile(list, [0, 100])\n    delta = high - low\n    if delta != 0:\n        for i in range(0, len(list)):\n            list[i] = (list[i]-low)/delta\n    return  list,low,high\n\nnorm_full_train_data, train_low, train_high = Normalize(full_train_data_sequenced[:,-(timesteps*2):,:])\nprint(norm_full_train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:15:04.932359Z","iopub.execute_input":"2022-03-20T07:15:04.932584Z","iopub.status.idle":"2022-03-20T07:15:05.238607Z","shell.execute_reply.started":"2022-03-20T07:15:04.932559Z","shell.execute_reply":"2022-03-20T07:15:05.237438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features = 9\n\nX_train = norm_full_train_data[:,-28*2:-28,:]\ny_train = norm_full_train_data[:,-28:,8] \n\nX_train = X_train.reshape((X_train.shape[0], X_train.shape[1], num_features))\ny_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:15:05.24058Z","iopub.execute_input":"2022-03-20T07:15:05.240921Z","iopub.status.idle":"2022-03-20T07:15:05.249356Z","shell.execute_reply.started":"2022-03-20T07:15:05.240863Z","shell.execute_reply":"2022-03-20T07:15:05.247828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_decoder_model():\n    \n    # Use Keras sequential model\n    model = Sequential()\n    \n    # Encoder LSTM layer with Dropout regularisation; Set return_sequences to False since we are feeding last output to decoder layer\n    model.add(LSTM(units = 100, activation='relu', input_shape = (X_train.shape[1], X_train.shape[2])))\n    model.add(Dropout(0.2))\n    \n    # The fixed-length output of the encoder is repeated, once for each required time step in the output sequence with the RepeatVector wrapper\n    model.add(RepeatVector(horizon))\n    \n    # Decoder LSTM layer with Dropout regularisation; Set return_sequences to True to feed each output time step to a Dense layer\n    model.add(LSTM(units = 100, activation='relu', return_sequences=True))\n    model.add(Dropout(0.2))\n    \n    # Same dense layer is repeated for each output timestep with the TimeDistributed wrapper\n    model.add(TimeDistributed(Dense(units=1, activation = \"linear\")))\n    \n    return model\n\nmodel = Sequential()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:15:05.252143Z","iopub.execute_input":"2022-03-20T07:15:05.252785Z","iopub.status.idle":"2022-03-20T07:15:05.261919Z","shell.execute_reply.started":"2022-03-20T07:15:05.252717Z","shell.execute_reply":"2022-03-20T07:15:05.260784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = encoder_decoder_model()\n#model.summary()\n# Venilla RNN\nmodel.add(LSTM(128, activation='relu', input_shape=(28, n_features),return_sequences=False))\nmodel.add(RepeatVector(n_out_seq_length))\nmodel.add(LSTM(32, activation='relu',return_sequences=True))\nmodel.add(Dropout(0.1))  \nmodel.add(TimeDistributed(Dense(num_y)))   # num_y means the shape of y,in some problem(like translate), it can be many.\n                                                #In that case, you should set the  activation= 'softmax'\nmodel.compile(optimizer='adam', loss='mse')\n# demonstrate prediction\nmodel.fit(X_train, y, epochs=10, batch_size=1000)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:15:05.263492Z","iopub.execute_input":"2022-03-20T07:15:05.26448Z","iopub.status.idle":"2022-03-20T07:15:05.599746Z","shell.execute_reply.started":"2022-03-20T07:15:05.264426Z","shell.execute_reply":"2022-03-20T07:15:05.598803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='MeanSquaredError', metrics = ['RootMeanSquaredError'])","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:15:05.601422Z","iopub.execute_input":"2022-03-20T07:15:05.60175Z","iopub.status.idle":"2022-03-20T07:15:05.620108Z","shell.execute_reply.started":"2022-03-20T07:15:05.601707Z","shell.execute_reply":"2022-03-20T07:15:05.619223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his=model.fit(X_train,y_train,\n              epochs = 500,\n              batch_size = 1000,\n              verbose = 2\n             )","metadata":{"execution":{"iopub.status.busy":"2022-03-20T07:15:05.621581Z","iopub.execute_input":"2022-03-20T07:15:05.622022Z","iopub.status.idle":"2022-03-20T09:01:00.177625Z","shell.execute_reply.started":"2022-03-20T07:15:05.621986Z","shell.execute_reply":"2022-03-20T09:01:00.175968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}