{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91421f23-57da-4270-9af6-c0f85b05ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b822e4-ef7a-4008-b867-1ac93a114bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "process_df = pd.read_pickle('processed.pkl')\n",
    "\n",
    "# since we do it by store only, store_id is useless\n",
    "# cat_id, dept_id are useful\n",
    "unused_features = [\n",
    "    'id',\n",
    "    'state_id',\n",
    "    'store_id',\n",
    "    # 'cat_id',\n",
    "    # 'dept_id',\n",
    "    'date',\n",
    "    'wm_yr_wk',\n",
    "    'd',\n",
    "    'sales',\n",
    "    'revenue'\n",
    "]\n",
    "\n",
    "# retrieve training features\n",
    "used_features = process_df.columns[~process_df.columns.isin(unused_features)]\n",
    "\n",
    "FIRST_DAY = 0\n",
    "STORES = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "def prepare_data(df, store):\n",
    "    df = df[df['d'] >= FIRST_DAY]\n",
    "    df = df[(df['store_id'] == store)]\n",
    "    return df\n",
    "\n",
    "# lightgbm params\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'metric': 'rmse',\n",
    "          'objective': 'regression',\n",
    "          'n_jobs': -1,\n",
    "          'seed': 5013,\n",
    "          'learning_rate': 0.01,\n",
    "          'bagging_fraction': 0.75,\n",
    "          'bagging_freq': 10, \n",
    "          'colsample_bytree': 0.75, \n",
    "          'force_col_wise': True\n",
    "         }\n",
    "\n",
    "model_dir = './models_store/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0594816-e95b-4c2a-85bf-4341c0ded702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting: CA_1\n",
      "[LightGBM] [Info] Total Bins 6425\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.317171\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.84408\tvalid_1's rmse: 2.41814\n",
      "[200]\ttraining's rmse: 2.56204\tvalid_1's rmse: 2.2091\n",
      "[300]\ttraining's rmse: 2.48267\tvalid_1's rmse: 2.17265\n",
      "[400]\ttraining's rmse: 2.44448\tvalid_1's rmse: 2.16294\n",
      "[500]\ttraining's rmse: 2.4184\tvalid_1's rmse: 2.15794\n",
      "[600]\ttraining's rmse: 2.40103\tvalid_1's rmse: 2.15563\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's rmse: 2.393\tvalid_1's rmse: 2.15496\n",
      "starting: CA_2\n",
      "[LightGBM] [Info] Total Bins 6289\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.967477\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.07083\tvalid_1's rmse: 2.30929\n",
      "[200]\ttraining's rmse: 1.92828\tvalid_1's rmse: 2.13387\n",
      "[300]\ttraining's rmse: 1.89042\tvalid_1's rmse: 2.09186\n",
      "[400]\ttraining's rmse: 1.87105\tvalid_1's rmse: 2.07726\n",
      "[500]\ttraining's rmse: 1.85896\tvalid_1's rmse: 2.06759\n",
      "[600]\ttraining's rmse: 1.85013\tvalid_1's rmse: 2.06054\n",
      "[700]\ttraining's rmse: 1.8413\tvalid_1's rmse: 2.05828\n",
      "[800]\ttraining's rmse: 1.8331\tvalid_1's rmse: 2.05239\n",
      "[900]\ttraining's rmse: 1.82627\tvalid_1's rmse: 2.0493\n",
      "[1000]\ttraining's rmse: 1.82068\tvalid_1's rmse: 2.04563\n",
      "Early stopping, best iteration is:\n",
      "[1005]\ttraining's rmse: 1.82041\tvalid_1's rmse: 2.04529\n",
      "starting: CA_3\n",
      "[LightGBM] [Info] Total Bins 6578\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.915871\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 4.10751\tvalid_1's rmse: 3.26524\n",
      "[200]\ttraining's rmse: 3.60655\tvalid_1's rmse: 2.89965\n",
      "[300]\ttraining's rmse: 3.46108\tvalid_1's rmse: 2.82404\n",
      "[400]\ttraining's rmse: 3.39873\tvalid_1's rmse: 2.80827\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttraining's rmse: 3.39171\tvalid_1's rmse: 2.80752\n",
      "starting: CA_4\n",
      "[LightGBM] [Info] Total Bins 6146\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.701097\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 1.53278\tvalid_1's rmse: 1.48432\n",
      "[200]\ttraining's rmse: 1.43585\tvalid_1's rmse: 1.41703\n",
      "[300]\ttraining's rmse: 1.41067\tvalid_1's rmse: 1.40817\n",
      "[400]\ttraining's rmse: 1.3991\tvalid_1's rmse: 1.40652\n",
      "[500]\ttraining's rmse: 1.39164\tvalid_1's rmse: 1.40631\n",
      "Early stopping, best iteration is:\n",
      "[486]\ttraining's rmse: 1.39264\tvalid_1's rmse: 1.40613\n",
      "starting: TX_1\n",
      "[LightGBM] [Info] Total Bins 6383\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.957398\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.3259\tvalid_1's rmse: 2.08987\n",
      "[200]\ttraining's rmse: 2.10182\tvalid_1's rmse: 1.88067\n",
      "[300]\ttraining's rmse: 2.04226\tvalid_1's rmse: 1.83924\n",
      "[400]\ttraining's rmse: 2.01423\tvalid_1's rmse: 1.83023\n",
      "[500]\ttraining's rmse: 1.99504\tvalid_1's rmse: 1.8265\n",
      "[600]\ttraining's rmse: 1.98109\tvalid_1's rmse: 1.82199\n",
      "[700]\ttraining's rmse: 1.96953\tvalid_1's rmse: 1.81973\n",
      "Early stopping, best iteration is:\n",
      "[737]\ttraining's rmse: 1.96583\tvalid_1's rmse: 1.81939\n",
      "starting: TX_2\n",
      "[LightGBM] [Info] Total Bins 6509\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.236093\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.89941\tvalid_1's rmse: 2.10562\n",
      "[200]\ttraining's rmse: 2.55917\tvalid_1's rmse: 1.90146\n",
      "[300]\ttraining's rmse: 2.47028\tvalid_1's rmse: 1.89984\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's rmse: 2.49883\tvalid_1's rmse: 1.89494\n",
      "starting: TX_3\n",
      "[LightGBM] [Info] Total Bins 6457\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.040983\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.5072\tvalid_1's rmse: 2.07846\n",
      "[200]\ttraining's rmse: 2.21225\tvalid_1's rmse: 1.89152\n",
      "[300]\ttraining's rmse: 2.13061\tvalid_1's rmse: 1.8857\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's rmse: 2.15692\tvalid_1's rmse: 1.88251\n",
      "starting: WI_1\n",
      "[LightGBM] [Info] Total Bins 6259\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 0.877233\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 1.78715\tvalid_1's rmse: 1.86553\n",
      "[200]\ttraining's rmse: 1.65344\tvalid_1's rmse: 1.73909\n",
      "[300]\ttraining's rmse: 1.61823\tvalid_1's rmse: 1.71764\n",
      "[400]\ttraining's rmse: 1.6015\tvalid_1's rmse: 1.71314\n",
      "[500]\ttraining's rmse: 1.58999\tvalid_1's rmse: 1.71151\n",
      "[600]\ttraining's rmse: 1.58139\tvalid_1's rmse: 1.71159\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's rmse: 1.5836\tvalid_1's rmse: 1.71108\n",
      "starting: WI_2\n",
      "[LightGBM] [Info] Total Bins 6424\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.112327\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.8626\tvalid_1's rmse: 3.53186\n",
      "[200]\ttraining's rmse: 2.65475\tvalid_1's rmse: 3.17701\n",
      "[300]\ttraining's rmse: 2.59528\tvalid_1's rmse: 3.07153\n",
      "[400]\ttraining's rmse: 2.56452\tvalid_1's rmse: 3.02843\n",
      "[500]\ttraining's rmse: 2.54305\tvalid_1's rmse: 3.00762\n",
      "[600]\ttraining's rmse: 2.52391\tvalid_1's rmse: 2.98876\n",
      "[700]\ttraining's rmse: 2.50912\tvalid_1's rmse: 2.98202\n",
      "[800]\ttraining's rmse: 2.49398\tvalid_1's rmse: 2.97707\n",
      "[900]\ttraining's rmse: 2.48\tvalid_1's rmse: 2.97242\n",
      "[1000]\ttraining's rmse: 2.46656\tvalid_1's rmse: 2.96892\n",
      "Early stopping, best iteration is:\n",
      "[1010]\ttraining's rmse: 2.46549\tvalid_1's rmse: 2.96809\n",
      "starting: WI_3\n",
      "[LightGBM] [Info] Total Bins 6449\n",
      "[LightGBM] [Info] Number of data points in the train set: 5747365, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 1.098934\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.78456\tvalid_1's rmse: 2.50343\n",
      "[200]\ttraining's rmse: 2.47978\tvalid_1's rmse: 2.1924\n",
      "[300]\ttraining's rmse: 2.39023\tvalid_1's rmse: 2.11249\n",
      "[400]\ttraining's rmse: 2.34358\tvalid_1's rmse: 2.08128\n",
      "[500]\ttraining's rmse: 2.31157\tvalid_1's rmse: 2.07093\n",
      "[600]\ttraining's rmse: 2.28692\tvalid_1's rmse: 2.05753\n",
      "[700]\ttraining's rmse: 2.26676\tvalid_1's rmse: 2.05302\n",
      "[800]\ttraining's rmse: 2.24894\tvalid_1's rmse: 2.04936\n",
      "[900]\ttraining's rmse: 2.23323\tvalid_1's rmse: 2.04508\n",
      "[1000]\ttraining's rmse: 2.21879\tvalid_1's rmse: 2.04357\n",
      "Early stopping, best iteration is:\n",
      "[1005]\ttraining's rmse: 2.2182\tvalid_1's rmse: 2.04273\n"
     ]
    }
   ],
   "source": [
    "for store in STORES:\n",
    "    print('starting:',store)\n",
    "    \n",
    "    # get train and val data\n",
    "    train_df = prepare_data(process_df,store)\n",
    "    x_train = train_df[(train_df['date'] <= '2016-03-27')]\n",
    "    y_train = x_train['sales']\n",
    "    x_val = train_df[(train_df['date'] > '2016-03-27') & (train_df['date'] <= '2016-04-24')]\n",
    "    y_val = x_val['sales']\n",
    "\n",
    "    # create train and val dataset\n",
    "    lgb_train = lgb.Dataset(x_train[used_features], y_train)\n",
    "    lgb_val = lgb.Dataset(x_val[used_features], y_val)\n",
    "\n",
    "    # model training\n",
    "    model = lgb.train(params, lgb_train, num_boost_round = 2500, early_stopping_rounds = 50, \n",
    "                      valid_sets = [lgb_train, lgb_val], verbose_eval = 100\n",
    "                     )\n",
    "\n",
    "    # store model\n",
    "    model_name = store+'_'+'.bin'\n",
    "    pickle.dump(model, open(os.path.join(model_dir,model_name), 'wb'))\n",
    "\n",
    "    del train_df, x_train, y_train, x_val, y_val, lgb_train, lgb_val\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f11ba9-7626-4bdd-ab8e-ee83b72f26bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dgl]",
   "language": "python",
   "name": "conda-env-dgl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
