Because there are too many reviews, we cannot reply to each reviewer individually. We have concluded the main concerns of the reviewers as follows:

Lack of a numerical metric for the results: For a numerical metric, we can consider pixel-level metrics like Mean Squared Error (MSE), or we can use semantic metrics like whether the image after inpainting recovers the semantic information in the ground truth image. As we can see from the reconstruction results, the PCA reconstruction is not lossless. Therefore, we believe that MSE is not a good metric here because even if the image is not damaged, the MSE is still quite large after PCA reconstruction. In fact, we chose a digital image classifier (using the human visual system) to evaluate the semantic information recovery. We did not provide the recovery accuracy as that would require a lot of human labor. However, state-of-the-art deep learning methods, such as CNN, can provide a classifier better than humans in digital image classification. We are able to provide the recovery accuracy in the future by using a CNN model.

Lack of comparison with other methods: Due to the novelty of the inpainting algorithm design, it is not easy or straightforward to replace other algorithms from the course to server as a comparison. There are also other types of methods for image inpainting. The state-of-the-art methods in image inpainting are deep learning (DL) methods, like this [
https://huggingface.co/spaces/multimodalart/stable-diffusion-inpainting] model based on stable diffusion. We tested recovering our damaged digital images using it, but the results were poor. The reason is that the model is not adapted to our dataset, and the low-resolution digital images are too specific. We believe that a DL model would perform better if we train it on this dataset from scratch. We are able to provide the result of DL methods in the future.