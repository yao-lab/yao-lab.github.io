{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "plt.style.use('fivethirtyeight')\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "import tqdm\r\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('merge_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\r\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\r\n",
    "\r\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\r\n",
    "\r\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBR Best parameters\r\n",
    "import numpy as np\r\n",
    "from sklearn import linear_model\r\n",
    "from tqdm import tqdm\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\r\n",
    "\r\n",
    "# store r2_score\r\n",
    "rList=[]\r\n",
    "combineList = []\r\n",
    "\r\n",
    "#parameters\r\n",
    "loss_list = ['huber'] #, 'squared_error']\r\n",
    "learning_rate = [0.01, 0.03, 0.05, 0.1]\r\n",
    "max_depth = [3,4,5,6]\r\n",
    "\r\n",
    "for i in range(30):\r\n",
    "    df_train = data2[(data2.yyyymm>=195703)&(data2.yyyymm<197503)]\r\n",
    "    df_validation = data2[(data2.yyyymm>=197503)&(data2.yyyymm<198703)]\r\n",
    "    df_test = data2[(data2.yyyymm>=198703)&(data2.yyyymm<201603)]\r\n",
    "\r\n",
    "    df_train = df_train.copy()\r\n",
    "    df_validation = df_validation.copy()\r\n",
    "    df_test = df_test.copy()\r\n",
    "\r\n",
    "    trainingstart = 195703\r\n",
    "    trainingend = 197503 + i*100\r\n",
    "    validend = trainingend + 1200\r\n",
    "    testend = validend + 100\r\n",
    "\r\n",
    "    trainingMask = (data2.yyyymm >= trainingstart) & (data2.yyyymm< trainingend)\r\n",
    "    trainingData = data2.loc[trainingMask]\r\n",
    "    \r\n",
    "    validationMask = (data2.yyyymm >= trainingend) & (data2.yyyymm< validend)\r\n",
    "    validationData = data2.loc[validationMask]\r\n",
    "    \r\n",
    "    testMask = (data2.yyyymm >= validend) & (data2.yyyymm < testend)\r\n",
    "    testData = data2.loc[testMask]\r\n",
    "    \r\n",
    "    \r\n",
    "    trainingData_y = trainingData['excess_ret']\r\n",
    "    trainingData_x = trainingData.drop(['excess_ret','permno', 'yyyymm'], axis=1)\r\n",
    "    \r\n",
    "    validationData_y = validationData['excess_ret']\r\n",
    "    validationData_x = validationData.drop(['excess_ret','permno', 'yyyymm'], axis=1)\r\n",
    "    \r\n",
    "    testData_y = testData['excess_ret']\r\n",
    "    testData_x = testData.drop(['excess_ret','permno', 'yyyymm'], axis =1)\r\n",
    "    \r\n",
    "    bestRSqr = float(\"-inf\")\r\n",
    "    bestGBR = None\r\n",
    "    bestCombine = None\r\n",
    "    \r\n",
    "    for lr in learning_rate:\r\n",
    "        for max_dep in max_depth:\r\n",
    "            gbr = GBR(max_depth=max_dep,learning_rate=lr,loss=l)\r\n",
    "            gbr.fit(X_train,y_train)\r\n",
    "\r\n",
    "            pred = gbr.predict(validationData_x)\r\n",
    "            currentRSqr = r2_score(validationData_y.values, pred)\r\n",
    "            \r\n",
    "            if(currentRSqr>bestRSqr):\r\n",
    "                bestRSqr=currentRSqr\r\n",
    "                bestGBR=gbr\r\n",
    "                bestCombine=(learning_rate,max_depth)\r\n",
    "        \r\n",
    "    resultPred = bestEnet.predict(testData_x)\r\n",
    "    resultRSqr = r2_score(testData_y.values, resultPred)\r\n",
    "    print('result R square for batch',i,': ', resultRSqr, 'best combine:', bestCombine)\r\n",
    "    rList.append(resultRSqr)\r\n",
    "    combineList.append(bestCombine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The recursive performance evaluation scheme\r\n",
    "train_score2=[0]*30\r\n",
    "validation_score2=[0]*30\r\n",
    "test_score2=[0]*30\r\n",
    "scaler=StandardScaler()\r\n",
    "minmax=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\r\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\r\n",
    "\r\n",
    "bestRSqr = float(\"-inf\")\r\n",
    "bestGBR = None\r\n",
    "loss_list = ['huber']\r\n",
    "max_dep = 3\r\n",
    "lr = 0.01\r\n",
    "best_year = 0\r\n",
    "\r\n",
    "for i in range(0,30):\r\n",
    "    print('Batch {}:\\nTrain data:1960-{}\\nValuation data:{}-{}\\nTest data:{}-{}'.format(i,1978+i,1978+i,1990+i,1990+i,1991+i))\r\n",
    "    data_train=data2[(data2.yyyymm>=196001)&(data2.yyyymm<197801+i*100)]\r\n",
    "    data_validation=data2[(data2.yyyymm>=197801+i*100)&(data2.yyyymm<199001+i*100)]\r\n",
    "    data_test=data2[(data2.yyyymm>=196001+i*100)&(data2.yyyymm<196101+i*100)]\r\n",
    "\r\n",
    "    #Normalize\r\n",
    "    X_train=data_train.drop(\"excess_ret\",axis=1).copy()\r\n",
    "    X_train=scaler.fit_transform(X_train)\r\n",
    "    X_validation=data_validation.drop(\"excess_ret\",axis=1).copy()\r\n",
    "    X_validation=scaler.transform(X_validation)\r\n",
    "    X_test=data_test.drop(\"excess_ret\",axis=1).copy()\r\n",
    "    X_test=scaler.transform(X_test)\r\n",
    "\r\n",
    "    y_train=data_train[[\"excess_ret\"]].copy()\r\n",
    "    y_validation=data_validation[[\"excess_ret\"]].copy()\r\n",
    "    y_test=data_test[[\"excess_ret\"]].copy()\r\n",
    "    y_train=scaler.fit_transform(y_train)\r\n",
    "    y_test=scaler.transform(y_test)\r\n",
    "    y_validation=scaler.transform(y_validation)\r\n",
    "    \r\n",
    "    gbr = GBR(max_depth=3,learning_rate=0.01,loss='huber')\r\n",
    "    gbr.fit(X_train,y_train)\r\n",
    "    y_train_pred=gbr.predict(X_train)\r\n",
    "    train_score2[i]=r2_score(y_train,y_train_pred)\r\n",
    "    y_validation_pred=gbr.predict(X_validation)\r\n",
    "    validation_score2[i]=r2_score(y_validation,y_validation_pred)\r\n",
    "    y_test_pred=gbr.predict(X_test)\r\n",
    "    test_score2[i]=r2_score(y_test,y_test_pred)\r\n",
    "    currentRSqr = test_score2[i]\r\n",
    "\r\n",
    "    if(currentRSqr>bestRSqr):\r\n",
    "        bestRSqr=currentRSqr\r\n",
    "        bestRFR = gbr\r\n",
    "        best_year = 196001+i*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score =pd.DataFrame(test_score2)\r\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performence of GBR+H\r\n",
    "plt.figure(figsize=(10,5))\r\n",
    "plt.title(\"GBR Performance\")\r\n",
    "year=np.arange(1990,2020)\r\n",
    "plt.plot(year,test_score2)\r\n",
    "plt.xlabel(\"year\")\r\n",
    "plt.ylabel(\"score--R-square\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Importance \r\n",
    "#X_test0 = best_data1.drop(best_data1.columns[0],axis=1,inplace=True).copy()\r\n",
    "\r\n",
    "X_test0 = data2[(data2.yyyymm>=best_year)&(data2.yyyymm<best_year+100)]\r\n",
    "print(X_test0.shape)\r\n",
    "a = X_test0.drop(\"excess_ret\",axis=1).copy()\r\n",
    "print(a.shape)\r\n",
    "id = a.columns\r\n",
    "L = len(a.columns)\r\n",
    "train_score=[0]*L\r\n",
    "validation_score=[0]*L\r\n",
    "test_score2 = [0]*L\r\n",
    "importance_GBR_H=[0]*L\r\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable importance\r\n",
    "\r\n",
    "for i in range(0,L):\r\n",
    "    \r\n",
    "    X_test = X_test0.drop(\"excess_ret\",axis=1).copy()\r\n",
    "    X_test.loc[:,id[i]]=0\r\n",
    "    X_test=scaler.fit_transform(X_test)\r\n",
    "\r\n",
    "    y_test=X_test0[[\"excess_ret\"]].copy()\r\n",
    "    y_test=scaler.fit_transform(y_test)\r\n",
    "    \r\n",
    "\r\n",
    "    y_test_pred=bestRFR.predict(X_test)\r\n",
    "    test_score2[i] = r2_score(y_test,y_test_pred)\r\n",
    "    importance_GBR_H[i] = bestRSqr - test_score2[i]\r\n",
    "\r\n",
    "    \r\n",
    "    del X_test,y_test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_GBR_H = np.abs(importance_GBR_H)\r\n",
    "importance_GBR_H1 = pd.DataFrame(importance_GBR_H,columns=['Importance'], index=id)\r\n",
    "importance_GBR_H1 = importance_GBR_H1.sort_values(by='Importance',ascending=True)\r\n",
    "importance_GBR_H1 = importance_GBR_H1.tail(20)\r\n",
    "importance_GBR_H1.plot(kind='barh', figsize=(9, 7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit (conda)",
   "name": "python370jvsc74a57bd0d351f2582fb8059b3c2081c3e2402978b636173226be95e0dabb346cc1ecff00"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}