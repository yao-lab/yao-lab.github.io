{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80147ccb",
   "metadata": {
    "executionInfo": {
     "elapsed": 1794,
     "status": "ok",
     "timestamp": 1650859702842,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "80147ccb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "\n",
    "IMAGE_WIDTH = {5: 15, 20: 60, 60: 180}\n",
    "IMAGE_HEIGHT = {5: 32, 20: 64, 60: 96}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ae6e8",
   "metadata": {
    "id": "e25ae6e8"
   },
   "source": [
    "# Construct CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85940d59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3502,
     "status": "ok",
     "timestamp": 1650859706342,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "85940d59",
    "outputId": "dc00ce78-75ad-4662-bf7a-c95782525ea1"
   },
   "outputs": [],
   "source": [
    "# Final Convolution has 256 filters. Output dimension 256, 3, 60\n",
    "# Original Structure: all feed into a fully connected layer: number of weights 2 * 256 * 3 * 60 = 92160\n",
    "# Here I create 2 sparse linear layers \n",
    "# layer 1: 3 * 60 feed into one node for every filter: number of weights 3 * 60 * 256  = 46080\n",
    "# layer 2: 252 nodes feed into 2 final nodes: number of weights 2 * 256  = 512  \n",
    "\n",
    "import torch\n",
    "import os\n",
    "#masking the fully connected layer weights: 252 * 46080, where for each row only 3* 60 are 1's, \n",
    "#corresponding to one filer \n",
    "\n",
    "mask = np.zeros([252, 46080])\n",
    "for i in range(len(mask)):\n",
    "    mask[i,(i*180):((i+1)*180)] = 1\n",
    "mask = torch.from_numpy(mask) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "    mask.cuda()\n",
    "\n",
    "\n",
    "\n",
    "class CNN_Sparse(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 mask,\n",
    "                 num_class=2,       \n",
    "                 initial_filter = 64,\n",
    "                 filter_sizes= (5,3),\n",
    "                 maxpool_sizes= (2,1),\n",
    "                 dilation=(2,1),\n",
    "                 stride=(2,1),\n",
    "                 p=0.5,\n",
    "                 BN=True,\n",
    "                 Activation='LRELU'\n",
    "                ):\n",
    "        \n",
    "        super(CNN_Sparse, self).__init__()\n",
    "        \n",
    "        padding = (\n",
    "            (filter_sizes[0]-1)//2,\n",
    "            (filter_sizes[1]-1)//2\n",
    "       )\n",
    "        \n",
    "        #BOOLEAN:whether to use batch norm\n",
    "        self.BN = BN\n",
    "        #STRING: type of activation\n",
    "        self.Activation = Activation\n",
    "        # int : 2 for binary\n",
    "        self.num_class = num_class\n",
    "        # float: prob for dropout\n",
    "        self.p = p\n",
    "        \n",
    "        if self.Activation=='LRELU':\n",
    "            self.lrelu = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        else:\n",
    "            self.lrelu = nn.ReLU(inplace=True)\n",
    "            \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=initial_filter, \n",
    "                      kernel_size=filter_sizes,\n",
    "                      padding=padding,\n",
    "                      stride=stride, \n",
    "                      dilation=dilation)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(initial_filter)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=maxpool_sizes, \n",
    "                                       stride=maxpool_sizes)\n",
    "            \n",
    "            \n",
    "        self.conv2= nn.Conv2d(\n",
    "                        in_channels=initial_filter, \n",
    "                      out_channels=initial_filter*2, \n",
    "                      kernel_size=filter_sizes,\n",
    "                      padding=padding\n",
    "                      )\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(initial_filter*2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=maxpool_sizes, stride=maxpool_sizes)\n",
    "            \n",
    "        self.conv3 = nn.Conv2d(in_channels=initial_filter*2, \n",
    "                      out_channels=initial_filter*4, \n",
    "                      kernel_size=filter_sizes,\n",
    "                      padding=padding\n",
    "                      )\n",
    "                        \n",
    "        self.bn3=nn.BatchNorm2d(initial_filter*4)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=maxpool_sizes, stride=maxpool_sizes)\n",
    "            \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=self.p)\n",
    "        \n",
    "        #XAVIER initialization\n",
    "        nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        nn.init.xavier_uniform_(self.conv3.weight)\n",
    "\n",
    "        \n",
    "        ################################################\n",
    "        # a sparse linear layer\n",
    "        ################################################\n",
    "        self.fc1 = nn.Linear(46080, 252)\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        with torch.no_grad():\n",
    "            self.fc1.weight.mul_(mask)\n",
    "\n",
    "        self.fc2 = nn.Linear(252, 1)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        #print('Block1')\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        if self.BN:\n",
    "            x = self.bn1(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.pool1(x)\n",
    "        #print(x.shape)\n",
    "\n",
    "        #print('Block2')\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        if self.BN:\n",
    "            x = self.bn2(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.pool2(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #print('Block3')\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        if self.BN:\n",
    "            x = self.bn3(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.pool3(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "    device = torch.device(\"cuda:2\" if use_gpu else \"cpu\")\n",
    "    print('GPU')\n",
    "    model = CNN_Sparse(mask)\n",
    "    model = model.cuda()\n",
    "    print(model)\n",
    "else:\n",
    "    model = CNN_Sparse(mask)\n",
    "    print(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(1, 64, 60)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b5ea9",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1650859706342,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "380b5ea9"
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29209c",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650859706343,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "2c29209c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#changing the model_name will save the output to another path\n",
    "model_name ='regression_return_normalized_sparse_model'\n",
    "target_label ='return_pred_normalized' \n",
    "#'regression_return_normalized','regression_sharpe_normalized','regression_adjusted_return_normalized'\n",
    "#'return_pred_normalized','sharpe_pred_normalized', 'adj_return_normalized'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042461ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650859706343,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "042461ea",
    "outputId": "cc0113ad-7e7c-4618-ed13-75f08c2e4830",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show basic information of model\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(1, 64, 60)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32fd90",
   "metadata": {
    "id": "5f32fd90"
   },
   "source": [
    "# Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c591b28",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650859706343,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "9c591b28"
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.0005 \n",
    "BATCH_SIZE = {'train':128,\n",
    "              'test':128}\n",
    "momentum = 0.9\n",
    "num_epochs = 50\n",
    "#Patience of early stopping\n",
    "patience = 2\n",
    "     \n",
    "#pin_memory ensures movement of data from cpu to gpu is efficient and fast. \n",
    "#In case one uses inbuilt datasets like MNIST or CIFAR10 then this parameter is not required as in that case data is loaded directly into GPU. \n",
    "#num_workers attribute tells the data loader instance how many sub-processes to use for data loading\n",
    "pin_memory = True\n",
    "num_workers = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2ae75",
   "metadata": {
    "id": "f2f2ae75"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4Kfv1mT_Nq6w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4814,
     "status": "ok",
     "timestamp": 1650859711151,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "4Kfv1mT_Nq6w",
    "outputId": "918fdcdf-615d-43c8-c8f8-41a80cf9d8e2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b451bbd",
   "metadata": {
    "executionInfo": {
     "elapsed": 2742,
     "status": "ok",
     "timestamp": 1650859713886,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "0b451bbd"
   },
   "outputs": [],
   "source": [
    "Label_Raw = pd.read_csv('drive/MyDrive/Colab Notebooks/Label_Raw_Addtional_Predictors.csv',\n",
    "                        index_col=[0])\n",
    "length_Train=pd.read_hdf('drive/MyDrive/Colab Notebooks/length_Train.h5',key='data')\n",
    "\n",
    "\n",
    "#Now all images are saved in 1993 file\n",
    "year = 1993\n",
    "Images = np.memmap(\n",
    "            op.join(\"drive/MyDrive/Colab Notebooks\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), \n",
    "            dtype=np.uint8, mode='r+').reshape(\n",
    "                                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20]))\n",
    "        \n",
    "Label_Raw = Label_Raw.reset_index().drop('index',axis=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4b527",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650859713888,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "84a4b527",
    "outputId": "8161204d-5a1b-4665-ca14-93330be94148"
   },
   "outputs": [],
   "source": [
    "len(Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04de891",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650859713889,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "a04de891",
    "outputId": "e7626099-12f8-44de-f729-f63a99a749bc"
   },
   "outputs": [],
   "source": [
    "#Convert into labels:\n",
    "# 1: positive return\n",
    "# 0: negative returns\n",
    "raw_labels = Label_Raw[target_label].mask(Label_Raw[target_label]==0).dropna()\n",
    "\n",
    "#adjust format for dataloader below\n",
    "annotations = raw_labels.reset_index().rename(columns= {'index':'img_name',\n",
    "                                           target_label:'label'})\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956bdd5",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1650859713890,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "f956bdd5"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed60dbb",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1650859713890,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "0ed60dbb"
   },
   "outputs": [],
   "source": [
    "#Use Pytorch's DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5ee6f",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1650859713891,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "5bf5ee6f"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class CNNDataset(Dataset):\n",
    "    def __init__(self, Images_map ,annotations, transform=None):\n",
    "        \n",
    "        self.annotations = annotations\n",
    "        self.transform = transform\n",
    "        self.Images = Images_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_id = self.annotations.iloc[index, 0]\n",
    "        \n",
    "        img = torch.from_numpy(self.Images[[img_id]]).type(torch.float)        \n",
    "        \n",
    "        y_label = torch.tensor((self.annotations.iloc[index, 1])).type(torch.float)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059c2f3",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1650859713891,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "5059c2f3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d6f37",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650859713892,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "f24d6f37"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_size = int(len(annotations) * 0.7)\n",
    "val_size = len(annotations) - train_size\n",
    "#create dataset object\n",
    "dataset = CNNDataset(Images,annotations)\n",
    "\n",
    "#split train vs validation\n",
    "train_set, validation_set = torch.utils.data.random_split(dataset,[train_size,val_size])\n",
    "\n",
    "#load data\n",
    "trainloader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE['train'],shuffle=True,\n",
    "                          num_workers=num_workers,pin_memory=pin_memory)\n",
    "valloader = DataLoader(dataset=validation_set, batch_size=BATCH_SIZE['test'],shuffle=False,\n",
    "                               num_workers=num_workers, pin_memory=pin_memory) \n",
    "\n",
    "loaders = {'train': trainloader, 'test': valloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2191677",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2826,
     "status": "ok",
     "timestamp": 1650859716709,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "b2191677",
    "outputId": "1a8e2efb-c6ac-465d-80e1-2f35980b8540",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.pyplot import show\n",
    "for img in images[:10]:\n",
    "    imshow(img[0])\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e21a3a",
   "metadata": {
    "id": "d5e21a3a"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a847cc",
   "metadata": {
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1650859717888,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "84a847cc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import scipy.stats\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650ce5c",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1650859717889,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "c650ce5c"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr)  #Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b110d",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ed7b110d",
    "outputId": "cbd8510b-9a0e-4666-cc0d-c15193f4a727",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train 5 models with different random seeds\n",
    "for seed in range(0,5):\n",
    "\n",
    "    # The log for recording train (test) loss and errors.\n",
    "    log = {\n",
    "        'num_params': [],\n",
    "        'train_loss': [],\n",
    "        'train_error': [],\n",
    "        'test_loss': [],\n",
    "        'test_error': []\n",
    "    }\n",
    "    log_saver = log \n",
    "    num_epochs = 50\n",
    "\n",
    "\n",
    "    print('seed '+str(seed))\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if use_gpu:\n",
    "        mask.cuda()\n",
    "    \n",
    "    #######################################\n",
    "    model = CNN_Sparse(mask)\n",
    "    #######################################\n",
    "    if use_gpu:\n",
    "        print('GPU')\n",
    "        device = torch.device(\"cuda:2\" if use_gpu else \"cpu\")\n",
    "        model = model.cuda()\n",
    "\n",
    "    name = model_name+'_'+str(seed)\n",
    "\n",
    "    since = time.time()\n",
    "    steps = 0\n",
    "    last_loss = 100\n",
    "    triggertimes = 0\n",
    "\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  #Adam\n",
    "    number_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    log_saver['num_params'].append(number_params)\n",
    "\n",
    "    print(f'total parameters: {number_params}')    \n",
    "\n",
    "    \n",
    "    #iterating over epochs    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "                        \n",
    "            loss_meter = AverageMeter()      \n",
    "            mean_meter = AverageMeter()\n",
    "            mean_sq_meter = AverageMeter()\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "            \n",
    "                        \n",
    "            for i, data in enumerate(loaders[re.findall('[a-zA-Z]+',phase)[0]]):\n",
    "                inputs, labels = data\n",
    "                \n",
    "                #normalize greyscale to [0,1]\n",
    "                normalize = True\n",
    "                if normalize:\n",
    "                    inputs /=255\n",
    "                \n",
    "                if use_gpu:\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs) \n",
    "                \n",
    "                if steps <1000000 and steps % 5000 ==0 :\n",
    "                    display(\n",
    "                        pd.Series( outputs.view(-1).detach().cpu().numpy()).describe()\n",
    "                        )\n",
    "\n",
    "                                    \n",
    "                loss = criterion(outputs.view(-1), \n",
    "                    labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    ######################\n",
    "                    # Zero out gradients\n",
    "                    ######################\n",
    "                    with torch.no_grad():\n",
    "                      if use_gpu:\n",
    "                        model.fc1.weight.grad.mul_(mask.cuda())\n",
    "                      else:\n",
    "                        model.fc1.weight.grad.mul_(mask)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    steps += 1\n",
    "\n",
    "                N = outputs.size(0)\n",
    "\n",
    "                loss_meter.update(loss.data.item(), N)\n",
    "                \n",
    "                #metrics to compute R-squared                \n",
    "                mean_meter.update(labels.mean().item(),N)\n",
    "                mean_sq_meter.update((labels**2).mean().item(),N)\n",
    "                \n",
    "                \n",
    "                        \n",
    "            epoch_loss = loss_meter.avg\n",
    "            mean_tss = mean_sq_meter.avg - mean_meter.avg\n",
    "            epoch_error = epoch_loss / mean_tss\n",
    "                        \n",
    "            if phase == 'train':\n",
    "                log_saver['train_loss'].append(epoch_loss)\n",
    "                log_saver['train_error'].append(epoch_error)\n",
    "\n",
    "            elif phase == 'test':\n",
    "\n",
    "                log_saver['test_loss'].append(epoch_loss)\n",
    "                log_saver['test_error'].append(epoch_error)\n",
    "\n",
    "#            if phase != 'train':\n",
    "            print(\n",
    "                    f'{phase} loss: {epoch_loss:.4f}; error: {epoch_error:.4f}'\n",
    "            )\n",
    "            print('sample count total:')\n",
    "            print(i)\n",
    "            print(loss_meter.count)\n",
    "            \n",
    "                    \n",
    "        if epoch % 100 == 0 or epoch == num_epochs - 1:\n",
    "            print('Saving..')\n",
    "            state = {'net': model, 'epoch': epoch, 'log': log_saver}\n",
    "\n",
    "            if not os.path.isdir('drive/MyDrive/Colab Notebooks/checkpoint_CNN/'+model_name):\n",
    "                os.mkdir('drive/MyDrive/Colab Notebooks/checkpoint_CNN/'+model_name)\n",
    "            torch.save(state,\n",
    "                       'drive/MyDrive/Colab Notebooks/checkpoint_CNN/'+model_name+'/'+name+'.t7')\n",
    "            \n",
    "        #Early Stopping            \n",
    "        print('Cycle Completed for: '+phase+', total samples '+str(loss_meter.count))\n",
    "        current_loss = epoch_loss\n",
    "        if current_loss >= last_loss:\n",
    "            trigger_times += 1\n",
    "            print('Trigger Times:', trigger_times)\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "                #return model, log_saver\n",
    "        else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "        last_loss = current_loss\n",
    "                    \n",
    "            \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s'\n",
    "    )\n",
    "    \n",
    "    #save final model:\n",
    "    state = {'net': model, 'epoch': epoch, 'log': log_saver}\n",
    "    torch.save(state,\n",
    "               'drive/MyDrive/Colab Notebooks/checkpoint_CNN/'+model_name+'/'+name+'_final.t7')\n",
    "\n",
    "\n",
    "pd.Series( outputs.view(-1).detach().cpu().numpy()).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iS--KSZGESiP",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iS--KSZGESiP",
    "outputId": "42af1448-8fa9-4032-ae08-271a523e966d"
   },
   "outputs": [],
   "source": [
    "#check\n",
    "\n",
    "print(model.fc1.weight*10000)\n",
    "print((model.fc1.weight !=0).sum(axis=1))                            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664f29d",
   "metadata": {
    "id": "3664f29d"
   },
   "source": [
    "# Plot the results (for the last model in the loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c646ea",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "93c646ea",
    "outputId": "7aa3ca20-f5a9-4447-d87e-eab34c8123ba"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  import numpy as np\n",
    "  def plot(log, result_dir):\n",
    "      fontdict = {'size': 30}\n",
    "\n",
    "      def get_fig(i, title):\n",
    "          fig = plt.figure(i, figsize=(20, 10))\n",
    "          ax = fig.add_subplot(111)\n",
    "          #plt.title(title, fontsize=30, y=1.04)\n",
    "          plt.xticks(fontsize=20)\n",
    "          plt.yticks(fontsize=20)\n",
    "          return fig, ax\n",
    "\n",
    "      fig1, ax1 = get_fig(1, 'Loss on Cifar10')\n",
    "      fig2, ax2 = get_fig(2, 'Error on Cifar10')\n",
    "\n",
    "      ax1.plot(log['train_loss'],'b', linewidth=3, label='training')\n",
    "      ax1.plot(log['test_loss'],'r', linewidth=3, label='test')\n",
    "      ax1.set_ylabel('loss',fontdict=fontdict)\n",
    "      ax2.plot(log['train_error'],'b', linewidth=3, label='training')\n",
    "      ax2.plot(log['test_error'],'r', linewidth=3, label='test')\n",
    "      ax2.set_ylabel('error',fontdict=fontdict)\n",
    "\n",
    "      for ax in [ax1, ax2]:\n",
    "          ax.set_xlabel('Number of epochs', fontdict=fontdict)\n",
    "          ax.legend(loc='upper right', fontsize=20)\n",
    "          \n",
    "      if not os.path.exists(result_dir):\n",
    "          os.mkdir(result_dir)\n",
    "      fig1.savefig(result_dir + 'loss.png')\n",
    "      fig2.savefig(result_dir + 'error.png')\n",
    "  plot(log, './alex_results/')\n",
    "  plt.show()\n",
    "except:\n",
    "  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269dafed",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "269dafed"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0cb039",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1f0cb039"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1234a79",
   "metadata": {
    "id": "d1234a79"
   },
   "source": [
    "# Evaluating the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d11f405",
   "metadata": {
    "id": "5d11f405"
   },
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90f153",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 6189,
     "status": "ok",
     "timestamp": 1650859724074,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "af90f153",
    "outputId": "65dfcc6d-814a-4f19-e62a-e76fedcf50cd"
   },
   "outputs": [],
   "source": [
    "Label_Test=pd.read_csv('drive/MyDrive/Colab Notebooks/Label_Test_Addtional_Predictors.csv',index_col=[0])\n",
    "\n",
    "length_Test=pd.read_hdf('drive/MyDrive/Colab Notebooks/length_Test.h5',key='data')   \n",
    "\n",
    "year = 2000\n",
    "Images_Test = np.memmap(\n",
    "                    op.join(\"drive/MyDrive/Colab Notebooks\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), \n",
    "                    dtype=np.uint8, mode='r+',order='C',\n",
    "                    shape=(len(Label_Test), IMAGE_HEIGHT[20], IMAGE_WIDTH[20]))\n",
    "Label_Test = Label_Test.reset_index().drop('index',axis=1) \n",
    "Label_Test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd0308",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650859724076,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "cadd0308",
    "outputId": "4d034cfc-6f73-4378-d659-407420188627"
   },
   "outputs": [],
   "source": [
    "Label_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046c46e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1650859724076,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "7046c46e",
    "outputId": "43287bc7-8c82-49eb-8e0e-84c6d8efe682"
   },
   "outputs": [],
   "source": [
    "Images_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ddcd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1650859724077,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "8d7ddcd9",
    "outputId": "13968a63-1c1b-4c3f-d9bc-8a8f2518ba73"
   },
   "outputs": [],
   "source": [
    "raw_labels = (\n",
    "    Label_Test[target_label].mask(Label_Test[target_label]==0).dropna()\n",
    "    )\n",
    "\n",
    "\n",
    "annotations_test = raw_labels.reset_index().rename(columns= {'index':'img_name',\n",
    "                                           target_label:'label'})\n",
    "annotations_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee9240",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650859724078,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "5bee9240"
   },
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataset_test = CNNDataset(Images_Test,annotations_test)\n",
    "\n",
    "\n",
    "testloader = DataLoader(dataset=dataset_test, \n",
    "                        batch_size=BATCH_SIZE['test'],\n",
    "                        shuffle=False,\n",
    "                        num_workers=num_workers, pin_memory=pin_memory) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc483e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1650859725065,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "6dc483e7",
    "outputId": "357e88a8-4810-4559-da58-38f721128057"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.pyplot import show\n",
    "for img in images[:10]:\n",
    "    imshow(img[0])\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02d29e",
   "metadata": {
    "id": "cd02d29e"
   },
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cerzmg_IXHDk",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cerzmg_IXHDk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BccK5WMWXgmM",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BccK5WMWXgmM"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2f56f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68888,
     "status": "ok",
     "timestamp": 1650859253771,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "61c2f56f",
    "outputId": "f441dfab-1c7c-43e8-e61f-05791ccd16da"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "epoch_loss = pd.Series()\n",
    "epoch_accuracy = pd.Series()\n",
    "PREDICTIONS = {}\n",
    "# The log for recording train (test) loss and errors.\n",
    "\n",
    "for seed in range(0,5):\n",
    "\n",
    "  \n",
    "    print('seed '+str(seed))\n",
    "    torch.manual_seed(seed)\n",
    "    name = model_name+'_'+str(seed)\n",
    "    \n",
    "    state = torch.load(\n",
    "        'drive/MyDrive/Colab Notebooks/checkpoint_CNN/'+model_name+'/'+name+'_final.t7')\n",
    "                    \n",
    "\n",
    "    model = state['net']\n",
    "\n",
    "    number_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'total parameters: {number_params}')\n",
    "\n",
    "    if use_gpu:\n",
    "        print('GPU')\n",
    "        model = model.cuda()\n",
    "        \n",
    "    since = time.time()\n",
    "    steps = 0\n",
    "\n",
    "    loss_meter = AverageMeter()      \n",
    "    mean_meter = AverageMeter()\n",
    "    mean_sq_meter = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    Predictions = []\n",
    "\n",
    "\n",
    "    for i, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        normalize = True\n",
    "        if normalize:\n",
    "            inputs /=255\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = model(inputs) \n",
    "\n",
    "\n",
    "        if use_gpu:\n",
    "          prob = list(outputs.cpu().view(-1).detach().numpy())          \n",
    "        else:\n",
    "          prob = list(outputs.view(-1).detach().numpy())\n",
    "        \n",
    "        Predictions += prob\n",
    "\n",
    "        loss = criterion(outputs.view(-1), \n",
    "            labels)\n",
    "\n",
    "        N = outputs.size(0)\n",
    "\n",
    "        loss_meter.update(loss.data.item(), N)\n",
    "\n",
    "        #metric used to compute r-squared\n",
    "\n",
    "        mean_meter.update(labels.mean().item(),N)\n",
    "\n",
    "        mean_sq_meter.update((labels**2).mean().item(),N)\n",
    "\n",
    "        del inputs, labels, outputs\n",
    "\n",
    "\n",
    "    epoch_loss.loc[seed] = loss_meter.avg\n",
    "    mean_tss = mean_sq_meter.avg - mean_meter.avg\n",
    "    epoch_accuracy.loc[seed] = epoch_loss.loc[seed] / mean_tss \n",
    "    PREDICTIONS[seed] = pd.Series(Predictions)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BH6Ulwe-PLAE",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1650859253784,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "BH6Ulwe-PLAE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q8jDtS-8WpC6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650859253785,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "q8jDtS-8WpC6",
    "outputId": "cf24c622-89e7-46bf-e03e-232652d6b4c0"
   },
   "outputs": [],
   "source": [
    "#check\n",
    "\n",
    "print(model.fc1.weight*10000)\n",
    "print((model.fc1.weight !=0).sum(axis=1))                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503e777",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650859253786,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "f503e777"
   },
   "outputs": [],
   "source": [
    "#averaging all results\n",
    "Predictions = pd.concat(PREDICTIONS,axis=1)\n",
    "Predictions['mean'] = Predictions.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938dd0f",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650859253786,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "9938dd0f"
   },
   "outputs": [],
   "source": [
    "#check\n",
    "assert len(Predictions) == len(annotations_test), \"Unequal dimensions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b52b92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1650859253787,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "97b52b92",
    "outputId": "77264e98-8ac8-45ff-f22a-8414381d0bd0"
   },
   "outputs": [],
   "source": [
    "Predictions.index = annotations_test.index\n",
    "annotations_test['prediction'] = Predictions['mean']\n",
    "Label_Test['prediction']=annotations_test.set_index('img_name')['prediction']\n",
    "Label_Test['prediction'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfad7cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20601,
     "status": "ok",
     "timestamp": 1650859274384,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "4bfad7cc",
    "outputId": "40943c57-b93f-4fd5-b7dd-351f41309ea2"
   },
   "outputs": [],
   "source": [
    "#Store results\n",
    "\n",
    "if not os.path.isdir('drive/MyDrive/Colab Notebooks/output_summary/'):\n",
    "    os.mkdir('drive/MyDrive/Colab Notebooks/output_summary/')\n",
    "\n",
    "try:\n",
    "    Summary=pd.read_hdf('drive/MyDrive/Colab Notebooks/output_summary/Test Results.h5',key='df')\n",
    "except:\n",
    "    Summary = pd.DataFrame(columns=['test loss','test accuracy'])\n",
    "\n",
    "    \n",
    "test_results = pd.Series({\n",
    "            'test loss':epoch_loss.mean(),\n",
    "            'test accuracy':epoch_accuracy.mean()})\n",
    "Summary.loc[model_name] = test_results\n",
    "Summary.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Test Results.h5',key='df')\n",
    "\n",
    "\n",
    "test_results.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Test Results.h5',key=model_name)\n",
    "epoch_loss.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/epoch_loss.h5',key=model_name)\n",
    "epoch_accuracy.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/epoch_accuracy.h5',key=model_name)\n",
    "Predictions.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Predictions by seed.h5',key=model_name)\n",
    "Label_Test.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Predictions.h5',key=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ab30d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1650859729666,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "037ab30d",
    "outputId": "81fbf814-a1b9-41de-a145-0e19cc95c9fb"
   },
   "outputs": [],
   "source": [
    "Label_Test=pd.read_hdf('drive/MyDrive/Colab Notebooks/output_summary/Predictions.h5',key=model_name)\n",
    "Label_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wNiXoPxJC7R5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1650859730765,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "wNiXoPxJC7R5",
    "outputId": "0ff3dd74-e71c-4287-cdcc-ef191041931b"
   },
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799af70",
   "metadata": {
    "id": "7799af70"
   },
   "source": [
    "# Portfolio Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db7852",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650859730766,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "e9db7852"
   },
   "outputs": [],
   "source": [
    "pred_field = 'prediction'\n",
    "return_field = 'Ret_month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf21032",
   "metadata": {
    "executionInfo": {
     "elapsed": 1162,
     "status": "ok",
     "timestamp": 1650859731922,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "fdf21032"
   },
   "outputs": [],
   "source": [
    "y_pred = Label_Test.set_index(['Date','StockID'])[pred_field].unstack()\n",
    "return_next_per = Label_Test.set_index(['Date','StockID'])[return_field].unstack()\n",
    "marketcap = Label_Test.set_index(['Date','StockID'])['MarketCap'].unstack()\n",
    "vol = Label_Test.set_index(['Date','StockID'])['EWMA_vol'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9365c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1650859731923,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "4fe9365c"
   },
   "outputs": [],
   "source": [
    "# to monitor the performance of the model\n",
    "# stocks are split into 10 deciles based on the factor value generated by the model\n",
    "y_rank = y_pred.rank(axis=1)\n",
    "y_count = y_rank.max(axis=1)\n",
    "#split stocks on each date into deciles\n",
    "y_normalize = y_rank.div(y_count,axis=0).sub(0.1/y_count,axis=0) * 10\n",
    "decile_portfolio = np.floor(y_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df348553",
   "metadata": {
    "executionInfo": {
     "elapsed": 4539,
     "status": "ok",
     "timestamp": 1650859736460,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "df348553"
   },
   "outputs": [],
   "source": [
    "#the weighting scheme within each decile can be:\n",
    "# equally-weighted\n",
    "# value-weighted\n",
    "Portfolio_Returns = {}\n",
    "EW = {}\n",
    "VW = {}\n",
    "\n",
    "#portfolio weights\n",
    "EW_w = {} #equally weighted portfolio\n",
    "VW_w = {} # value (market capitalization) weighted portfolios\n",
    "\n",
    "Count = {}\n",
    "for i in range(0,10):\n",
    "        port = (decile_portfolio==i)\n",
    "        \n",
    "        #equal weight\n",
    "        EW[i+1]=return_next_per.where(port).mean(axis=1)\n",
    "        \n",
    "        if i in [0,9]:\n",
    "            EW_w[i+1]=((port * 1).div(port.sum(axis=1),axis=0)).fillna(0)\n",
    "        \n",
    "        #total number of stocks \n",
    "        Count[i] = port.sum(axis=1)\n",
    "        \n",
    "        #market cap weight\n",
    "        marketcap_port = marketcap.where(port)\n",
    "        marketcap_port = marketcap_port.div(marketcap_port.sum(axis=1),axis=0)\n",
    "        \n",
    "        VW[i+1] = (marketcap_port * return_next_per).sum(axis=1)\n",
    "        if i in [0,9]:\n",
    "            VW_w[i+1]=marketcap_port.fillna(0)\n",
    "            \n",
    "#portfolio weights\n",
    "EW_w = EW_w[10] - EW_w[1]\n",
    "VW_w = VW_w[10] - VW_w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af55d682",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650859736461,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "af55d682"
   },
   "outputs": [],
   "source": [
    "#Vol Scaled Portfolio\n",
    "# this is an experiment: no need to report it \n",
    "# since different stocks have different volatilities,\n",
    "# we would like to hold less of a stock if it is more volatile\n",
    "\n",
    "\n",
    "#demean s.t scores [-0.5,+0.5]\n",
    "y_vol_scale = (y_normalize/10 - 0.5)\n",
    "#adjust the volatility\n",
    "y_vol_scale = y_vol_scale/vol\n",
    "#adjust to have same leverage\n",
    "mult = (EW_w.abs() ).sum(axis=1) / (y_vol_scale.abs() ).sum(axis=1)\n",
    "W_vol_scale  = y_vol_scale.mul(mult,axis=0)\n",
    "\n",
    "Port_vol_scale = (W_vol_scale * return_next_per).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca39c9",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650859736461,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "54ca39c9"
   },
   "outputs": [],
   "source": [
    "\n",
    "Portfolio_Returns['EW'] = EW\n",
    "Portfolio_Returns['VW'] = VW\n",
    "Portfolio_Returns['Vol Controlled'] = Port_vol_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcW9R6WP5nIw",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650859736461,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "mcW9R6WP5nIw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae383c",
   "metadata": {
    "executionInfo": {
     "elapsed": 1106,
     "status": "ok",
     "timestamp": 1650859737564,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "a5ae383c"
   },
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    Portfolio_Returns['EW'],axis=1).to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Portfolio_Returns_EW.h5',key=model_name)\n",
    "pd.concat(\n",
    "    Portfolio_Returns['VW'],axis=1).to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Portfolio_Returns_VW.h5',key=model_name)\n",
    "Portfolio_Returns['Vol Controlled'].to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Portfolio_Returns_Vol Controlled.h5',key=model_name)\n",
    "\n",
    "EW_w.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Equal_Weight_Portfolio.h5',key=model_name)\n",
    "\n",
    "VW_w.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Value_Weight_Portfolio.h5',key=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cbd6e",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650859737564,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "90e62f67"
   },
   "source": [
    "# Compute Performance of This Single Strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28f404",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650859737565,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "6e28f404"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "def alpha_t(HL):\n",
    "    t_stat = HL.mean()/(\n",
    "        HL.std()/np.sqrt(len(HL)))\n",
    "    return 1 - t.cdf(t_stat, len(HL)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1be21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "executionInfo": {
     "elapsed": 1400,
     "status": "ok",
     "timestamp": 1650859738961,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "daa1be21",
    "outputId": "8402cf7c-6dbc-4739-dfea-d8e6a2f3686a"
   },
   "outputs": [],
   "source": [
    "#p-values of the sharpe ratio\n",
    "rejection = pd.Series()\n",
    "\n",
    "#equal weighted portfolio\n",
    "ret = pd.concat(Portfolio_Returns['EW'],axis=1)\n",
    "HL = ret[10] - ret[1]\n",
    "Dec = pd.concat({\n",
    "    'Ret':ret.mean()*12,\n",
    "    'SR':ret.mean()/ret.std()*(12**0.5)\n",
    "},axis=1)\n",
    "\n",
    "Dec.loc['H-L'] = pd.Series({\n",
    "    'Ret':(HL).mean()*12,\n",
    "    'SR': (HL).mean()/ (HL).std()*(12**0.5)\n",
    "})\n",
    "\n",
    "rejection.loc['Equal-Weight'] = alpha_t(HL)\n",
    "#Turnover\n",
    "portfolio_beginning = EW_w.shift() * (1+return_next_per.shift())\n",
    "scaling_factor = (EW_w.shift() * return_next_per.shift()).sum(axis=1)+1\n",
    "portfolio_beginning = portfolio_beginning.div(scaling_factor,axis=0)\n",
    "TO = EW_w -  portfolio_beginning\n",
    "TO = TO.abs().sum(axis=1).mean()/2\n",
    "\n",
    "\n",
    "#value weighted portfolio\n",
    "ret = pd.concat(Portfolio_Returns['VW'],axis=1)\n",
    "HL = ret[10] - ret[1]\n",
    "Dec2 = pd.concat({\n",
    "    'Ret':ret.mean()*12,\n",
    "    'SR':ret.mean()/ret.std()*(12**0.5)\n",
    "},axis=1)\n",
    "\n",
    "Dec2.loc['H-L'] = pd.Series({\n",
    "    'Ret':(HL).mean()*12,\n",
    "    'SR': (HL).mean()/ (HL).std()*(12**0.5)\n",
    "})\n",
    "rejection.loc['Value-Weight'] = alpha_t(HL)\n",
    "\n",
    "#Turnover\n",
    "portfolio_beginning = VW_w.shift() * (1+return_next_per.shift())\n",
    "scaling_factor = (VW_w.shift() * return_next_per.shift()).sum(axis=1)+1\n",
    "portfolio_beginning = portfolio_beginning.div(scaling_factor,axis=0)\n",
    "TO2 = VW_w -  portfolio_beginning\n",
    "TO2 = TO2.abs().sum(axis=1).mean()/2\n",
    "\n",
    "pd.concat({'Equal-Weight':Dec,\n",
    "          'Value-weight':Dec2},\n",
    "          axis=1).to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Portfolio Stats.h5',key=model_name)\n",
    "pd.concat({'Equal-Weight':Dec,\n",
    "          'Value-weight':Dec2},\n",
    "          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9531483",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1650859738962,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "c9531483",
    "outputId": "785eed0f-3b0c-4aa7-a0fa-2630673211ec"
   },
   "outputs": [],
   "source": [
    "#significance\n",
    "rejection.to_hdf('drive/MyDrive/Colab Notebooks/output_summary/rejection.h5',key=model_name)\n",
    "rejection.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99ee52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1650859738962,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "6d99ee52",
    "outputId": "9c29598a-4df2-461a-8652-aa9e85169021"
   },
   "outputs": [],
   "source": [
    "#turnover \n",
    "portfolio_beginning = W_vol_scale.shift() * (1+return_next_per.shift())\n",
    "scaling_factor = (W_vol_scale.shift() * return_next_per.shift()).sum(axis=1)+1\n",
    "portfolio_beginning = portfolio_beginning.div(scaling_factor,axis=0)\n",
    "\n",
    "TO3 = W_vol_scale -  portfolio_beginning\n",
    "TO3 = TO3.abs().sum(axis=1).mean()/2\n",
    "\n",
    "pd.Series({'Equal-Weight':TO,\n",
    "          'Value-weight':TO2,\n",
    "          'Vol-Scale':TO3,\n",
    "          }).to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Turnover.h5',key=model_name)\n",
    "\n",
    "pd.Series({'Equal-Weight':TO,\n",
    "          'Value-weight':TO2,\n",
    "          'Vol-Scale':TO3,\n",
    "          }).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32870ce7",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1650859738962,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "f6970634"
   },
   "source": [
    "# Factor Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f193762",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1650859738963,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "6f193762",
    "outputId": "1db7f3fd-ad50-49a2-a606-52e99b58f86c"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "mom = pd.read_csv('drive/MyDrive/Colab Notebooks/F-F_Momentum_Factor.csv',index_col=[0])\n",
    "mom.index= [\n",
    "    datetime.datetime(int(np.floor(ind/100)),int(ind %100),28) for ind in mom.index]\n",
    "\n",
    "reversal = pd.read_csv('drive/MyDrive/Colab Notebooks/F-F_ST_Reversal_Factor.csv',index_col=[0])\n",
    "reversal.index= [\n",
    "    datetime.datetime(int(np.floor(ind/100)),int(ind %100),28) for ind in reversal.index]\n",
    "\n",
    "\n",
    "\n",
    "ff5 = pd.read_csv('drive/MyDrive/Colab Notebooks/F-F_Research_Data_5_Factors_2x3.csv',index_col=[0])\n",
    "ff5.index= [\n",
    "    datetime.datetime(int(np.floor(ind/100)),int(ind %100),28) for ind in ff5.index]\n",
    "\n",
    "\n",
    "ff5['Momentum'] = mom\n",
    "ff5['Reversal'] = reversal\n",
    "\n",
    "ff5 /=100\n",
    "ff5= ff5.resample('BM').last().drop('RF',axis=1)\n",
    "ff5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd578e6a",
   "metadata": {
    "executionInfo": {
     "elapsed": 2700,
     "status": "ok",
     "timestamp": 1650859741650,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "fd578e6a"
   },
   "outputs": [],
   "source": [
    "#Grad Cam shows the image most activated when price patterns are volatile?\n",
    "Factor = {}\n",
    "\n",
    "#try lowVol 1/vol\n",
    "y_rank = (1/vol).rank(axis=1)\n",
    "y_count = y_rank.max(axis=1)\n",
    "y_normalize = y_rank.div(y_count,axis=0).sub(0.1/y_count,axis=0) * 10\n",
    "decile_portfolio = np.floor(y_normalize)\n",
    "\n",
    "EW_factor = {}\n",
    "VW_factor = {}\n",
    "\n",
    "for i in range(0,10):\n",
    "        port = (decile_portfolio==i)\n",
    "        \n",
    "        #equal weight\n",
    "        EW_factor[i+1]=return_next_per.where(port).mean(axis=1)\n",
    "        \n",
    "        #market cap weight\n",
    "        marketcap_port = marketcap.where(port)\n",
    "        marketcap_port = marketcap_port.div(marketcap_port.sum(axis=1),axis=0)\n",
    "        \n",
    "        VW_factor[i+1] = (marketcap_port * return_next_per).sum(axis=1)\n",
    "            \n",
    "#portfolio weights\n",
    "Factor['LowVol'] = pd.concat({\n",
    "    'EW':EW_factor[10] - EW_factor[1],\n",
    "    'VW':VW_factor[10] - VW_factor[1],\n",
    "},axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zohsip6m7HgC",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1650859741652,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "Zohsip6m7HgC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GrboSUgc7nf5",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1650859741653,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "GrboSUgc7nf5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d7e00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1650859742437,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "538d7e00",
    "outputId": "32dec0cb-e627-45bc-a260-f21adb9119d7"
   },
   "outputs": [],
   "source": [
    "#Compute factor loadings of CNN model under both value weighted (VW) and equal weighted (EW) setting\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "Summary = {}\n",
    "Factor['LowVol'].index = pd.to_datetime(Factor['LowVol'].index)\n",
    "\n",
    "for w in ['VW','EW']:\n",
    "    \n",
    "    ret = pd.concat(Portfolio_Returns[w],axis=1)\n",
    "    HL = ret[10] - ret[1]\n",
    "\n",
    "    HL.index = pd.to_datetime(HL.index)\n",
    "\n",
    "    ff5['Y'] = HL\n",
    "    ff5.dropna(inplace=True)    \n",
    "    summary_return = {}\n",
    "    \n",
    "    #cnn factor return ~ Famma French 5 factor \n",
    "    reg = OLS(endog = ff5['Y'],\n",
    "              exog = sm.add_constant(ff5[['CMA','HML','Mkt-RF','RMW','SMB']])\n",
    "             ).fit()\n",
    "\n",
    "    summary = reg.params.append(\n",
    "        reg.tvalues.rename(index={ind: ind+' t-stat' for ind in reg.tvalues.index})\n",
    "    ).sort_index()\n",
    "    \n",
    "    summary_return['Famma-French 5 Factor']=summary\n",
    "    \n",
    "    \n",
    "    #cnn factor return ~ Momentum + Reversal \n",
    "    reg = OLS(endog = ff5['Y'],\n",
    "              exog = sm.add_constant(ff5[['Momentum','Reversal']])\n",
    "             ).fit()\n",
    "\n",
    "    summary = reg.params.append(\n",
    "        reg.tvalues.rename(index={ind: ind+' t-stat' for ind in reg.tvalues.index})\n",
    "    ).sort_index()\n",
    "    \n",
    "    summary_return['Momentum/Reversal']=summary\n",
    "    \n",
    "    \n",
    "    dataset_factor = ff5.join(\n",
    "                        pd.concat({\n",
    "                                'LowVol':Factor['LowVol'][w],\n",
    "                                },axis=1)        \n",
    "    ).dropna()\n",
    "            \n",
    "    #cnn factor return ~ LowVol     \n",
    "    reg = OLS(endog = dataset_factor['Y'],\n",
    "              exog = sm.add_constant(dataset_factor['LowVol'])\n",
    "             ).fit()\n",
    "\n",
    "    summary = reg.params.append(\n",
    "        reg.tvalues.rename(index={ind: ind+' t-stat' for ind in reg.tvalues.index})\n",
    "    ).sort_index()\n",
    "    \n",
    "    summary_return['LowVol']=summary\n",
    "        \n",
    "    #cnn factor return ~ All Factors  \n",
    "    reg = OLS(endog = dataset_factor['Y'],\n",
    "              exog = sm.add_constant(dataset_factor.drop('Y',axis=1))\n",
    "             ).fit()\n",
    "\n",
    "    summary = reg.params.append(\n",
    "        reg.tvalues.rename(index={ind: ind+' t-stat' for ind in reg.tvalues.index})\n",
    "    ).sort_index()\n",
    "    \n",
    "    summary_return['All']=summary\n",
    "    \n",
    "    \n",
    "    Summary[w] = pd.concat(summary_return,axis=1)\n",
    "\n",
    "\n",
    "Summary = pd.concat(Summary,axis=1)\n",
    "\n",
    "Summary.loc[['const','const t-stat']].append(\n",
    "    Summary.drop(['const','const t-stat'])\n",
    ").to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Factor_Loadings.h5',key=model_name)\n",
    "\n",
    "Summary.loc[['const','const t-stat']].append(\n",
    "    Summary.drop(['const','const t-stat'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f5d1a6",
   "metadata": {
    "id": "f5f5d1a6"
   },
   "source": [
    "# Compare Performance of different strategies \n",
    "# [this part is used for ROBUSTNESS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b920a21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1650859742438,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "3b920a21",
    "outputId": "28c32a89-e8db-4721-ee0b-debffa8edbd7"
   },
   "outputs": [],
   "source": [
    "#Load Saved Results on Errors & Accuracy\n",
    "loss_validation = []\n",
    "accuracy_validation = []\n",
    "for seed in range(0,5):\n",
    "    print('seed '+str(seed))\n",
    "    name = model_name+'_'+str(seed)    \n",
    "    state = torch.load(\n",
    "        'drive/MyDrive/Colab Notebooks/checkpoint_CNN/'+model_name+'/'+name+'_final.t7')\n",
    "\n",
    "    loss_validation.append(state['log']['test_loss'][-1])\n",
    "    accuracy_validation.append(state['log']['test_error'][-1])\n",
    "loss_validation = np.mean(loss_validation)\n",
    "accuracy_validation = np.mean(accuracy_validation)\n",
    "\n",
    "test_results = pd.read_hdf('drive/MyDrive/Colab Notebooks/output_summary/Test Results.h5',\n",
    "                           key=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6b97d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 3444,
     "status": "ok",
     "timestamp": 1650859745876,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "f2d6b97d",
    "outputId": "b8db0aff-0810-4422-ea3e-f7877720283b"
   },
   "outputs": [],
   "source": [
    "stats = {}\n",
    "stats['Loss'] = pd.Series({'V':loss_validation,\n",
    "                           'T':test_results.loc['test loss']})\n",
    "stats['R_squared'] = pd.Series({'V':1- accuracy_validation,\n",
    "                               'T':1- test_results.loc['test accuracy']})\n",
    "\n",
    "stats['Correlation'] = pd.Series({\n",
    "    'pearson':pd.concat([\n",
    "        Label_Test[pred_field], \n",
    "        Label_Test[return_field]],axis=1).corr(method='pearson').iloc[0,1],\n",
    "    'spearman':pd.concat([\n",
    "        Label_Test[pred_field], \n",
    "        Label_Test[return_field]],axis=1).corr(method='spearman').iloc[0,1]})\n",
    "\n",
    "\n",
    "\n",
    "portfolio_return = {}\n",
    "ret = pd.concat(Portfolio_Returns['EW'],axis=1)\n",
    "portfolio_return['EW'] = ret[10] - ret[1]\n",
    "\n",
    "ret = pd.concat(Portfolio_Returns['VW'],axis=1)\n",
    "portfolio_return['VW'] = ret[10] - ret[1]\n",
    "\n",
    "portfolio_return['Vol Controlled']  = Portfolio_Returns['Vol Controlled']\n",
    "\n",
    "\n",
    "stats['SR'] = pd.Series({col: \n",
    "                         portfolio_return[col].mean() / portfolio_return[col].std() *(12**0.5) \n",
    "                         for col in portfolio_return.keys()})\n",
    "\n",
    "stats['Vol'] = pd.Series({col:portfolio_return[col].std() *(12**0.5) \n",
    "                         for col in portfolio_return.keys()})\n",
    "\n",
    "\n",
    "stats['Max Draw-Down / Vol'] = pd.Series({col:\n",
    "                        (portfolio_return[col].cumsum().cummax() - portfolio_return[col].cumsum()).max()\n",
    "                        for col in portfolio_return.keys()}) / stats['Vol']\n",
    "pd.concat(stats).to_frame(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106a472",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650859745876,
     "user": {
      "displayName": "Tony Tan",
      "userId": "01264543888653027516"
     },
     "user_tz": -480
    },
    "id": "d106a472"
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.concat(portfolio_return,axis=1).to_hdf('drive/MyDrive/Colab Notebooks/output_summary/portfolio_return.h5',key=model_name)\n",
    "pd.concat(stats).to_hdf('drive/MyDrive/Colab Notebooks/output_summary/Robustness.h5',key=model_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "d1234a79"
   ],
   "machine_shape": "hm",
   "name": "CNN Training_Evaluation_Regression_Model-Sparse Linear Layer.ipynb",
   "provenance": [
    {
     "file_id": "174ctCxBH-Dt_ZZLtCSh7qWgf3QdUNkUL",
     "timestamp": 1650627573765
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
