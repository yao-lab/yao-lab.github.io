{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "registered-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-shelter",
   "metadata": {},
   "source": [
    "# The objective of this competition is to use historical loan application data to predict whether or not an applicant will be able to repay a loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-context",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conventional-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./application_train.csv\")\n",
    "test_data = pd.read_csv(\"./application_test.csv\")\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "major-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.read_csv(\"./bureau.csv\")\n",
    "#bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "three-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_balance = pd.read_csv(\"./POS_CASH_balance.csv\")\n",
    "#pos_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "heard-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "pte_appli = pd.read_csv(\"./previous_application.csv\")\n",
    "#pte_appli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affected-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv(\"./credit_card_balance.csv\")\n",
    "#credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-solid",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "colored-elephant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    282686\n",
       "1     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.TARGET.value_counts() ## imbalanced data\n",
    "#train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-destination",
   "metadata": {},
   "source": [
    "## Label Encoding and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complex-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (307511, 243)\n",
      "Testing dataset shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "#Label Encoding\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in train_data:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(train_data[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(train_data[col])\n",
    "            # Transform both training and testing data\n",
    "            train_data[col] = le.transform(train_data[col])\n",
    "            test_data[col] = le.transform(test_data[col])\n",
    "\n",
    "# one-hot encoding of categorical variables\n",
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "print('Training dataset shape: ', train_data.shape)\n",
    "print('Testing dataset shape: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "functioning-wednesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 240)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "# Align training data and testing data together\n",
    "labels = train_data['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "train_data, test_data = train_data.align(test_data, join = 'inner', axis = 1)\n",
    "\n",
    "# Add the target back in\n",
    "train_data['TARGET'] = labels\n",
    "\n",
    "print('Training Features shape: ', train_data.shape)\n",
    "print('Testing Features shape: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-hours",
   "metadata": {},
   "source": [
    "## To see if there is anomaly in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "historical-australian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    307511.000000\n",
       "mean      63815.045904\n",
       "std      141275.766519\n",
       "min      -17912.000000\n",
       "25%       -2760.000000\n",
       "50%       -1213.000000\n",
       "75%        -289.000000\n",
       "max      365243.000000\n",
       "Name: DAYS_EMPLOYED, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['DAYS_EMPLOYED'].describe() # How many days before the application the person started current employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "korean-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\n",
    "plt.xlabel('Days Employment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "indian-qatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an anomalous flag column\n",
    "train_data['DAYS_EMPLOYED_ANOM'] = train_data[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "train_data['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "train_data['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\n",
    "plt.xlabel('Days Employment');\n",
    "# now the data seems much more normal than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "animated-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same procedure to testing dataset\n",
    "test_data['DAYS_EMPLOYED_ANOM'] = test_data[\"DAYS_EMPLOYED\"] == 365243\n",
    "test_data[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-vanilla",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-orchestra",
   "metadata": {},
   "source": [
    "## Features from other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "injured-planning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Groupby the client id (SK_ID_CURR), count the number of previous loans, and rename the column\n",
    "previous_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\n",
    "# DPD (days past due) during the month of previous credit\n",
    "pos_data = pos_balance.groupby(['SK_ID_CURR'], as_index = False)[\"SK_DPD\"].mean().rename(columns = {'SK_DPD': 'mean_of_SK_DPD'})\n",
    "# Interest rate normalized on previous credit\n",
    "pte_data = pte_appli.groupby(['SK_ID_CURR'], as_index = False)['RATE_INTEREST_PRIVILEGED'].mean().rename(columns = {'RATE_INTEREST_PRIVILEGED': 'mean_of_RATE_INTEREST_PRIVILEGED'})\n",
    "#Credit card limit during the month of the previous credit\n",
    "credit_data = credit.groupby(['SK_ID_CURR'], as_index = False)['AMT_CREDIT_LIMIT_ACTUAL'].mean().rename(columns = {'AMT_CREDIT_LIMIT_ACTUAL': 'mean_of_AMT_CREDIT_LIMIT_ACTUAL'})\n",
    "#Balance during the month of previous credit\n",
    "balance_data = credit.groupby(['SK_ID_CURR'], as_index = False)['AMT_BALANCE'].mean().rename(columns = {'AMT_BALANCE': 'mean_of_AMT_BALANCE'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hawaiian-airport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DAYS_EMPLOYED_ANOM</th>\n",
       "      <th>previous_loan_counts</th>\n",
       "      <th>mean_of_SK_DPD</th>\n",
       "      <th>mean_of_RATE_INTEREST_PRIVILEGED</th>\n",
       "      <th>mean_of_AMT_CREDIT_LIMIT_ACTUAL</th>\n",
       "      <th>mean_of_AMT_BALANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0      100002                   0             0                1   \n",
       "1      100003                   0             0                0   \n",
       "2      100004                   1             1                1   \n",
       "3      100006                   0             0                1   \n",
       "4      100007                   0             0                1   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          202500.0    406597.5      24700.5         351000.0   \n",
       "1             0          270000.0   1293502.5      35698.5        1129500.0   \n",
       "2             0           67500.0    135000.0       6750.0         135000.0   \n",
       "3             0          135000.0    312682.5      29686.5         297000.0   \n",
       "4             0          121500.0    513000.0      21865.5         513000.0   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  ...  WALLSMATERIAL_MODE_Wooden  \\\n",
       "0                    0.018801  ...                          0   \n",
       "1                    0.003541  ...                          0   \n",
       "2                    0.010032  ...                          0   \n",
       "3                    0.008019  ...                          0   \n",
       "4                    0.028663  ...                          0   \n",
       "\n",
       "   EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  TARGET  \\\n",
       "0                       1                        0       1   \n",
       "1                       1                        0       0   \n",
       "2                       0                        0       0   \n",
       "3                       0                        0       0   \n",
       "4                       0                        0       0   \n",
       "\n",
       "   DAYS_EMPLOYED_ANOM  previous_loan_counts  mean_of_SK_DPD  \\\n",
       "0               False                   8.0             0.0   \n",
       "1               False                   4.0             0.0   \n",
       "2               False                   2.0             0.0   \n",
       "3               False                   0.0             0.0   \n",
       "4               False                   1.0             0.0   \n",
       "\n",
       "   mean_of_RATE_INTEREST_PRIVILEGED  mean_of_AMT_CREDIT_LIMIT_ACTUAL  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                         270000.0   \n",
       "4                               0.0                              0.0   \n",
       "\n",
       "   mean_of_AMT_BALANCE  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join to the training dataframe from other dataset\n",
    "train_data = train_data.merge(previous_loan_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "train_data = train_data.merge(pos_data, on = 'SK_ID_CURR', how = 'left')\n",
    "train_data = train_data.merge(pte_data, on = 'SK_ID_CURR', how = 'left')\n",
    "train_data = train_data.merge(credit_data, on = 'SK_ID_CURR', how = 'left')\n",
    "train_data = train_data.merge(balance_data, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "\n",
    "# Fill the missing values with 0 \n",
    "train_data['previous_loan_counts'] = train_data['previous_loan_counts'].fillna(0)\n",
    "train_data['mean_of_SK_DPD'] = train_data['mean_of_SK_DPD'].fillna(0)\n",
    "train_data['mean_of_RATE_INTEREST_PRIVILEGED'] = train_data['mean_of_RATE_INTEREST_PRIVILEGED'].fillna(0)\n",
    "train_data['mean_of_AMT_CREDIT_LIMIT_ACTUAL'] = train_data['mean_of_AMT_CREDIT_LIMIT_ACTUAL'].fillna(0)\n",
    "train_data['mean_of_AMT_BALANCE'] = train_data['mean_of_AMT_BALANCE'].fillna(0)\n",
    "\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intelligent-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing for testing dataset\n",
    "test_data = test_data.merge(previous_loan_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "test_data = test_data.merge(pos_data, on = 'SK_ID_CURR', how = 'left')\n",
    "test_data = test_data.merge(pte_data, on = 'SK_ID_CURR', how = 'left')\n",
    "test_data = test_data.merge(credit_data, on = 'SK_ID_CURR', how = 'left')\n",
    "test_data = test_data.merge(balance_data, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "\n",
    "# Fill the missing values with 0 \n",
    "test_data['previous_loan_counts'] = test_data['previous_loan_counts'].fillna(0)\n",
    "test_data['mean_of_SK_DPD'] = test_data['mean_of_SK_DPD'].fillna(0)\n",
    "test_data['mean_of_RATE_INTEREST_PRIVILEGED'] = test_data['mean_of_RATE_INTEREST_PRIVILEGED'].fillna(0)\n",
    "test_data['mean_of_AMT_CREDIT_LIMIT_ACTUAL'] = test_data['mean_of_AMT_CREDIT_LIMIT_ACTUAL'].fillna(0)\n",
    "test_data['mean_of_AMT_BALANCE'] = test_data['mean_of_AMT_BALANCE'].fillna(0)\n",
    "\n",
    "\n",
    "#test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-convertible",
   "metadata": {},
   "source": [
    "## Domain Knowledge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "outstanding-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['CREDIT_INCOME_PERCENT'] = train_data['AMT_CREDIT'] / train_data['AMT_INCOME_TOTAL']\n",
    "train_data['ANNUITY_INCOME_PERCENT'] = train_data['AMT_ANNUITY'] / train_data['AMT_INCOME_TOTAL']\n",
    "test_data['CREDIT_INCOME_PERCENT'] = test_data['AMT_CREDIT'] / test_data['AMT_INCOME_TOTAL']\n",
    "test_data['ANNUITY_INCOME_PERCENT'] = test_data['AMT_ANNUITY'] / test_data['AMT_INCOME_TOTAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "soviet-timber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive Correlations:\n",
      " FLAG_DOCUMENT_3                                      0.044346\n",
      "REG_CITY_NOT_LIVE_CITY                               0.044395\n",
      "FLAG_EMP_PHONE                                       0.045982\n",
      "mean_of_AMT_BALANCE                                  0.048523\n",
      "NAME_EDUCATION_TYPE_Secondary / secondary special    0.049824\n",
      "REG_CITY_NOT_WORK_CITY                               0.050994\n",
      "DAYS_ID_PUBLISH                                      0.051457\n",
      "CODE_GENDER_M                                        0.054713\n",
      "DAYS_LAST_PHONE_CHANGE                               0.055218\n",
      "NAME_INCOME_TYPE_Working                             0.057481\n",
      "REGION_RATING_CLIENT                                 0.058899\n",
      "REGION_RATING_CLIENT_W_CITY                          0.060893\n",
      "DAYS_EMPLOYED                                        0.074958\n",
      "DAYS_BIRTH                                           0.078239\n",
      "TARGET                                               1.000000\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Most Negative Correlations:\n",
      " EXT_SOURCE_3                           -0.178919\n",
      "EXT_SOURCE_2                           -0.160472\n",
      "EXT_SOURCE_1                           -0.155317\n",
      "NAME_EDUCATION_TYPE_Higher education   -0.056593\n",
      "CODE_GENDER_F                          -0.054704\n",
      "NAME_INCOME_TYPE_Pensioner             -0.046209\n",
      "ORGANIZATION_TYPE_XNA                  -0.045987\n",
      "DAYS_EMPLOYED_ANOM                     -0.045987\n",
      "FLOORSMAX_AVG                          -0.044003\n",
      "FLOORSMAX_MEDI                         -0.043768\n",
      "FLOORSMAX_MODE                         -0.043226\n",
      "EMERGENCYSTATE_MODE_No                 -0.042201\n",
      "HOUSETYPE_MODE_block of flats          -0.040594\n",
      "AMT_GOODS_PRICE                        -0.039645\n",
      "REGION_POPULATION_RELATIVE             -0.037227\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find correlations with the target and sort\n",
    "correlations = train_data.corr()['TARGET'].sort_values()\n",
    "\n",
    "# Display correlations\n",
    "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-husband",
   "metadata": {},
   "source": [
    "# Preprocessing for missing data and standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cordless-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rural-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ids\n",
    "train_ids = train_data['SK_ID_CURR']\n",
    "test_ids = test_data['SK_ID_CURR']\n",
    "\n",
    "# Drop the ids and target from the training data\n",
    "train = train_data.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "test = test_data.drop(columns = ['SK_ID_CURR'])\n",
    "\n",
    "# Extract feature names\n",
    "features = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "breathing-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing data\n",
    "\n",
    "# Median imputation of missing values\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "# Fit on the training data\n",
    "imputer.fit(train)\n",
    "\n",
    "# Transform both training and testing data\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "confident-trading",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Standardizing\n",
    "# Standardize the dataset’s features onto unit scale (mean = 0 and variance = 1)\n",
    "\n",
    "# fit on the training set and transform on the training and test set.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "formal-viewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data features shape:  (307511, 246)\n",
      "Testing data features shape:  (48744, 246)\n"
     ]
    }
   ],
   "source": [
    "print('Training data features shape: ', train.shape)\n",
    "print('Testing data features shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-steal",
   "metadata": {},
   "source": [
    "# No feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "experimental-cannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data features shape:  (307511, 246)\n",
      "Testing data features shape:  (48744, 246)\n"
     ]
    }
   ],
   "source": [
    "train_all = train.copy()\n",
    "test_all = test.copy()\n",
    "print('Training data features shape: ', train_all.shape)\n",
    "print('Testing data features shape: ', test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-avenue",
   "metadata": {},
   "source": [
    "# Feature Selection -- PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bigger-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "terminal-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95) # choose the minimum number of principal components such that 95% of the variance is retained\n",
    "# Fit PCA on training set.\n",
    "pca.fit(train) # fitting PCA on the training set only\n",
    "# Apply the mapping to both the training set and the testing set.\n",
    "train = pca.transform(train)\n",
    "test = pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "invalid-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data features shape:  (307511, 173)\n",
      "Testing data features shape:  (48744, 173)\n"
     ]
    }
   ],
   "source": [
    "print('Training data features shape: ', train.shape)\n",
    "print('Testing data features shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-minneapolis",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-timing",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "prime-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Make the model with the specified regularization parameter\n",
    "log_reg = LogisticRegression(C = 0.001)\n",
    "log_reg_all = LogisticRegression(C = 0.001)\n",
    "\n",
    "# Train on the training data\n",
    "log_reg.fit(train, labels) # labels = train_data['TARGET']\n",
    "log_reg_all.fit(train_all, labels)\n",
    "\n",
    "# Make predictions\n",
    "# Make sure to select the second column only\n",
    "log_reg_pred = log_reg.predict_proba(test)[:, 1]\n",
    "log_reg_pred_all = log_reg_all.predict_proba(test_all)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "different-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-acaf947ee859>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit_logistic['TARGET'] = log_reg_pred\n",
      "<ipython-input-30-acaf947ee859>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit_logistic_all['TARGET'] = log_reg_pred_all\n"
     ]
    }
   ],
   "source": [
    "# Submission dataframe\n",
    "submit_logistic = test_data[['SK_ID_CURR']]\n",
    "submit_logistic['TARGET'] = log_reg_pred\n",
    "\n",
    "submit_logistic_all = test_data[['SK_ID_CURR']]\n",
    "submit_logistic_all['TARGET'] = log_reg_pred_all\n",
    "\n",
    "submit_logistic.to_csv('logistic regression.csv', index = False)\n",
    "submit_logistic_all.to_csv('logistic regression_all.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-celtic",
   "metadata": {},
   "source": [
    "# Score: 0.73276 for logistic regression\n",
    "# Score: 0.74354 for logistic regression without feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-jackson",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "genetic-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Make the random forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, min_samples_leaf = 60, random_state = 50, verbose = 1, n_jobs = -1, oob_score=True)\n",
    "random_forest_all = RandomForestClassifier(n_estimators = 100, min_samples_leaf = 60, random_state = 50, verbose = 1, n_jobs = -1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "suitable-condition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   22.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Train on the training data\n",
    "random_forest.fit(train, labels)\n",
    "random_forest_all.fit(train_all, labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_rf = random_forest.predict_proba(test)[:, 1]\n",
    "predictions_rf_all = random_forest_all.predict_proba(test_all)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "married-washington",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-39bcf5fa9e39>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit_rf['TARGET'] = predictions_rf\n",
      "<ipython-input-33-39bcf5fa9e39>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit_rf_all['TARGET'] = predictions_rf_all\n"
     ]
    }
   ],
   "source": [
    "# Make a submission dataframe\n",
    "submit_rf = test_data[['SK_ID_CURR']]\n",
    "submit_rf['TARGET'] = predictions_rf\n",
    "submit_rf_all = test_data[['SK_ID_CURR']]\n",
    "submit_rf_all['TARGET'] = predictions_rf_all\n",
    "\n",
    "# Save the submission dataframe\n",
    "submit_rf.to_csv('random_forest.csv', index = False)\n",
    "submit_rf_all.to_csv('random_forest_all.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-delivery",
   "metadata": {},
   "source": [
    "# Score: 0.69170 for random forest\n",
    "# Score: 0.73162 for random forest without feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-finnish",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "psychological-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "accessible-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to np arrays\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "train_all = np.array(train_all)\n",
    "test_all = np.array(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hollow-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the kfold object\n",
    "n_folds = 5\n",
    "k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "southwest-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty array for test predictions\n",
    "test_predictions = np.zeros(test.shape[0])\n",
    "test_predictions_all = np.zeros(test_all.shape[0])\n",
    "\n",
    "# Empty array for out of fold validation predictions\n",
    "out_of_fold = np.zeros(train.shape[0])\n",
    "out_of_fold_all = np.zeros(train_all.shape[0])\n",
    "\n",
    "# Lists for recording validation and training scores\n",
    "valid_scores = []\n",
    "train_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "beautiful-hazard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.802448\ttrain's binary_logloss: 0.555706\tvalid's auc: 0.729067\tvalid's binary_logloss: 0.57451\n",
      "[400]\ttrain's auc: 0.842752\ttrain's binary_logloss: 0.514152\tvalid's auc: 0.730231\tvalid's binary_logloss: 0.547259\n",
      "Early stopping, best iteration is:\n",
      "[332]\ttrain's auc: 0.830757\ttrain's binary_logloss: 0.526459\tvalid's auc: 0.730611\tvalid's binary_logloss: 0.555065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:27, 27.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.802684\ttrain's binary_logloss: 0.555683\tvalid's auc: 0.730692\tvalid's binary_logloss: 0.574228\n",
      "[400]\ttrain's auc: 0.842917\ttrain's binary_logloss: 0.514101\tvalid's auc: 0.733681\tvalid's binary_logloss: 0.546386\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttrain's auc: 0.847847\ttrain's binary_logloss: 0.508888\tvalid's auc: 0.73393\tvalid's binary_logloss: 0.542874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:57, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.802138\ttrain's binary_logloss: 0.556337\tvalid's auc: 0.731092\tvalid's binary_logloss: 0.576559\n",
      "[400]\ttrain's auc: 0.84245\ttrain's binary_logloss: 0.51497\tvalid's auc: 0.733342\tvalid's binary_logloss: 0.549222\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttrain's auc: 0.828901\ttrain's binary_logloss: 0.528764\tvalid's auc: 0.734127\tvalid's binary_logloss: 0.557992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:25, 28.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.801946\ttrain's binary_logloss: 0.556536\tvalid's auc: 0.733455\tvalid's binary_logloss: 0.573076\n",
      "[400]\ttrain's auc: 0.842667\ttrain's binary_logloss: 0.514851\tvalid's auc: 0.735549\tvalid's binary_logloss: 0.545624\n",
      "Early stopping, best iteration is:\n",
      "[377]\ttrain's auc: 0.838685\ttrain's binary_logloss: 0.518878\tvalid's auc: 0.735744\tvalid's binary_logloss: 0.54821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:54, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.802878\ttrain's binary_logloss: 0.55542\tvalid's auc: 0.731768\tvalid's binary_logloss: 0.575741\n",
      "[400]\ttrain's auc: 0.843301\ttrain's binary_logloss: 0.513771\tvalid's auc: 0.7327\tvalid's binary_logloss: 0.548635\n",
      "Early stopping, best iteration is:\n",
      "[317]\ttrain's auc: 0.828284\ttrain's binary_logloss: 0.52894\tvalid's auc: 0.733562\tvalid's binary_logloss: 0.558428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [02:20, 28.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# For selected features via PCA\n",
    "# Iterate through each fold\n",
    "for train_indices, valid_indices in tqdm(k_fold.split(train)):\n",
    "\n",
    "    # Training data for the fold\n",
    "    train_features, train_labels = train[train_indices], labels[train_indices]\n",
    "    # Validation data for the fold\n",
    "    valid_features, valid_labels = train[valid_indices], labels[valid_indices]\n",
    "\n",
    "    # Create the model\n",
    "    model = lgb.LGBMClassifier(n_estimators=5000, objective = 'binary', \n",
    "                               class_weight = 'balanced', learning_rate = 0.05, \n",
    "                               reg_alpha = 0.1, reg_lambda = 0.1, max_depth = 6,\n",
    "                               subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "              eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "              eval_names = ['valid', 'train'],\n",
    "              early_stopping_rounds = 100, verbose = 200)\n",
    "\n",
    "    # Record the best iteration\n",
    "    best_iteration = model.best_iteration_\n",
    "\n",
    "    # Make predictions\n",
    "    test_predictions += model.predict_proba(test, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "\n",
    "    # Record the out of fold predictions\n",
    "    out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "\n",
    "    # Record the best score\n",
    "    valid_score = model.best_score_['valid']['auc']\n",
    "    train_score = model.best_score_['train']['auc']\n",
    "\n",
    "    valid_scores.append(valid_score)\n",
    "    train_scores.append(train_score)\n",
    "\n",
    "    # Clean up memory\n",
    "    gc.enable()\n",
    "    del model, train_features, valid_features\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "endangered-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the submission dataframe\n",
    "submission_lgbm = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "endangered-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lgbm.to_csv('lgbm.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-correction",
   "metadata": {},
   "source": [
    "### For all features without selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "novel-express",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.799108\ttrain's binary_logloss: 0.547861\tvalid's auc: 0.75824\tvalid's binary_logloss: 0.561723\n",
      "[400]\ttrain's auc: 0.826194\ttrain's binary_logloss: 0.519572\tvalid's auc: 0.759879\tvalid's binary_logloss: 0.543983\n",
      "Early stopping, best iteration is:\n",
      "[439]\ttrain's auc: 0.830942\ttrain's binary_logloss: 0.514531\tvalid's auc: 0.760095\tvalid's binary_logloss: 0.541025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:22, 22.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.798789\ttrain's binary_logloss: 0.548417\tvalid's auc: 0.760485\tvalid's binary_logloss: 0.561724\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttrain's auc: 0.812421\ttrain's binary_logloss: 0.534234\tvalid's auc: 0.761223\tvalid's binary_logloss: 0.553321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:37, 18.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.79783\ttrain's binary_logloss: 0.549446\tvalid's auc: 0.765784\tvalid's binary_logloss: 0.562599\n",
      "[400]\ttrain's auc: 0.825053\ttrain's binary_logloss: 0.521242\tvalid's auc: 0.767038\tvalid's binary_logloss: 0.544855\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttrain's auc: 0.820763\ttrain's binary_logloss: 0.52575\tvalid's auc: 0.767292\tvalid's binary_logloss: 0.54754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:55, 18.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.798323\ttrain's binary_logloss: 0.548877\tvalid's auc: 0.761415\tvalid's binary_logloss: 0.561163\n",
      "Early stopping, best iteration is:\n",
      "[295]\ttrain's auc: 0.812589\ttrain's binary_logloss: 0.534115\tvalid's auc: 0.763043\tvalid's binary_logloss: 0.551844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:11, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.79874\ttrain's binary_logloss: 0.548347\tvalid's auc: 0.761322\tvalid's binary_logloss: 0.563003\n",
      "[400]\ttrain's auc: 0.826424\ttrain's binary_logloss: 0.519552\tvalid's auc: 0.76268\tvalid's binary_logloss: 0.54552\n",
      "Early stopping, best iteration is:\n",
      "[364]\ttrain's auc: 0.821945\ttrain's binary_logloss: 0.524249\tvalid's auc: 0.762851\tvalid's binary_logloss: 0.548286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:30, 18.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each fold\n",
    "valid_scores = []\n",
    "train_scores = []\n",
    "\n",
    "for train_indices, valid_indices in tqdm(k_fold.split(train_all)):\n",
    "\n",
    "    # Training data for the fold\n",
    "    train_features, train_labels = train_all[train_indices], labels[train_indices]\n",
    "    # Validation data for the fold\n",
    "    valid_features, valid_labels = train_all[valid_indices], labels[valid_indices]\n",
    "\n",
    "    # Create the model\n",
    "    model = lgb.LGBMClassifier(n_estimators=5000, objective = 'binary', \n",
    "                               class_weight = 'balanced', learning_rate = 0.05, \n",
    "                               reg_alpha = 0.1, reg_lambda = 0.1, max_depth = 6,\n",
    "                               subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "              eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "              eval_names = ['valid', 'train'],\n",
    "              early_stopping_rounds = 100, verbose = 200)\n",
    "\n",
    "    # Record the best iteration\n",
    "    best_iteration = model.best_iteration_\n",
    "\n",
    "    # Make predictions\n",
    "    test_predictions_all += model.predict_proba(test_all, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "\n",
    "    # Record the out of fold predictions\n",
    "    out_of_fold_all[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "\n",
    "    # Record the best score\n",
    "    valid_score = model.best_score_['valid']['auc']\n",
    "    train_score = model.best_score_['train']['auc']\n",
    "\n",
    "    valid_scores.append(valid_score)\n",
    "    train_scores.append(train_score)\n",
    "\n",
    "    # Clean up memory\n",
    "    gc.enable()\n",
    "    del model, train_features, valid_features\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "signed-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the submission dataframe\n",
    "submission_lgbm_all = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "rental-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lgbm_all.to_csv('lgbm_all.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-little",
   "metadata": {},
   "source": [
    "# Score: 0.72514 for LightGBM\n",
    "# Score: 0.75137 for LightGBM without feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-bundle",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-charity",
   "metadata": {},
   "source": [
    "## PCA is a good way to select linear related features, and we can see that logistic regression performs really well in this case.\n",
    "## While PCA may miss some features that have non-linear relation with the target, we find that without feature selections, these three models all perform better than selected features which indicate that most of our features have non-linear relations with the target."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
