{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca412f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "embed_path = \"F:\\\\HKUST\\\\Independent Project\\\\data\\\\sgns.financial.word.bin\"\n",
    "model = gensim.models.KeyedVectors.load(embed_path, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cce28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467370"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(model.index_to_key)\n",
    "vocab_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb226447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/467370 is ，\n",
      "word #1/467370 is 的\n",
      "word #2/467370 is 。\n",
      "word #3/467370 is 、\n",
      "word #4/467370 is 在\n",
      "word #5/467370 is 和\n",
      "word #6/467370 is %\n",
      "word #7/467370 is ：\n",
      "word #8/467370 is 了\n",
      "word #9/467370 is “\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(model.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(model.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812aaee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('公司股票', 0.6080008745193481),\n",
       " ('1011.8755', 0.594128429889679),\n",
       " ('036135', 0.5868029594421387),\n",
       " ('5662.60万', 0.5835570096969604),\n",
       " ('股', 0.5812890529632568)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([\"股票\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61265937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SecuCode</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>specret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600068</td>\n",
       "      <td>事件：\\r\\n\\r\\n    葛洲坝2009年新签工程订单同比增长37.9%。公告...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.013306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002008</td>\n",
       "      <td>投资提示\\r\\n\\r\\n　　经过两年调整，公司有望跨入新一轮增长期。1）PCB设备等...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.000854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600707</td>\n",
       "      <td>我们认为，公司基于定向增发顺利进行的角度考虑，对CRT 业务的固定资产采取大笔计...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.031626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600104</td>\n",
       "      <td>自主品牌发展势头良好，2010 年有望扭亏为盈；合资企业上海通用、上海大众盈利能...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.032972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600423</td>\n",
       "      <td>停牌前重大资产收购预期较弱，股价对重组预期反映不明显。根据我们了解，停牌前机构投资者...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.018194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002264</td>\n",
       "      <td>公司公告其全资子公司泉州新华都购物广场有限公司拟以人民币5750 万元收购泉州奇龙物...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>601918</td>\n",
       "      <td>公司四个在产煤矿产能1055 万吨/年，未来三年将有板集矿、口孜东矿和刘庄二期三个...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.002262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>601699</td>\n",
       "      <td>支撑评级的要点\\r\\n\\r\\n    公司煤炭产量的42%为冶金用喷吹煤；随着近期...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.009319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>601699</td>\n",
       "      <td>通过兼并重组可新增煤炭资源储量2 亿吨以上，重建投产后有望新增产能400 万吨以上...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.009319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>601001</td>\n",
       "      <td>集团参与资源整合，长期看同煤集团的资产注入将为公司未来发展提供主要的增长动力；公司...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.003922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600997</td>\n",
       "      <td>公司肥精煤属稀缺资源，可以提供业绩稳定安全边际；而焦炭业务则可以增大公司业绩弹性，...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.001635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600519</td>\n",
       "      <td>茅台酒于元旦正式提价，陈年酒提价幅度大大超越普通酒，陈年酒占收入利润贡献高达三成...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.001746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>002032</td>\n",
       "      <td>“炊具+家用电器”双线战略延伸了产品线，打开成长空间公司产品已经从厨房走入生活，家...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.006383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600383</td>\n",
       "      <td>近期销售情况较好的大公司\\r\\n\\r\\n    公司前11月销售额完成179亿，...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.013110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600348</td>\n",
       "      <td>支撑评级的要点\\r\\n\\r\\n    煤种优势明显。电煤占总产量的73%，其中大部...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.004996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600016</td>\n",
       "      <td>投资提示：\\r\\n\\r\\n    上调民生银行评级至“推荐”，股价上涨潜力30-...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>600281</td>\n",
       "      <td>工信部日前印发《促进中部地区原材料工业结构调整和优化升级方案》的通知，在扶优扶强...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.034413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600460</td>\n",
       "      <td>重要事件：\\r\\n\\r\\n    士兰微是国内为数不多坚持IDM模式的集成电路设计...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.080257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>600460</td>\n",
       "      <td>事件：\\r\\n\\r\\n    公司于 1 月4 日公告非公开增发预案，拟以不低于8...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.080257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600893</td>\n",
       "      <td>09 年军品业务收入规模与年初预计基本一致，预计2010 年军品业务增长继续。公...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.015693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>600823</td>\n",
       "      <td>强势转战商业地产，盈利模式根本转变。增发注资后公司主营业务由经营房地产业务变更为主...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.009551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>600677</td>\n",
       "      <td>2009 年12 月31 日，航天通信全资子公司杭州中汇与萧山建发公司签订了《杭...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.036723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>600510</td>\n",
       "      <td>估值和建议：首次关注，给予“推荐”评级：公司目前股价对应NAV溢价29.33%，2...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.008330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>600198</td>\n",
       "      <td>电子书在2009 年已经开始出货，这是一个好的开始：09 年底浙江移动已开始推广...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.079612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>600649</td>\n",
       "      <td>粤海投资 — 买入\\r\\n\\r\\n    我们认为，粤海投资6.9%的2010 年...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.015407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>600874</td>\n",
       "      <td>粤海投资 — 买入\\r\\n\\r\\n    我们认为，粤海投资6.9%的2010 年...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.004262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>600008</td>\n",
       "      <td>粤海投资 — 买入\\r\\n\\r\\n    我们认为，粤海投资6.9%的2010 年...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.009090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>002187</td>\n",
       "      <td>公司增发收购事宜获证监会核准\\r\\n\\r\\n　　公司今日公告证监会核准公司以20.7...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.004411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>002068</td>\n",
       "      <td>投资要点：\\r\\n\\r\\n    量的增长确定：09 年11 月公告：内蒙乌海4 ...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.007414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000860</td>\n",
       "      <td>白酒业务是公司盈利能力最强的业务，主要有牛栏山二锅头、宁城老窖两块业务。白酒行业利...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.003120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SecuCode                                            content       date  \\\n",
       "0    600068       事件：\\r\\n\\r\\n    葛洲坝2009年新签工程订单同比增长37.9%。公告... 2010-01-04   \n",
       "1    002008    　　投资提示\\r\\n\\r\\n　　经过两年调整，公司有望跨入新一轮增长期。1）PCB设备等... 2010-01-04   \n",
       "2    600707        我们认为，公司基于定向增发顺利进行的角度考虑，对CRT 业务的固定资产采取大笔计... 2010-01-04   \n",
       "3    600104        自主品牌发展势头良好，2010 年有望扭亏为盈；合资企业上海通用、上海大众盈利能... 2010-01-04   \n",
       "4    600423    　　停牌前重大资产收购预期较弱，股价对重组预期反映不明显。根据我们了解，停牌前机构投资者... 2010-01-04   \n",
       "5    002264    　　公司公告其全资子公司泉州新华都购物广场有限公司拟以人民币5750 万元收购泉州奇龙物... 2010-01-04   \n",
       "6    601918       公司四个在产煤矿产能1055 万吨/年，未来三年将有板集矿、口孜东矿和刘庄二期三个... 2010-01-04   \n",
       "7    601699       支撑评级的要点\\r\\n\\r\\n    公司煤炭产量的42%为冶金用喷吹煤；随着近期... 2010-01-04   \n",
       "8    601699       通过兼并重组可新增煤炭资源储量2 亿吨以上，重建投产后有望新增产能400 万吨以上... 2010-01-04   \n",
       "9    601001       集团参与资源整合，长期看同煤集团的资产注入将为公司未来发展提供主要的增长动力；公司... 2010-01-04   \n",
       "10   600997       公司肥精煤属稀缺资源，可以提供业绩稳定安全边际；而焦炭业务则可以增大公司业绩弹性，... 2010-01-04   \n",
       "11   600519        茅台酒于元旦正式提价，陈年酒提价幅度大大超越普通酒，陈年酒占收入利润贡献高达三成... 2010-01-04   \n",
       "12   002032       “炊具+家用电器”双线战略延伸了产品线，打开成长空间公司产品已经从厨房走入生活，家... 2010-01-04   \n",
       "13   600383        近期销售情况较好的大公司\\r\\n\\r\\n    公司前11月销售额完成179亿，... 2010-01-04   \n",
       "14   600348       支撑评级的要点\\r\\n\\r\\n    煤种优势明显。电煤占总产量的73%，其中大部... 2010-01-04   \n",
       "15   600016        投资提示：\\r\\n\\r\\n    上调民生银行评级至“推荐”，股价上涨潜力30-... 2010-01-04   \n",
       "16   600281        工信部日前印发《促进中部地区原材料工业结构调整和优化升级方案》的通知，在扶优扶强... 2010-01-04   \n",
       "17   600460       重要事件：\\r\\n\\r\\n    士兰微是国内为数不多坚持IDM模式的集成电路设计... 2010-01-04   \n",
       "18   600460       事件：\\r\\n\\r\\n    公司于 1 月4 日公告非公开增发预案，拟以不低于8... 2010-01-04   \n",
       "19   600893        09 年军品业务收入规模与年初预计基本一致，预计2010 年军品业务增长继续。公... 2010-01-04   \n",
       "20   600823       强势转战商业地产，盈利模式根本转变。增发注资后公司主营业务由经营房地产业务变更为主... 2010-01-04   \n",
       "21   600677        2009 年12 月31 日，航天通信全资子公司杭州中汇与萧山建发公司签订了《杭... 2010-01-04   \n",
       "22   600510       估值和建议：首次关注，给予“推荐”评级：公司目前股价对应NAV溢价29.33%，2... 2010-01-04   \n",
       "23   600198        电子书在2009 年已经开始出货，这是一个好的开始：09 年底浙江移动已开始推广... 2010-01-04   \n",
       "24   600649       粤海投资 — 买入\\r\\n\\r\\n    我们认为，粤海投资6.9%的2010 年... 2010-01-04   \n",
       "25   600874       粤海投资 — 买入\\r\\n\\r\\n    我们认为，粤海投资6.9%的2010 年... 2010-01-04   \n",
       "26   600008       粤海投资 — 买入\\r\\n\\r\\n    我们认为，粤海投资6.9%的2010 年... 2010-01-04   \n",
       "27   002187    　　公司增发收购事宜获证监会核准\\r\\n\\r\\n　　公司今日公告证监会核准公司以20.7... 2010-01-04   \n",
       "28   002068       投资要点：\\r\\n\\r\\n    量的增长确定：09 年11 月公告：内蒙乌海4 ... 2010-01-04   \n",
       "29   000860       白酒业务是公司盈利能力最强的业务，主要有牛栏山二锅头、宁城老窖两块业务。白酒行业利... 2010-01-04   \n",
       "\n",
       "     specret  \n",
       "0  -0.013306  \n",
       "1  -0.000854  \n",
       "2   0.031626  \n",
       "3   0.032972  \n",
       "4   0.018194  \n",
       "5   0.002592  \n",
       "6   0.002262  \n",
       "7   0.009319  \n",
       "8   0.009319  \n",
       "9   0.003922  \n",
       "10 -0.001635  \n",
       "11  0.001746  \n",
       "12 -0.006383  \n",
       "13 -0.013110  \n",
       "14  0.004996  \n",
       "15  0.022800  \n",
       "16  0.034413  \n",
       "17  0.080257  \n",
       "18  0.080257  \n",
       "19  0.015693  \n",
       "20 -0.009551  \n",
       "21 -0.036723  \n",
       "22 -0.008330  \n",
       "23  0.079612  \n",
       "24  0.015407  \n",
       "25 -0.004262  \n",
       "26 -0.009090  \n",
       "27 -0.004411  \n",
       "28  0.007414  \n",
       "29  0.003120  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import xlwt\n",
    "data = pd.read_parquet(\"F:\\\\HKUST\\\\Independent Project\\\\data\\\\anatxt.parquet.gzip\")\n",
    "#提取所需要的列\n",
    "data=data[['SecuCode','content','create_date']]\n",
    "data1=pd.read_parquet(\"F:\\\\HKUST\\\\Independent Project\\\\data\\\\dsf.parquet.gzip\")\n",
    "#去除specret为空值的行\n",
    "label_data = data1.dropna(axis=0, how='any')\n",
    "#提取所需要的列\n",
    "label_data=label_data[['SecuCode','date','specret']]\n",
    "data.rename(columns={'create_date':'date'},inplace=True)\n",
    "data_final = pd.merge(data, label_data, on=['SecuCode','date'])\n",
    "#去重\n",
    "data_final=data_final.drop_duplicates()\n",
    "#重新按时间排序\n",
    "data_final = data_final.sort_values(\"date\",ascending=True)\n",
    "#重排索引\n",
    "data_final = data_final.reset_index(drop=True)\n",
    "train_start = data_final[data_final.date == \"2010-01-04\"].index.tolist()[0]\n",
    "#去除2010年以前的数据\n",
    "data_final = data_final.iloc[train_start:,:]\n",
    "#重排索引\n",
    "data_final = data_final.reset_index(drop=True)\n",
    "data_final.iloc[:30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee1d9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471213"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac4dc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180034"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_end = data_final[data_final.date == \"2015-01-05\"].index.tolist()[0]\n",
    "train_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41f4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test set\n",
    "train_num = 2000\n",
    "data_trial = data_final.iloc[:train_num, :]\n",
    "test_num = 2000\n",
    "data_test = data_final.iloc[train_num : train_num + test_num, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86a8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "#使用正则表达式筛选中文字符\n",
    "def find_chinese (file):\n",
    "    pattern = re.compile(r'[^\\u4e00-\\u9fa5]')\n",
    "    chinese_txt = re.sub(pattern,'',file)\n",
    "    return chinese_txt\n",
    "\n",
    "#中文分词+保留形容词、动词\n",
    "import jieba.posseg as pseg\n",
    "def cut_word(text):\n",
    "    #精确模式\n",
    "    words = pseg.cut(text)\n",
    "    #jieba_text = ' '.join(jieba_list)\n",
    "    jieba_list = [x.word for x in words if x.flag == 'v' or x.flag =='a']\n",
    "    #jieba_list = []\n",
    "    #single = ['w', 'r', 'ns', 'f', 'p', 'c', 'q', 'n', 'nr', 'm', 'u']\n",
    "    #double = ['nw', 'u', 'm', 't', 'TIME', 'nr', 'PER', 'nz', 'n', 'q', 'ORG', 'f', 'LOC', 'r', 's']\n",
    "    #trible = ['s', 'r', 'LOC', 'f', 'ORG', 'nt', 'n', 'nz', 'PER', 'nr', 'TIME', 't', 'm', 'nw']\n",
    "    #quart = ['s', 'LOC', 'f', 'ORG', 'n', 'nz', 'PER', 'nr', 'TIME', 't', 'm', 'nw']\n",
    "    #for x in words:\n",
    "        #if len(x.word) == 1 and x.flag not in single:\n",
    "            #jieba_list.append(x.word)\n",
    "        #if len(x.word) == 2 and x.flag not in double:\n",
    "            #jieba_list.append(x.word)\n",
    "        #if len(x.word) == 3 and x.flag not in trible:\n",
    "            #jieba_list.append(x.word)\n",
    "        #if len(x.word) >= 4 and x.flag not in quart:\n",
    "            #jieba_list.append(x.word)            \n",
    "    return jieba_list\n",
    "\n",
    "#去除停用词\n",
    "def remove_stopwords(text):\n",
    "    #读取停用词表\n",
    "    stopwords = [line.strip() for line in open('F:\\\\HKUST\\\\Independent Project\\\\data\\\\hit_stopwords.txt','r',encoding='utf-8').readlines()]\n",
    "    seg_txt = [w for w in text if w not in stopwords] # and len(w) > 1]\n",
    "    return seg_txt\n",
    "\n",
    "#文本预处理\n",
    "def text_preprocess(data):\n",
    "    text_word = []\n",
    "    for i in range(data.shape[0]):\n",
    "        #筛选汉字\n",
    "        chinese_news = find_chinese(data.iloc[i, 1])\n",
    "        #中文分词\n",
    "        chinese_cut = cut_word(chinese_news)\n",
    "        #去除停用词\n",
    "        chinese_sentence = remove_stopwords(chinese_cut)\n",
    "        #\n",
    "        text_word.append(chinese_sentence)\n",
    "    return text_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "020563dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\yjq\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.282 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "train_text = text_preprocess(data_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e141967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79468fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def build_vector(text,size,wv):\n",
    "    #创建一个指定大小的数据空间\n",
    "    vec = np.zeros(size).reshape((1,size))\n",
    "    #count是统计有多少词向量\n",
    "    count = 0\n",
    "    #循环所有的词向量进行求和\n",
    "    for w in text:\n",
    "        try:\n",
    "            vec +=  wv[w].reshape((1,size))\n",
    "            count +=1\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    #循环完成后求均值\n",
    "    if count!=0:\n",
    "        vec/=count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d6b4be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030370</td>\n",
       "      <td>-0.056744</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>-0.019255</td>\n",
       "      <td>-0.006017</td>\n",
       "      <td>-0.051193</td>\n",
       "      <td>-0.021314</td>\n",
       "      <td>-0.041546</td>\n",
       "      <td>-0.015571</td>\n",
       "      <td>-0.052761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019219</td>\n",
       "      <td>-0.042735</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>-0.012763</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.015474</td>\n",
       "      <td>-0.015886</td>\n",
       "      <td>-0.012409</td>\n",
       "      <td>-0.001223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016936</td>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.017485</td>\n",
       "      <td>-0.026333</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>-0.022599</td>\n",
       "      <td>-0.037507</td>\n",
       "      <td>-0.040421</td>\n",
       "      <td>-0.008670</td>\n",
       "      <td>-0.062948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>-0.052365</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>-0.011846</td>\n",
       "      <td>0.021361</td>\n",
       "      <td>-0.017130</td>\n",
       "      <td>0.040887</td>\n",
       "      <td>-0.015592</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>-0.000843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042627</td>\n",
       "      <td>-0.040110</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>-0.033423</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>-0.018085</td>\n",
       "      <td>-0.017378</td>\n",
       "      <td>-0.019651</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>-0.055701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021373</td>\n",
       "      <td>-0.043819</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.006600</td>\n",
       "      <td>0.013855</td>\n",
       "      <td>-0.016172</td>\n",
       "      <td>0.018356</td>\n",
       "      <td>-0.021831</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.002710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026494</td>\n",
       "      <td>-0.032739</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>-0.030891</td>\n",
       "      <td>-0.004459</td>\n",
       "      <td>-0.029257</td>\n",
       "      <td>-0.027130</td>\n",
       "      <td>-0.035272</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>-0.058719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>-0.045291</td>\n",
       "      <td>-0.003868</td>\n",
       "      <td>-0.022344</td>\n",
       "      <td>0.021483</td>\n",
       "      <td>-0.019041</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>-0.018807</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>-0.002182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002442</td>\n",
       "      <td>-0.037084</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>-0.034008</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>-0.034323</td>\n",
       "      <td>-0.017156</td>\n",
       "      <td>-0.037992</td>\n",
       "      <td>-0.013556</td>\n",
       "      <td>-0.046378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>-0.049776</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>-0.025305</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>0.015176</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.033797</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.013568</td>\n",
       "      <td>-0.044218</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>-0.031744</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>-0.030468</td>\n",
       "      <td>-0.017588</td>\n",
       "      <td>-0.039741</td>\n",
       "      <td>-0.014720</td>\n",
       "      <td>-0.039966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019947</td>\n",
       "      <td>-0.029277</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>-0.018605</td>\n",
       "      <td>-0.019311</td>\n",
       "      <td>-0.007593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.013160</td>\n",
       "      <td>-0.050687</td>\n",
       "      <td>-0.005089</td>\n",
       "      <td>-0.031645</td>\n",
       "      <td>-0.015809</td>\n",
       "      <td>-0.021044</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.028494</td>\n",
       "      <td>-0.004234</td>\n",
       "      <td>-0.051311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021124</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>0.012744</td>\n",
       "      <td>-0.007744</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.034004</td>\n",
       "      <td>-0.007209</td>\n",
       "      <td>-0.020034</td>\n",
       "      <td>-0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.031829</td>\n",
       "      <td>-0.038783</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>-0.011094</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>-0.032028</td>\n",
       "      <td>-0.020851</td>\n",
       "      <td>-0.028190</td>\n",
       "      <td>-0.007783</td>\n",
       "      <td>-0.042008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012652</td>\n",
       "      <td>-0.032976</td>\n",
       "      <td>0.025470</td>\n",
       "      <td>-0.019662</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>0.029299</td>\n",
       "      <td>-0.008292</td>\n",
       "      <td>-0.016110</td>\n",
       "      <td>-0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.017958</td>\n",
       "      <td>-0.037306</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>-0.032175</td>\n",
       "      <td>-0.014334</td>\n",
       "      <td>-0.021689</td>\n",
       "      <td>-0.031589</td>\n",
       "      <td>-0.020062</td>\n",
       "      <td>-0.010157</td>\n",
       "      <td>-0.050930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021590</td>\n",
       "      <td>-0.033945</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.029812</td>\n",
       "      <td>0.017298</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>-0.010059</td>\n",
       "      <td>-0.027628</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.022150</td>\n",
       "      <td>-0.029276</td>\n",
       "      <td>-0.005971</td>\n",
       "      <td>-0.020165</td>\n",
       "      <td>-0.015178</td>\n",
       "      <td>-0.043475</td>\n",
       "      <td>-0.023401</td>\n",
       "      <td>-0.034398</td>\n",
       "      <td>-0.010269</td>\n",
       "      <td>-0.056414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015680</td>\n",
       "      <td>-0.054162</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.015136</td>\n",
       "      <td>-0.022325</td>\n",
       "      <td>-0.007620</td>\n",
       "      <td>-0.019619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.030370 -0.056744 -0.002491 -0.019255 -0.006017 -0.051193 -0.021314   \n",
       "1     0.016936 -0.048927 -0.017485 -0.026333  0.000292 -0.022599 -0.037507   \n",
       "2     0.042627 -0.040110  0.006933 -0.033423  0.000546 -0.018085 -0.017378   \n",
       "3     0.026494 -0.032739  0.000582 -0.030891 -0.004459 -0.029257 -0.027130   \n",
       "4     0.002442 -0.037084  0.002810 -0.034008  0.003174 -0.034323 -0.017156   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.013568 -0.044218  0.005704 -0.031744 -0.021053 -0.030468 -0.017588   \n",
       "1996  0.013160 -0.050687 -0.005089 -0.031645 -0.015809 -0.021044 -0.007842   \n",
       "1997  0.031829 -0.038783  0.002647 -0.011094  0.003926 -0.032028 -0.020851   \n",
       "1998  0.017958 -0.037306 -0.004900 -0.032175 -0.014334 -0.021689 -0.031589   \n",
       "1999  0.022150 -0.029276 -0.005971 -0.020165 -0.015178 -0.043475 -0.023401   \n",
       "\n",
       "           7         8         9    ...       290       291       292  \\\n",
       "0    -0.041546 -0.015571 -0.052761  ... -0.019219 -0.042735  0.006405   \n",
       "1    -0.040421 -0.008670 -0.062948  ...  0.000385 -0.052365  0.006009   \n",
       "2    -0.019651  0.014278 -0.055701  ... -0.021373 -0.043819 -0.001086   \n",
       "3    -0.035272  0.005148 -0.058719  ... -0.009257 -0.045291 -0.003868   \n",
       "4    -0.037992 -0.013556 -0.046378  ...  0.006737 -0.049776  0.012071   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995 -0.039741 -0.014720 -0.039966  ... -0.019947 -0.029277  0.016114   \n",
       "1996 -0.028494 -0.004234 -0.051311  ... -0.021124 -0.044503  0.012744   \n",
       "1997 -0.028190 -0.007783 -0.042008  ... -0.012652 -0.032976  0.025470   \n",
       "1998 -0.020062 -0.010157 -0.050930  ... -0.021590 -0.033945  0.000341   \n",
       "1999 -0.034398 -0.010269 -0.056414  ... -0.015680 -0.054162  0.012694   \n",
       "\n",
       "           293       294       295       296       297       298       299  \n",
       "0    -0.012763  0.010322  0.005741  0.015474 -0.015886 -0.012409 -0.001223  \n",
       "1    -0.011846  0.021361 -0.017130  0.040887 -0.015592  0.001310 -0.000843  \n",
       "2    -0.006600  0.013855 -0.016172  0.018356 -0.021831  0.004363  0.002710  \n",
       "3    -0.022344  0.021483 -0.019041  0.010498 -0.018807  0.005045 -0.002182  \n",
       "4    -0.025305  0.023371  0.015176  0.013056  0.001423 -0.033797  0.001150  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.004479  0.003796  0.012122  0.023347 -0.018605 -0.019311 -0.007593  \n",
       "1996 -0.007744  0.007178  0.007925  0.034004 -0.007209 -0.020034 -0.003400  \n",
       "1997 -0.019662  0.011115 -0.006008  0.029299 -0.008292 -0.016110 -0.003989  \n",
       "1998 -0.029812  0.017298 -0.016667  0.014367 -0.010059 -0.027628  0.000805  \n",
       "1999 -0.001328  0.003635  0.004819  0.015136 -0.022325 -0.007620 -0.019619  \n",
       "\n",
       "[2000 rows x 300 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = [build_vector(train_text[i],300,model) for i in range(train_num)]\n",
    "#train_data = np.resize(train_data,(train_num,300))\n",
    "train_data = [train_data[i][0] for i in range(train_num)]\n",
    "trainX = pd.DataFrame(train_data)\n",
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de139637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.013306\n",
       "1      -0.000854\n",
       "2       0.031626\n",
       "3       0.032972\n",
       "4       0.018194\n",
       "          ...   \n",
       "1995    0.013175\n",
       "1996    0.013175\n",
       "1997    0.013175\n",
       "1998   -0.003384\n",
       "1999   -0.043035\n",
       "Name: specret, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY = data_trial['specret']\n",
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22bc13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = text_preprocess(data_test)\n",
    "test_data = [build_vector(test_text[i],300,model) for i in range(test_num)]\n",
    "#test_data = np.resize(test_data,(test_num,300))\n",
    "test_data = [test_data[i][0] for i in range(test_num)]\n",
    "testX = pd.DataFrame(test_data)\n",
    "testY = data_test['specret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "179eef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#初始化SVR\n",
    "svr = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=5,\n",
    "                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                               \"gamma\": np.logspace(-2, 2, 5)})\n",
    "\n",
    "#训练\n",
    "svr.fit(trainX, trainY)\n",
    "\n",
    "#测试\n",
    "y_svr = svr.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "763e98f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>svr_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr_p</th>\n",
       "      <td>0.093496</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p     svr_p\n",
       "true_p  1.000000  0.093496\n",
       "svr_p   0.093496  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'svr_p':y_svr})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138e6a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>svr_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr_p</th>\n",
       "      <td>0.037969</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p     svr_p\n",
       "true_p  1.000000  0.037969\n",
       "svr_p   0.037969  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "305fe6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regr = LinearRegression()\n",
    "regr.fit(trainX, trainY)\n",
    "y_lr =regr.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3aaa887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>lr_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_p</th>\n",
       "      <td>0.061896</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p      lr_p\n",
       "true_p  1.000000  0.061896\n",
       "lr_p    0.061896  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'lr_p':y_lr})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8403aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>lr_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_p</th>\n",
       "      <td>0.051656</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p      lr_p\n",
       "true_p  1.000000  0.051656\n",
       "lr_p    0.051656  1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a218f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "regressor.fit(trainX, trainY)\n",
    "y_rf = regressor.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e182668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>rf_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_p</th>\n",
       "      <td>0.080494</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p      rf_p\n",
       "true_p  1.000000  0.080494\n",
       "rf_p    0.080494  1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'rf_p':y_rf})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b9aba9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>rf_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_p</th>\n",
       "      <td>0.038991</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p      rf_p\n",
       "true_p  1.000000  0.038991\n",
       "rf_p    0.038991  1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ce0abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification label\n",
    "trainXY = pd.concat([trainX,trainY],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4d3546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>specret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003445</td>\n",
       "      <td>-0.044249</td>\n",
       "      <td>-0.003241</td>\n",
       "      <td>-0.028130</td>\n",
       "      <td>-0.016566</td>\n",
       "      <td>-0.030403</td>\n",
       "      <td>-0.026434</td>\n",
       "      <td>-0.039335</td>\n",
       "      <td>-0.023922</td>\n",
       "      <td>-0.056787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052098</td>\n",
       "      <td>-0.013640</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.018535</td>\n",
       "      <td>-0.017792</td>\n",
       "      <td>-0.007239</td>\n",
       "      <td>-0.001484</td>\n",
       "      <td>-0.109493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008619</td>\n",
       "      <td>-0.038859</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>-0.030389</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>-0.038488</td>\n",
       "      <td>-0.025095</td>\n",
       "      <td>-0.026551</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.060233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062234</td>\n",
       "      <td>-0.021404</td>\n",
       "      <td>-0.002666</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>-0.010561</td>\n",
       "      <td>-0.001750</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>-0.108201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000741</td>\n",
       "      <td>-0.019934</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-0.033181</td>\n",
       "      <td>-0.002265</td>\n",
       "      <td>-0.031800</td>\n",
       "      <td>-0.023553</td>\n",
       "      <td>-0.022829</td>\n",
       "      <td>-0.009285</td>\n",
       "      <td>-0.040819</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035982</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.015651</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>-0.002275</td>\n",
       "      <td>-0.031382</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>-0.108201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007850</td>\n",
       "      <td>-0.043581</td>\n",
       "      <td>-0.005605</td>\n",
       "      <td>-0.043905</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>-0.039932</td>\n",
       "      <td>-0.032041</td>\n",
       "      <td>-0.028137</td>\n",
       "      <td>-0.006023</td>\n",
       "      <td>-0.044841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>-0.015326</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.016203</td>\n",
       "      <td>-0.016477</td>\n",
       "      <td>-0.010663</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>-0.108201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036933</td>\n",
       "      <td>-0.050908</td>\n",
       "      <td>-0.007437</td>\n",
       "      <td>-0.011669</td>\n",
       "      <td>-0.008288</td>\n",
       "      <td>-0.030208</td>\n",
       "      <td>-0.027219</td>\n",
       "      <td>-0.046125</td>\n",
       "      <td>-0.016191</td>\n",
       "      <td>-0.055026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039485</td>\n",
       "      <td>-0.002200</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>-0.002486</td>\n",
       "      <td>0.032428</td>\n",
       "      <td>-0.013547</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>-0.002339</td>\n",
       "      <td>-0.108190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.025979</td>\n",
       "      <td>-0.041539</td>\n",
       "      <td>-0.016066</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.030291</td>\n",
       "      <td>-0.013697</td>\n",
       "      <td>-0.005430</td>\n",
       "      <td>-0.020395</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.050807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050246</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>-0.026431</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>-0.020672</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>-0.015091</td>\n",
       "      <td>-0.033542</td>\n",
       "      <td>-0.014857</td>\n",
       "      <td>0.112143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.029424</td>\n",
       "      <td>-0.029367</td>\n",
       "      <td>-0.005116</td>\n",
       "      <td>-0.035868</td>\n",
       "      <td>-0.002861</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>-0.017111</td>\n",
       "      <td>-0.038410</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>-0.043911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037982</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>-0.018588</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>-0.002376</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>-0.033297</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.115613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.015593</td>\n",
       "      <td>-0.022089</td>\n",
       "      <td>-0.012384</td>\n",
       "      <td>-0.038723</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>-0.020793</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.047872</td>\n",
       "      <td>-0.008691</td>\n",
       "      <td>-0.052499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055064</td>\n",
       "      <td>-0.017246</td>\n",
       "      <td>-0.020152</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.014514</td>\n",
       "      <td>0.038058</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0.122027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.026802</td>\n",
       "      <td>-0.035845</td>\n",
       "      <td>-0.010175</td>\n",
       "      <td>-0.038047</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>-0.030837</td>\n",
       "      <td>-0.024382</td>\n",
       "      <td>-0.023383</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>-0.054278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042980</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>-0.017777</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>-0.008229</td>\n",
       "      <td>0.016651</td>\n",
       "      <td>-0.001783</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.122027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.025796</td>\n",
       "      <td>-0.023392</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>-0.016628</td>\n",
       "      <td>-0.012955</td>\n",
       "      <td>-0.014010</td>\n",
       "      <td>-0.019124</td>\n",
       "      <td>-0.029414</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>-0.051938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032686</td>\n",
       "      <td>-0.018927</td>\n",
       "      <td>-0.005718</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>-0.014818</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>-0.003021</td>\n",
       "      <td>-0.028293</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.123939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.003445 -0.044249 -0.003241 -0.028130 -0.016566 -0.030403 -0.026434   \n",
       "1     0.008619 -0.038859  0.005425 -0.030389  0.015094 -0.038488 -0.025095   \n",
       "2     0.000741 -0.019934  0.004980 -0.033181 -0.002265 -0.031800 -0.023553   \n",
       "3     0.007850 -0.043581 -0.005605 -0.043905  0.008349 -0.039932 -0.032041   \n",
       "4     0.036933 -0.050908 -0.007437 -0.011669 -0.008288 -0.030208 -0.027219   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.025979 -0.041539 -0.016066 -0.013337 -0.030291 -0.013697 -0.005430   \n",
       "1996  0.029424 -0.029367 -0.005116 -0.035868 -0.002861 -0.030018 -0.017111   \n",
       "1997  0.015593 -0.022089 -0.012384 -0.038723  0.011333 -0.020793  0.000214   \n",
       "1998  0.026802 -0.035845 -0.010175 -0.038047  0.006858 -0.030837 -0.024382   \n",
       "1999  0.025796 -0.023392 -0.003630 -0.016628 -0.012955 -0.014010 -0.019124   \n",
       "\n",
       "             7         8         9  ...       291       292       293  \\\n",
       "0    -0.039335 -0.023922 -0.056787  ... -0.052098 -0.013640  0.006287   \n",
       "1    -0.026551 -0.003148 -0.060233  ... -0.062234 -0.021404 -0.002666   \n",
       "2    -0.022829 -0.009285 -0.040819  ... -0.035982 -0.002273 -0.008725   \n",
       "3    -0.028137 -0.006023 -0.044841  ... -0.050063  0.000331 -0.015326   \n",
       "4    -0.046125 -0.016191 -0.055026  ... -0.039485 -0.002200 -0.004913   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995 -0.020395 -0.004874 -0.050807  ... -0.050246  0.008815 -0.026431   \n",
       "1996 -0.038410  0.004610 -0.043911  ... -0.037982  0.000742 -0.018588   \n",
       "1997 -0.047872 -0.008691 -0.052499  ... -0.055064 -0.017246 -0.020152   \n",
       "1998 -0.023383  0.008531 -0.054278  ... -0.042980  0.007777 -0.017777   \n",
       "1999 -0.029414 -0.030149 -0.051938  ... -0.032686 -0.018927 -0.005718   \n",
       "\n",
       "           294       295       296       297       298       299   specret  \n",
       "0     0.004733  0.000857  0.018535 -0.017792 -0.007239 -0.001484 -0.109493  \n",
       "1    -0.023000  0.009759  0.002233 -0.010561 -0.001750  0.016288 -0.108201  \n",
       "2     0.006449  0.015651  0.022450 -0.002275 -0.031382  0.012316 -0.108201  \n",
       "3     0.010207  0.002996  0.016203 -0.016477 -0.010663  0.005336 -0.108201  \n",
       "4     0.016218 -0.002486  0.032428 -0.013547  0.002774 -0.002339 -0.108190  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.012622 -0.020672  0.018864 -0.015091 -0.033542 -0.014857  0.112143  \n",
       "1996  0.008780 -0.002376  0.010016  0.006213 -0.033297  0.012571  0.115613  \n",
       "1997  0.012898  0.014514  0.038058 -0.001592  0.000084  0.017764  0.122027  \n",
       "1998  0.023124 -0.008229  0.016651 -0.001783 -0.002190  0.000231  0.122027  \n",
       "1999  0.009379 -0.014818  0.018198 -0.003021 -0.028293 -0.000052  0.123939  \n",
       "\n",
       "[2000 rows x 301 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重新按时间排序\n",
    "trainXY = trainXY.sort_values(\"specret\",ascending=True)\n",
    "#重排索引\n",
    "trainXY = trainXY.reset_index(drop=True)\n",
    "trainXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2d67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classfi_Y1 = [1 if i>=0 else 0 for i in trainXY['specret'] ]\n",
    "classfi_X1 = trainXY.iloc[:,:300] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb14db21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=55)\n",
    "neigh.fit(classfi_X1, classfi_Y1)\n",
    "y_knn = neigh.predict(testX)\n",
    "y_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39af30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn_prob = np.array(neigh.predict_proba(testX))\n",
    "y_knn = y_knn_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db981dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>knn_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_p</th>\n",
       "      <td>0.059296</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p     knn_p\n",
       "true_p  1.000000  0.059296\n",
       "knn_p   0.059296  1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'knn_p':y_knn})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4495dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>knn_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_p</th>\n",
       "      <td>0.047028</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p     knn_p\n",
       "true_p  1.000000  0.047028\n",
       "knn_p   0.047028  1.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a99d901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logis = LogisticRegression(penalty='l2')\n",
    "logis.fit(classfi_X1, classfi_Y1)\n",
    "y_logis = logis.predict(testX)\n",
    "y_logis_prob = np.array(logis.predict_proba(testX))\n",
    "y_logis = y_logis_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dee6142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>logis_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logis_p</th>\n",
       "      <td>0.104692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           true_p   logis_p\n",
       "true_p   1.000000  0.104692\n",
       "logis_p  0.104692  1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'logis_p':y_logis})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "230b34c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>logis_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.05526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logis_p</th>\n",
       "      <td>0.05526</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_p  logis_p\n",
       "true_p   1.00000  0.05526\n",
       "logis_p  0.05526  1.00000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "460d33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(classfi_X1, classfi_Y1)\n",
    "y_rf_classifi = clf.predict(testX)\n",
    "y_rf_classifi_prob = np.array(clf.predict_proba(testX))\n",
    "y_rf_classifi = y_rf_classifi_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7064f1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>rf_classifi_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_classifi_p</th>\n",
       "      <td>0.110427</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 true_p  rf_classifi_p\n",
       "true_p         1.000000       0.110427\n",
       "rf_classifi_p  0.110427       1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'rf_classifi_p':y_rf_classifi})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfcb17fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>rf_classifi_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_classifi_p</th>\n",
       "      <td>0.058946</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 true_p  rf_classifi_p\n",
       "true_p         1.000000       0.058946\n",
       "rf_classifi_p  0.058946       1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1969a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top30 bottom30 as label\n",
    "trainXY_30 = pd.concat([trainXY.iloc[:int(0.3*trainXY.shape[0]),:],trainXY.iloc[int(0.7*trainXY.shape[0]):,:]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3262dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_30 = pd.concat([trainXY.iloc[:int(0.3*trainXY.shape[0]),:300],trainXY.iloc[int(0.7*trainXY.shape[0]):,:300]],axis=0)\n",
    "trainY_30 = [0 if i<=int(0.3*trainXY.shape[0]) else 1 for i in range(trainXY_30.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3ed0928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainY_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e649bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh_30 = KNeighborsClassifier(n_neighbors=55)\n",
    "neigh_30.fit(trainX_30, trainY_30)\n",
    "y_knn_30 = neigh_30.predict(testX)\n",
    "y_knn_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07055069",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn_30_prob = np.array(neigh.predict_proba(testX))\n",
    "y_knn_30 = y_knn_30_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf460918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>knn_30_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_30_p</th>\n",
       "      <td>0.059296</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            true_p  knn_30_p\n",
       "true_p    1.000000  0.059296\n",
       "knn_30_p  0.059296  1.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'knn_30_p':y_knn_30})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "385ec068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>knn_30_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_30_p</th>\n",
       "      <td>0.047028</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            true_p  knn_30_p\n",
       "true_p    1.000000  0.047028\n",
       "knn_30_p  0.047028  1.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b77ccabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logis_30 = LogisticRegression(penalty='l2')\n",
    "logis_30.fit(trainX_30, trainY_30)\n",
    "y_logis_30 = logis_30.predict(testX)\n",
    "y_logis_30_prob = np.array(logis_30.predict_proba(testX))\n",
    "y_logis_30 = y_logis_30_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63a494f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>logis_30_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logis_30_p</th>\n",
       "      <td>0.120599</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              true_p  logis_30_p\n",
       "true_p      1.000000    0.120599\n",
       "logis_30_p  0.120599    1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'logis_30_p':y_logis_30})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54fb00c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>logis_30_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logis_30_p</th>\n",
       "      <td>0.068412</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              true_p  logis_30_p\n",
       "true_p      1.000000    0.068412\n",
       "logis_30_p  0.068412    1.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b13d85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_30 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_30.fit(trainX_30, trainY_30)\n",
    "y_rf_30_classifi = clf_30.predict(testX)\n",
    "y_rf_30_classifi_prob = np.array(clf_30.predict_proba(testX))\n",
    "y_rf_30_classifi = y_rf_30_classifi_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27a22e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>rf_30_classifi_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_30_classifi_p</th>\n",
       "      <td>0.128126</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    true_p  rf_30_classifi_p\n",
       "true_p            1.000000          0.128126\n",
       "rf_30_classifi_p  0.128126          1.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec = pd.DataFrame({'true_p':testY,'rf_30_classifi_p':y_rf_30_classifi})\n",
    "coef_word2vec .corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "819fe5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_p</th>\n",
       "      <th>rf_30_classifi_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_30_classifi_p</th>\n",
       "      <td>0.063217</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    true_p  rf_30_classifi_p\n",
       "true_p            1.000000          0.063217\n",
       "rf_30_classifi_p  0.063217          1.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_word2vec .corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96a6b4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SecuCode</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>specret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600068</td>\n",
       "      <td>事件：\\r\\n\\r\\n    葛洲坝2009年新签工程订单同比增长37.9%。公告...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.013306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002008</td>\n",
       "      <td>投资提示\\r\\n\\r\\n　　经过两年调整，公司有望跨入新一轮增长期。1）PCB设备等...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.000854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600707</td>\n",
       "      <td>我们认为，公司基于定向增发顺利进行的角度考虑，对CRT 业务的固定资产采取大笔计...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.031626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600104</td>\n",
       "      <td>自主品牌发展势头良好，2010 年有望扭亏为盈；合资企业上海通用、上海大众盈利能...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.032972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600423</td>\n",
       "      <td>停牌前重大资产收购预期较弱，股价对重组预期反映不明显。根据我们了解，停牌前机构投资者...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.018194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002264</td>\n",
       "      <td>公司公告其全资子公司泉州新华都购物广场有限公司拟以人民币5750 万元收购泉州奇龙物...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>601918</td>\n",
       "      <td>公司四个在产煤矿产能1055 万吨/年，未来三年将有板集矿、口孜东矿和刘庄二期三个...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.002262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>601699</td>\n",
       "      <td>支撑评级的要点\\r\\n\\r\\n    公司煤炭产量的42%为冶金用喷吹煤；随着近期...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.009319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>601699</td>\n",
       "      <td>通过兼并重组可新增煤炭资源储量2 亿吨以上，重建投产后有望新增产能400 万吨以上...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.009319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>601001</td>\n",
       "      <td>集团参与资源整合，长期看同煤集团的资产注入将为公司未来发展提供主要的增长动力；公司...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.003922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600997</td>\n",
       "      <td>公司肥精煤属稀缺资源，可以提供业绩稳定安全边际；而焦炭业务则可以增大公司业绩弹性，...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.001635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600519</td>\n",
       "      <td>茅台酒于元旦正式提价，陈年酒提价幅度大大超越普通酒，陈年酒占收入利润贡献高达三成...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.001746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>002032</td>\n",
       "      <td>“炊具+家用电器”双线战略延伸了产品线，打开成长空间公司产品已经从厨房走入生活，家...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.006383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600383</td>\n",
       "      <td>近期销售情况较好的大公司\\r\\n\\r\\n    公司前11月销售额完成179亿，...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>-0.013110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600348</td>\n",
       "      <td>支撑评级的要点\\r\\n\\r\\n    煤种优势明显。电煤占总产量的73%，其中大部...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.004996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600016</td>\n",
       "      <td>投资提示：\\r\\n\\r\\n    上调民生银行评级至“推荐”，股价上涨潜力30-...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>600281</td>\n",
       "      <td>工信部日前印发《促进中部地区原材料工业结构调整和优化升级方案》的通知，在扶优扶强...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.034413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600460</td>\n",
       "      <td>重要事件：\\r\\n\\r\\n    士兰微是国内为数不多坚持IDM模式的集成电路设计...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.080257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>600460</td>\n",
       "      <td>事件：\\r\\n\\r\\n    公司于 1 月4 日公告非公开增发预案，拟以不低于8...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.080257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600893</td>\n",
       "      <td>09 年军品业务收入规模与年初预计基本一致，预计2010 年军品业务增长继续。公...</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.015693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SecuCode                                            content       date  \\\n",
       "0    600068       事件：\\r\\n\\r\\n    葛洲坝2009年新签工程订单同比增长37.9%。公告... 2010-01-04   \n",
       "1    002008    　　投资提示\\r\\n\\r\\n　　经过两年调整，公司有望跨入新一轮增长期。1）PCB设备等... 2010-01-04   \n",
       "2    600707        我们认为，公司基于定向增发顺利进行的角度考虑，对CRT 业务的固定资产采取大笔计... 2010-01-04   \n",
       "3    600104        自主品牌发展势头良好，2010 年有望扭亏为盈；合资企业上海通用、上海大众盈利能... 2010-01-04   \n",
       "4    600423    　　停牌前重大资产收购预期较弱，股价对重组预期反映不明显。根据我们了解，停牌前机构投资者... 2010-01-04   \n",
       "5    002264    　　公司公告其全资子公司泉州新华都购物广场有限公司拟以人民币5750 万元收购泉州奇龙物... 2010-01-04   \n",
       "6    601918       公司四个在产煤矿产能1055 万吨/年，未来三年将有板集矿、口孜东矿和刘庄二期三个... 2010-01-04   \n",
       "7    601699       支撑评级的要点\\r\\n\\r\\n    公司煤炭产量的42%为冶金用喷吹煤；随着近期... 2010-01-04   \n",
       "8    601699       通过兼并重组可新增煤炭资源储量2 亿吨以上，重建投产后有望新增产能400 万吨以上... 2010-01-04   \n",
       "9    601001       集团参与资源整合，长期看同煤集团的资产注入将为公司未来发展提供主要的增长动力；公司... 2010-01-04   \n",
       "10   600997       公司肥精煤属稀缺资源，可以提供业绩稳定安全边际；而焦炭业务则可以增大公司业绩弹性，... 2010-01-04   \n",
       "11   600519        茅台酒于元旦正式提价，陈年酒提价幅度大大超越普通酒，陈年酒占收入利润贡献高达三成... 2010-01-04   \n",
       "12   002032       “炊具+家用电器”双线战略延伸了产品线，打开成长空间公司产品已经从厨房走入生活，家... 2010-01-04   \n",
       "13   600383        近期销售情况较好的大公司\\r\\n\\r\\n    公司前11月销售额完成179亿，... 2010-01-04   \n",
       "14   600348       支撑评级的要点\\r\\n\\r\\n    煤种优势明显。电煤占总产量的73%，其中大部... 2010-01-04   \n",
       "15   600016        投资提示：\\r\\n\\r\\n    上调民生银行评级至“推荐”，股价上涨潜力30-... 2010-01-04   \n",
       "16   600281        工信部日前印发《促进中部地区原材料工业结构调整和优化升级方案》的通知，在扶优扶强... 2010-01-04   \n",
       "17   600460       重要事件：\\r\\n\\r\\n    士兰微是国内为数不多坚持IDM模式的集成电路设计... 2010-01-04   \n",
       "18   600460       事件：\\r\\n\\r\\n    公司于 1 月4 日公告非公开增发预案，拟以不低于8... 2010-01-04   \n",
       "19   600893        09 年军品业务收入规模与年初预计基本一致，预计2010 年军品业务增长继续。公... 2010-01-04   \n",
       "\n",
       "     specret  \n",
       "0  -0.013306  \n",
       "1  -0.000854  \n",
       "2   0.031626  \n",
       "3   0.032972  \n",
       "4   0.018194  \n",
       "5   0.002592  \n",
       "6   0.002262  \n",
       "7   0.009319  \n",
       "8   0.009319  \n",
       "9   0.003922  \n",
       "10 -0.001635  \n",
       "11  0.001746  \n",
       "12 -0.006383  \n",
       "13 -0.013110  \n",
       "14  0.004996  \n",
       "15  0.022800  \n",
       "16  0.034413  \n",
       "17  0.080257  \n",
       "18  0.080257  \n",
       "19  0.015693  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#portfolio construction\n",
    "data_final.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "561dc590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SecuCode</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>specret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>000001</td>\n",
       "      <td>中报要点\\r\\n&amp;#1048708; \\r\\n　　2010 年上半年深发展的净息差恢...</td>\n",
       "      <td>2010-08-25</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>000001</td>\n",
       "      <td>2010年中报显示，上半年公司总资产规模达到6243.98亿元，同比增长15.3...</td>\n",
       "      <td>2010-08-25</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>000001</td>\n",
       "      <td>深发展10 年中期收入和净利润同比增长13.42%和31.23%，EPS 0.9...</td>\n",
       "      <td>2010-08-25</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>000001</td>\n",
       "      <td>深发展银行2010 年上半年实现利息净收入74.09 亿元，同比增长16.43%...</td>\n",
       "      <td>2010-08-25</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>000001</td>\n",
       "      <td>投资要点\\r\\n\\r\\n    净利润增长约31.23%。上半年，实现营业收入8...</td>\n",
       "      <td>2010-08-25</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>000001</td>\n",
       "      <td>深发展公布2010 年中报：报告期内，公司实现营业收入84.96 亿元，同比增长13...</td>\n",
       "      <td>2010-08-26</td>\n",
       "      <td>-0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>000001</td>\n",
       "      <td>业绩概述：\\r\\n\\r\\n    中报业绩略低于预期。深发展2010 年中期实现...</td>\n",
       "      <td>2010-08-30</td>\n",
       "      <td>-0.007038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件：\\r\\n　　\\r\\n　　深发展公布10 年半年报。实现营业收入84.96 亿元...</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>0.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件描述\\r\\n\\r\\n　　2010 年9 月2 日，深发展公布资产重组公告，主要内...</td>\n",
       "      <td>2010-09-01</td>\n",
       "      <td>-0.007805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件\\r\\n\\r\\n    深发展发布公告，拟通过向中国平安保险（集团）股份有限...</td>\n",
       "      <td>2010-09-01</td>\n",
       "      <td>-0.007805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>000001</td>\n",
       "      <td>换股对价略有溢价。收购平安银行支付金额291 亿元，对应平安银行10 年的PB 和P...</td>\n",
       "      <td>2010-09-01</td>\n",
       "      <td>-0.007805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件：\\r\\n\\r\\n    深发展今日公告，公司拟向中国平安以17.75 元每...</td>\n",
       "      <td>2010-09-01</td>\n",
       "      <td>-0.007805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>000001</td>\n",
       "      <td>整合方案概览：\\r\\n\\r\\n　　中国平安以所持平安银行的约78.25亿股股份（约占...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>000001</td>\n",
       "      <td>两家银行的协同作用。平安银行发展零售业务和中小企业业务的战略定位同深发展相近。\\r\\...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>000001</td>\n",
       "      <td>深发展与平安银行的对价方案低于预期。 按照公司披露的重组方案，对平安银行预估值为29...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>000001</td>\n",
       "      <td>1．事件\\r\\n\\r\\n    今日深发展发布重大资产重组公告，拟通过非公开增发...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件：\\r\\n\\r\\n    1、9 月1 日晚，深发展发布购买资产和关联交易重...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>000001</td>\n",
       "      <td>（1）标的公司平安银行估值适中。在此次资产交易过程中，关键因素是平安银行股份的定价。...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件：\\r\\n&amp;#1048698; \\r\\n　　深发展9 月1 日晚公告发行股份购买...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>000001</td>\n",
       "      <td>深发展公告与中国平安的重大资产重组方案。中国平安将以其持有的平安银行78.25亿股（...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>000001</td>\n",
       "      <td>1. 深发展整合平安银行再下一城\\r\\n\\r\\n　　2010 年5 月，中国平安以向...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>000001</td>\n",
       "      <td>公司公布了对控股股东中国平安定向增发预案，中国平安将以平安银行股权资产 + 现金...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>000001</td>\n",
       "      <td>交易对价处于合理范围。本次深发展定向增发每股价格17.75 元，对应10 年PB 为...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件：\\r\\n\\r\\n　　深发展和中国平安同时发布重组预案\\r\\n\\r\\n　　点评：...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件：深发展发布公告称拟向中国平安保险（集团）发行股份，中国平安拟以其持有的平安...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>000001</td>\n",
       "      <td>平安银行注入深发展方案确定。方案可理解为两个步骤：（1）平安集团拿出26.92 ...</td>\n",
       "      <td>2010-09-02</td>\n",
       "      <td>0.033119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件：\\r\\n\\r\\n    深发展9 月2 日召开拟与平安银行两行整合的重大无...</td>\n",
       "      <td>2010-09-03</td>\n",
       "      <td>-0.015085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件\\r\\n\\r\\n    深发展公告重大资产重组方案：中国平安以其所持有的平安银...</td>\n",
       "      <td>2010-09-03</td>\n",
       "      <td>-0.015085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>000001</td>\n",
       "      <td>本报告导读：\\r\\n\\r\\n    9 月30 日召开股东大会，如获批准，再报送...</td>\n",
       "      <td>2010-09-20</td>\n",
       "      <td>-0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>000001</td>\n",
       "      <td>What''s changed\\r\\n\\r\\n    Shenzhen Devel...</td>\n",
       "      <td>2010-09-27</td>\n",
       "      <td>0.003994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>000001</td>\n",
       "      <td>本文首先梳理了深发展20 多年来的经营发展状况，向投资者展示了深发展在长期缺乏有力的...</td>\n",
       "      <td>2010-09-29</td>\n",
       "      <td>-0.006461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>000001</td>\n",
       "      <td>结论与建议：\\r\\n\\r\\n　　9月30日，深发展股东大会通过了深发展和平安银行整合...</td>\n",
       "      <td>2010-10-12</td>\n",
       "      <td>-0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>000001</td>\n",
       "      <td>从合并对价看，平安集团强势地位明显。平安银行2010 年6 月30 日的经审计账...</td>\n",
       "      <td>2010-10-26</td>\n",
       "      <td>-0.002349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>000001</td>\n",
       "      <td>投资要点\\r\\n\\r\\n    事件：\\r\\n\\r\\n    深发展银行今日公布...</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件：\\r\\n\\r\\n    深发展银行发布2010年三季报，前三季度公司实现营...</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>000001</td>\n",
       "      <td>业绩简评\\r\\n\\r\\n    深发展 2010 年中期实现净利润47.34 亿...</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>000001</td>\n",
       "      <td>业绩增长符合预期。前三季度，公司实现净利润47.3 亿元，同比增长30.0%，其...</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>000001</td>\n",
       "      <td>事件描述\\r\\n\\r\\n　　深发展银行2010 年前三季度实现利息净收入114.60...</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>000001</td>\n",
       "      <td>利润环比增长17%，贷款环比增长7%。深发展第三季度实现净利润17.01亿元，较上季...</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>000001</td>\n",
       "      <td>报告关键点：\\r\\n\\r\\n    3季度净利润环比增长16.9%，息差上升和成...</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SecuCode                                            content       date  \\\n",
       "100   000001    　　中报要点\\r\\n&#1048708; \\r\\n　　2010 年上半年深发展的净息差恢... 2010-08-25   \n",
       "101   000001        2010年中报显示，上半年公司总资产规模达到6243.98亿元，同比增长15.3... 2010-08-25   \n",
       "102   000001        深发展10 年中期收入和净利润同比增长13.42%和31.23%，EPS 0.9... 2010-08-25   \n",
       "103   000001        深发展银行2010 年上半年实现利息净收入74.09 亿元，同比增长16.43%... 2010-08-25   \n",
       "104   000001        投资要点\\r\\n\\r\\n    净利润增长约31.23%。上半年，实现营业收入8... 2010-08-25   \n",
       "105   000001    　　深发展公布2010 年中报：报告期内，公司实现营业收入84.96 亿元，同比增长13... 2010-08-26   \n",
       "106   000001        业绩概述：\\r\\n\\r\\n    中报业绩略低于预期。深发展2010 年中期实现... 2010-08-30   \n",
       "107   000001    　　事件：\\r\\n　　\\r\\n　　深发展公布10 年半年报。实现营业收入84.96 亿元... 2010-08-31   \n",
       "108   000001    　　事件描述\\r\\n\\r\\n　　2010 年9 月2 日，深发展公布资产重组公告，主要内... 2010-09-01   \n",
       "109   000001        事件\\r\\n\\r\\n    深发展发布公告，拟通过向中国平安保险（集团）股份有限... 2010-09-01   \n",
       "110   000001    　　换股对价略有溢价。收购平安银行支付金额291 亿元，对应平安银行10 年的PB 和P... 2010-09-01   \n",
       "111   000001        事件：\\r\\n\\r\\n    深发展今日公告，公司拟向中国平安以17.75 元每... 2010-09-01   \n",
       "112   000001    　　整合方案概览：\\r\\n\\r\\n　　中国平安以所持平安银行的约78.25亿股股份（约占... 2010-09-02   \n",
       "113   000001    　　两家银行的协同作用。平安银行发展零售业务和中小企业业务的战略定位同深发展相近。\\r\\... 2010-09-02   \n",
       "114   000001    　　深发展与平安银行的对价方案低于预期。 按照公司披露的重组方案，对平安银行预估值为29... 2010-09-02   \n",
       "115   000001        1．事件\\r\\n\\r\\n    今日深发展发布重大资产重组公告，拟通过非公开增发... 2010-09-02   \n",
       "116   000001        事件：\\r\\n\\r\\n    1、9 月1 日晚，深发展发布购买资产和关联交易重... 2010-09-02   \n",
       "117   000001    　　（1）标的公司平安银行估值适中。在此次资产交易过程中，关键因素是平安银行股份的定价。... 2010-09-02   \n",
       "118   000001    　　事件：\\r\\n&#1048698; \\r\\n　　深发展9 月1 日晚公告发行股份购买... 2010-09-02   \n",
       "119   000001    　　深发展公告与中国平安的重大资产重组方案。中国平安将以其持有的平安银行78.25亿股（... 2010-09-02   \n",
       "120   000001    　　1. 深发展整合平安银行再下一城\\r\\n\\r\\n　　2010 年5 月，中国平安以向... 2010-09-02   \n",
       "121   000001        公司公布了对控股股东中国平安定向增发预案，中国平安将以平安银行股权资产 + 现金... 2010-09-02   \n",
       "122   000001    　　交易对价处于合理范围。本次深发展定向增发每股价格17.75 元，对应10 年PB 为... 2010-09-02   \n",
       "123   000001    　　事件：\\r\\n\\r\\n　　深发展和中国平安同时发布重组预案\\r\\n\\r\\n　　点评：... 2010-09-02   \n",
       "124   000001        事件：深发展发布公告称拟向中国平安保险（集团）发行股份，中国平安拟以其持有的平安... 2010-09-02   \n",
       "125   000001        平安银行注入深发展方案确定。方案可理解为两个步骤：（1）平安集团拿出26.92 ... 2010-09-02   \n",
       "126   000001        事件：\\r\\n\\r\\n    深发展9 月2 日召开拟与平安银行两行整合的重大无... 2010-09-03   \n",
       "127   000001       事件\\r\\n\\r\\n    深发展公告重大资产重组方案：中国平安以其所持有的平安银... 2010-09-03   \n",
       "128   000001        本报告导读：\\r\\n\\r\\n    9 月30 日召开股东大会，如获批准，再报送... 2010-09-20   \n",
       "129   000001       What''s changed\\r\\n\\r\\n    Shenzhen Devel... 2010-09-27   \n",
       "130   000001    　　本文首先梳理了深发展20 多年来的经营发展状况，向投资者展示了深发展在长期缺乏有力的... 2010-09-29   \n",
       "131   000001    　　结论与建议：\\r\\n\\r\\n　　9月30日，深发展股东大会通过了深发展和平安银行整合... 2010-10-12   \n",
       "132   000001        从合并对价看，平安集团强势地位明显。平安银行2010 年6 月30 日的经审计账... 2010-10-26   \n",
       "133   000001        投资要点\\r\\n\\r\\n    事件：\\r\\n\\r\\n    深发展银行今日公布... 2010-10-27   \n",
       "134   000001        事件：\\r\\n\\r\\n    深发展银行发布2010年三季报，前三季度公司实现营... 2010-10-27   \n",
       "135   000001        业绩简评\\r\\n\\r\\n    深发展 2010 年中期实现净利润47.34 亿... 2010-10-27   \n",
       "136   000001        业绩增长符合预期。前三季度，公司实现净利润47.3 亿元，同比增长30.0%，其... 2010-10-27   \n",
       "137   000001    　　事件描述\\r\\n\\r\\n　　深发展银行2010 年前三季度实现利息净收入114.60... 2010-10-27   \n",
       "138   000001    　　利润环比增长17%，贷款环比增长7%。深发展第三季度实现净利润17.01亿元，较上季... 2010-10-27   \n",
       "139   000001        报告关键点：\\r\\n\\r\\n    3季度净利润环比增长16.9%，息差上升和成... 2010-10-27   \n",
       "\n",
       "      specret  \n",
       "100  0.025080  \n",
       "101  0.025080  \n",
       "102  0.025080  \n",
       "103  0.025080  \n",
       "104  0.025080  \n",
       "105 -0.000332  \n",
       "106 -0.007038  \n",
       "107  0.011628  \n",
       "108 -0.007805  \n",
       "109 -0.007805  \n",
       "110 -0.007805  \n",
       "111 -0.007805  \n",
       "112  0.033119  \n",
       "113  0.033119  \n",
       "114  0.033119  \n",
       "115  0.033119  \n",
       "116  0.033119  \n",
       "117  0.033119  \n",
       "118  0.033119  \n",
       "119  0.033119  \n",
       "120  0.033119  \n",
       "121  0.033119  \n",
       "122  0.033119  \n",
       "123  0.033119  \n",
       "124  0.033119  \n",
       "125  0.033119  \n",
       "126 -0.015085  \n",
       "127 -0.015085  \n",
       "128 -0.000551  \n",
       "129  0.003994  \n",
       "130 -0.006461  \n",
       "131 -0.001074  \n",
       "132 -0.002349  \n",
       "133  0.002752  \n",
       "134  0.002752  \n",
       "135  0.002752  \n",
       "136  0.002752  \n",
       "137  0.002752  \n",
       "138  0.002752  \n",
       "139  0.002752  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#按照股票代码和日期排序\n",
    "data_final = data_final.sort_values(by=[\"SecuCode\",\"date\"],ascending=True)\n",
    "#重排索引\n",
    "data_final = data_final.reset_index(drop=True)\n",
    "data_final.iloc[100:140,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0d4b236b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data_final['SecuCode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "175ab836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateRange(beginDate, endDate):\n",
    "    dates = []\n",
    "    dt = datetime.datetime.strptime(beginDate, \"%Y-%m-%d\")\n",
    "    date = beginDate[:]\n",
    "    while date <= endDate:\n",
    "        dates.append(date)\n",
    "        dt = dt + datetime.timedelta(1)\n",
    "        date = dt.strftime(\"%Y-%m-%d\")\n",
    "    return dates\n",
    "def monthRange(beginDate, endDate):\n",
    "    monthSet = set()\n",
    "    for date in dateRange(beginDate, endDate):\n",
    "        monthSet.add(date[0:7])\n",
    "    monthList = []\n",
    "    for month in monthSet:\n",
    "        monthList.append(month)\n",
    "    return sorted(monthList)\n",
    "#monthRange('2015-01-01','2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "adb001b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre30_return(data_final):\n",
    "    data_final['date'] = pd.to_datetime(data_final['date'])\n",
    "    data_portfolio = data_final.set_index('date')\n",
    "    \n",
    "    months = monthRange('2015-01-01','2015-04-01')\n",
    "    all_month_return = []\n",
    "    for i in range(len(months)-1):\n",
    "        pre_30 = data_portfolio.loc[months[i]]\n",
    "        follow_30 = data_portfolio.loc[months[i+1]]\n",
    "        #pre_30 = data_portfolio.loc['2015-01']\n",
    "        #follow_30 = data_portfolio.loc['2015-02']\n",
    "    \n",
    "        #word2vec\n",
    "        train_text = text_preprocess(pre_30)\n",
    "        train_data = [build_vector(train_text[i],300,model) for i in range(len(pre_30))]\n",
    "        #train_data = np.resize(train_data,(train_num,300))\n",
    "        train_data = [train_data[i][0] for i in range(len(pre_30))]\n",
    "        trainX = pd.DataFrame(train_data)\n",
    "        pre_30['senti_score'] = svr.predict(trainX)\n",
    "\n",
    "        #construct 11 portfolio\n",
    "        pre_30mean = pre_30.groupby('SecuCode')['senti_score'].mean()\n",
    "        pre_30mean = pre_30mean.sort_values()\n",
    "        #分成10组\n",
    "        group = []\n",
    "        for i in range(10):\n",
    "            temp = pre_30mean.index[int(i*0.1*len(pre_30mean.index)):int((i+1)*0.1*len(pre_30mean.index))]\n",
    "            group.append(temp)\n",
    "        folllow_30mean = follow_30.groupby(['SecuCode',follow_30.index])['specret'].mean()\n",
    "        month_return = {}\n",
    "        for i in group[0]:\n",
    "            if i in folllow_30mean.index:\n",
    "                temp_return = sum(folllow_30mean[i])\n",
    "                month_return.update({i:temp_return})\n",
    "        group_month_return = []\n",
    "        for i in range(len(group)):\n",
    "            month_return = 0\n",
    "            for j in group[i]:\n",
    "                if j in folllow_30mean.index:\n",
    "                    month_return += sum(folllow_30mean[j])\n",
    "            group_month_return.append(month_return)\n",
    "        group_month_return.append(group_month_return[-1]-group_month_return[0])\n",
    "        all_month_return.append(group_month_return)\n",
    "    return all_month_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "868dfc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-197-ecc63e243dfa>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre_30['senti_score'] = svr.predict(trainX)\n",
      "<ipython-input-197-ecc63e243dfa>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre_30['senti_score'] = svr.predict(trainX)\n",
      "<ipython-input-197-ecc63e243dfa>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre_30['senti_score'] = svr.predict(trainX)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.6005395242768258,\n",
       "  0.2544715114951058,\n",
       "  0.4896769289869325,\n",
       "  0.9439982238657283,\n",
       "  0.5161114694194014,\n",
       "  0.754923384470711,\n",
       "  0.6559547439353284,\n",
       "  0.510220655548855,\n",
       "  0.8024821577369446,\n",
       "  0.2987807644359032,\n",
       "  -0.3017587598409226],\n",
       " [1.0480584389010472,\n",
       "  0.7089489676666838,\n",
       "  1.0626751601613669,\n",
       "  0.2942422128098236,\n",
       "  0.9365543767746431,\n",
       "  0.8252769400755992,\n",
       "  1.1621391650993829,\n",
       "  1.5035541840844098,\n",
       "  0.724844265374879,\n",
       "  1.3952405879095582,\n",
       "  0.34718214900851097],\n",
       " [1.2601506520654249,\n",
       "  0.5272776525165989,\n",
       "  1.4340725218932062,\n",
       "  0.8498858439387702,\n",
       "  1.663292142400826,\n",
       "  0.6831883001265464,\n",
       "  1.2870260203773483,\n",
       "  0.5635818622325492,\n",
       "  1.5133633820341759,\n",
       "  0.9557870772811471,\n",
       "  -0.3043635747842778]]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre30_return(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "71f19c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre60_return(data_final):\n",
    "    data_final['date'] = pd.to_datetime(data_final['date'])\n",
    "    data_portfolio = data_final.set_index('date')\n",
    "    \n",
    "    months = monthRange('2014-11-01','2021-05-01')\n",
    "    all_month_return = []\n",
    "    for i in range(len(months)-2):\n",
    "        pre_30 = data_portfolio.loc[months[i]]\n",
    "        follow_30 = data_portfolio.loc[months[i+2]]\n",
    "        #pre_30 = data_portfolio.loc['2015-01']\n",
    "        #follow_30 = data_portfolio.loc['2015-02']\n",
    "    \n",
    "        #word2vec\n",
    "        train_text = text_preprocess(pre_30)\n",
    "        train_data = [build_vector(train_text[i],300,model) for i in range(len(pre_30))]\n",
    "        #train_data = np.resize(train_data,(train_num,300))\n",
    "        train_data = [train_data[i][0] for i in range(len(pre_30))]\n",
    "        trainX = pd.DataFrame(train_data)\n",
    "        pre_30['senti_score'] = svr.predict(trainX)\n",
    "\n",
    "        #construct 11 portfolio\n",
    "        pre_30mean = pre_30.groupby('SecuCode')['senti_score'].mean()\n",
    "        pre_30mean = pre_30mean.sort_values()\n",
    "        #分成10组\n",
    "        group = []\n",
    "        for i in range(10):\n",
    "            temp = pre_30mean.index[int(i*0.1*len(pre_30mean.index)):int((i+1)*0.1*len(pre_30mean.index))]\n",
    "            group.append(temp)\n",
    "        folllow_30mean = follow_30.groupby(['SecuCode',follow_30.index])['specret'].mean()\n",
    "        month_return = {}\n",
    "        for i in group[0]:\n",
    "            if i in folllow_30mean.index:\n",
    "                temp_return = sum(folllow_30mean[i])\n",
    "                month_return.update({i:temp_return})\n",
    "        group_month_return = []\n",
    "        for i in range(len(group)):\n",
    "            month_return = 0\n",
    "            for j in group[i]:\n",
    "                if j in folllow_30mean.index:\n",
    "                    month_return += sum(folllow_30mean[j])\n",
    "            group_month_return.append(month_return)\n",
    "        group_month_return.append(group_month_return[-1]-group_month_return[0])\n",
    "        all_month_return.append(group_month_return)\n",
    "    return all_month_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ecc87e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre90_return(data_final):\n",
    "    data_final['date'] = pd.to_datetime(data_final['date'])\n",
    "    data_portfolio = data_final.set_index('date')\n",
    "    \n",
    "    months = monthRange('2014-10-01','2021-05-01')\n",
    "    all_month_return = []\n",
    "    for i in range(len(months)-2):\n",
    "        pre_30 = data_portfolio.loc[months[i]]\n",
    "        follow_30 = data_portfolio.loc[months[i+3]]\n",
    "        #pre_30 = data_portfolio.loc['2015-01']\n",
    "        #follow_30 = data_portfolio.loc['2015-02']\n",
    "    \n",
    "        #word2vec\n",
    "        train_text = text_preprocess(pre_30)\n",
    "        train_data = [build_vector(train_text[i],300,model) for i in range(len(pre_30))]\n",
    "        #train_data = np.resize(train_data,(train_num,300))\n",
    "        train_data = [train_data[i][0] for i in range(len(pre_30))]\n",
    "        trainX = pd.DataFrame(train_data)\n",
    "        pre_30['senti_score'] = svr.predict(trainX)\n",
    "\n",
    "        #construct 11 portfolio\n",
    "        pre_30mean = pre_30.groupby('SecuCode')['senti_score'].mean()\n",
    "        pre_30mean = pre_30mean.sort_values()\n",
    "        #分成10组\n",
    "        group = []\n",
    "        for i in range(10):\n",
    "            temp = pre_30mean.index[int(i*0.1*len(pre_30mean.index)):int((i+1)*0.1*len(pre_30mean.index))]\n",
    "            group.append(temp)\n",
    "        folllow_30mean = follow_30.groupby(['SecuCode',follow_30.index])['specret'].mean()\n",
    "        month_return = {}\n",
    "        for i in group[0]:\n",
    "            if i in folllow_30mean.index:\n",
    "                temp_return = sum(folllow_30mean[i])\n",
    "                month_return.update({i:temp_return})\n",
    "        group_month_return = []\n",
    "        for i in range(len(group)):\n",
    "            month_return = 0\n",
    "            for j in group[i]:\n",
    "                if j in folllow_30mean.index:\n",
    "                    month_return += sum(folllow_30mean[j])\n",
    "            group_month_return.append(month_return)\n",
    "        group_month_return.append(group_month_return[-1]-group_month_return[0])\n",
    "        all_month_return.append(group_month_return)\n",
    "    return all_month_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee3558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
