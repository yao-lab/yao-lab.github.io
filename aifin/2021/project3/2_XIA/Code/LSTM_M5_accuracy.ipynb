{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:55:36.932265Z",
     "iopub.status.busy": "2021-12-13T11:55:36.931628Z",
     "iopub.status.idle": "2021-12-13T11:55:48.505163Z",
     "shell.execute_reply": "2021-12-13T11:55:48.503810Z",
     "shell.execute_reply.started": "2021-12-13T11:55:36.932205Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd  \n",
    "\n",
    "import os \n",
    "import re\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "# Allows us to see more information regarding the DataFrame\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:55:48.643642Z",
     "iopub.status.busy": "2021-12-13T11:55:48.643201Z",
     "iopub.status.idle": "2021-12-13T11:56:01.371204Z",
     "shell.execute_reply": "2021-12-13T11:56:01.369998Z",
     "shell.execute_reply.started": "2021-12-13T11:55:48.643582Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('sales_train_validation.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "sell_prices = pd.read_csv('m5-forecasting-accuracy/sell_prices.csv')\n",
    "submission_file = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Calendar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:56:07.313064Z",
     "iopub.status.busy": "2021-12-13T11:56:07.312671Z",
     "iopub.status.idle": "2021-12-13T11:56:07.543019Z",
     "shell.execute_reply": "2021-12-13T11:56:07.542304Z",
     "shell.execute_reply.started": "2021-12-13T11:56:07.313030Z"
    }
   },
   "outputs": [],
   "source": [
    "days = range(1, 1970)\n",
    "time_series_columns = [f'd_{i}' for i in days]\n",
    "transfer_cal = pd.DataFrame(calendar[['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']].values.T, index=['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI'], columns= time_series_columns)\n",
    "transfer_cal = transfer_cal.fillna(0)\n",
    "event_name_1_se = transfer_cal.loc['event_name_1'].apply(lambda x: x if re.search(\"^\\d+$\", str(x)) else np.nan).fillna(10)\n",
    "event_name_2_se = transfer_cal.loc['event_name_2'].apply(lambda x: x if re.search(\"^\\d+$\", str(x)) else np.nan).fillna(10)\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar = calendar[calendar['date']>= '2016-2-01']  # reduce memory\n",
    "calendar= transform(calendar)\n",
    "# Attempts to convert events into time series data.\n",
    "transfer_cal = pd.DataFrame(calendar[['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']].values.T,\n",
    "                            index=['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sell Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:56:07.885470Z",
     "iopub.status.busy": "2021-12-13T11:56:07.885135Z",
     "iopub.status.idle": "2021-12-13T11:56:12.802581Z",
     "shell.execute_reply": "2021-12-13T11:56:12.801592Z",
     "shell.execute_reply.started": "2021-12-13T11:56:07.885425Z"
    }
   },
   "outputs": [],
   "source": [
    "price_fea = calendar[['wm_yr_wk','date']].merge(sell_prices, on = ['wm_yr_wk'], how = 'left')\n",
    "price_fea['id'] = price_fea['item_id']+'_'+price_fea['store_id']+'_validation'\n",
    "df = price_fea.pivot('id','date','sell_price')\n",
    "price_df = train_data.merge(df,on=['id'],how= 'left').iloc[:,-140:] # -145: starts dataframe column at 2016-01-27 \n",
    "price_df.index = train_data.id\n",
    "train_data = downcast_dtypes(train_data)\n",
    "train_data = train_data.iloc[:, -140:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Merge and backfill na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:00:03.417141Z",
     "iopub.status.busy": "2021-12-13T12:00:03.416734Z",
     "iopub.status.idle": "2021-12-13T12:00:03.425071Z",
     "shell.execute_reply": "2021-12-13T12:00:03.424070Z",
     "shell.execute_reply.started": "2021-12-13T12:00:03.417092Z"
    }
   },
   "outputs": [],
   "source": [
    "time_series_col1 = train_data.columns\n",
    "time_series_col2 = price_df.columns\n",
    "time_series_col3 = transfer_cal.columns\n",
    "price_df.columns = time_series_col1\n",
    "transfer_cal.columns = time_series_col1\n",
    "full_train_data = pd.concat([train_data, transfer_cal, price_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:00:04.697680Z",
     "iopub.status.busy": "2021-12-13T12:00:04.697360Z",
     "iopub.status.idle": "2021-12-13T12:00:04.814894Z",
     "shell.execute_reply": "2021-12-13T12:00:04.813775Z",
     "shell.execute_reply.started": "2021-12-13T12:00:04.697646Z"
    }
   },
   "outputs": [],
   "source": [
    "full_train_data.fillna(method='backfill', axis=1, inplace=True)\n",
    "np.sum(full_train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:00:04.817202Z",
     "iopub.status.busy": "2021-12-13T12:00:04.816854Z",
     "iopub.status.idle": "2021-12-13T12:00:05.405272Z",
     "shell.execute_reply": "2021-12-13T12:00:05.404132Z",
     "shell.execute_reply.started": "2021-12-13T12:00:04.817166Z"
    }
   },
   "outputs": [],
   "source": [
    "full_train_data_transposed = full_train_data.T\n",
    "full_train_data_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-13T12:00:05.407591Z",
     "iopub.status.busy": "2021-12-13T12:00:05.407173Z",
     "iopub.status.idle": "2021-12-13T12:00:09.809385Z",
     "shell.execute_reply": "2021-12-13T12:00:09.808625Z",
     "shell.execute_reply.started": "2021-12-13T12:00:05.407543Z"
    }
   },
   "outputs": [],
   "source": [
    "object_cols = [cname for cname in full_train_data_transposed.columns \n",
    "               if full_train_data_transposed[cname].dtype == \"object\" \n",
    "               and cname != \"date\"]\n",
    "num_cols = [cname for cname in full_train_data_transposed.columns \n",
    "            if full_train_data_transposed[cname].dtype in ['int64', 'float64', 'int16', 'float32']\n",
    "            and cname not in ['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']]\n",
    "all_cols = num_cols + object_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Split Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:55:48.596935Z",
     "iopub.status.busy": "2021-12-13T11:55:48.596530Z",
     "iopub.status.idle": "2021-12-13T11:55:48.610138Z",
     "shell.execute_reply": "2021-12-13T11:55:48.609026Z",
     "shell.execute_reply.started": "2021-12-13T11:55:48.596903Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_sequences(sequences, timesteps, horizon):\n",
    "    Sequences, Targets = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + timesteps\n",
    "        out_end_ix = end_ix + horizon-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        Sequences.append(seq_x)\n",
    "        Targets.append(seq_y)\n",
    "        show_shapes()\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:00:10.285287Z",
     "iopub.status.busy": "2021-12-13T12:00:10.284474Z",
     "iopub.status.idle": "2021-12-13T12:01:11.181058Z",
     "shell.execute_reply": "2021-12-13T12:01:11.179881Z",
     "shell.execute_reply.started": "2021-12-13T12:00:10.285224Z"
    }
   },
   "outputs": [],
   "source": [
    "timesteps = 28\n",
    "horizon = 28\n",
    "\n",
    "full_train_data_sequenced = []   \n",
    "\n",
    "for i in tqdm(range(train_data.shape[0])):    \n",
    "\n",
    "    full_train_data_sequenced.append([list(t) for t in zip(full_train_data_transposed['event_name_1'][-(100+14):-(14)],\n",
    "                                       full_train_data_transposed['event_type_1'][-(100+14):-(14)],\n",
    "                                       full_train_data_transposed['event_name_2'][-(100+14):-(14)],     \n",
    "                                       full_train_data_transposed['event_type_2'][-(100+14):-(14)],\n",
    "                                       full_train_data_transposed['snap_CA'][-(100+14):-(14)],\n",
    "                                       full_train_data_transposed['snap_TX'][-(100+14):-(14)],\n",
    "                                       full_train_data_transposed['snap_WI'][-(100+14):-(14)],\n",
    "                                       price_df.iloc[i][-100:],\n",
    "                                       train_data.iloc[i][-100:])]) \n",
    "\n",
    "full_train_data_sequenced = np.asarray(full_train_data_sequenced, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(list):\n",
    "    list = np.array(list)\n",
    "    low, high = np.percentile(list, [0, 100])\n",
    "    delta = high - low\n",
    "    if delta != 0:\n",
    "        for i in range(0, len(list)):\n",
    "            list[i] = (list[i]-low)/delta\n",
    "    return  list,low,high\n",
    "\n",
    "def FNoramlize(list,low,high):\n",
    "    delta = high - low\n",
    "    if delta != 0:\n",
    "        for i in range(0, len(list)):\n",
    "            list[i] = list[i]*delta + low\n",
    "    return list\n",
    "\n",
    "def Normalize2(list,low,high):\n",
    "    list = np.array(list)\n",
    "    delta = high - low\n",
    "    if delta != 0:\n",
    "        for i in range(0, len(list)):\n",
    "            list[i] = (list[i]-low)/delta\n",
    "    return  list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:01:11.182870Z",
     "iopub.status.busy": "2021-12-13T12:01:11.182593Z",
     "iopub.status.idle": "2021-12-13T12:01:11.602463Z",
     "shell.execute_reply": "2021-12-13T12:01:11.601200Z",
     "shell.execute_reply.started": "2021-12-13T12:01:11.182839Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_full_train_data, train_low, train_high = Normalize(full_train_data_sequenced[:,-(timesteps*2):,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:01:11.614871Z",
     "iopub.status.busy": "2021-12-13T12:01:11.614394Z",
     "iopub.status.idle": "2021-12-13T12:01:11.627559Z",
     "shell.execute_reply": "2021-12-13T12:01:11.626762Z",
     "shell.execute_reply.started": "2021-12-13T12:01:11.614820Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = 9\n",
    "\n",
    "X_train = norm_full_train_data[:,-28*2:-28,:]\n",
    "y_train = norm_full_train_data[:,-28:,8] \n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], num_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "\n",
    "show_shapes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:01:11.629480Z",
     "iopub.status.busy": "2021-12-13T12:01:11.628949Z",
     "iopub.status.idle": "2021-12-13T12:01:11.641563Z",
     "shell.execute_reply": "2021-12-13T12:01:11.640148Z",
     "shell.execute_reply.started": "2021-12-13T12:01:11.629445Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoder_decoder_model():\n",
    "    \n",
    "    # Use Keras sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Encoder LSTM layer with Dropout regularisation; Set return_sequences to False since we are feeding last output to decoder layer\n",
    "    model.add(LSTM(units = 100, activation='relu', input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # The fixed-length output of the encoder is repeated, once for each required time step in the output sequence with the RepeatVector wrapper\n",
    "    model.add(RepeatVector(horizon))\n",
    "    \n",
    "    # Decoder LSTM layer with Dropout regularisation; Set return_sequences to True to feed each output time step to a Dense layer\n",
    "    model.add(LSTM(units = 100, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Same dense layer is repeated for each output timestep with the TimeDistributed wrapper\n",
    "    model.add(TimeDistributed(Dense(units=1, activation = \"linear\")))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:01:11.644376Z",
     "iopub.status.busy": "2021-12-13T12:01:11.643659Z",
     "iopub.status.idle": "2021-12-13T12:01:12.067039Z",
     "shell.execute_reply": "2021-12-13T12:01:12.066098Z",
     "shell.execute_reply.started": "2021-12-13T12:01:11.644307Z"
    }
   },
   "outputs": [],
   "source": [
    "model = encoder_decoder_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User settings:  \n",
    "\n",
    "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0  \n",
    "   KMP_BLOCKTIME=0  \n",
    "   KMP_DUPLICATE_LIB_OK=True  \n",
    "   KMP_INIT_AT_FORK=FALSE  \n",
    "   KMP_SETTINGS=1  \n",
    "   KMP_WARNINGS=0  \n",
    "\n",
    "Effective settings:  \n",
    "\n",
    "   KMP_ABORT_DELAY=0  \n",
    "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'  \n",
    "   KMP_ALIGN_ALLOC=64  \n",
    "   KMP_ALL_THREADPRIVATE=128  \n",
    "   KMP_ATOMIC_MODE=2  \n",
    "   KMP_BLOCKTIME=0  \n",
    "   KMP_CPUINFO_FILE: value is not defined  \n",
    "   KMP_DETERMINISTIC_REDUCTION=false  \n",
    "   KMP_DEVICE_THREAD_LIMIT=2147483647  \n",
    "   KMP_DISP_NUM_BUFFERS=7  \n",
    "   KMP_DUPLICATE_LIB_OK=true  \n",
    "   KMP_ENABLE_TASK_THROTTLING=true  \n",
    "   KMP_FORCE_REDUCTION: value is not defined  \n",
    "   KMP_FOREIGN_THREADS_THREADPRIVATE=true  \n",
    "   KMP_FORKJOIN_BARRIER='2,2'  \n",
    "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'  \n",
    "   KMP_GTID_MODE=3  \n",
    "   KMP_HANDLE_SIGNALS=false  \n",
    "   KMP_HOT_TEAMS_MAX_LEVEL=1  \n",
    "   KMP_HOT_TEAMS_MODE=0  \n",
    "   KMP_INIT_AT_FORK=true  \n",
    "   KMP_LIBRARY=throughput  \n",
    "   KMP_LOCK_KIND=queuing  \n",
    "   KMP_MALLOC_POOL_INCR=1M  \n",
    "   KMP_NUM_LOCKS_IN_BLOCK=1  \n",
    "   KMP_PLAIN_BARRIER='2,2'  \n",
    "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'  \n",
    "   KMP_REDUCTION_BARRIER='1,1'  \n",
    "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'  \n",
    "   KMP_SCHEDULE='static,balanced;guided,iterative'  \n",
    "   KMP_SETTINGS=true  \n",
    "   KMP_SPIN_BACKOFF_PARAMS='4096,100'  \n",
    "   KMP_STACKOFFSET=64  \n",
    "   KMP_STACKPAD=0  \n",
    "   KMP_STACKSIZE=8M  \n",
    "   KMP_STORAGE_MAP=false  \n",
    "   KMP_TASKING=2  \n",
    "   KMP_TASKLOOP_MIN_TASKS=0  \n",
    "   KMP_TASK_STEALING_CONSTRAINT=1  \n",
    "   KMP_TEAMS_THREAD_LIMIT=4  \n",
    "   KMP_TOPOLOGY_METHOD=all  \n",
    "   KMP_USE_YIELD=1  \n",
    "   KMP_VERSION=false   \n",
    "   KMP_WARNINGS=false  \n",
    "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'  \n",
    "   OMP_ALLOCATOR=omp_default_mem_alloc  \n",
    "   OMP_CANCELLATION=false  \n",
    "   OMP_DEFAULT_DEVICE=0  \n",
    "   OMP_DISPLAY_AFFINITY=false  \n",
    "   OMP_DISPLAY_ENV=false  \n",
    "   OMP_DYNAMIC=false  \n",
    "   OMP_MAX_ACTIVE_LEVELS=1  \n",
    "   OMP_MAX_TASK_PRIORITY=0  \n",
    "   OMP_NESTED: deprecated; max-active-levels-var=1  \n",
    "   OMP_NUM_THREADS: value is not defined  \n",
    "   OMP_PLACES: value is not defined  \n",
    "   OMP_PROC_BIND='intel'  \n",
    "   OMP_SCHEDULE='static'  \n",
    "   OMP_STACKSIZE=8M  \n",
    "   OMP_TARGET_OFFLOAD=DEFAULT  \n",
    "   OMP_THREAD_LIMIT=2147483647  \n",
    "   OMP_WAIT_POLICY=PASSIVE  \n",
    "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'  \n",
    "\n",
    "2021-12-13 12:01:11.707844: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.  \n",
    "Model: \"sequential\"  \n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "lstm (LSTM)                  (None, 100)               44000     \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 100)               0         \n",
    "_________________________________________________________________\n",
    "repeat_vector (RepeatVector) (None, 28, 100)           0         \n",
    "_________________________________________________________________\n",
    "lstm_1 (LSTM)                (None, 28, 100)           80400     \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 28, 100)           0         \n",
    "_________________________________________________________________\n",
    "time_distributed (TimeDistri (None, 28, 1)             101       \n",
    "=================================================================\n",
    "Total params: 124,501  \n",
    "Trainable params: 124,501  \n",
    "Non-trainable params: 0  \n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Settings  \n",
    "- optimazation: Adam\n",
    "- Loss: mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:01:12.069699Z",
     "iopub.status.busy": "2021-12-13T12:01:12.068966Z",
     "iopub.status.idle": "2021-12-13T12:01:12.092923Z",
     "shell.execute_reply": "2021-12-13T12:01:12.092017Z",
     "shell.execute_reply.started": "2021-12-13T12:01:12.069511Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-13T12:01:12.095266Z",
     "iopub.status.busy": "2021-12-13T12:01:12.094666Z",
     "iopub.status.idle": "2021-12-13T12:05:22.800914Z",
     "shell.execute_reply": "2021-12-13T12:05:22.800011Z",
     "shell.execute_reply.started": "2021-12-13T12:01:12.095216Z"
    }
   },
   "outputs": [],
   "source": [
    "his=model.fit(X_train,y_train,epochs=15,batch_size=1000,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021-12-12 12:01:12.227976: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR   Optimization Passes are enabled (registered 2)  \n",
    "Epoch 1/15  \n",
    "31/31 - 21s - loss: 1.8586e-04 - accuracy: 0.5628  \n",
    "Epoch 2/15  \n",
    "31/31 - 17s - loss: 1.0374e-04 - accuracy: 0.5628  \n",
    "Epoch 3/15  \n",
    "31/31 - 16s - loss: 8.9260e-05 - accuracy: 0.5628  \n",
    "Epoch 4/15  \n",
    "31/31 - 17s - loss: 8.5961e-05 - accuracy: 0.5628   \n",
    "Epoch 5/15  \n",
    "31/31 - 16s - loss: 8.4330e-05 - accuracy: 0.5628  \n",
    "Epoch 6/15  \n",
    "31/31 - 17s - loss: 8.4499e-05 - accuracy: 0.5628  \n",
    "Epoch 7/15  \n",
    "31/31 - 16s - loss: 8.4180e-05 - accuracy: 0.5628  \n",
    "Epoch 8/15  \n",
    "31/31 - 17s - loss: 8.3415e-05 - accuracy: 0.5628  \n",
    "Epoch 9/15  \n",
    "31/31 - 16s - loss: 8.3446e-05 - accuracy: 0.5628  \n",
    "Epoch 10/15  \n",
    "31/31 - 17s - loss: 8.2113e-05 - accuracy: 0.5628  \n",
    "Epoch 11/15  \n",
    "31/31 - 16s - loss: 8.2478e-05 - accuracy: 0.5628  \n",
    "Epoch 12/15  \n",
    "31/31 - 17s - loss: 8.1590e-05 - accuracy: 0.5628  \n",
    "Epoch 13/15  \n",
    "31/31 - 16s - loss: 8.2032e-05 - accuracy: 0.5628  \n",
    "Epoch 14/15  \n",
    "31/31 - 17s - loss: 8.2135e-05 - accuracy: 0.5628  \n",
    "Epoch 15/15  \n",
    "31/31 - 16s - loss: 8.1992e-05 - accuracy: 0.5628  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:05:22.803360Z",
     "iopub.status.busy": "2021-12-13T12:05:22.802831Z",
     "iopub.status.idle": "2021-12-13T12:05:23.113513Z",
     "shell.execute_reply": "2021-12-13T12:05:23.112763Z",
     "shell.execute_reply.started": "2021-12-13T12:05:22.803323Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(his.history['loss'])\n",
    "plt.plot(his.history['accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss','accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:05:23.140159Z",
     "iopub.status.busy": "2021-12-13T12:05:23.139740Z",
     "iopub.status.idle": "2021-12-13T12:05:40.806560Z",
     "shell.execute_reply": "2021-12-13T12:05:40.804289Z",
     "shell.execute_reply.started": "2021-12-13T12:05:23.140107Z"
    }
   },
   "outputs": [],
   "source": [
    "test_input = np.array(X_train[:, -timesteps:, :]) \n",
    "test_input = test_input.reshape((X_train.shape[0], timesteps, num_features)) \n",
    "y_test = model.predict(test_input[:,-timesteps:, :], verbose=2)\n",
    "test_forecast= np.concatenate((test_input[:,:,8].reshape(test_input.shape[0],test_input.shape[1]), \n",
    "                           y_test.astype(np.float32).reshape(test_input.shape[0],test_input.shape[1])),axis=1).reshape((test_input.shape[0],test_input.shape[1]+28,1))\n",
    "# Reverse normalization\n",
    "test_forecast = FNoramlize(test_forecast,train_low,train_high)\n",
    "test_forecast = np.rint(test_forecast)\n",
    "forecast = pd.DataFrame(test_forecast.reshape(test_forecast.shape[0],test_forecast.shape[1])).iloc[:,-28:]\n",
    "forecast.columns = [f'F{i}' for i in range(1, forecast.shape[1] + 1)]\n",
    "forecast[forecast < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:05:41.104984Z",
     "iopub.status.busy": "2021-12-13T12:05:41.104306Z",
     "iopub.status.idle": "2021-12-13T12:05:46.415933Z",
     "shell.execute_reply": "2021-12-13T12:05:46.414935Z",
     "shell.execute_reply.started": "2021-12-13T12:05:41.104933Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('sales_train_validation.csv')\n",
    "validation_ids = train_data['id'].values\n",
    "evaluation_ids = [i.replace('validation', 'evaluation') for i in validation_ids]\n",
    "ids = np.concatenate([validation_ids, evaluation_ids])\n",
    "predictions = pd.DataFrame(ids, columns=['id'])\n",
    "forecast = pd.concat([forecast]*2).reset_index(drop=True)\n",
    "predictions = pd.concat([predictions, forecast], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T12:23:40.058486Z",
     "iopub.status.busy": "2021-12-13T12:23:40.058080Z",
     "iopub.status.idle": "2021-12-13T12:23:40.470297Z",
     "shell.execute_reply": "2021-12-13T12:23:40.468939Z",
     "shell.execute_reply.started": "2021-12-13T12:23:40.058437Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions.to_csv('submission.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
