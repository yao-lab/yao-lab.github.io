{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14b53aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IMAGE_WIDTH = {5: 15, 20: 60, 60: 180}\n",
    "IMAGE_HEIGHT = {5: 32, 20: 64, 60: 96}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2415204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images =[]\n",
    "label_df= pd.DataFrame()\n",
    "for year in range(1993,2000):\n",
    "    train = np.memmap(op.join(\"monthly_20d/\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), dtype=np.uint8, mode='r+').reshape(\\\n",
    "                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20]))\n",
    "    train = np.array(train/255.0)\n",
    "    images.append(train)\n",
    "    label_df_train = pd.read_feather(op.join(\"monthly_20d/\", f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\"))\n",
    "    label_df= pd.concat([label_df,label_df_train],axis= 0)\n",
    "images = np.concatenate(images, axis=0, out=None)\n",
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6925ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =[]\n",
    "y_test= pd.DataFrame()\n",
    "for year in range(2000,2005):\n",
    "    train = np.memmap(op.join(\"monthly_20d/\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), dtype=np.uint8, mode='r+').reshape(\\\n",
    "                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20]))\n",
    "    train = np.array(train/255.0)\n",
    "    x_test.append(train)\n",
    "    label_df_train = pd.read_feather(op.join(\"monthly_20d/\", f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\"))\n",
    "    y_test= pd.concat([y_test,label_df_train],axis= 0)\n",
    "x_test = np.concatenate(x_test, axis=0, out=None)\n",
    "y_test = y_test['Retx_20d'].copy()\n",
    "y_test[y_test.isna()]=0\n",
    "x_test = np.reshape(x_test,( -1,1,64,60))\n",
    "y_test = np.array(y_test).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f647b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape train: (486409, 1, 64, 60) shape validation (208462, 1, 64, 60) shape test (436268, 1, 64, 60)\n"
     ]
    }
   ],
   "source": [
    "y = label_df['Retx_20d'].copy()\n",
    "# y = pd.get_dummies(y)\n",
    "y[y.isna()]=0\n",
    "y = np.array(y).reshape((-1,1))\n",
    "\n",
    "images = np.reshape(images,( -1,1,64,60))\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, y, test_size=0.3, random_state=10, shuffle=True)\n",
    "\n",
    "print('shape train:',np.shape(x_train),'shape validation',np.shape(x_val),'shape test',np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a63723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = label_df['Retx_20d'].copy()\n",
    "# y[y.isna()]=0\n",
    "# y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad66555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data # 获取迭代数据\n",
    "from torch.autograd import Variable # 获取变量\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "import torch.utils.data as Dataset\n",
    "from torchsummary import summary\n",
    "torch.cuda.empty_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec3d477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea25d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subDataset(Dataset.Dataset):\n",
    "    #初始化，定义数据内容和标签\n",
    "    def __init__(self, Data, Label):\n",
    "        self.Data = Data\n",
    "        self.Label = Label\n",
    "    #返回数据集大小\n",
    "    def __len__(self):\n",
    "        return len(self.Data)\n",
    "    #得到数据内容和标签\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.Tensor(self.Data[index])\n",
    "        label = torch.Tensor(self.Label[index])\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a986374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        print(self.path)\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6884b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = subDataset(x_train, y_train)\n",
    "val_dataset = subDataset(x_val, y_val)\n",
    "test_dataset = subDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4aa7195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset[0]\n",
    "train_loader = data.DataLoader(train_dataset,batch_size=128,shuffle=True)\n",
    "val_loader= data.DataLoader(val_dataset,batch_size=128,shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset,batch_size=128,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de9f6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1,\n",
    "                            out_channels=64,\n",
    "                            kernel_size=[5,3],\n",
    "                            stride=[1,3],\n",
    "                            padding=[2,1],\n",
    "                            dilation =[1,2]\n",
    "                            ),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64,128, kernel_size=[5,3], padding=[2,1],stride=[1,3]),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128,256, kernel_size=[5,3],padding=[2,1], stride=[1,3]),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        self.conv4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(256,512, kernel_size=[5,3],padding=[2,1],stride=[1,3]),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(512*4,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ada43c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 4)\n",
      "Let's use 4 GPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CNN(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(5, 3), stride=(1, 3), padding=(2, 1), dilation=(1, 2))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(5, 3), stride=(1, 3), padding=(2, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(5, 3), stride=(1, 3), padding=(2, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(5, 3), stride=(1, 3), padding=(2, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc1): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_ids=range(torch.cuda.device_count())\n",
    "print(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs\")\n",
    "# dim = 0 [64, xxx] -> [32, ...], [32, ...] on 2GPUs\n",
    "model = nn.DataParallel(model, device_ids=device_ids)\n",
    "model.cuda(device=device_ids[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b65f395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 20]           1,024\n",
      "            Conv2d-2           [-1, 64, 64, 20]           1,024\n",
      "       BatchNorm2d-3           [-1, 64, 64, 20]             128\n",
      "           Dropout-4           [-1, 64, 64, 20]               0\n",
      "       BatchNorm2d-5           [-1, 64, 64, 20]             128\n",
      "         LeakyReLU-6           [-1, 64, 64, 20]               0\n",
      "         MaxPool2d-7           [-1, 64, 32, 20]               0\n",
      "           Dropout-8           [-1, 64, 64, 20]               0\n",
      "         LeakyReLU-9           [-1, 64, 64, 20]               0\n",
      "           Conv2d-10           [-1, 128, 32, 7]         123,008\n",
      "        MaxPool2d-11           [-1, 64, 32, 20]               0\n",
      "           Conv2d-12           [-1, 128, 32, 7]         123,008\n",
      "      BatchNorm2d-13           [-1, 128, 32, 7]             256\n",
      "          Dropout-14           [-1, 128, 32, 7]               0\n",
      "      BatchNorm2d-15           [-1, 128, 32, 7]             256\n",
      "        LeakyReLU-16           [-1, 128, 32, 7]               0\n",
      "        MaxPool2d-17           [-1, 128, 16, 7]               0\n",
      "          Dropout-18           [-1, 128, 32, 7]               0\n",
      "           Conv2d-19           [-1, 256, 16, 3]         491,776\n",
      "        LeakyReLU-20           [-1, 128, 32, 7]               0\n",
      "        MaxPool2d-21           [-1, 128, 16, 7]               0\n",
      "           Conv2d-22           [-1, 256, 16, 3]         491,776\n",
      "      BatchNorm2d-23           [-1, 256, 16, 3]             512\n",
      "          Dropout-24           [-1, 256, 16, 3]               0\n",
      "      BatchNorm2d-25           [-1, 256, 16, 3]             512\n",
      "        LeakyReLU-26           [-1, 256, 16, 3]               0\n",
      "        MaxPool2d-27            [-1, 256, 8, 3]               0\n",
      "          Dropout-28           [-1, 256, 16, 3]               0\n",
      "           Conv2d-29            [-1, 512, 8, 1]       1,966,592\n",
      "        LeakyReLU-30           [-1, 256, 16, 3]               0\n",
      "        MaxPool2d-31            [-1, 256, 8, 3]               0\n",
      "           Conv2d-32            [-1, 512, 8, 1]       1,966,592\n",
      "      BatchNorm2d-33            [-1, 512, 8, 1]           1,024\n",
      "          Dropout-34            [-1, 512, 8, 1]               0\n",
      "      BatchNorm2d-35            [-1, 512, 8, 1]           1,024\n",
      "        LeakyReLU-36            [-1, 512, 8, 1]               0\n",
      "        MaxPool2d-37            [-1, 512, 4, 1]               0\n",
      "          Flatten-38                 [-1, 2048]               0\n",
      "          Dropout-39            [-1, 512, 8, 1]               0\n",
      "           Linear-40                    [-1, 1]           2,049\n",
      "        LeakyReLU-41            [-1, 512, 8, 1]               0\n",
      "        MaxPool2d-42            [-1, 512, 4, 1]               0\n",
      "          Flatten-43                 [-1, 2048]               0\n",
      "              CNN-44                    [-1, 1]               0\n",
      "           Linear-45                    [-1, 1]           2,049\n",
      "              CNN-46                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 5,172,738\n",
      "Trainable params: 5,172,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 8.75\n",
      "Params size (MB): 19.73\n",
      "Estimated Total Size (MB): 28.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1,64,60),device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a0f6959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../cnn_model/cnn_torch/ret_20_pred_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "patience= 6\n",
    "epochs=120\n",
    "loss_func = torch.nn.MSELoss()\n",
    "opt = torch.optim.Adam(model.parameters(),lr=0.00001)\n",
    "early_stopping = EarlyStopping(patience, path= '../cnn_model/cnn_torch/ret_20_pred_checkpoint.pt',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac017aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 64, kernel_size=(5, 3), stride=(1, 3), padding=(2, 1), dilation=(1, 2))\n",
      "Conv2d(64, 128, kernel_size=(5, 3), stride=(1, 3), padding=(2, 1))\n",
      "Conv2d(128, 256, kernel_size=(5, 3), stride=(1, 3), padding=(2, 1))\n",
      "Conv2d(256, 512, kernel_size=(5, 3), stride=(1, 3), padding=(2, 1))\n"
     ]
    }
   ],
   "source": [
    "# summary(model, input_size=(1,64,60), device=\"cuda\")\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m)\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        # nn.init.kaiming_normal(m.weight.data)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e176e82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1:  iteration: 1:\t loss: 0.03254452347755432\n",
      "val loss:\t 0.0242947\n",
      "epoch: 1:  iteration: 21:\t loss: 0.029633579775691032\n",
      "epoch: 1:  iteration: 41:\t loss: 0.019318651407957077\n",
      "epoch: 1:  iteration: 61:\t loss: 0.020320624113082886\n",
      "epoch: 1:  iteration: 81:\t loss: 0.034864019602537155\n",
      "epoch: 1:  iteration: 101:\t loss: 0.03769470378756523\n",
      "val loss:\t 0.044998594\n",
      "epoch: 1:  iteration: 121:\t loss: 0.037856653332710266\n",
      "epoch: 1:  iteration: 141:\t loss: 0.020882241427898407\n",
      "epoch: 1:  iteration: 161:\t loss: 0.07306124269962311\n",
      "epoch: 1:  iteration: 181:\t loss: 0.026083074510097504\n",
      "epoch: 1:  iteration: 201:\t loss: 0.025807388126850128\n",
      "val loss:\t 0.14170116\n",
      "epoch: 1:  iteration: 221:\t loss: 0.014948343858122826\n",
      "epoch: 1:  iteration: 241:\t loss: 0.03244765102863312\n",
      "epoch: 1:  iteration: 261:\t loss: 0.022918174043297768\n",
      "epoch: 1:  iteration: 281:\t loss: 0.014522850513458252\n",
      "epoch: 1:  iteration: 301:\t loss: 0.014734743162989616\n",
      "val loss:\t 0.05831874\n",
      "epoch: 1:  iteration: 321:\t loss: 0.03240840882062912\n",
      "epoch: 1:  iteration: 341:\t loss: 0.024297181516885757\n",
      "epoch: 1:  iteration: 361:\t loss: 0.021911103278398514\n",
      "epoch: 1:  iteration: 381:\t loss: 0.02273417077958584\n",
      "epoch: 1:  iteration: 401:\t loss: 0.014183811843395233\n",
      "val loss:\t 0.057775665\n",
      "epoch: 1:  iteration: 421:\t loss: 0.022918634116649628\n",
      "epoch: 1:  iteration: 441:\t loss: 0.02322559244930744\n",
      "epoch: 1:  iteration: 461:\t loss: 0.03971273452043533\n",
      "epoch: 1:  iteration: 481:\t loss: 0.042276062071323395\n",
      "epoch: 1:  iteration: 501:\t loss: 0.0286032035946846\n",
      "val loss:\t 0.048213445\n",
      "epoch: 1:  iteration: 521:\t loss: 0.027685537934303284\n",
      "epoch: 1:  iteration: 541:\t loss: 0.055366113781929016\n",
      "epoch: 1:  iteration: 561:\t loss: 0.03455383703112602\n",
      "epoch: 1:  iteration: 581:\t loss: 0.02409970387816429\n",
      "epoch: 1:  iteration: 601:\t loss: 0.08869907259941101\n",
      "val loss:\t 0.024663292\n",
      "epoch: 1:  iteration: 621:\t loss: 0.031345635652542114\n",
      "epoch: 1:  iteration: 641:\t loss: 0.017691180109977722\n",
      "epoch: 1:  iteration: 661:\t loss: 0.030416063964366913\n",
      "epoch: 1:  iteration: 681:\t loss: 0.025799404829740524\n",
      "epoch: 1:  iteration: 701:\t loss: 0.01979663595557213\n",
      "val loss:\t 0.021948261\n",
      "epoch: 1:  iteration: 721:\t loss: 0.02328837476670742\n",
      "epoch: 1:  iteration: 741:\t loss: 0.02313079684972763\n",
      "epoch: 1:  iteration: 761:\t loss: 0.04122624546289444\n",
      "epoch: 1:  iteration: 781:\t loss: 0.03775973618030548\n",
      "epoch: 1:  iteration: 801:\t loss: 0.0926121398806572\n",
      "val loss:\t 0.038955115\n",
      "epoch: 1:  iteration: 821:\t loss: 0.03365343064069748\n",
      "epoch: 1:  iteration: 841:\t loss: 0.025646056979894638\n",
      "epoch: 1:  iteration: 861:\t loss: 0.021045684814453125\n",
      "epoch: 1:  iteration: 881:\t loss: 0.03107593022286892\n",
      "epoch: 1:  iteration: 901:\t loss: 0.02565786987543106\n",
      "val loss:\t 0.16402082\n",
      "epoch: 1:  iteration: 921:\t loss: 0.04039011150598526\n",
      "epoch: 1:  iteration: 941:\t loss: 0.026086870580911636\n",
      "epoch: 1:  iteration: 961:\t loss: 0.020140036940574646\n",
      "epoch: 1:  iteration: 981:\t loss: 0.026979248970746994\n",
      "epoch: 1:  iteration: 1001:\t loss: 0.06759260594844818\n",
      "val loss:\t 0.024215067\n",
      "epoch: 1:  iteration: 1021:\t loss: 0.09989988803863525\n",
      "epoch: 1:  iteration: 1041:\t loss: 0.05584195628762245\n",
      "epoch: 1:  iteration: 1061:\t loss: 0.027502773329615593\n",
      "epoch: 1:  iteration: 1081:\t loss: 0.03372058644890785\n",
      "epoch: 1:  iteration: 1101:\t loss: 0.02517162635922432\n",
      "val loss:\t 0.024122078\n",
      "epoch: 1:  iteration: 1121:\t loss: 0.02038995549082756\n",
      "epoch: 1:  iteration: 1141:\t loss: 0.056049808859825134\n",
      "epoch: 1:  iteration: 1161:\t loss: 0.027479514479637146\n",
      "epoch: 1:  iteration: 1181:\t loss: 0.025797326117753983\n",
      "epoch: 1:  iteration: 1201:\t loss: 0.039888814091682434\n",
      "val loss:\t 0.028257154\n",
      "epoch: 1:  iteration: 1221:\t loss: 0.022273050621151924\n",
      "epoch: 1:  iteration: 1241:\t loss: 0.028233351185917854\n",
      "epoch: 1:  iteration: 1261:\t loss: 0.02203724905848503\n",
      "epoch: 1:  iteration: 1281:\t loss: 0.02972962148487568\n",
      "epoch: 1:  iteration: 1301:\t loss: 0.01935604400932789\n",
      "val loss:\t 0.053396884\n",
      "epoch: 1:  iteration: 1321:\t loss: 0.01606069691479206\n",
      "epoch: 1:  iteration: 1341:\t loss: 0.020570363849401474\n",
      "epoch: 1:  iteration: 1361:\t loss: 0.023014212027192116\n",
      "epoch: 1:  iteration: 1381:\t loss: 0.020481204614043236\n",
      "epoch: 1:  iteration: 1401:\t loss: 0.0267786905169487\n",
      "val loss:\t 0.020546205\n",
      "epoch: 1:  iteration: 1421:\t loss: 0.0815594345331192\n",
      "epoch: 1:  iteration: 1441:\t loss: 0.01833234541118145\n",
      "epoch: 1:  iteration: 1461:\t loss: 0.0232562143355608\n",
      "epoch: 1:  iteration: 1481:\t loss: 0.02051655575633049\n",
      "epoch: 1:  iteration: 1501:\t loss: 0.028875675052404404\n",
      "val loss:\t 0.026282046\n",
      "epoch: 1:  iteration: 1521:\t loss: 0.018782086670398712\n",
      "epoch: 1:  iteration: 1541:\t loss: 0.04580849036574364\n",
      "epoch: 1:  iteration: 1561:\t loss: 0.08428144454956055\n",
      "epoch: 1:  iteration: 1581:\t loss: 0.03935517743229866\n",
      "epoch: 1:  iteration: 1601:\t loss: 0.020030878484249115\n",
      "val loss:\t 0.023255454\n",
      "epoch: 1:  iteration: 1621:\t loss: 0.04187372326850891\n",
      "epoch: 1:  iteration: 1641:\t loss: 0.019643934443593025\n",
      "epoch: 1:  iteration: 1661:\t loss: 0.02161329612135887\n",
      "epoch: 1:  iteration: 1681:\t loss: 0.07243978977203369\n",
      "epoch: 1:  iteration: 1701:\t loss: 0.02461325004696846\n",
      "val loss:\t 0.034552574\n",
      "epoch: 1:  iteration: 1721:\t loss: 0.024988260120153427\n",
      "epoch: 1:  iteration: 1741:\t loss: 0.019940540194511414\n",
      "epoch: 1:  iteration: 1761:\t loss: 0.023610124364495277\n",
      "epoch: 1:  iteration: 1781:\t loss: 0.019578851759433746\n",
      "epoch: 1:  iteration: 1801:\t loss: 0.014682445675134659\n",
      "val loss:\t 0.02760702\n",
      "epoch: 1:  iteration: 1821:\t loss: 0.1057286262512207\n",
      "epoch: 1:  iteration: 1841:\t loss: 0.017824221402406693\n",
      "epoch: 1:  iteration: 1861:\t loss: 0.02185947820544243\n",
      "epoch: 1:  iteration: 1881:\t loss: 0.0350332111120224\n",
      "epoch: 1:  iteration: 1901:\t loss: 0.024407729506492615\n",
      "val loss:\t 0.025680589\n",
      "epoch: 1:  iteration: 1921:\t loss: 0.021671243011951447\n",
      "epoch: 1:  iteration: 1941:\t loss: 0.01816265657544136\n",
      "epoch: 1:  iteration: 1961:\t loss: 0.025155264884233475\n",
      "epoch: 1:  iteration: 1981:\t loss: 0.07514321058988571\n",
      "epoch: 1:  iteration: 2001:\t loss: 0.03232743591070175\n",
      "val loss:\t 0.050681543\n",
      "epoch: 1:  iteration: 2021:\t loss: 0.015637187287211418\n",
      "epoch: 1:  iteration: 2041:\t loss: 0.011872509494423866\n",
      "epoch: 1:  iteration: 2061:\t loss: 0.030089888721704483\n",
      "epoch: 1:  iteration: 2081:\t loss: 0.043283745646476746\n",
      "epoch: 1:  iteration: 2101:\t loss: 0.05734496936202049\n",
      "val loss:\t 0.016140588\n",
      "epoch: 1:  iteration: 2121:\t loss: 0.02012287825345993\n",
      "epoch: 1:  iteration: 2141:\t loss: 0.028319288045167923\n",
      "epoch: 1:  iteration: 2161:\t loss: 0.11420530080795288\n",
      "epoch: 1:  iteration: 2181:\t loss: 0.028655199334025383\n",
      "epoch: 1:  iteration: 2201:\t loss: 0.01638171449303627\n",
      "val loss:\t 0.05361577\n",
      "epoch: 1:  iteration: 2221:\t loss: 0.016304289922118187\n",
      "epoch: 1:  iteration: 2241:\t loss: 0.022845948114991188\n",
      "epoch: 1:  iteration: 2261:\t loss: 0.08003892004489899\n",
      "epoch: 1:  iteration: 2281:\t loss: 0.06526902318000793\n",
      "epoch: 1:  iteration: 2301:\t loss: 0.015134207904338837\n",
      "val loss:\t 0.018698875\n",
      "epoch: 1:  iteration: 2321:\t loss: 0.02624882385134697\n",
      "epoch: 1:  iteration: 2341:\t loss: 0.02284078672528267\n",
      "epoch: 1:  iteration: 2361:\t loss: 0.035692617297172546\n",
      "epoch: 1:  iteration: 2381:\t loss: 0.02033853530883789\n",
      "epoch: 1:  iteration: 2401:\t loss: 0.02811998501420021\n",
      "val loss:\t 0.030952746\n",
      "epoch: 1:  iteration: 2421:\t loss: 0.019095534458756447\n",
      "epoch: 1:  iteration: 2441:\t loss: 0.037641558796167374\n",
      "epoch: 1:  iteration: 2461:\t loss: 0.01997227966785431\n",
      "epoch: 1:  iteration: 2481:\t loss: 0.022771717980504036\n",
      "epoch: 1:  iteration: 2501:\t loss: 0.021921928972005844\n",
      "val loss:\t 0.025092008\n",
      "epoch: 1:  iteration: 2521:\t loss: 0.03019772097468376\n",
      "epoch: 1:  iteration: 2541:\t loss: 0.03783174604177475\n",
      "epoch: 1:  iteration: 2561:\t loss: 0.023745086044073105\n",
      "epoch: 1:  iteration: 2581:\t loss: 0.015814799815416336\n",
      "epoch: 1:  iteration: 2601:\t loss: 0.03782171756029129\n",
      "val loss:\t 0.035489842\n",
      "epoch: 1:  iteration: 2621:\t loss: 0.03180084377527237\n",
      "epoch: 1:  iteration: 2641:\t loss: 0.04820043966174126\n",
      "epoch: 1:  iteration: 2661:\t loss: 0.020017225295305252\n",
      "epoch: 1:  iteration: 2681:\t loss: 0.014266852289438248\n",
      "epoch: 1:  iteration: 2701:\t loss: 0.08890927582979202\n",
      "val loss:\t 0.017834954\n",
      "epoch: 1:  iteration: 2721:\t loss: 0.03366871178150177\n",
      "epoch: 1:  iteration: 2741:\t loss: 0.0308823361992836\n",
      "epoch: 1:  iteration: 2761:\t loss: 0.03232729434967041\n",
      "epoch: 1:  iteration: 2781:\t loss: 0.0232212096452713\n",
      "epoch: 1:  iteration: 2801:\t loss: 0.08273490518331528\n",
      "val loss:\t 0.01929798\n",
      "epoch: 1:  iteration: 2821:\t loss: 0.012126382440328598\n",
      "epoch: 1:  iteration: 2841:\t loss: 0.026134872809052467\n",
      "epoch: 1:  iteration: 2861:\t loss: 0.03391507267951965\n",
      "epoch: 1:  iteration: 2881:\t loss: 0.01287877932190895\n",
      "epoch: 1:  iteration: 2901:\t loss: 0.026864752173423767\n",
      "val loss:\t 0.01917839\n",
      "epoch: 1:  iteration: 2921:\t loss: 0.02140272781252861\n",
      "epoch: 1:  iteration: 2941:\t loss: 0.03504427894949913\n",
      "epoch: 1:  iteration: 2961:\t loss: 0.018070323392748833\n",
      "epoch: 1:  iteration: 2981:\t loss: 0.014008531346917152\n",
      "epoch: 1:  iteration: 3001:\t loss: 0.019527489319443703\n",
      "val loss:\t 0.022309454\n",
      "epoch: 1:  iteration: 3021:\t loss: 0.035754356533288956\n",
      "epoch: 1:  iteration: 3041:\t loss: 0.029195718467235565\n",
      "epoch: 1:  iteration: 3061:\t loss: 0.027778811752796173\n",
      "epoch: 1:  iteration: 3081:\t loss: 0.022032426670193672\n",
      "epoch: 1:  iteration: 3101:\t loss: 0.022192733362317085\n",
      "val loss:\t 0.024582967\n",
      "epoch: 1:  iteration: 3121:\t loss: 0.01638076640665531\n",
      "epoch: 1:  iteration: 3141:\t loss: 0.025968007743358612\n",
      "epoch: 1:  iteration: 3161:\t loss: 0.019204378128051758\n",
      "epoch: 1:  iteration: 3181:\t loss: 0.019597891718149185\n",
      "epoch: 1:  iteration: 3201:\t loss: 0.0328039787709713\n",
      "val loss:\t 0.014450248\n",
      "epoch: 1:  iteration: 3221:\t loss: 0.025231685489416122\n",
      "epoch: 1:  iteration: 3241:\t loss: 0.019544824957847595\n",
      "epoch: 1:  iteration: 3261:\t loss: 0.024055495858192444\n",
      "epoch: 1:  iteration: 3281:\t loss: 0.02150675840675831\n",
      "epoch: 1:  iteration: 3301:\t loss: 0.02808373048901558\n",
      "val loss:\t 0.022863492\n",
      "epoch: 1:  iteration: 3321:\t loss: 0.043160729110240936\n",
      "epoch: 1:  iteration: 3341:\t loss: 0.014255724847316742\n",
      "epoch: 1:  iteration: 3361:\t loss: 0.02179698273539543\n",
      "epoch: 1:  iteration: 3381:\t loss: 0.017396070063114166\n",
      "epoch: 1:  iteration: 3401:\t loss: 0.08138930797576904\n",
      "val loss:\t 0.029969051\n",
      "epoch: 1:  iteration: 3421:\t loss: 0.024742502719163895\n",
      "epoch: 1:  iteration: 3441:\t loss: 0.0225130133330822\n",
      "epoch: 1:  iteration: 3461:\t loss: 0.024714626371860504\n",
      "epoch: 1:  iteration: 3481:\t loss: 0.041379012167453766\n",
      "epoch: 1:  iteration: 3501:\t loss: 0.014362189918756485\n",
      "val loss:\t 0.015571823\n",
      "epoch: 1:  iteration: 3521:\t loss: 0.023953953757882118\n",
      "epoch: 1:  iteration: 3541:\t loss: 0.027849921956658363\n",
      "epoch: 1:  iteration: 3561:\t loss: 0.029068877920508385\n",
      "epoch: 1:  iteration: 3581:\t loss: 0.06002127006649971\n",
      "epoch: 1:  iteration: 3601:\t loss: 0.03286897391080856\n",
      "val loss:\t 0.018770315\n",
      "epoch: 1:  iteration: 3621:\t loss: 0.01870548352599144\n",
      "epoch: 1:  iteration: 3641:\t loss: 0.01246921718120575\n",
      "epoch: 1:  iteration: 3661:\t loss: 0.03535736724734306\n",
      "epoch: 1:  iteration: 3681:\t loss: 0.023481197655200958\n",
      "epoch: 1:  iteration: 3701:\t loss: 0.03545833006501198\n",
      "val loss:\t 0.015457632\n",
      "epoch: 1:  iteration: 3721:\t loss: 0.02684742771089077\n",
      "epoch: 1:  iteration: 3741:\t loss: 0.02581406943500042\n",
      "epoch: 1:  iteration: 3761:\t loss: 0.02976188436150551\n",
      "epoch: 1:  iteration: 3781:\t loss: 0.022391922771930695\n",
      "epoch: 1:  iteration: 3801:\t loss: 0.030549854040145874\n",
      "val loss:\t 0.046241846\n",
      "EarlyStopping counter: 3 out of 6\n",
      "----------------epoch end--------------------- 0\n",
      "|loss_train| 0.0003696517669595778\n",
      "|loss_test| 0.007883342914283276\n",
      "epoch: 2:  iteration: 1:\t loss: 0.022800449281930923\n",
      "val loss:\t 0.019175153\n",
      "epoch: 2:  iteration: 21:\t loss: 0.016944970935583115\n",
      "epoch: 2:  iteration: 41:\t loss: 0.022185657173395157\n",
      "epoch: 2:  iteration: 61:\t loss: 0.016425658017396927\n",
      "epoch: 2:  iteration: 81:\t loss: 0.02386232651770115\n",
      "epoch: 2:  iteration: 101:\t loss: 0.023743361234664917\n",
      "val loss:\t 0.02225884\n",
      "epoch: 2:  iteration: 121:\t loss: 0.02832968533039093\n",
      "epoch: 2:  iteration: 141:\t loss: 0.07560276985168457\n",
      "epoch: 2:  iteration: 161:\t loss: 0.044148869812488556\n",
      "epoch: 2:  iteration: 181:\t loss: 0.016026360914111137\n",
      "epoch: 2:  iteration: 201:\t loss: 0.024266637861728668\n",
      "val loss:\t 0.01695952\n",
      "epoch: 2:  iteration: 221:\t loss: 0.02358962595462799\n",
      "epoch: 2:  iteration: 241:\t loss: 0.08855654299259186\n",
      "epoch: 2:  iteration: 261:\t loss: 0.02058788761496544\n",
      "epoch: 2:  iteration: 281:\t loss: 0.026670187711715698\n",
      "epoch: 2:  iteration: 301:\t loss: 0.026647306978702545\n",
      "val loss:\t 0.036704287\n",
      "epoch: 2:  iteration: 321:\t loss: 0.6116293668746948\n",
      "epoch: 2:  iteration: 341:\t loss: 0.02184488996863365\n",
      "epoch: 2:  iteration: 361:\t loss: 0.06226646155118942\n",
      "epoch: 2:  iteration: 381:\t loss: 0.01784532144665718\n",
      "epoch: 2:  iteration: 401:\t loss: 0.023152314126491547\n",
      "val loss:\t 0.020466559\n",
      "epoch: 2:  iteration: 421:\t loss: 0.016963142901659012\n",
      "epoch: 2:  iteration: 441:\t loss: 0.04918551817536354\n",
      "epoch: 2:  iteration: 461:\t loss: 0.022499334067106247\n",
      "epoch: 2:  iteration: 481:\t loss: 0.04853178933262825\n",
      "epoch: 2:  iteration: 501:\t loss: 0.11229882389307022\n",
      "val loss:\t 0.019951621\n",
      "epoch: 2:  iteration: 521:\t loss: 0.022836385294795036\n",
      "epoch: 2:  iteration: 541:\t loss: 0.028668034821748734\n",
      "epoch: 2:  iteration: 561:\t loss: 0.022296780720353127\n",
      "epoch: 2:  iteration: 581:\t loss: 0.01986628584563732\n",
      "epoch: 2:  iteration: 601:\t loss: 0.011662226170301437\n",
      "val loss:\t 0.032689795\n",
      "epoch: 2:  iteration: 621:\t loss: 0.024935223162174225\n",
      "epoch: 2:  iteration: 641:\t loss: 0.02765459194779396\n",
      "epoch: 2:  iteration: 661:\t loss: 0.020388074219226837\n",
      "epoch: 2:  iteration: 681:\t loss: 0.027028370648622513\n",
      "epoch: 2:  iteration: 701:\t loss: 0.05850950628519058\n",
      "val loss:\t 0.036083497\n",
      "epoch: 2:  iteration: 721:\t loss: 0.020868569612503052\n",
      "epoch: 2:  iteration: 741:\t loss: 0.025290802121162415\n",
      "epoch: 2:  iteration: 761:\t loss: 0.07219937443733215\n",
      "epoch: 2:  iteration: 781:\t loss: 0.04269368201494217\n",
      "epoch: 2:  iteration: 801:\t loss: 0.020624464377760887\n",
      "val loss:\t 0.023384936\n",
      "epoch: 2:  iteration: 821:\t loss: 0.02668003737926483\n",
      "epoch: 2:  iteration: 841:\t loss: 0.013740362599492073\n",
      "epoch: 2:  iteration: 861:\t loss: 0.02474479377269745\n",
      "epoch: 2:  iteration: 881:\t loss: 0.027535783126950264\n",
      "epoch: 2:  iteration: 901:\t loss: 0.02234097570180893\n",
      "val loss:\t 0.03269145\n",
      "epoch: 2:  iteration: 921:\t loss: 0.020872611552476883\n",
      "epoch: 2:  iteration: 941:\t loss: 0.036252059042453766\n",
      "epoch: 2:  iteration: 961:\t loss: 0.027107490226626396\n",
      "epoch: 2:  iteration: 981:\t loss: 0.01985381916165352\n",
      "epoch: 2:  iteration: 1001:\t loss: 0.03881169855594635\n",
      "val loss:\t 0.028220128\n",
      "epoch: 2:  iteration: 1021:\t loss: 0.0291275791823864\n",
      "epoch: 2:  iteration: 1041:\t loss: 0.03179720789194107\n",
      "epoch: 2:  iteration: 1061:\t loss: 0.0414491668343544\n",
      "epoch: 2:  iteration: 1081:\t loss: 0.050252579152584076\n",
      "epoch: 2:  iteration: 1101:\t loss: 0.031527914106845856\n",
      "val loss:\t 0.027642481\n",
      "epoch: 2:  iteration: 1121:\t loss: 0.017754733562469482\n",
      "epoch: 2:  iteration: 1141:\t loss: 0.019363023340702057\n",
      "epoch: 2:  iteration: 1161:\t loss: 0.03471943363547325\n",
      "epoch: 2:  iteration: 1181:\t loss: 0.019236281514167786\n",
      "epoch: 2:  iteration: 1201:\t loss: 0.03506682440638542\n",
      "val loss:\t 0.497532\n",
      "epoch: 2:  iteration: 1221:\t loss: 0.030588839203119278\n",
      "epoch: 2:  iteration: 1241:\t loss: 0.03052474930882454\n",
      "epoch: 2:  iteration: 1261:\t loss: 0.03996330499649048\n",
      "epoch: 2:  iteration: 1281:\t loss: 0.022118810564279556\n",
      "epoch: 2:  iteration: 1301:\t loss: 0.018882745876908302\n",
      "val loss:\t 0.14172721\n",
      "epoch: 2:  iteration: 1321:\t loss: 0.29659491777420044\n",
      "epoch: 2:  iteration: 1341:\t loss: 0.0199099313467741\n",
      "epoch: 2:  iteration: 1361:\t loss: 0.019694015383720398\n",
      "epoch: 2:  iteration: 1381:\t loss: 0.02370746061205864\n",
      "epoch: 2:  iteration: 1401:\t loss: 0.02090783417224884\n",
      "val loss:\t 0.028785516\n",
      "epoch: 2:  iteration: 1421:\t loss: 0.023913029581308365\n",
      "epoch: 2:  iteration: 1441:\t loss: 0.04748126119375229\n",
      "epoch: 2:  iteration: 1461:\t loss: 0.013758265413343906\n",
      "epoch: 2:  iteration: 1481:\t loss: 0.04725177586078644\n",
      "epoch: 2:  iteration: 1501:\t loss: 0.015297017991542816\n",
      "val loss:\t 0.024442846\n",
      "epoch: 2:  iteration: 1521:\t loss: 0.022778935730457306\n",
      "epoch: 2:  iteration: 1541:\t loss: 0.021912256255745888\n",
      "epoch: 2:  iteration: 1561:\t loss: 0.016805194318294525\n",
      "epoch: 2:  iteration: 1581:\t loss: 0.025496646761894226\n",
      "epoch: 2:  iteration: 1601:\t loss: 0.02074829861521721\n",
      "val loss:\t 0.019128535\n",
      "epoch: 2:  iteration: 1621:\t loss: 0.029946547001600266\n",
      "epoch: 2:  iteration: 1641:\t loss: 0.022379128262400627\n",
      "epoch: 2:  iteration: 1661:\t loss: 0.027250822633504868\n",
      "epoch: 2:  iteration: 1681:\t loss: 0.021060308441519737\n",
      "epoch: 2:  iteration: 1701:\t loss: 0.02716810815036297\n",
      "val loss:\t 0.022548795\n",
      "epoch: 2:  iteration: 1721:\t loss: 0.021353168413043022\n",
      "epoch: 2:  iteration: 1741:\t loss: 0.02371860109269619\n",
      "epoch: 2:  iteration: 1761:\t loss: 0.03648889809846878\n",
      "epoch: 2:  iteration: 1781:\t loss: 0.033600371330976486\n",
      "epoch: 2:  iteration: 1801:\t loss: 0.018786581233143806\n",
      "val loss:\t 0.026765835\n",
      "epoch: 2:  iteration: 1821:\t loss: 0.0341612808406353\n",
      "epoch: 2:  iteration: 1841:\t loss: 0.0183777566999197\n",
      "epoch: 2:  iteration: 1861:\t loss: 0.03994506597518921\n",
      "epoch: 2:  iteration: 1881:\t loss: 0.020830340683460236\n",
      "epoch: 2:  iteration: 1901:\t loss: 0.031806379556655884\n",
      "val loss:\t 0.028131817\n",
      "epoch: 2:  iteration: 1921:\t loss: 0.029216021299362183\n",
      "epoch: 2:  iteration: 1941:\t loss: 0.06691686064004898\n",
      "epoch: 2:  iteration: 1961:\t loss: 0.052251167595386505\n",
      "epoch: 2:  iteration: 1981:\t loss: 0.028068967163562775\n",
      "epoch: 2:  iteration: 2001:\t loss: 0.047665610909461975\n",
      "val loss:\t 0.037106387\n",
      "epoch: 2:  iteration: 2021:\t loss: 0.01731347292661667\n",
      "epoch: 2:  iteration: 2041:\t loss: 0.02327115833759308\n",
      "epoch: 2:  iteration: 2061:\t loss: 0.028145283460617065\n",
      "epoch: 2:  iteration: 2081:\t loss: 0.0285680890083313\n",
      "epoch: 2:  iteration: 2101:\t loss: 0.023342158645391464\n",
      "val loss:\t 0.029340839\n",
      "epoch: 2:  iteration: 2121:\t loss: 0.02174556255340576\n",
      "epoch: 2:  iteration: 2141:\t loss: 0.017220159992575645\n",
      "epoch: 2:  iteration: 2161:\t loss: 0.02060752362012863\n",
      "epoch: 2:  iteration: 2181:\t loss: 0.01760287582874298\n",
      "epoch: 2:  iteration: 2201:\t loss: 0.02063363790512085\n",
      "val loss:\t 0.036087863\n",
      "epoch: 2:  iteration: 2221:\t loss: 0.024427901953458786\n",
      "epoch: 2:  iteration: 2241:\t loss: 0.03308232128620148\n",
      "epoch: 2:  iteration: 2261:\t loss: 0.027475319802761078\n",
      "epoch: 2:  iteration: 2281:\t loss: 0.02703402191400528\n",
      "epoch: 2:  iteration: 2301:\t loss: 0.02147701382637024\n",
      "val loss:\t 0.026478905\n",
      "epoch: 2:  iteration: 2321:\t loss: 0.015866637229919434\n",
      "epoch: 2:  iteration: 2341:\t loss: 0.038490962237119675\n",
      "epoch: 2:  iteration: 2361:\t loss: 0.02439388819038868\n",
      "epoch: 2:  iteration: 2381:\t loss: 0.024009941145777702\n",
      "epoch: 2:  iteration: 2401:\t loss: 0.027850650250911713\n",
      "val loss:\t 0.027523406\n",
      "epoch: 2:  iteration: 2421:\t loss: 0.03379160910844803\n",
      "epoch: 2:  iteration: 2441:\t loss: 0.02303628996014595\n",
      "epoch: 2:  iteration: 2461:\t loss: 0.031828396022319794\n",
      "epoch: 2:  iteration: 2481:\t loss: 0.02225298061966896\n",
      "epoch: 2:  iteration: 2501:\t loss: 0.02654782496392727\n",
      "val loss:\t 0.026465569\n",
      "epoch: 2:  iteration: 2521:\t loss: 0.04211752861738205\n",
      "epoch: 2:  iteration: 2541:\t loss: 0.02535029873251915\n",
      "epoch: 2:  iteration: 2561:\t loss: 0.028819436207413673\n",
      "epoch: 2:  iteration: 2581:\t loss: 0.024500269442796707\n",
      "epoch: 2:  iteration: 2601:\t loss: 0.03338655084371567\n",
      "val loss:\t 0.0173281\n",
      "epoch: 2:  iteration: 2621:\t loss: 0.03780277073383331\n",
      "epoch: 2:  iteration: 2641:\t loss: 0.025692831724882126\n",
      "epoch: 2:  iteration: 2661:\t loss: 0.037900470197200775\n",
      "epoch: 2:  iteration: 2681:\t loss: 0.026304904371500015\n",
      "epoch: 2:  iteration: 2701:\t loss: 0.0330137237906456\n",
      "val loss:\t 0.013737196\n",
      "epoch: 2:  iteration: 2721:\t loss: 0.03408772498369217\n",
      "epoch: 2:  iteration: 2741:\t loss: 0.026702366769313812\n",
      "epoch: 2:  iteration: 2761:\t loss: 0.018989723175764084\n",
      "epoch: 2:  iteration: 2781:\t loss: 0.020381271839141846\n",
      "epoch: 2:  iteration: 2801:\t loss: 0.02211822383105755\n",
      "val loss:\t 0.023846826\n",
      "epoch: 2:  iteration: 2821:\t loss: 0.04293082654476166\n",
      "epoch: 2:  iteration: 2841:\t loss: 0.03330568969249725\n",
      "epoch: 2:  iteration: 2861:\t loss: 0.16578206419944763\n",
      "epoch: 2:  iteration: 2881:\t loss: 0.02404499053955078\n",
      "epoch: 2:  iteration: 2901:\t loss: 0.019354883581399918\n",
      "val loss:\t 0.026833475\n",
      "epoch: 2:  iteration: 2921:\t loss: 0.02994130551815033\n",
      "epoch: 2:  iteration: 2941:\t loss: 0.029917653650045395\n",
      "epoch: 2:  iteration: 2961:\t loss: 0.020265232771635056\n",
      "epoch: 2:  iteration: 2981:\t loss: 0.021185413002967834\n",
      "epoch: 2:  iteration: 3001:\t loss: 0.02797943912446499\n",
      "val loss:\t 0.025713865\n",
      "epoch: 2:  iteration: 3021:\t loss: 0.05135558545589447\n",
      "epoch: 2:  iteration: 3041:\t loss: 0.017187386751174927\n",
      "epoch: 2:  iteration: 3061:\t loss: 0.019768450409173965\n",
      "epoch: 2:  iteration: 3081:\t loss: 0.017371900379657745\n",
      "epoch: 2:  iteration: 3101:\t loss: 0.032881077378988266\n",
      "val loss:\t 0.027368534\n",
      "epoch: 2:  iteration: 3121:\t loss: 0.017622889950871468\n",
      "epoch: 2:  iteration: 3141:\t loss: 0.019913721829652786\n",
      "epoch: 2:  iteration: 3161:\t loss: 0.01735217496752739\n",
      "epoch: 2:  iteration: 3181:\t loss: 0.027562662959098816\n",
      "epoch: 2:  iteration: 3201:\t loss: 0.015988361090421677\n",
      "val loss:\t 0.026661549\n",
      "epoch: 2:  iteration: 3221:\t loss: 0.029330428689718246\n",
      "epoch: 2:  iteration: 3241:\t loss: 0.029506448656320572\n",
      "epoch: 2:  iteration: 3261:\t loss: 0.018252849578857422\n",
      "epoch: 2:  iteration: 3281:\t loss: 0.020083479583263397\n",
      "epoch: 2:  iteration: 3301:\t loss: 0.0367443785071373\n",
      "val loss:\t 0.023213163\n",
      "epoch: 2:  iteration: 3321:\t loss: 0.018161773681640625\n",
      "epoch: 2:  iteration: 3341:\t loss: 0.016543664038181305\n",
      "epoch: 2:  iteration: 3361:\t loss: 0.0641918033361435\n",
      "epoch: 2:  iteration: 3381:\t loss: 0.018675584346055984\n",
      "epoch: 2:  iteration: 3401:\t loss: 0.030919454991817474\n",
      "val loss:\t 0.19225399\n",
      "epoch: 2:  iteration: 3421:\t loss: 0.02070675417780876\n",
      "epoch: 2:  iteration: 3441:\t loss: 0.020372159779071808\n",
      "epoch: 2:  iteration: 3461:\t loss: 0.016608648002147675\n",
      "epoch: 2:  iteration: 3481:\t loss: 0.033647119998931885\n",
      "epoch: 2:  iteration: 3501:\t loss: 0.029053395614027977\n",
      "val loss:\t 0.023992926\n",
      "epoch: 2:  iteration: 3521:\t loss: 0.020701099187135696\n",
      "epoch: 2:  iteration: 3541:\t loss: 0.01904376596212387\n",
      "epoch: 2:  iteration: 3561:\t loss: 0.046138517558574677\n",
      "epoch: 2:  iteration: 3581:\t loss: 0.0598275251686573\n",
      "epoch: 2:  iteration: 3601:\t loss: 0.027912350371479988\n",
      "val loss:\t 0.047717296\n",
      "epoch: 2:  iteration: 3621:\t loss: 0.030989456921815872\n",
      "epoch: 2:  iteration: 3641:\t loss: 0.052083127200603485\n",
      "epoch: 2:  iteration: 3661:\t loss: 0.03987446427345276\n",
      "epoch: 2:  iteration: 3681:\t loss: 0.024366281926631927\n",
      "epoch: 2:  iteration: 3701:\t loss: 0.03123377449810505\n",
      "val loss:\t 0.015592922\n",
      "epoch: 2:  iteration: 3721:\t loss: 0.021345846354961395\n",
      "epoch: 2:  iteration: 3741:\t loss: 0.01865624263882637\n",
      "epoch: 2:  iteration: 3761:\t loss: 0.04128452390432358\n",
      "epoch: 2:  iteration: 3781:\t loss: 0.01811288297176361\n",
      "epoch: 2:  iteration: 3801:\t loss: 0.055437345057725906\n",
      "val loss:\t 0.035299\n",
      "EarlyStopping counter: 4 out of 6\n",
      "----------------epoch end--------------------- 1\n",
      "|loss_train| 0.00015702369273640215\n",
      "|loss_test| 0.046372752636671066\n",
      "epoch: 3:  iteration: 1:\t loss: 0.019354967400431633\n",
      "val loss:\t 0.020093095\n",
      "epoch: 3:  iteration: 21:\t loss: 0.022504350170493126\n",
      "epoch: 3:  iteration: 41:\t loss: 0.0477847121655941\n",
      "epoch: 3:  iteration: 61:\t loss: 0.034103669226169586\n",
      "epoch: 3:  iteration: 81:\t loss: 0.02578679472208023\n",
      "epoch: 3:  iteration: 101:\t loss: 0.035128120332956314\n",
      "val loss:\t 0.02689235\n",
      "epoch: 3:  iteration: 121:\t loss: 0.027281370013952255\n",
      "epoch: 3:  iteration: 141:\t loss: 0.04184607416391373\n",
      "epoch: 3:  iteration: 161:\t loss: 0.04074636474251747\n",
      "epoch: 3:  iteration: 181:\t loss: 0.04194091260433197\n",
      "epoch: 3:  iteration: 201:\t loss: 0.028983429074287415\n",
      "val loss:\t 0.08258425\n",
      "epoch: 3:  iteration: 221:\t loss: 0.016565099358558655\n",
      "epoch: 3:  iteration: 241:\t loss: 0.01898983307182789\n",
      "epoch: 3:  iteration: 261:\t loss: 0.022644713521003723\n",
      "epoch: 3:  iteration: 281:\t loss: 0.021469712257385254\n",
      "epoch: 3:  iteration: 301:\t loss: 0.02174634486436844\n",
      "val loss:\t 0.039131436\n",
      "epoch: 3:  iteration: 321:\t loss: 0.01797422766685486\n",
      "epoch: 3:  iteration: 341:\t loss: 0.02395864948630333\n",
      "epoch: 3:  iteration: 361:\t loss: 0.016112349927425385\n",
      "epoch: 3:  iteration: 381:\t loss: 0.021642547100782394\n",
      "epoch: 3:  iteration: 401:\t loss: 0.022143961861729622\n",
      "val loss:\t 0.028841741\n",
      "epoch: 3:  iteration: 421:\t loss: 0.01559063233435154\n",
      "epoch: 3:  iteration: 441:\t loss: 0.03507644683122635\n",
      "epoch: 3:  iteration: 461:\t loss: 0.02880471758544445\n",
      "epoch: 3:  iteration: 481:\t loss: 0.03922959044575691\n",
      "epoch: 3:  iteration: 501:\t loss: 0.016963783651590347\n",
      "val loss:\t 0.027080555\n",
      "epoch: 3:  iteration: 521:\t loss: 0.03420587629079819\n",
      "epoch: 3:  iteration: 541:\t loss: 0.023832350969314575\n",
      "epoch: 3:  iteration: 561:\t loss: 0.027930885553359985\n",
      "epoch: 3:  iteration: 581:\t loss: 0.031123491004109383\n",
      "epoch: 3:  iteration: 601:\t loss: 0.1691904067993164\n",
      "val loss:\t 0.022313695\n",
      "epoch: 3:  iteration: 621:\t loss: 0.03992542251944542\n",
      "epoch: 3:  iteration: 641:\t loss: 0.018787134438753128\n",
      "epoch: 3:  iteration: 661:\t loss: 0.022845381870865822\n",
      "epoch: 3:  iteration: 681:\t loss: 0.0263653676956892\n",
      "epoch: 3:  iteration: 701:\t loss: 0.017723403871059418\n",
      "val loss:\t 0.019466724\n",
      "epoch: 3:  iteration: 721:\t loss: 0.024072734639048576\n",
      "epoch: 3:  iteration: 741:\t loss: 0.022717855870723724\n",
      "epoch: 3:  iteration: 761:\t loss: 0.01772007718682289\n",
      "epoch: 3:  iteration: 781:\t loss: 0.019706273451447487\n",
      "epoch: 3:  iteration: 801:\t loss: 0.028669513761997223\n",
      "val loss:\t 0.02203049\n",
      "epoch: 3:  iteration: 821:\t loss: 0.027408113703131676\n",
      "epoch: 3:  iteration: 841:\t loss: 0.06817346811294556\n",
      "epoch: 3:  iteration: 861:\t loss: 0.02396717481315136\n",
      "epoch: 3:  iteration: 881:\t loss: 0.026681508868932724\n",
      "epoch: 3:  iteration: 901:\t loss: 0.026121672242879868\n",
      "val loss:\t 0.042367592\n",
      "epoch: 3:  iteration: 921:\t loss: 0.04189284145832062\n",
      "epoch: 3:  iteration: 941:\t loss: 0.03153647854924202\n",
      "epoch: 3:  iteration: 961:\t loss: 0.022295987233519554\n",
      "epoch: 3:  iteration: 981:\t loss: 0.021815763786435127\n",
      "epoch: 3:  iteration: 1001:\t loss: 0.0594501867890358\n",
      "val loss:\t 0.04662577\n",
      "epoch: 3:  iteration: 1021:\t loss: 0.04904448986053467\n",
      "epoch: 3:  iteration: 1041:\t loss: 0.02117723412811756\n",
      "epoch: 3:  iteration: 1061:\t loss: 0.10529384016990662\n",
      "epoch: 3:  iteration: 1081:\t loss: 0.025186698883771896\n",
      "epoch: 3:  iteration: 1101:\t loss: 0.02209959365427494\n",
      "val loss:\t 0.03243634\n",
      "epoch: 3:  iteration: 1121:\t loss: 0.03221205621957779\n",
      "epoch: 3:  iteration: 1141:\t loss: 0.017555246129631996\n",
      "epoch: 3:  iteration: 1161:\t loss: 0.015151908621191978\n",
      "epoch: 3:  iteration: 1181:\t loss: 0.03565458208322525\n",
      "epoch: 3:  iteration: 1201:\t loss: 0.026651136577129364\n",
      "val loss:\t 0.095510446\n",
      "epoch: 3:  iteration: 1221:\t loss: 0.01876707933843136\n",
      "epoch: 3:  iteration: 1241:\t loss: 0.024055471643805504\n",
      "epoch: 3:  iteration: 1261:\t loss: 0.014178457669913769\n",
      "epoch: 3:  iteration: 1281:\t loss: 0.031817369163036346\n",
      "epoch: 3:  iteration: 1301:\t loss: 0.034752003848552704\n",
      "val loss:\t 0.021152915\n",
      "epoch: 3:  iteration: 1321:\t loss: 0.025005917996168137\n",
      "epoch: 3:  iteration: 1341:\t loss: 0.04695282503962517\n",
      "epoch: 3:  iteration: 1361:\t loss: 0.049127425998449326\n",
      "epoch: 3:  iteration: 1381:\t loss: 0.02419869974255562\n",
      "epoch: 3:  iteration: 1401:\t loss: 0.03442627564072609\n",
      "val loss:\t 0.0196236\n",
      "epoch: 3:  iteration: 1421:\t loss: 0.02885705605149269\n",
      "epoch: 3:  iteration: 1441:\t loss: 0.017816882580518723\n",
      "epoch: 3:  iteration: 1461:\t loss: 0.020291879773139954\n",
      "epoch: 3:  iteration: 1481:\t loss: 0.020321503281593323\n",
      "epoch: 3:  iteration: 1501:\t loss: 0.025357622653245926\n",
      "val loss:\t 0.037478976\n",
      "epoch: 3:  iteration: 1521:\t loss: 0.023899851366877556\n",
      "epoch: 3:  iteration: 1541:\t loss: 0.07175169140100479\n",
      "epoch: 3:  iteration: 1561:\t loss: 0.022430984303355217\n",
      "epoch: 3:  iteration: 1581:\t loss: 0.03619912639260292\n",
      "epoch: 3:  iteration: 1601:\t loss: 0.027886660769581795\n",
      "val loss:\t 0.023768418\n",
      "epoch: 3:  iteration: 1621:\t loss: 0.052645791321992874\n",
      "epoch: 3:  iteration: 1641:\t loss: 0.015205604955554008\n",
      "epoch: 3:  iteration: 1661:\t loss: 0.06779811531305313\n",
      "epoch: 3:  iteration: 1681:\t loss: 0.07290652394294739\n",
      "epoch: 3:  iteration: 1701:\t loss: 0.022627513855695724\n",
      "val loss:\t 0.026253277\n",
      "epoch: 3:  iteration: 1721:\t loss: 0.028315944597125053\n",
      "epoch: 3:  iteration: 1741:\t loss: 0.02345600724220276\n",
      "epoch: 3:  iteration: 1761:\t loss: 0.060523904860019684\n",
      "epoch: 3:  iteration: 1781:\t loss: 0.03774699568748474\n",
      "epoch: 3:  iteration: 1801:\t loss: 0.024753648787736893\n",
      "val loss:\t 0.017083619\n",
      "epoch: 3:  iteration: 1821:\t loss: 0.013841470703482628\n",
      "epoch: 3:  iteration: 1841:\t loss: 0.02108766697347164\n",
      "epoch: 3:  iteration: 1861:\t loss: 0.6935948729515076\n",
      "epoch: 3:  iteration: 1881:\t loss: 0.02898580953478813\n",
      "epoch: 3:  iteration: 1901:\t loss: 0.018725790083408356\n",
      "val loss:\t 0.042021837\n",
      "epoch: 3:  iteration: 1921:\t loss: 0.027647852897644043\n",
      "epoch: 3:  iteration: 1941:\t loss: 0.013581212610006332\n",
      "epoch: 3:  iteration: 1961:\t loss: 0.014800777658820152\n",
      "epoch: 3:  iteration: 1981:\t loss: 0.024167312309145927\n",
      "epoch: 3:  iteration: 2001:\t loss: 0.027157561853528023\n",
      "val loss:\t 0.021044416\n",
      "epoch: 3:  iteration: 2021:\t loss: 0.031526923179626465\n",
      "epoch: 3:  iteration: 2041:\t loss: 0.02082069218158722\n",
      "epoch: 3:  iteration: 2061:\t loss: 0.04795791953802109\n",
      "epoch: 3:  iteration: 2081:\t loss: 0.02576354704797268\n",
      "epoch: 3:  iteration: 2101:\t loss: 0.03946738690137863\n",
      "val loss:\t 0.020787548\n",
      "epoch: 3:  iteration: 2121:\t loss: 0.02481062337756157\n",
      "epoch: 3:  iteration: 2141:\t loss: 0.017449505627155304\n",
      "epoch: 3:  iteration: 2161:\t loss: 0.027988934889435768\n",
      "epoch: 3:  iteration: 2181:\t loss: 0.020356927067041397\n",
      "epoch: 3:  iteration: 2201:\t loss: 0.030199367552995682\n",
      "val loss:\t 0.019895367\n",
      "epoch: 3:  iteration: 2221:\t loss: 0.01892751269042492\n",
      "epoch: 3:  iteration: 2241:\t loss: 0.022019196301698685\n",
      "epoch: 3:  iteration: 2261:\t loss: 0.035051703453063965\n",
      "epoch: 3:  iteration: 2281:\t loss: 0.02201687917113304\n",
      "epoch: 3:  iteration: 2301:\t loss: 0.02078317478299141\n",
      "val loss:\t 0.04306688\n",
      "epoch: 3:  iteration: 2321:\t loss: 0.030334042385220528\n",
      "epoch: 3:  iteration: 2341:\t loss: 0.020829182118177414\n",
      "epoch: 3:  iteration: 2361:\t loss: 0.016109667718410492\n",
      "epoch: 3:  iteration: 2381:\t loss: 0.020487509667873383\n",
      "epoch: 3:  iteration: 2401:\t loss: 0.033043213188648224\n",
      "val loss:\t 0.034196995\n",
      "epoch: 3:  iteration: 2421:\t loss: 0.01947765052318573\n",
      "epoch: 3:  iteration: 2441:\t loss: 0.021695300936698914\n",
      "epoch: 3:  iteration: 2461:\t loss: 0.0673915222287178\n",
      "epoch: 3:  iteration: 2481:\t loss: 0.04216701537370682\n",
      "epoch: 3:  iteration: 2501:\t loss: 0.025656525045633316\n",
      "val loss:\t 0.022568487\n",
      "epoch: 3:  iteration: 2521:\t loss: 0.048051778227090836\n",
      "epoch: 3:  iteration: 2541:\t loss: 0.030630189925432205\n",
      "epoch: 3:  iteration: 2561:\t loss: 0.04886910319328308\n",
      "epoch: 3:  iteration: 2581:\t loss: 0.033530961722135544\n",
      "epoch: 3:  iteration: 2601:\t loss: 0.019983995705842972\n",
      "val loss:\t 0.0157797\n",
      "epoch: 3:  iteration: 2621:\t loss: 0.02831161767244339\n",
      "epoch: 3:  iteration: 2641:\t loss: 0.025768371298909187\n",
      "epoch: 3:  iteration: 2661:\t loss: 0.02003074809908867\n",
      "epoch: 3:  iteration: 2681:\t loss: 0.034516409039497375\n",
      "epoch: 3:  iteration: 2701:\t loss: 0.016482312232255936\n",
      "val loss:\t 0.027445141\n",
      "epoch: 3:  iteration: 2721:\t loss: 0.032693736255168915\n",
      "epoch: 3:  iteration: 2741:\t loss: 0.023647364228963852\n",
      "epoch: 3:  iteration: 2761:\t loss: 0.020314974710345268\n",
      "epoch: 3:  iteration: 2781:\t loss: 0.024351151660084724\n",
      "epoch: 3:  iteration: 2801:\t loss: 0.023739945143461227\n",
      "val loss:\t 0.028693248\n",
      "epoch: 3:  iteration: 2821:\t loss: 0.035924628376960754\n",
      "epoch: 3:  iteration: 2841:\t loss: 0.02448255941271782\n",
      "epoch: 3:  iteration: 2861:\t loss: 0.023960545659065247\n",
      "epoch: 3:  iteration: 2881:\t loss: 0.02243310585618019\n",
      "epoch: 3:  iteration: 2901:\t loss: 0.32722392678260803\n",
      "val loss:\t 0.03975109\n",
      "epoch: 3:  iteration: 2921:\t loss: 0.02209344133734703\n",
      "epoch: 3:  iteration: 2941:\t loss: 0.0523260198533535\n",
      "epoch: 3:  iteration: 2961:\t loss: 0.04415179044008255\n",
      "epoch: 3:  iteration: 2981:\t loss: 0.025151435285806656\n",
      "epoch: 3:  iteration: 3001:\t loss: 0.0223288144916296\n",
      "val loss:\t 0.022178259\n",
      "epoch: 3:  iteration: 3021:\t loss: 0.03055197186768055\n",
      "epoch: 3:  iteration: 3041:\t loss: 0.016576211899518967\n",
      "epoch: 3:  iteration: 3061:\t loss: 0.03671783208847046\n",
      "epoch: 3:  iteration: 3081:\t loss: 0.02163795754313469\n",
      "epoch: 3:  iteration: 3101:\t loss: 0.06643199920654297\n",
      "val loss:\t 0.027022878\n",
      "epoch: 3:  iteration: 3121:\t loss: 0.017589598894119263\n",
      "epoch: 3:  iteration: 3141:\t loss: 0.018445417284965515\n",
      "epoch: 3:  iteration: 3161:\t loss: 0.021098248660564423\n",
      "epoch: 3:  iteration: 3181:\t loss: 0.032161563634872437\n",
      "epoch: 3:  iteration: 3201:\t loss: 0.016442539170384407\n",
      "val loss:\t 0.025586214\n",
      "epoch: 3:  iteration: 3221:\t loss: 0.030796652659773827\n",
      "epoch: 3:  iteration: 3241:\t loss: 0.019276225939393044\n",
      "epoch: 3:  iteration: 3261:\t loss: 0.02653134986758232\n",
      "epoch: 3:  iteration: 3281:\t loss: 0.011463018134236336\n",
      "epoch: 3:  iteration: 3301:\t loss: 0.019371911883354187\n",
      "val loss:\t 0.036829278\n",
      "epoch: 3:  iteration: 3321:\t loss: 0.026599213480949402\n",
      "epoch: 3:  iteration: 3341:\t loss: 0.028690652921795845\n",
      "epoch: 3:  iteration: 3361:\t loss: 0.0185931995511055\n",
      "epoch: 3:  iteration: 3381:\t loss: 0.03008679300546646\n",
      "epoch: 3:  iteration: 3401:\t loss: 0.03499327600002289\n",
      "val loss:\t 0.036610316\n",
      "epoch: 3:  iteration: 3421:\t loss: 0.01874932460486889\n",
      "epoch: 3:  iteration: 3441:\t loss: 0.024281984195113182\n",
      "epoch: 3:  iteration: 3461:\t loss: 0.029615256935358047\n",
      "epoch: 3:  iteration: 3481:\t loss: 0.038359858095645905\n",
      "epoch: 3:  iteration: 3501:\t loss: 0.02324153110384941\n",
      "val loss:\t 0.02118839\n",
      "epoch: 3:  iteration: 3521:\t loss: 0.03795527666807175\n",
      "epoch: 3:  iteration: 3541:\t loss: 0.03858821839094162\n",
      "epoch: 3:  iteration: 3561:\t loss: 0.03623992204666138\n",
      "epoch: 3:  iteration: 3581:\t loss: 0.04137265682220459\n",
      "epoch: 3:  iteration: 3601:\t loss: 0.02374167926609516\n",
      "val loss:\t 0.017581642\n",
      "epoch: 3:  iteration: 3621:\t loss: 0.4548967480659485\n",
      "epoch: 3:  iteration: 3641:\t loss: 0.023445598781108856\n",
      "epoch: 3:  iteration: 3661:\t loss: 0.052026763558387756\n",
      "epoch: 3:  iteration: 3681:\t loss: 0.023653240874409676\n",
      "epoch: 3:  iteration: 3701:\t loss: 0.019188137724995613\n",
      "val loss:\t 0.031507097\n",
      "epoch: 3:  iteration: 3721:\t loss: 0.02179270051419735\n",
      "epoch: 3:  iteration: 3741:\t loss: 0.018843624740839005\n",
      "epoch: 3:  iteration: 3761:\t loss: 0.03506579250097275\n",
      "epoch: 3:  iteration: 3781:\t loss: 0.028532687574625015\n",
      "epoch: 3:  iteration: 3801:\t loss: 0.07098022848367691\n",
      "val loss:\t 0.016857054\n",
      "EarlyStopping counter: 5 out of 6\n",
      "----------------epoch end--------------------- 2\n",
      "|loss_train| 0.0005357846966944635\n",
      "|loss_test| 0.0005853620823472738\n",
      "epoch: 4:  iteration: 1:\t loss: 0.02794284000992775\n",
      "val loss:\t 0.027648441\n",
      "epoch: 4:  iteration: 21:\t loss: 0.020993737503886223\n",
      "epoch: 4:  iteration: 41:\t loss: 0.027558378875255585\n",
      "epoch: 4:  iteration: 61:\t loss: 0.027239076793193817\n",
      "epoch: 4:  iteration: 81:\t loss: 0.019433584064245224\n",
      "epoch: 4:  iteration: 101:\t loss: 0.012858578935265541\n",
      "val loss:\t 0.018693395\n",
      "epoch: 4:  iteration: 121:\t loss: 0.021403081715106964\n",
      "epoch: 4:  iteration: 141:\t loss: 0.023727398365736008\n",
      "epoch: 4:  iteration: 161:\t loss: 0.020483914762735367\n",
      "epoch: 4:  iteration: 181:\t loss: 0.029112443327903748\n",
      "epoch: 4:  iteration: 201:\t loss: 0.04022618755698204\n",
      "val loss:\t 0.015395756\n",
      "epoch: 4:  iteration: 221:\t loss: 0.024058911949396133\n",
      "epoch: 4:  iteration: 241:\t loss: 0.03234397992491722\n",
      "epoch: 4:  iteration: 261:\t loss: 0.029410647228360176\n",
      "epoch: 4:  iteration: 281:\t loss: 0.03683030605316162\n",
      "epoch: 4:  iteration: 301:\t loss: 0.06739778816699982\n",
      "val loss:\t 0.03133044\n",
      "epoch: 4:  iteration: 321:\t loss: 0.023256242275238037\n",
      "epoch: 4:  iteration: 341:\t loss: 0.029372110962867737\n",
      "epoch: 4:  iteration: 361:\t loss: 0.07537318766117096\n",
      "epoch: 4:  iteration: 381:\t loss: 0.02471166104078293\n",
      "epoch: 4:  iteration: 401:\t loss: 0.04258638247847557\n",
      "val loss:\t 0.02399908\n",
      "epoch: 4:  iteration: 421:\t loss: 0.04213012009859085\n",
      "epoch: 4:  iteration: 441:\t loss: 0.023152600973844528\n",
      "epoch: 4:  iteration: 461:\t loss: 0.03368329256772995\n",
      "epoch: 4:  iteration: 481:\t loss: 0.029253443703055382\n",
      "epoch: 4:  iteration: 501:\t loss: 0.01844683103263378\n",
      "val loss:\t 0.02950354\n",
      "epoch: 4:  iteration: 521:\t loss: 0.021332260221242905\n",
      "epoch: 4:  iteration: 541:\t loss: 0.08399182558059692\n",
      "epoch: 4:  iteration: 561:\t loss: 0.048517853021621704\n",
      "epoch: 4:  iteration: 581:\t loss: 0.0639069601893425\n",
      "epoch: 4:  iteration: 601:\t loss: 0.02181066945195198\n",
      "val loss:\t 0.018389173\n",
      "epoch: 4:  iteration: 621:\t loss: 0.012131045572459698\n",
      "epoch: 4:  iteration: 641:\t loss: 0.019540825858712196\n",
      "epoch: 4:  iteration: 661:\t loss: 0.050419192761182785\n",
      "epoch: 4:  iteration: 681:\t loss: 0.0249796062707901\n",
      "epoch: 4:  iteration: 701:\t loss: 0.018742483109235764\n",
      "val loss:\t 0.026193464\n",
      "epoch: 4:  iteration: 721:\t loss: 0.027127116918563843\n",
      "epoch: 4:  iteration: 741:\t loss: 0.02418622374534607\n",
      "epoch: 4:  iteration: 761:\t loss: 0.02245992235839367\n",
      "epoch: 4:  iteration: 781:\t loss: 0.019114863127470016\n",
      "epoch: 4:  iteration: 801:\t loss: 0.020944999530911446\n",
      "val loss:\t 0.016889177\n",
      "epoch: 4:  iteration: 821:\t loss: 0.021476952359080315\n",
      "epoch: 4:  iteration: 841:\t loss: 0.022112267091870308\n",
      "epoch: 4:  iteration: 861:\t loss: 0.029703598469495773\n",
      "epoch: 4:  iteration: 881:\t loss: 0.025852197781205177\n",
      "epoch: 4:  iteration: 901:\t loss: 0.019888658076524734\n",
      "val loss:\t 0.016090827\n",
      "epoch: 4:  iteration: 921:\t loss: 0.02316085807979107\n",
      "epoch: 4:  iteration: 941:\t loss: 0.025449281558394432\n",
      "epoch: 4:  iteration: 961:\t loss: 0.01800311915576458\n",
      "epoch: 4:  iteration: 981:\t loss: 0.10041947662830353\n",
      "epoch: 4:  iteration: 1001:\t loss: 0.01579318195581436\n",
      "val loss:\t 0.018930648\n",
      "epoch: 4:  iteration: 1021:\t loss: 0.023911945521831512\n",
      "epoch: 4:  iteration: 1041:\t loss: 0.017426684498786926\n",
      "epoch: 4:  iteration: 1061:\t loss: 0.027983758598566055\n",
      "epoch: 4:  iteration: 1081:\t loss: 0.03656627982854843\n",
      "epoch: 4:  iteration: 1101:\t loss: 0.021707259118556976\n",
      "val loss:\t 0.051679328\n",
      "epoch: 4:  iteration: 1121:\t loss: 0.023692455142736435\n",
      "epoch: 4:  iteration: 1141:\t loss: 0.05049964413046837\n",
      "epoch: 4:  iteration: 1161:\t loss: 0.0321076326072216\n",
      "epoch: 4:  iteration: 1181:\t loss: 0.022114552557468414\n",
      "epoch: 4:  iteration: 1201:\t loss: 0.07775567471981049\n",
      "val loss:\t 0.038069606\n",
      "epoch: 4:  iteration: 1221:\t loss: 0.03808044642210007\n",
      "epoch: 4:  iteration: 1241:\t loss: 0.04897589236497879\n",
      "epoch: 4:  iteration: 1261:\t loss: 0.021344732493162155\n",
      "epoch: 4:  iteration: 1281:\t loss: 0.033670470118522644\n",
      "epoch: 4:  iteration: 1301:\t loss: 0.02114027366042137\n",
      "val loss:\t 0.028175864\n",
      "epoch: 4:  iteration: 1321:\t loss: 0.04205264896154404\n",
      "epoch: 4:  iteration: 1341:\t loss: 0.025347072631120682\n",
      "epoch: 4:  iteration: 1361:\t loss: 0.016876177862286568\n",
      "epoch: 4:  iteration: 1381:\t loss: 0.03815720975399017\n",
      "epoch: 4:  iteration: 1401:\t loss: 0.021240152418613434\n",
      "val loss:\t 0.03458105\n",
      "epoch: 4:  iteration: 1421:\t loss: 0.05502529442310333\n",
      "epoch: 4:  iteration: 1441:\t loss: 0.026630418375134468\n",
      "epoch: 4:  iteration: 1461:\t loss: 0.032044801861047745\n",
      "epoch: 4:  iteration: 1481:\t loss: 0.025227271020412445\n",
      "epoch: 4:  iteration: 1501:\t loss: 0.01665959134697914\n",
      "val loss:\t 0.03685702\n",
      "epoch: 4:  iteration: 1521:\t loss: 0.020301520824432373\n",
      "epoch: 4:  iteration: 1541:\t loss: 0.027084942907094955\n",
      "epoch: 4:  iteration: 1561:\t loss: 0.02078324183821678\n",
      "epoch: 4:  iteration: 1581:\t loss: 0.10948144644498825\n",
      "epoch: 4:  iteration: 1601:\t loss: 0.01843688264489174\n",
      "val loss:\t 0.01531573\n",
      "epoch: 4:  iteration: 1621:\t loss: 0.02141239494085312\n",
      "epoch: 4:  iteration: 1641:\t loss: 0.014449112117290497\n",
      "epoch: 4:  iteration: 1661:\t loss: 0.019082242622971535\n",
      "epoch: 4:  iteration: 1681:\t loss: 0.024360455572605133\n",
      "epoch: 4:  iteration: 1701:\t loss: 0.02629777602851391\n",
      "val loss:\t 0.027403446\n",
      "epoch: 4:  iteration: 1721:\t loss: 0.020359527319669724\n",
      "epoch: 4:  iteration: 1741:\t loss: 0.04254516214132309\n",
      "epoch: 4:  iteration: 1761:\t loss: 0.03938067704439163\n",
      "epoch: 4:  iteration: 1781:\t loss: 0.03554614633321762\n",
      "epoch: 4:  iteration: 1801:\t loss: 0.025056129321455956\n",
      "val loss:\t 0.04800338\n",
      "epoch: 4:  iteration: 1821:\t loss: 0.034666214138269424\n",
      "epoch: 4:  iteration: 1841:\t loss: 0.026309335604310036\n",
      "epoch: 4:  iteration: 1861:\t loss: 0.014570044353604317\n",
      "epoch: 4:  iteration: 1881:\t loss: 0.04258091747760773\n",
      "epoch: 4:  iteration: 1901:\t loss: 0.014386311173439026\n",
      "val loss:\t 0.092152\n",
      "epoch: 4:  iteration: 1921:\t loss: 0.025876693427562714\n",
      "epoch: 4:  iteration: 1941:\t loss: 0.020153013989329338\n",
      "epoch: 4:  iteration: 1961:\t loss: 0.06306180357933044\n",
      "epoch: 4:  iteration: 1981:\t loss: 0.017368528991937637\n",
      "epoch: 4:  iteration: 2001:\t loss: 0.020581960678100586\n",
      "val loss:\t 0.03209211\n",
      "epoch: 4:  iteration: 2021:\t loss: 0.014997249469161034\n",
      "epoch: 4:  iteration: 2041:\t loss: 0.01934531144797802\n",
      "epoch: 4:  iteration: 2061:\t loss: 0.017685018479824066\n",
      "epoch: 4:  iteration: 2081:\t loss: 0.02276521548628807\n",
      "epoch: 4:  iteration: 2101:\t loss: 0.02560736984014511\n",
      "val loss:\t 0.03405851\n",
      "epoch: 4:  iteration: 2121:\t loss: 0.10792501270771027\n",
      "epoch: 4:  iteration: 2141:\t loss: 0.02462877333164215\n",
      "epoch: 4:  iteration: 2161:\t loss: 0.026164846494793892\n",
      "epoch: 4:  iteration: 2181:\t loss: 0.027485881000757217\n",
      "epoch: 4:  iteration: 2201:\t loss: 0.08660584688186646\n",
      "val loss:\t 0.0278038\n",
      "epoch: 4:  iteration: 2221:\t loss: 0.0363737978041172\n",
      "epoch: 4:  iteration: 2241:\t loss: 0.014374897815287113\n",
      "epoch: 4:  iteration: 2261:\t loss: 0.034758929163217545\n",
      "epoch: 4:  iteration: 2281:\t loss: 0.027127910405397415\n",
      "epoch: 4:  iteration: 2301:\t loss: 0.034103456884622574\n",
      "val loss:\t 0.036293276\n",
      "epoch: 4:  iteration: 2321:\t loss: 0.027561426162719727\n",
      "epoch: 4:  iteration: 2341:\t loss: 0.024044884368777275\n",
      "epoch: 4:  iteration: 2361:\t loss: 0.0343121699988842\n",
      "epoch: 4:  iteration: 2381:\t loss: 0.019505823031067848\n",
      "epoch: 4:  iteration: 2401:\t loss: 0.019692586734890938\n",
      "val loss:\t 0.01917915\n",
      "epoch: 4:  iteration: 2421:\t loss: 0.02998087927699089\n",
      "epoch: 4:  iteration: 2441:\t loss: 0.022410796955227852\n",
      "epoch: 4:  iteration: 2461:\t loss: 0.017329661175608635\n",
      "epoch: 4:  iteration: 2481:\t loss: 0.04412928968667984\n",
      "epoch: 4:  iteration: 2501:\t loss: 0.020071590319275856\n",
      "val loss:\t 0.024783531\n",
      "epoch: 4:  iteration: 2521:\t loss: 0.024675242602825165\n",
      "epoch: 4:  iteration: 2541:\t loss: 0.026297738775610924\n",
      "epoch: 4:  iteration: 2561:\t loss: 0.027753040194511414\n",
      "epoch: 4:  iteration: 2581:\t loss: 0.02499064989387989\n",
      "epoch: 4:  iteration: 2601:\t loss: 0.02077421545982361\n",
      "val loss:\t 0.11495419\n",
      "epoch: 4:  iteration: 2621:\t loss: 0.022312702611088753\n",
      "epoch: 4:  iteration: 2641:\t loss: 0.08908219635486603\n",
      "epoch: 4:  iteration: 2661:\t loss: 0.030578721314668655\n",
      "epoch: 4:  iteration: 2681:\t loss: 0.11871784180402756\n",
      "epoch: 4:  iteration: 2701:\t loss: 0.021520841866731644\n",
      "val loss:\t 0.048723277\n",
      "epoch: 4:  iteration: 2721:\t loss: 0.04568334296345711\n",
      "epoch: 4:  iteration: 2741:\t loss: 0.033452097326517105\n",
      "epoch: 4:  iteration: 2761:\t loss: 0.030627550557255745\n",
      "epoch: 4:  iteration: 2781:\t loss: 0.024496201425790787\n",
      "epoch: 4:  iteration: 2801:\t loss: 0.015592129901051521\n",
      "val loss:\t 0.034312412\n",
      "epoch: 4:  iteration: 2821:\t loss: 0.031169498339295387\n",
      "epoch: 4:  iteration: 2841:\t loss: 0.01515124924480915\n",
      "epoch: 4:  iteration: 2861:\t loss: 0.026832755655050278\n",
      "epoch: 4:  iteration: 2881:\t loss: 0.020511850714683533\n",
      "epoch: 4:  iteration: 2901:\t loss: 0.022212978452444077\n",
      "val loss:\t 0.032317877\n",
      "epoch: 4:  iteration: 2921:\t loss: 0.03907223418354988\n",
      "epoch: 4:  iteration: 2941:\t loss: 0.03181881085038185\n",
      "epoch: 4:  iteration: 2961:\t loss: 0.03051358461380005\n",
      "epoch: 4:  iteration: 2981:\t loss: 0.02651592716574669\n",
      "epoch: 4:  iteration: 3001:\t loss: 0.02469838224351406\n",
      "val loss:\t 0.020422855\n",
      "epoch: 4:  iteration: 3021:\t loss: 0.020343657582998276\n",
      "epoch: 4:  iteration: 3041:\t loss: 0.020550698041915894\n",
      "epoch: 4:  iteration: 3061:\t loss: 0.031852059066295624\n",
      "epoch: 4:  iteration: 3081:\t loss: 0.020064473152160645\n",
      "epoch: 4:  iteration: 3101:\t loss: 0.025955375283956528\n",
      "val loss:\t 0.017109172\n",
      "epoch: 4:  iteration: 3121:\t loss: 0.021781668066978455\n",
      "epoch: 4:  iteration: 3141:\t loss: 0.03631631284952164\n",
      "epoch: 4:  iteration: 3161:\t loss: 0.030557632446289062\n",
      "epoch: 4:  iteration: 3181:\t loss: 0.033012229949235916\n",
      "epoch: 4:  iteration: 3201:\t loss: 0.03647257387638092\n",
      "val loss:\t 0.018171526\n",
      "epoch: 4:  iteration: 3221:\t loss: 0.023952310904860497\n",
      "epoch: 4:  iteration: 3241:\t loss: 0.10319781303405762\n",
      "epoch: 4:  iteration: 3261:\t loss: 0.017994828522205353\n",
      "epoch: 4:  iteration: 3281:\t loss: 0.021829254925251007\n",
      "epoch: 4:  iteration: 3301:\t loss: 0.034331776201725006\n",
      "val loss:\t 0.025759198\n",
      "epoch: 4:  iteration: 3321:\t loss: 0.05522369220852852\n",
      "epoch: 4:  iteration: 3341:\t loss: 0.6214616298675537\n",
      "epoch: 4:  iteration: 3361:\t loss: 0.039712075144052505\n",
      "epoch: 4:  iteration: 3381:\t loss: 0.027669845148921013\n",
      "epoch: 4:  iteration: 3401:\t loss: 0.03201521188020706\n",
      "val loss:\t 0.042989593\n",
      "epoch: 4:  iteration: 3421:\t loss: 0.024027574807405472\n",
      "epoch: 4:  iteration: 3441:\t loss: 0.0747300535440445\n",
      "epoch: 4:  iteration: 3461:\t loss: 0.02851901389658451\n",
      "epoch: 4:  iteration: 3481:\t loss: 0.01660824939608574\n",
      "epoch: 4:  iteration: 3501:\t loss: 0.043577127158641815\n",
      "val loss:\t 0.013241516\n",
      "epoch: 4:  iteration: 3521:\t loss: 0.034932296723127365\n",
      "epoch: 4:  iteration: 3541:\t loss: 0.02600713260471821\n",
      "epoch: 4:  iteration: 3561:\t loss: 0.01916305348277092\n",
      "epoch: 4:  iteration: 3581:\t loss: 0.02741127833724022\n",
      "epoch: 4:  iteration: 3601:\t loss: 0.027439283207058907\n",
      "val loss:\t 0.020104669\n",
      "epoch: 4:  iteration: 3621:\t loss: 0.03379463031888008\n",
      "epoch: 4:  iteration: 3641:\t loss: 0.018149852752685547\n",
      "epoch: 4:  iteration: 3661:\t loss: 0.013718487694859505\n",
      "epoch: 4:  iteration: 3681:\t loss: 0.02709154412150383\n",
      "epoch: 4:  iteration: 3701:\t loss: 0.030637888237833977\n",
      "val loss:\t 0.02846549\n",
      "epoch: 4:  iteration: 3721:\t loss: 0.024046003818511963\n",
      "epoch: 4:  iteration: 3741:\t loss: 0.024955354630947113\n",
      "epoch: 4:  iteration: 3761:\t loss: 0.02114095725119114\n",
      "epoch: 4:  iteration: 3781:\t loss: 0.017500676214694977\n",
      "epoch: 4:  iteration: 3801:\t loss: 0.006671881303191185\n",
      "val loss:\t 0.030069478\n",
      "Validation loss decreased (0.006928 --> 0.006672).  Saving model ...\n",
      "----------------epoch end--------------------- 3\n",
      "|loss_train| 0.0002976657706312835\n",
      "|loss_test| 0.00019131653243675828\n",
      "epoch: 5:  iteration: 1:\t loss: 0.10551033914089203\n",
      "val loss:\t 0.020772122\n",
      "epoch: 5:  iteration: 21:\t loss: 0.01766059175133705\n",
      "epoch: 5:  iteration: 41:\t loss: 0.017725234851241112\n",
      "epoch: 5:  iteration: 61:\t loss: 0.031372688710689545\n",
      "epoch: 5:  iteration: 81:\t loss: 0.019446173682808876\n",
      "epoch: 5:  iteration: 101:\t loss: 0.03485593944787979\n",
      "val loss:\t 0.025611635\n",
      "epoch: 5:  iteration: 121:\t loss: 0.019329305738210678\n",
      "epoch: 5:  iteration: 141:\t loss: 0.023026347160339355\n",
      "epoch: 5:  iteration: 161:\t loss: 0.019851207733154297\n",
      "epoch: 5:  iteration: 181:\t loss: 0.027704741805791855\n",
      "epoch: 5:  iteration: 201:\t loss: 0.026973171159625053\n",
      "val loss:\t 0.11690558\n",
      "epoch: 5:  iteration: 221:\t loss: 0.05594692379236221\n",
      "epoch: 5:  iteration: 241:\t loss: 0.022202564403414726\n",
      "epoch: 5:  iteration: 261:\t loss: 0.03197557479143143\n",
      "epoch: 5:  iteration: 281:\t loss: 0.028033465147018433\n",
      "epoch: 5:  iteration: 301:\t loss: 0.022311324253678322\n",
      "val loss:\t 0.020574227\n",
      "epoch: 5:  iteration: 321:\t loss: 0.02020920068025589\n",
      "epoch: 5:  iteration: 341:\t loss: 0.030438359826803207\n",
      "epoch: 5:  iteration: 361:\t loss: 0.022320318967103958\n",
      "epoch: 5:  iteration: 381:\t loss: 0.026676859706640244\n",
      "epoch: 5:  iteration: 401:\t loss: 0.032021645456552505\n",
      "val loss:\t 0.014924559\n",
      "epoch: 5:  iteration: 421:\t loss: 0.06523707509040833\n",
      "epoch: 5:  iteration: 441:\t loss: 0.07547812163829803\n",
      "epoch: 5:  iteration: 461:\t loss: 0.016429174691438675\n",
      "epoch: 5:  iteration: 481:\t loss: 0.05333121865987778\n",
      "epoch: 5:  iteration: 501:\t loss: 0.050050996243953705\n",
      "val loss:\t 0.02027345\n",
      "epoch: 5:  iteration: 521:\t loss: 0.01912708207964897\n",
      "epoch: 5:  iteration: 541:\t loss: 0.020926490426063538\n",
      "epoch: 5:  iteration: 561:\t loss: 0.04255566745996475\n",
      "epoch: 5:  iteration: 581:\t loss: 0.02120465599000454\n",
      "epoch: 5:  iteration: 601:\t loss: 0.043524306267499924\n",
      "val loss:\t 0.03010916\n",
      "epoch: 5:  iteration: 621:\t loss: 0.02364245243370533\n",
      "epoch: 5:  iteration: 641:\t loss: 0.02307550236582756\n",
      "epoch: 5:  iteration: 661:\t loss: 0.019137471914291382\n",
      "epoch: 5:  iteration: 681:\t loss: 0.02823067642748356\n",
      "epoch: 5:  iteration: 701:\t loss: 0.037375129759311676\n",
      "val loss:\t 0.033046898\n",
      "epoch: 5:  iteration: 721:\t loss: 0.034962888807058334\n",
      "epoch: 5:  iteration: 741:\t loss: 0.04913965240120888\n",
      "epoch: 5:  iteration: 761:\t loss: 0.023397093638777733\n",
      "epoch: 5:  iteration: 781:\t loss: 0.018133115023374557\n",
      "epoch: 5:  iteration: 801:\t loss: 0.03375423699617386\n",
      "val loss:\t 0.017992932\n",
      "epoch: 5:  iteration: 821:\t loss: 0.019377415999770164\n",
      "epoch: 5:  iteration: 841:\t loss: 0.05424772948026657\n",
      "epoch: 5:  iteration: 861:\t loss: 0.03962426632642746\n",
      "epoch: 5:  iteration: 881:\t loss: 0.025316953659057617\n",
      "epoch: 5:  iteration: 901:\t loss: 0.021127037703990936\n",
      "val loss:\t 0.02411025\n",
      "epoch: 5:  iteration: 921:\t loss: 0.025419041514396667\n",
      "epoch: 5:  iteration: 941:\t loss: 0.05824751406908035\n",
      "epoch: 5:  iteration: 961:\t loss: 0.018824230879545212\n",
      "epoch: 5:  iteration: 981:\t loss: 0.03374490886926651\n",
      "epoch: 5:  iteration: 1001:\t loss: 0.02267279662191868\n",
      "val loss:\t 0.018964138\n",
      "epoch: 5:  iteration: 1021:\t loss: 0.025886088609695435\n",
      "epoch: 5:  iteration: 1041:\t loss: 0.040542975068092346\n",
      "epoch: 5:  iteration: 1061:\t loss: 0.020861301571130753\n",
      "epoch: 5:  iteration: 1081:\t loss: 0.016495995223522186\n",
      "epoch: 5:  iteration: 1101:\t loss: 0.4385319650173187\n",
      "val loss:\t 0.08507192\n",
      "epoch: 5:  iteration: 1121:\t loss: 0.026677988469600677\n",
      "epoch: 5:  iteration: 1141:\t loss: 0.02363668754696846\n",
      "epoch: 5:  iteration: 1161:\t loss: 0.012724177911877632\n",
      "epoch: 5:  iteration: 1181:\t loss: 0.02217896655201912\n",
      "epoch: 5:  iteration: 1201:\t loss: 0.022585272789001465\n",
      "val loss:\t 0.042189125\n",
      "epoch: 5:  iteration: 1221:\t loss: 0.03342249244451523\n",
      "epoch: 5:  iteration: 1241:\t loss: 0.023791907355189323\n",
      "epoch: 5:  iteration: 1261:\t loss: 0.02399386093020439\n",
      "epoch: 5:  iteration: 1281:\t loss: 0.03690279275178909\n",
      "epoch: 5:  iteration: 1301:\t loss: 0.025471776723861694\n",
      "val loss:\t 0.030906286\n",
      "epoch: 5:  iteration: 1321:\t loss: 0.01737465336918831\n",
      "epoch: 5:  iteration: 1341:\t loss: 0.04206427186727524\n",
      "epoch: 5:  iteration: 1361:\t loss: 0.01988864317536354\n",
      "epoch: 5:  iteration: 1381:\t loss: 0.03091178461909294\n",
      "epoch: 5:  iteration: 1401:\t loss: 0.03011288121342659\n",
      "val loss:\t 0.020276703\n",
      "epoch: 5:  iteration: 1421:\t loss: 0.018604403361678123\n",
      "epoch: 5:  iteration: 1441:\t loss: 0.029371242970228195\n",
      "epoch: 5:  iteration: 1461:\t loss: 0.03927096724510193\n",
      "epoch: 5:  iteration: 1481:\t loss: 0.023560423403978348\n",
      "epoch: 5:  iteration: 1501:\t loss: 0.05083443969488144\n",
      "val loss:\t 0.0336241\n",
      "epoch: 5:  iteration: 1521:\t loss: 0.02027169056236744\n",
      "epoch: 5:  iteration: 1541:\t loss: 0.04427177831530571\n",
      "epoch: 5:  iteration: 1561:\t loss: 0.04169607162475586\n",
      "epoch: 5:  iteration: 1581:\t loss: 0.01978723332285881\n",
      "epoch: 5:  iteration: 1601:\t loss: 0.020372003316879272\n",
      "val loss:\t 0.016823297\n",
      "epoch: 5:  iteration: 1621:\t loss: 0.028908491134643555\n",
      "epoch: 5:  iteration: 1641:\t loss: 0.02701129950582981\n",
      "epoch: 5:  iteration: 1661:\t loss: 0.020093213766813278\n",
      "epoch: 5:  iteration: 1681:\t loss: 0.02069687284529209\n",
      "epoch: 5:  iteration: 1701:\t loss: 0.048799388110637665\n",
      "val loss:\t 0.02376949\n",
      "epoch: 5:  iteration: 1721:\t loss: 0.02258267067372799\n",
      "epoch: 5:  iteration: 1741:\t loss: 0.029704906046390533\n",
      "epoch: 5:  iteration: 1761:\t loss: 0.036263108253479004\n",
      "epoch: 5:  iteration: 1781:\t loss: 0.030661404132843018\n",
      "epoch: 5:  iteration: 1801:\t loss: 0.11217764765024185\n",
      "val loss:\t 0.025757922\n",
      "epoch: 5:  iteration: 1821:\t loss: 0.02143034152686596\n",
      "epoch: 5:  iteration: 1841:\t loss: 0.02430029585957527\n",
      "epoch: 5:  iteration: 1861:\t loss: 0.02215270884335041\n",
      "epoch: 5:  iteration: 1881:\t loss: 0.022833801805973053\n",
      "epoch: 5:  iteration: 1901:\t loss: 0.018557608127593994\n",
      "val loss:\t 0.038834736\n",
      "epoch: 5:  iteration: 1921:\t loss: 0.01956995017826557\n",
      "epoch: 5:  iteration: 1941:\t loss: 0.03506875038146973\n",
      "epoch: 5:  iteration: 1961:\t loss: 0.021966442465782166\n",
      "epoch: 5:  iteration: 1981:\t loss: 0.024785876274108887\n",
      "epoch: 5:  iteration: 2001:\t loss: 0.02000436931848526\n",
      "val loss:\t 0.034441628\n",
      "epoch: 5:  iteration: 2021:\t loss: 0.03806721419095993\n",
      "epoch: 5:  iteration: 2041:\t loss: 0.029167620465159416\n",
      "epoch: 5:  iteration: 2061:\t loss: 0.06750181317329407\n",
      "epoch: 5:  iteration: 2081:\t loss: 0.014494990929961205\n",
      "epoch: 5:  iteration: 2101:\t loss: 0.017583006992936134\n",
      "val loss:\t 0.020695835\n",
      "epoch: 5:  iteration: 2121:\t loss: 0.015683479607105255\n",
      "epoch: 5:  iteration: 2141:\t loss: 0.021874289959669113\n",
      "epoch: 5:  iteration: 2161:\t loss: 0.018294408917427063\n",
      "epoch: 5:  iteration: 2181:\t loss: 0.02257981151342392\n",
      "epoch: 5:  iteration: 2201:\t loss: 0.02224891446530819\n",
      "val loss:\t 0.027278611\n",
      "epoch: 5:  iteration: 2221:\t loss: 0.03756733983755112\n",
      "epoch: 5:  iteration: 2241:\t loss: 0.024066483601927757\n",
      "epoch: 5:  iteration: 2261:\t loss: 0.03872009366750717\n",
      "epoch: 5:  iteration: 2281:\t loss: 0.014882078394293785\n",
      "epoch: 5:  iteration: 2301:\t loss: 0.035172946751117706\n",
      "val loss:\t 0.10649323\n",
      "epoch: 5:  iteration: 2321:\t loss: 0.037507299333810806\n",
      "epoch: 5:  iteration: 2341:\t loss: 0.06585492938756943\n",
      "epoch: 5:  iteration: 2361:\t loss: 0.028679532930254936\n",
      "epoch: 5:  iteration: 2381:\t loss: 0.0265622790902853\n",
      "epoch: 5:  iteration: 2401:\t loss: 0.023140456527471542\n",
      "val loss:\t 0.023678044\n",
      "epoch: 5:  iteration: 2421:\t loss: 0.023925604298710823\n",
      "epoch: 5:  iteration: 2441:\t loss: 0.022391337901353836\n",
      "epoch: 5:  iteration: 2461:\t loss: 0.03462909162044525\n",
      "epoch: 5:  iteration: 2481:\t loss: 0.031125474721193314\n",
      "epoch: 5:  iteration: 2501:\t loss: 0.014047157019376755\n",
      "val loss:\t 0.023512036\n",
      "epoch: 5:  iteration: 2521:\t loss: 0.08774442225694656\n",
      "epoch: 5:  iteration: 2541:\t loss: 0.022714491933584213\n",
      "epoch: 5:  iteration: 2561:\t loss: 0.02034413069486618\n",
      "epoch: 5:  iteration: 2581:\t loss: 0.03162156417965889\n",
      "epoch: 5:  iteration: 2601:\t loss: 0.020082460716366768\n",
      "val loss:\t 0.030179244\n",
      "epoch: 5:  iteration: 2621:\t loss: 0.023687807843089104\n",
      "epoch: 5:  iteration: 2641:\t loss: 0.07139462977647781\n",
      "epoch: 5:  iteration: 2661:\t loss: 0.04161767289042473\n",
      "epoch: 5:  iteration: 2681:\t loss: 0.01856422796845436\n",
      "epoch: 5:  iteration: 2701:\t loss: 0.019891517236828804\n",
      "val loss:\t 0.016263027\n",
      "epoch: 5:  iteration: 2721:\t loss: 0.01688322424888611\n",
      "epoch: 5:  iteration: 2741:\t loss: 0.030877716839313507\n",
      "epoch: 5:  iteration: 2761:\t loss: 0.02130822464823723\n",
      "epoch: 5:  iteration: 2781:\t loss: 0.031520646065473557\n",
      "epoch: 5:  iteration: 2801:\t loss: 0.02873629331588745\n",
      "val loss:\t 0.051634826\n",
      "epoch: 5:  iteration: 2821:\t loss: 0.03872822970151901\n",
      "epoch: 5:  iteration: 2841:\t loss: 0.0221557579934597\n",
      "epoch: 5:  iteration: 2861:\t loss: 0.08943291008472443\n",
      "epoch: 5:  iteration: 2881:\t loss: 0.017725706100463867\n",
      "epoch: 5:  iteration: 2901:\t loss: 0.025425463914871216\n",
      "val loss:\t 0.02028043\n",
      "epoch: 5:  iteration: 2921:\t loss: 0.02341753989458084\n",
      "epoch: 5:  iteration: 2941:\t loss: 0.02873711660504341\n",
      "epoch: 5:  iteration: 2961:\t loss: 0.01504581980407238\n",
      "epoch: 5:  iteration: 2981:\t loss: 0.03132801875472069\n",
      "epoch: 5:  iteration: 3001:\t loss: 0.025360561907291412\n",
      "val loss:\t 0.13997993\n",
      "epoch: 5:  iteration: 3021:\t loss: 0.022446665912866592\n",
      "epoch: 5:  iteration: 3041:\t loss: 0.03477641940116882\n",
      "epoch: 5:  iteration: 3061:\t loss: 0.022980205714702606\n",
      "epoch: 5:  iteration: 3081:\t loss: 0.023354601114988327\n",
      "epoch: 5:  iteration: 3101:\t loss: 0.03166747838258743\n",
      "val loss:\t 0.01656691\n",
      "epoch: 5:  iteration: 3121:\t loss: 0.02174018695950508\n",
      "epoch: 5:  iteration: 3141:\t loss: 0.04201158881187439\n",
      "epoch: 5:  iteration: 3161:\t loss: 0.018121331930160522\n",
      "epoch: 5:  iteration: 3181:\t loss: 0.015570409595966339\n",
      "epoch: 5:  iteration: 3201:\t loss: 0.016184750944375992\n",
      "val loss:\t 0.031062191\n",
      "epoch: 5:  iteration: 3221:\t loss: 0.027455521747469902\n",
      "epoch: 5:  iteration: 3241:\t loss: 0.024729978293180466\n",
      "epoch: 5:  iteration: 3261:\t loss: 0.04513794183731079\n",
      "epoch: 5:  iteration: 3281:\t loss: 0.01754280924797058\n",
      "epoch: 5:  iteration: 3301:\t loss: 0.030447781085968018\n",
      "val loss:\t 0.031416494\n",
      "epoch: 5:  iteration: 3321:\t loss: 0.021879248321056366\n",
      "epoch: 5:  iteration: 3341:\t loss: 0.012787966057658195\n",
      "epoch: 5:  iteration: 3361:\t loss: 0.024388086050748825\n",
      "epoch: 5:  iteration: 3381:\t loss: 0.10046426951885223\n",
      "epoch: 5:  iteration: 3401:\t loss: 0.02023947983980179\n",
      "val loss:\t 0.036651243\n",
      "epoch: 5:  iteration: 3421:\t loss: 0.019181186333298683\n",
      "epoch: 5:  iteration: 3441:\t loss: 0.016729755327105522\n",
      "epoch: 5:  iteration: 3461:\t loss: 0.039522990584373474\n",
      "epoch: 5:  iteration: 3481:\t loss: 0.01937590166926384\n",
      "epoch: 5:  iteration: 3501:\t loss: 0.01946559175848961\n",
      "val loss:\t 0.012902774\n",
      "epoch: 5:  iteration: 3521:\t loss: 0.018493596464395523\n",
      "epoch: 5:  iteration: 3541:\t loss: 0.05215718597173691\n",
      "epoch: 5:  iteration: 3561:\t loss: 0.0261443629860878\n",
      "epoch: 5:  iteration: 3581:\t loss: 0.021262269467115402\n",
      "epoch: 5:  iteration: 3601:\t loss: 0.020815011113882065\n",
      "val loss:\t 0.023332138\n",
      "epoch: 5:  iteration: 3621:\t loss: 0.05859585106372833\n",
      "epoch: 5:  iteration: 3641:\t loss: 0.02643519826233387\n",
      "epoch: 5:  iteration: 3661:\t loss: 0.021365348249673843\n",
      "epoch: 5:  iteration: 3681:\t loss: 0.148594930768013\n",
      "epoch: 5:  iteration: 3701:\t loss: 0.02282673306763172\n",
      "val loss:\t 0.07276002\n",
      "epoch: 5:  iteration: 3721:\t loss: 0.040358081459999084\n",
      "epoch: 5:  iteration: 3741:\t loss: 0.020864488556981087\n",
      "epoch: 5:  iteration: 3761:\t loss: 0.02779974788427353\n",
      "epoch: 5:  iteration: 3781:\t loss: 0.02637353166937828\n",
      "epoch: 5:  iteration: 3801:\t loss: 0.008270853199064732\n",
      "val loss:\t 0.023740217\n",
      "EarlyStopping counter: 1 out of 6\n",
      "----------------epoch end--------------------- 4\n",
      "|loss_train| 0.00012479147699195892\n",
      "|loss_test| 7.429612742271274e-05\n",
      "epoch: 6:  iteration: 1:\t loss: 0.022374102845788002\n",
      "val loss:\t 0.027859539\n",
      "epoch: 6:  iteration: 21:\t loss: 0.03637424856424332\n",
      "epoch: 6:  iteration: 41:\t loss: 0.08760938048362732\n",
      "epoch: 6:  iteration: 61:\t loss: 0.01770305261015892\n",
      "epoch: 6:  iteration: 81:\t loss: 0.0160883367061615\n",
      "epoch: 6:  iteration: 101:\t loss: 0.03585252910852432\n",
      "val loss:\t 0.026048673\n",
      "epoch: 6:  iteration: 121:\t loss: 0.013585621491074562\n",
      "epoch: 6:  iteration: 141:\t loss: 0.04704151302576065\n",
      "epoch: 6:  iteration: 161:\t loss: 0.02014623023569584\n",
      "epoch: 6:  iteration: 181:\t loss: 0.02139883302152157\n",
      "epoch: 6:  iteration: 201:\t loss: 0.030209753662347794\n",
      "val loss:\t 0.030122977\n",
      "epoch: 6:  iteration: 221:\t loss: 0.029911382123827934\n",
      "epoch: 6:  iteration: 241:\t loss: 0.02176355943083763\n",
      "epoch: 6:  iteration: 261:\t loss: 0.020404186099767685\n",
      "epoch: 6:  iteration: 281:\t loss: 0.02483144961297512\n",
      "epoch: 6:  iteration: 301:\t loss: 0.015602334402501583\n",
      "val loss:\t 0.08694801\n",
      "epoch: 6:  iteration: 321:\t loss: 0.045319873839616776\n",
      "epoch: 6:  iteration: 341:\t loss: 0.02812003903090954\n",
      "epoch: 6:  iteration: 361:\t loss: 0.023889627307653427\n",
      "epoch: 6:  iteration: 381:\t loss: 0.04590843617916107\n",
      "epoch: 6:  iteration: 401:\t loss: 0.02230965346097946\n",
      "val loss:\t 0.033552885\n",
      "epoch: 6:  iteration: 421:\t loss: 0.02410735748708248\n",
      "epoch: 6:  iteration: 441:\t loss: 0.015360371209681034\n",
      "epoch: 6:  iteration: 461:\t loss: 0.020427759736776352\n",
      "epoch: 6:  iteration: 481:\t loss: 0.021678056567907333\n",
      "epoch: 6:  iteration: 501:\t loss: 0.016581278294324875\n",
      "val loss:\t 0.024479926\n",
      "epoch: 6:  iteration: 521:\t loss: 0.028540093451738358\n",
      "epoch: 6:  iteration: 541:\t loss: 0.1039222776889801\n",
      "epoch: 6:  iteration: 561:\t loss: 0.02779329940676689\n",
      "epoch: 6:  iteration: 581:\t loss: 0.025707509368658066\n",
      "epoch: 6:  iteration: 601:\t loss: 0.033157333731651306\n",
      "val loss:\t 0.030988794\n",
      "epoch: 6:  iteration: 621:\t loss: 0.020242728292942047\n",
      "epoch: 6:  iteration: 641:\t loss: 0.02955254167318344\n",
      "epoch: 6:  iteration: 661:\t loss: 0.016208209097385406\n",
      "epoch: 6:  iteration: 681:\t loss: 0.03050120547413826\n",
      "epoch: 6:  iteration: 701:\t loss: 0.023976540192961693\n",
      "val loss:\t 0.02750092\n",
      "epoch: 6:  iteration: 721:\t loss: 0.029821796342730522\n",
      "epoch: 6:  iteration: 741:\t loss: 0.026680659502744675\n",
      "epoch: 6:  iteration: 761:\t loss: 0.02639278769493103\n",
      "epoch: 6:  iteration: 781:\t loss: 0.015932731330394745\n",
      "epoch: 6:  iteration: 801:\t loss: 0.01713244803249836\n",
      "val loss:\t 0.034972664\n",
      "epoch: 6:  iteration: 821:\t loss: 0.018177714198827744\n",
      "epoch: 6:  iteration: 841:\t loss: 0.012694147415459156\n",
      "epoch: 6:  iteration: 861:\t loss: 0.03088458999991417\n",
      "epoch: 6:  iteration: 881:\t loss: 0.0358063168823719\n",
      "epoch: 6:  iteration: 901:\t loss: 0.02867884561419487\n",
      "val loss:\t 0.02438255\n",
      "epoch: 6:  iteration: 921:\t loss: 0.01870807260274887\n",
      "epoch: 6:  iteration: 941:\t loss: 0.02974976971745491\n",
      "epoch: 6:  iteration: 961:\t loss: 0.027417398989200592\n",
      "epoch: 6:  iteration: 981:\t loss: 0.0513814315199852\n",
      "epoch: 6:  iteration: 1001:\t loss: 0.023847196251153946\n",
      "val loss:\t 0.034485996\n",
      "epoch: 6:  iteration: 1021:\t loss: 0.024399694055318832\n",
      "epoch: 6:  iteration: 1041:\t loss: 0.030137646943330765\n",
      "epoch: 6:  iteration: 1061:\t loss: 0.021282458677887917\n",
      "epoch: 6:  iteration: 1081:\t loss: 0.03299940750002861\n",
      "epoch: 6:  iteration: 1101:\t loss: 0.01796995848417282\n",
      "val loss:\t 0.020609882\n",
      "epoch: 6:  iteration: 1121:\t loss: 0.024348370730876923\n",
      "epoch: 6:  iteration: 1141:\t loss: 0.016433529555797577\n",
      "epoch: 6:  iteration: 1161:\t loss: 0.025096474215388298\n",
      "epoch: 6:  iteration: 1181:\t loss: 0.018055737018585205\n",
      "epoch: 6:  iteration: 1201:\t loss: 0.02014903351664543\n",
      "val loss:\t 0.02342681\n",
      "epoch: 6:  iteration: 1221:\t loss: 0.022670187056064606\n",
      "epoch: 6:  iteration: 1241:\t loss: 0.04248160123825073\n",
      "epoch: 6:  iteration: 1261:\t loss: 0.023720066994428635\n",
      "epoch: 6:  iteration: 1281:\t loss: 0.018370021134614944\n",
      "epoch: 6:  iteration: 1301:\t loss: 0.03528037294745445\n",
      "val loss:\t 0.017220054\n",
      "epoch: 6:  iteration: 1321:\t loss: 0.10149761289358139\n",
      "epoch: 6:  iteration: 1341:\t loss: 0.041763439774513245\n",
      "epoch: 6:  iteration: 1361:\t loss: 0.14590542018413544\n",
      "epoch: 6:  iteration: 1381:\t loss: 0.03696012496948242\n",
      "epoch: 6:  iteration: 1401:\t loss: 0.034120410680770874\n",
      "val loss:\t 0.05173261\n",
      "epoch: 6:  iteration: 1421:\t loss: 0.030901171267032623\n",
      "epoch: 6:  iteration: 1441:\t loss: 0.031189341098070145\n",
      "epoch: 6:  iteration: 1461:\t loss: 0.01776188611984253\n",
      "epoch: 6:  iteration: 1481:\t loss: 0.020028647035360336\n",
      "epoch: 6:  iteration: 1501:\t loss: 0.01981315389275551\n",
      "val loss:\t 0.16373725\n",
      "epoch: 6:  iteration: 1521:\t loss: 0.03097887523472309\n",
      "epoch: 6:  iteration: 1541:\t loss: 0.032319847494363785\n",
      "epoch: 6:  iteration: 1561:\t loss: 0.026288403198122978\n",
      "epoch: 6:  iteration: 1581:\t loss: 0.10327597707509995\n",
      "epoch: 6:  iteration: 1601:\t loss: 0.04095189645886421\n",
      "val loss:\t 0.03473178\n",
      "epoch: 6:  iteration: 1621:\t loss: 0.017625557258725166\n",
      "epoch: 6:  iteration: 1641:\t loss: 0.04499657824635506\n",
      "epoch: 6:  iteration: 1661:\t loss: 0.023437034338712692\n",
      "epoch: 6:  iteration: 1681:\t loss: 0.03569895774126053\n",
      "epoch: 6:  iteration: 1701:\t loss: 0.09904645383358002\n",
      "val loss:\t 0.02655555\n",
      "epoch: 6:  iteration: 1721:\t loss: 0.019735751673579216\n",
      "epoch: 6:  iteration: 1741:\t loss: 0.022616293281316757\n",
      "epoch: 6:  iteration: 1761:\t loss: 0.02404484525322914\n",
      "epoch: 6:  iteration: 1781:\t loss: 0.022061381489038467\n",
      "epoch: 6:  iteration: 1801:\t loss: 0.024297740310430527\n",
      "val loss:\t 0.030088756\n",
      "epoch: 6:  iteration: 1821:\t loss: 0.017538364976644516\n",
      "epoch: 6:  iteration: 1841:\t loss: 0.024134933948516846\n",
      "epoch: 6:  iteration: 1861:\t loss: 0.024611983448266983\n",
      "epoch: 6:  iteration: 1881:\t loss: 0.02164645865559578\n",
      "epoch: 6:  iteration: 1901:\t loss: 0.021428227424621582\n",
      "val loss:\t 0.01710277\n",
      "epoch: 6:  iteration: 1921:\t loss: 0.023151695728302002\n",
      "epoch: 6:  iteration: 1941:\t loss: 0.02943621203303337\n",
      "epoch: 6:  iteration: 1961:\t loss: 0.029801076278090477\n",
      "epoch: 6:  iteration: 1981:\t loss: 0.023162629455327988\n",
      "epoch: 6:  iteration: 2001:\t loss: 0.027242083102464676\n",
      "val loss:\t 0.024352044\n",
      "epoch: 6:  iteration: 2021:\t loss: 0.04575619101524353\n",
      "epoch: 6:  iteration: 2041:\t loss: 0.07483358681201935\n",
      "epoch: 6:  iteration: 2061:\t loss: 0.020908571779727936\n",
      "epoch: 6:  iteration: 2081:\t loss: 0.01695013977587223\n",
      "epoch: 6:  iteration: 2101:\t loss: 0.040945108979940414\n",
      "val loss:\t 0.02402275\n",
      "epoch: 6:  iteration: 2121:\t loss: 0.057167697697877884\n",
      "epoch: 6:  iteration: 2141:\t loss: 0.02624233067035675\n",
      "epoch: 6:  iteration: 2161:\t loss: 0.027550067752599716\n",
      "epoch: 6:  iteration: 2181:\t loss: 0.0305775199085474\n",
      "epoch: 6:  iteration: 2201:\t loss: 0.030712692067027092\n",
      "val loss:\t 0.019830598\n",
      "epoch: 6:  iteration: 2221:\t loss: 0.02720789983868599\n",
      "epoch: 6:  iteration: 2241:\t loss: 0.0204640980809927\n",
      "epoch: 6:  iteration: 2261:\t loss: 0.018864762037992477\n",
      "epoch: 6:  iteration: 2281:\t loss: 0.06191723048686981\n",
      "epoch: 6:  iteration: 2301:\t loss: 0.02568752132356167\n",
      "val loss:\t 0.49709442\n",
      "epoch: 6:  iteration: 2321:\t loss: 0.024563126266002655\n",
      "epoch: 6:  iteration: 2341:\t loss: 0.014647875912487507\n",
      "epoch: 6:  iteration: 2361:\t loss: 0.014464080333709717\n",
      "epoch: 6:  iteration: 2381:\t loss: 0.021886151283979416\n",
      "epoch: 6:  iteration: 2401:\t loss: 0.015669673681259155\n",
      "val loss:\t 0.044683892\n",
      "epoch: 6:  iteration: 2421:\t loss: 0.019272036850452423\n",
      "epoch: 6:  iteration: 2441:\t loss: 0.0124543197453022\n",
      "epoch: 6:  iteration: 2461:\t loss: 0.028690176084637642\n",
      "epoch: 6:  iteration: 2481:\t loss: 0.026667237281799316\n",
      "epoch: 6:  iteration: 2501:\t loss: 0.024313822388648987\n",
      "val loss:\t 0.025605088\n",
      "epoch: 6:  iteration: 2521:\t loss: 0.01866539940237999\n",
      "epoch: 6:  iteration: 2541:\t loss: 0.018896758556365967\n",
      "epoch: 6:  iteration: 2561:\t loss: 0.01750965043902397\n",
      "epoch: 6:  iteration: 2581:\t loss: 0.022972218692302704\n",
      "epoch: 6:  iteration: 2601:\t loss: 0.02341156080365181\n",
      "val loss:\t 0.020889703\n",
      "epoch: 6:  iteration: 2621:\t loss: 0.022535152733325958\n",
      "epoch: 6:  iteration: 2641:\t loss: 0.025998426601290703\n",
      "epoch: 6:  iteration: 2661:\t loss: 0.01735910028219223\n",
      "epoch: 6:  iteration: 2681:\t loss: 0.03819850832223892\n",
      "epoch: 6:  iteration: 2701:\t loss: 0.017447454854846\n",
      "val loss:\t 0.0198509\n",
      "epoch: 6:  iteration: 2721:\t loss: 0.015694960951805115\n",
      "epoch: 6:  iteration: 2741:\t loss: 0.02324344590306282\n",
      "epoch: 6:  iteration: 2761:\t loss: 0.02857077866792679\n",
      "epoch: 6:  iteration: 2781:\t loss: 0.027185926213860512\n",
      "epoch: 6:  iteration: 2801:\t loss: 0.031027281656861305\n",
      "val loss:\t 0.033611096\n",
      "epoch: 6:  iteration: 2821:\t loss: 0.025611883029341698\n",
      "epoch: 6:  iteration: 2841:\t loss: 0.02611803635954857\n",
      "epoch: 6:  iteration: 2861:\t loss: 0.0332002118229866\n",
      "epoch: 6:  iteration: 2881:\t loss: 0.030830051749944687\n",
      "epoch: 6:  iteration: 2901:\t loss: 0.02782190963625908\n",
      "val loss:\t 0.023187947\n",
      "epoch: 6:  iteration: 2921:\t loss: 0.01966235414147377\n",
      "epoch: 6:  iteration: 2941:\t loss: 0.03007606789469719\n",
      "epoch: 6:  iteration: 2961:\t loss: 0.032691847532987595\n",
      "epoch: 6:  iteration: 2981:\t loss: 0.02869485691189766\n",
      "epoch: 6:  iteration: 3001:\t loss: 0.01855606958270073\n",
      "val loss:\t 0.03166894\n",
      "epoch: 6:  iteration: 3021:\t loss: 0.021373961120843887\n",
      "epoch: 6:  iteration: 3041:\t loss: 0.031197335571050644\n",
      "epoch: 6:  iteration: 3061:\t loss: 0.021324139088392258\n",
      "epoch: 6:  iteration: 3081:\t loss: 0.03254575654864311\n",
      "epoch: 6:  iteration: 3101:\t loss: 0.016266299411654472\n",
      "val loss:\t 0.040822368\n",
      "epoch: 6:  iteration: 3121:\t loss: 0.024653062224388123\n",
      "epoch: 6:  iteration: 3141:\t loss: 0.01969459094107151\n",
      "epoch: 6:  iteration: 3161:\t loss: 0.022290267050266266\n",
      "epoch: 6:  iteration: 3181:\t loss: 0.02706415206193924\n",
      "epoch: 6:  iteration: 3201:\t loss: 0.0254084262996912\n",
      "val loss:\t 0.032158002\n",
      "epoch: 6:  iteration: 3221:\t loss: 0.027859117835760117\n",
      "epoch: 6:  iteration: 3241:\t loss: 0.02077260985970497\n",
      "epoch: 6:  iteration: 3261:\t loss: 0.016298720613121986\n",
      "epoch: 6:  iteration: 3281:\t loss: 0.10677465796470642\n",
      "epoch: 6:  iteration: 3301:\t loss: 0.05066657438874245\n",
      "val loss:\t 0.03392604\n",
      "epoch: 6:  iteration: 3321:\t loss: 0.014569280669093132\n",
      "epoch: 6:  iteration: 3341:\t loss: 0.027242451906204224\n",
      "epoch: 6:  iteration: 3361:\t loss: 0.025398341938853264\n",
      "epoch: 6:  iteration: 3381:\t loss: 0.030958157032728195\n",
      "epoch: 6:  iteration: 3401:\t loss: 0.02423774264752865\n",
      "val loss:\t 0.028080579\n",
      "epoch: 6:  iteration: 3421:\t loss: 0.03724781796336174\n",
      "epoch: 6:  iteration: 3441:\t loss: 0.03464188799262047\n",
      "epoch: 6:  iteration: 3461:\t loss: 0.026796074584126472\n",
      "epoch: 6:  iteration: 3481:\t loss: 0.025778740644454956\n",
      "epoch: 6:  iteration: 3501:\t loss: 0.025055361911654472\n",
      "val loss:\t 0.055620953\n",
      "epoch: 6:  iteration: 3521:\t loss: 0.014902460388839245\n",
      "epoch: 6:  iteration: 3541:\t loss: 0.028297003358602524\n",
      "epoch: 6:  iteration: 3561:\t loss: 0.01825905777513981\n",
      "epoch: 6:  iteration: 3581:\t loss: 0.01998630352318287\n",
      "epoch: 6:  iteration: 3601:\t loss: 0.025921795517206192\n",
      "val loss:\t 0.022616617\n",
      "epoch: 6:  iteration: 3621:\t loss: 0.018149856477975845\n",
      "epoch: 6:  iteration: 3641:\t loss: 0.02351083606481552\n",
      "epoch: 6:  iteration: 3661:\t loss: 0.023959608748555183\n",
      "epoch: 6:  iteration: 3681:\t loss: 0.024427609518170357\n",
      "epoch: 6:  iteration: 3701:\t loss: 0.23825643956661224\n",
      "val loss:\t 0.029844519\n",
      "epoch: 6:  iteration: 3721:\t loss: 0.02961360290646553\n",
      "epoch: 6:  iteration: 3741:\t loss: 0.026504360139369965\n",
      "epoch: 6:  iteration: 3761:\t loss: 0.04429386556148529\n",
      "epoch: 6:  iteration: 3781:\t loss: 0.06053461879491806\n",
      "epoch: 6:  iteration: 3801:\t loss: 0.008039993233978748\n",
      "val loss:\t 0.017317433\n",
      "EarlyStopping counter: 2 out of 6\n",
      "----------------epoch end--------------------- 5\n",
      "|loss_train| 0.00020498596131801605\n",
      "|loss_test| 0.00029939477099105716\n",
      "epoch: 7:  iteration: 1:\t loss: 0.017444372177124023\n",
      "val loss:\t 0.027244925\n",
      "epoch: 7:  iteration: 21:\t loss: 0.06221652030944824\n",
      "epoch: 7:  iteration: 41:\t loss: 0.023213887587189674\n",
      "epoch: 7:  iteration: 61:\t loss: 0.01763281784951687\n",
      "epoch: 7:  iteration: 81:\t loss: 0.026422016322612762\n",
      "epoch: 7:  iteration: 101:\t loss: 0.02243855781853199\n",
      "val loss:\t 0.015523067\n",
      "epoch: 7:  iteration: 121:\t loss: 0.02439822629094124\n",
      "epoch: 7:  iteration: 141:\t loss: 0.04666822403669357\n",
      "epoch: 7:  iteration: 161:\t loss: 0.021083587780594826\n",
      "epoch: 7:  iteration: 181:\t loss: 0.021207407116889954\n",
      "epoch: 7:  iteration: 201:\t loss: 0.024487314745783806\n",
      "val loss:\t 0.044975165\n",
      "epoch: 7:  iteration: 221:\t loss: 0.04839858412742615\n",
      "epoch: 7:  iteration: 241:\t loss: 0.027914244681596756\n",
      "epoch: 7:  iteration: 261:\t loss: 0.023728352040052414\n",
      "epoch: 7:  iteration: 281:\t loss: 0.040711306035518646\n",
      "epoch: 7:  iteration: 301:\t loss: 0.02048250287771225\n",
      "val loss:\t 0.018948633\n",
      "epoch: 7:  iteration: 321:\t loss: 0.028949860483407974\n",
      "epoch: 7:  iteration: 341:\t loss: 0.029853710904717445\n",
      "epoch: 7:  iteration: 361:\t loss: 0.016932401806116104\n",
      "epoch: 7:  iteration: 381:\t loss: 0.025476671755313873\n",
      "epoch: 7:  iteration: 401:\t loss: 0.013499384745955467\n",
      "val loss:\t 0.021301428\n",
      "epoch: 7:  iteration: 421:\t loss: 0.022891614586114883\n",
      "epoch: 7:  iteration: 441:\t loss: 0.03559482470154762\n",
      "epoch: 7:  iteration: 461:\t loss: 0.0163591206073761\n",
      "epoch: 7:  iteration: 481:\t loss: 0.025384077802300453\n",
      "epoch: 7:  iteration: 501:\t loss: 0.034970834851264954\n",
      "val loss:\t 0.017283678\n",
      "epoch: 7:  iteration: 521:\t loss: 0.055166762322187424\n",
      "epoch: 7:  iteration: 541:\t loss: 0.022997720167040825\n",
      "epoch: 7:  iteration: 561:\t loss: 0.027280079200863838\n",
      "epoch: 7:  iteration: 581:\t loss: 0.022590553387999535\n",
      "epoch: 7:  iteration: 601:\t loss: 0.024706922471523285\n",
      "val loss:\t 0.022513213\n",
      "epoch: 7:  iteration: 621:\t loss: 0.025293728336691856\n",
      "epoch: 7:  iteration: 641:\t loss: 0.023188387975096703\n",
      "epoch: 7:  iteration: 661:\t loss: 0.027157170698046684\n",
      "epoch: 7:  iteration: 681:\t loss: 0.05103880167007446\n",
      "epoch: 7:  iteration: 701:\t loss: 0.05333646014332771\n",
      "val loss:\t 0.01682182\n",
      "epoch: 7:  iteration: 721:\t loss: 0.020418211817741394\n",
      "epoch: 7:  iteration: 741:\t loss: 0.024010710418224335\n",
      "epoch: 7:  iteration: 761:\t loss: 0.027210567146539688\n",
      "epoch: 7:  iteration: 781:\t loss: 0.018764320760965347\n",
      "epoch: 7:  iteration: 801:\t loss: 0.023700140416622162\n",
      "val loss:\t 0.022047032\n",
      "epoch: 7:  iteration: 821:\t loss: 0.032279886305332184\n",
      "epoch: 7:  iteration: 841:\t loss: 0.0588054433465004\n",
      "epoch: 7:  iteration: 861:\t loss: 0.01707557402551174\n",
      "epoch: 7:  iteration: 881:\t loss: 0.019721979275345802\n",
      "epoch: 7:  iteration: 901:\t loss: 0.028520673513412476\n",
      "val loss:\t 0.042538907\n",
      "epoch: 7:  iteration: 921:\t loss: 0.01582641527056694\n",
      "epoch: 7:  iteration: 941:\t loss: 0.025543857365846634\n",
      "epoch: 7:  iteration: 961:\t loss: 0.02679041400551796\n",
      "epoch: 7:  iteration: 981:\t loss: 0.025180913507938385\n",
      "epoch: 7:  iteration: 1001:\t loss: 0.02591259963810444\n",
      "val loss:\t 0.014292576\n",
      "epoch: 7:  iteration: 1021:\t loss: 0.01705121621489525\n",
      "epoch: 7:  iteration: 1041:\t loss: 0.026766838505864143\n",
      "epoch: 7:  iteration: 1061:\t loss: 0.018154803663492203\n",
      "epoch: 7:  iteration: 1081:\t loss: 0.044447168707847595\n",
      "epoch: 7:  iteration: 1101:\t loss: 0.02115424908697605\n",
      "val loss:\t 0.017083349\n",
      "epoch: 7:  iteration: 1121:\t loss: 0.021291591227054596\n",
      "epoch: 7:  iteration: 1141:\t loss: 0.04998966306447983\n",
      "epoch: 7:  iteration: 1161:\t loss: 0.014825969003140926\n",
      "epoch: 7:  iteration: 1181:\t loss: 0.03899356722831726\n",
      "epoch: 7:  iteration: 1201:\t loss: 0.028300441801548004\n",
      "val loss:\t 0.030818313\n",
      "epoch: 7:  iteration: 1221:\t loss: 0.018376408144831657\n",
      "epoch: 7:  iteration: 1241:\t loss: 0.02163860574364662\n",
      "epoch: 7:  iteration: 1261:\t loss: 0.01926608383655548\n",
      "epoch: 7:  iteration: 1281:\t loss: 0.016608363017439842\n",
      "epoch: 7:  iteration: 1301:\t loss: 0.026278436183929443\n",
      "val loss:\t 0.13817155\n",
      "epoch: 7:  iteration: 1321:\t loss: 0.04764459282159805\n",
      "epoch: 7:  iteration: 1341:\t loss: 0.01585172303020954\n",
      "epoch: 7:  iteration: 1361:\t loss: 0.01854044571518898\n",
      "epoch: 7:  iteration: 1381:\t loss: 0.020316684618592262\n",
      "epoch: 7:  iteration: 1401:\t loss: 0.04151294380426407\n",
      "val loss:\t 0.038862623\n",
      "epoch: 7:  iteration: 1421:\t loss: 0.01835509017109871\n",
      "epoch: 7:  iteration: 1441:\t loss: 0.024919655174016953\n",
      "epoch: 7:  iteration: 1461:\t loss: 0.034247174859046936\n",
      "epoch: 7:  iteration: 1481:\t loss: 0.043050650507211685\n",
      "epoch: 7:  iteration: 1501:\t loss: 0.025806792080402374\n",
      "val loss:\t 0.011989456\n",
      "epoch: 7:  iteration: 1521:\t loss: 0.025136316195130348\n",
      "epoch: 7:  iteration: 1541:\t loss: 0.022139951586723328\n",
      "epoch: 7:  iteration: 1561:\t loss: 0.016812309622764587\n",
      "epoch: 7:  iteration: 1581:\t loss: 0.019194994121789932\n",
      "epoch: 7:  iteration: 1601:\t loss: 0.022992171347141266\n",
      "val loss:\t 0.033860482\n",
      "epoch: 7:  iteration: 1621:\t loss: 0.027794593945145607\n",
      "epoch: 7:  iteration: 1641:\t loss: 0.027894746512174606\n",
      "epoch: 7:  iteration: 1661:\t loss: 0.026848820969462395\n",
      "epoch: 7:  iteration: 1681:\t loss: 0.02188061736524105\n",
      "epoch: 7:  iteration: 1701:\t loss: 0.03496592491865158\n",
      "val loss:\t 0.018390745\n",
      "epoch: 7:  iteration: 1721:\t loss: 0.023652318865060806\n",
      "epoch: 7:  iteration: 1741:\t loss: 0.028629226610064507\n",
      "epoch: 7:  iteration: 1761:\t loss: 0.02378677949309349\n",
      "epoch: 7:  iteration: 1781:\t loss: 0.02773382142186165\n",
      "epoch: 7:  iteration: 1801:\t loss: 0.02125103957951069\n",
      "val loss:\t 0.019049663\n",
      "epoch: 7:  iteration: 1821:\t loss: 0.03156287595629692\n",
      "epoch: 7:  iteration: 1841:\t loss: 0.08600646257400513\n",
      "epoch: 7:  iteration: 1861:\t loss: 0.036717094480991364\n",
      "epoch: 7:  iteration: 1881:\t loss: 0.022492777556180954\n",
      "epoch: 7:  iteration: 1901:\t loss: 0.02511627972126007\n",
      "val loss:\t 0.019599345\n",
      "epoch: 7:  iteration: 1921:\t loss: 0.022216789424419403\n",
      "epoch: 7:  iteration: 1941:\t loss: 0.027225801721215248\n",
      "epoch: 7:  iteration: 1961:\t loss: 0.020535167306661606\n",
      "epoch: 7:  iteration: 1981:\t loss: 0.021271176636219025\n",
      "epoch: 7:  iteration: 2001:\t loss: 0.05414929240942001\n",
      "val loss:\t 0.03587839\n",
      "epoch: 7:  iteration: 2021:\t loss: 0.022140881046652794\n",
      "epoch: 7:  iteration: 2041:\t loss: 0.02888890542089939\n",
      "epoch: 7:  iteration: 2061:\t loss: 0.026474107056856155\n",
      "epoch: 7:  iteration: 2081:\t loss: 0.047101374715566635\n",
      "epoch: 7:  iteration: 2101:\t loss: 0.022905997931957245\n",
      "val loss:\t 0.025619324\n",
      "epoch: 7:  iteration: 2121:\t loss: 0.05612431466579437\n",
      "epoch: 7:  iteration: 2141:\t loss: 0.03811216354370117\n",
      "epoch: 7:  iteration: 2161:\t loss: 0.016012264415621758\n",
      "epoch: 7:  iteration: 2181:\t loss: 0.03332173079252243\n",
      "epoch: 7:  iteration: 2201:\t loss: 0.040945976972579956\n",
      "val loss:\t 0.024932425\n",
      "epoch: 7:  iteration: 2221:\t loss: 0.0350586473941803\n",
      "epoch: 7:  iteration: 2241:\t loss: 0.015672866255044937\n",
      "epoch: 7:  iteration: 2261:\t loss: 0.033954739570617676\n",
      "epoch: 7:  iteration: 2281:\t loss: 0.0383589006960392\n",
      "epoch: 7:  iteration: 2301:\t loss: 0.021380996331572533\n",
      "val loss:\t 0.018303677\n",
      "epoch: 7:  iteration: 2321:\t loss: 0.02499370649456978\n",
      "epoch: 7:  iteration: 2341:\t loss: 0.04186507686972618\n",
      "epoch: 7:  iteration: 2361:\t loss: 0.045087914913892746\n",
      "epoch: 7:  iteration: 2381:\t loss: 0.030048169195652008\n",
      "epoch: 7:  iteration: 2401:\t loss: 0.03877855837345123\n",
      "val loss:\t 0.026825117\n",
      "epoch: 7:  iteration: 2421:\t loss: 0.029915522783994675\n",
      "epoch: 7:  iteration: 2441:\t loss: 0.01926586590707302\n",
      "epoch: 7:  iteration: 2461:\t loss: 0.017107998952269554\n",
      "epoch: 7:  iteration: 2481:\t loss: 0.021983226761221886\n",
      "epoch: 7:  iteration: 2501:\t loss: 0.023884624242782593\n",
      "val loss:\t 0.056592092\n",
      "epoch: 7:  iteration: 2521:\t loss: 0.019396085292100906\n",
      "epoch: 7:  iteration: 2541:\t loss: 0.02473534643650055\n",
      "epoch: 7:  iteration: 2561:\t loss: 0.028818845748901367\n",
      "epoch: 7:  iteration: 2581:\t loss: 0.031022783368825912\n",
      "epoch: 7:  iteration: 2601:\t loss: 0.017901025712490082\n",
      "val loss:\t 0.013886781\n",
      "epoch: 7:  iteration: 2621:\t loss: 0.027810461819171906\n",
      "epoch: 7:  iteration: 2641:\t loss: 0.04166421666741371\n",
      "epoch: 7:  iteration: 2661:\t loss: 0.02199980616569519\n",
      "epoch: 7:  iteration: 2681:\t loss: 0.04217161610722542\n",
      "epoch: 7:  iteration: 2701:\t loss: 0.02430093102157116\n",
      "val loss:\t 0.026593175\n",
      "epoch: 7:  iteration: 2721:\t loss: 0.028282225131988525\n",
      "epoch: 7:  iteration: 2741:\t loss: 0.026155371218919754\n",
      "epoch: 7:  iteration: 2761:\t loss: 0.018431060016155243\n",
      "epoch: 7:  iteration: 2781:\t loss: 0.0526113398373127\n",
      "epoch: 7:  iteration: 2801:\t loss: 0.01758158951997757\n",
      "val loss:\t 0.026472507\n",
      "epoch: 7:  iteration: 2821:\t loss: 0.020982544869184494\n",
      "epoch: 7:  iteration: 2841:\t loss: 0.01883404701948166\n",
      "epoch: 7:  iteration: 2861:\t loss: 0.02260563150048256\n",
      "epoch: 7:  iteration: 2881:\t loss: 0.021710455417633057\n",
      "epoch: 7:  iteration: 2901:\t loss: 0.019807159900665283\n",
      "val loss:\t 0.02137412\n",
      "epoch: 7:  iteration: 2921:\t loss: 0.014061172492802143\n",
      "epoch: 7:  iteration: 2941:\t loss: 0.026655150577425957\n",
      "epoch: 7:  iteration: 2961:\t loss: 0.026239503175020218\n",
      "epoch: 7:  iteration: 2981:\t loss: 0.026960479095578194\n",
      "epoch: 7:  iteration: 3001:\t loss: 0.02290377765893936\n",
      "val loss:\t 0.05406551\n",
      "epoch: 7:  iteration: 3021:\t loss: 0.08257128298282623\n",
      "epoch: 7:  iteration: 3041:\t loss: 0.016674987971782684\n",
      "epoch: 7:  iteration: 3061:\t loss: 0.025541383773088455\n",
      "epoch: 7:  iteration: 3081:\t loss: 0.018342522904276848\n",
      "epoch: 7:  iteration: 3101:\t loss: 0.019276095554232597\n",
      "val loss:\t 0.025956785\n",
      "epoch: 7:  iteration: 3121:\t loss: 0.02228272520005703\n",
      "epoch: 7:  iteration: 3141:\t loss: 0.022508392110466957\n",
      "epoch: 7:  iteration: 3161:\t loss: 0.03501174598932266\n",
      "epoch: 7:  iteration: 3181:\t loss: 0.03023982048034668\n",
      "epoch: 7:  iteration: 3201:\t loss: 0.07244657725095749\n",
      "val loss:\t 0.021874584\n",
      "epoch: 7:  iteration: 3221:\t loss: 0.021156147122383118\n",
      "epoch: 7:  iteration: 3241:\t loss: 0.04475029557943344\n",
      "epoch: 7:  iteration: 3261:\t loss: 0.028164852410554886\n",
      "epoch: 7:  iteration: 3281:\t loss: 0.018293321132659912\n",
      "epoch: 7:  iteration: 3301:\t loss: 0.023084666579961777\n",
      "val loss:\t 0.0929586\n",
      "epoch: 7:  iteration: 3321:\t loss: 0.024152938276529312\n",
      "epoch: 7:  iteration: 3341:\t loss: 0.037047043442726135\n",
      "epoch: 7:  iteration: 3361:\t loss: 0.02580580674111843\n",
      "epoch: 7:  iteration: 3381:\t loss: 0.01820198819041252\n",
      "epoch: 7:  iteration: 3401:\t loss: 0.03924734890460968\n",
      "val loss:\t 0.056968227\n",
      "epoch: 7:  iteration: 3421:\t loss: 0.015699516981840134\n",
      "epoch: 7:  iteration: 3441:\t loss: 0.021176718175411224\n",
      "epoch: 7:  iteration: 3461:\t loss: 0.02905086614191532\n",
      "epoch: 7:  iteration: 3481:\t loss: 0.019017469137907028\n",
      "epoch: 7:  iteration: 3501:\t loss: 0.05168002098798752\n",
      "val loss:\t 0.026769184\n",
      "epoch: 7:  iteration: 3521:\t loss: 0.023376137018203735\n",
      "epoch: 7:  iteration: 3541:\t loss: 0.025288749486207962\n",
      "epoch: 7:  iteration: 3561:\t loss: 0.02247057855129242\n",
      "epoch: 7:  iteration: 3581:\t loss: 0.033323559910058975\n",
      "epoch: 7:  iteration: 3601:\t loss: 0.02589811384677887\n",
      "val loss:\t 0.03858935\n",
      "epoch: 7:  iteration: 3621:\t loss: 0.061121292412281036\n",
      "epoch: 7:  iteration: 3641:\t loss: 0.02669709175825119\n",
      "epoch: 7:  iteration: 3661:\t loss: 0.033626582473516464\n",
      "epoch: 7:  iteration: 3681:\t loss: 0.026314781978726387\n",
      "epoch: 7:  iteration: 3701:\t loss: 0.028626199811697006\n",
      "val loss:\t 0.072835\n",
      "epoch: 7:  iteration: 3721:\t loss: 0.022218957543373108\n",
      "epoch: 7:  iteration: 3741:\t loss: 0.022338567301630974\n",
      "epoch: 7:  iteration: 3761:\t loss: 0.06101257726550102\n",
      "epoch: 7:  iteration: 3781:\t loss: 0.025028232485055923\n",
      "epoch: 7:  iteration: 3801:\t loss: 0.02056240476667881\n",
      "val loss:\t 0.032614022\n",
      "EarlyStopping counter: 3 out of 6\n",
      "----------------epoch end--------------------- 6\n",
      "|loss_train| 9.265558037441224e-05\n",
      "|loss_test| 0.00016640777175780386\n",
      "epoch: 8:  iteration: 1:\t loss: 0.02791362628340721\n",
      "val loss:\t 0.030454513\n",
      "epoch: 8:  iteration: 21:\t loss: 0.031016062945127487\n",
      "epoch: 8:  iteration: 41:\t loss: 0.02223978377878666\n",
      "epoch: 8:  iteration: 61:\t loss: 0.05509877949953079\n",
      "epoch: 8:  iteration: 81:\t loss: 0.023953694850206375\n",
      "epoch: 8:  iteration: 101:\t loss: 0.02161693014204502\n",
      "val loss:\t 0.018552832\n",
      "epoch: 8:  iteration: 121:\t loss: 0.019773202016949654\n",
      "epoch: 8:  iteration: 141:\t loss: 0.02181205339729786\n",
      "epoch: 8:  iteration: 161:\t loss: 0.03195422887802124\n",
      "epoch: 8:  iteration: 181:\t loss: 0.025988105684518814\n",
      "epoch: 8:  iteration: 201:\t loss: 0.015657126903533936\n",
      "val loss:\t 0.021088205\n",
      "epoch: 8:  iteration: 221:\t loss: 0.1540764570236206\n",
      "epoch: 8:  iteration: 241:\t loss: 0.013956200331449509\n",
      "epoch: 8:  iteration: 261:\t loss: 0.030938057228922844\n",
      "epoch: 8:  iteration: 281:\t loss: 0.017388103529810905\n",
      "epoch: 8:  iteration: 301:\t loss: 0.049731142818927765\n",
      "val loss:\t 0.019822072\n",
      "epoch: 8:  iteration: 321:\t loss: 0.022096732631325722\n",
      "epoch: 8:  iteration: 341:\t loss: 0.020738650113344193\n",
      "epoch: 8:  iteration: 361:\t loss: 0.025902455672621727\n",
      "epoch: 8:  iteration: 381:\t loss: 0.046621739864349365\n",
      "epoch: 8:  iteration: 401:\t loss: 0.038051389157772064\n",
      "val loss:\t 0.024371738\n",
      "epoch: 8:  iteration: 421:\t loss: 0.020938245579600334\n",
      "epoch: 8:  iteration: 441:\t loss: 0.018755419179797173\n",
      "epoch: 8:  iteration: 461:\t loss: 0.01624576561152935\n",
      "epoch: 8:  iteration: 481:\t loss: 0.03408670425415039\n",
      "epoch: 8:  iteration: 501:\t loss: 0.03162341192364693\n",
      "val loss:\t 0.018150069\n",
      "epoch: 8:  iteration: 521:\t loss: 0.02119913324713707\n",
      "epoch: 8:  iteration: 541:\t loss: 0.03232082352042198\n",
      "epoch: 8:  iteration: 561:\t loss: 0.02643796056509018\n",
      "epoch: 8:  iteration: 581:\t loss: 0.03399018943309784\n",
      "epoch: 8:  iteration: 601:\t loss: 0.0191696435213089\n",
      "val loss:\t 0.0229781\n",
      "epoch: 8:  iteration: 621:\t loss: 0.018114924430847168\n",
      "epoch: 8:  iteration: 641:\t loss: 0.01709006354212761\n",
      "epoch: 8:  iteration: 661:\t loss: 0.013708817772567272\n",
      "epoch: 8:  iteration: 681:\t loss: 0.02393885888159275\n",
      "epoch: 8:  iteration: 701:\t loss: 0.030883725732564926\n",
      "val loss:\t 0.030522782\n",
      "epoch: 8:  iteration: 721:\t loss: 0.04390336573123932\n",
      "epoch: 8:  iteration: 741:\t loss: 0.03488853573799133\n",
      "epoch: 8:  iteration: 761:\t loss: 0.028797373175621033\n",
      "epoch: 8:  iteration: 781:\t loss: 0.10795339941978455\n",
      "epoch: 8:  iteration: 801:\t loss: 0.026541175320744514\n",
      "val loss:\t 0.036747504\n",
      "epoch: 8:  iteration: 821:\t loss: 0.020917296409606934\n",
      "epoch: 8:  iteration: 841:\t loss: 0.024182653054594994\n",
      "epoch: 8:  iteration: 861:\t loss: 0.01951760984957218\n",
      "epoch: 8:  iteration: 881:\t loss: 0.03203275427222252\n",
      "epoch: 8:  iteration: 901:\t loss: 0.018801666796207428\n",
      "val loss:\t 0.015416313\n",
      "epoch: 8:  iteration: 921:\t loss: 0.026657309383153915\n",
      "epoch: 8:  iteration: 941:\t loss: 0.028662238270044327\n",
      "epoch: 8:  iteration: 961:\t loss: 0.031114324927330017\n",
      "epoch: 8:  iteration: 981:\t loss: 0.026660075411200523\n",
      "epoch: 8:  iteration: 1001:\t loss: 0.02344147115945816\n",
      "val loss:\t 0.026171792\n",
      "epoch: 8:  iteration: 1021:\t loss: 0.022413626313209534\n",
      "epoch: 8:  iteration: 1041:\t loss: 0.012426124885678291\n",
      "epoch: 8:  iteration: 1061:\t loss: 0.018476437777280807\n",
      "epoch: 8:  iteration: 1081:\t loss: 0.01841123215854168\n",
      "epoch: 8:  iteration: 1101:\t loss: 0.015721164643764496\n",
      "val loss:\t 0.04257873\n",
      "epoch: 8:  iteration: 1121:\t loss: 0.024704601615667343\n",
      "epoch: 8:  iteration: 1141:\t loss: 0.027745742350816727\n",
      "epoch: 8:  iteration: 1161:\t loss: 0.19515138864517212\n",
      "epoch: 8:  iteration: 1181:\t loss: 0.02707345224916935\n",
      "epoch: 8:  iteration: 1201:\t loss: 0.029432011768221855\n",
      "val loss:\t 0.03081389\n",
      "epoch: 8:  iteration: 1221:\t loss: 0.019693758338689804\n",
      "epoch: 8:  iteration: 1241:\t loss: 0.023729056119918823\n",
      "epoch: 8:  iteration: 1261:\t loss: 0.07243181765079498\n",
      "epoch: 8:  iteration: 1281:\t loss: 0.048142850399017334\n",
      "epoch: 8:  iteration: 1301:\t loss: 0.01904449611902237\n",
      "val loss:\t 0.023148753\n",
      "epoch: 8:  iteration: 1321:\t loss: 0.024188296869397163\n",
      "epoch: 8:  iteration: 1341:\t loss: 0.015623833984136581\n",
      "epoch: 8:  iteration: 1361:\t loss: 0.02526821382343769\n",
      "epoch: 8:  iteration: 1381:\t loss: 0.02567116543650627\n",
      "epoch: 8:  iteration: 1401:\t loss: 0.0354032926261425\n",
      "val loss:\t 0.021308262\n",
      "epoch: 8:  iteration: 1421:\t loss: 0.019265854731202126\n",
      "epoch: 8:  iteration: 1441:\t loss: 0.11789711564779282\n",
      "epoch: 8:  iteration: 1461:\t loss: 0.025789082050323486\n",
      "epoch: 8:  iteration: 1481:\t loss: 0.02211786061525345\n",
      "epoch: 8:  iteration: 1501:\t loss: 0.03185047581791878\n",
      "val loss:\t 0.023455203\n",
      "epoch: 8:  iteration: 1521:\t loss: 0.018058031797409058\n",
      "epoch: 8:  iteration: 1541:\t loss: 0.028132077306509018\n",
      "epoch: 8:  iteration: 1561:\t loss: 0.020918047055602074\n",
      "epoch: 8:  iteration: 1581:\t loss: 0.022389773279428482\n",
      "epoch: 8:  iteration: 1601:\t loss: 0.021284524351358414\n",
      "val loss:\t 0.025501948\n",
      "epoch: 8:  iteration: 1621:\t loss: 0.019223187118768692\n",
      "epoch: 8:  iteration: 1641:\t loss: 0.03880105912685394\n",
      "epoch: 8:  iteration: 1661:\t loss: 0.02744058519601822\n",
      "epoch: 8:  iteration: 1681:\t loss: 0.0221681147813797\n",
      "epoch: 8:  iteration: 1701:\t loss: 0.019902709871530533\n",
      "val loss:\t 0.027299985\n",
      "epoch: 8:  iteration: 1721:\t loss: 0.02545013837516308\n",
      "epoch: 8:  iteration: 1741:\t loss: 0.021091341972351074\n",
      "epoch: 8:  iteration: 1761:\t loss: 0.02408122643828392\n",
      "epoch: 8:  iteration: 1781:\t loss: 0.027941539883613586\n",
      "epoch: 8:  iteration: 1801:\t loss: 0.02868112176656723\n",
      "val loss:\t 0.01769058\n",
      "epoch: 8:  iteration: 1821:\t loss: 0.08371514827013016\n",
      "epoch: 8:  iteration: 1841:\t loss: 0.04892320930957794\n",
      "epoch: 8:  iteration: 1861:\t loss: 0.027105040848255157\n",
      "epoch: 8:  iteration: 1881:\t loss: 0.06893568485975266\n",
      "epoch: 8:  iteration: 1901:\t loss: 0.021841667592525482\n",
      "val loss:\t 0.031573303\n",
      "epoch: 8:  iteration: 1921:\t loss: 0.029065292328596115\n",
      "epoch: 8:  iteration: 1941:\t loss: 0.03048190101981163\n",
      "epoch: 8:  iteration: 1961:\t loss: 0.01448715291917324\n",
      "epoch: 8:  iteration: 1981:\t loss: 0.10655051469802856\n",
      "epoch: 8:  iteration: 2001:\t loss: 0.04803210496902466\n",
      "val loss:\t 0.022162005\n",
      "epoch: 8:  iteration: 2021:\t loss: 0.015199539251625538\n",
      "epoch: 8:  iteration: 2041:\t loss: 0.026289837434887886\n",
      "epoch: 8:  iteration: 2061:\t loss: 0.023486949503421783\n",
      "epoch: 8:  iteration: 2081:\t loss: 0.03535592183470726\n",
      "epoch: 8:  iteration: 2101:\t loss: 0.02518351748585701\n",
      "val loss:\t 0.03793098\n",
      "epoch: 8:  iteration: 2121:\t loss: 0.017601456493139267\n",
      "epoch: 8:  iteration: 2141:\t loss: 0.027708182111382484\n",
      "epoch: 8:  iteration: 2161:\t loss: 0.030455658212304115\n",
      "epoch: 8:  iteration: 2181:\t loss: 0.03368351235985756\n",
      "epoch: 8:  iteration: 2201:\t loss: 0.02707710862159729\n",
      "val loss:\t 0.020216068\n",
      "epoch: 8:  iteration: 2221:\t loss: 0.052546657621860504\n",
      "epoch: 8:  iteration: 2241:\t loss: 0.0169683787971735\n",
      "epoch: 8:  iteration: 2261:\t loss: 0.02373725175857544\n",
      "epoch: 8:  iteration: 2281:\t loss: 0.025358757004141808\n",
      "epoch: 8:  iteration: 2301:\t loss: 0.026515690609812737\n",
      "val loss:\t 0.020709356\n",
      "epoch: 8:  iteration: 2321:\t loss: 0.01873655617237091\n",
      "epoch: 8:  iteration: 2341:\t loss: 0.037484169006347656\n",
      "epoch: 8:  iteration: 2361:\t loss: 0.0795903280377388\n",
      "epoch: 8:  iteration: 2381:\t loss: 0.03584006801247597\n",
      "epoch: 8:  iteration: 2401:\t loss: 0.030381955206394196\n",
      "val loss:\t 0.0311057\n",
      "epoch: 8:  iteration: 2421:\t loss: 0.01876569539308548\n",
      "epoch: 8:  iteration: 2441:\t loss: 0.021738966926932335\n",
      "epoch: 8:  iteration: 2461:\t loss: 0.02500985376536846\n",
      "epoch: 8:  iteration: 2481:\t loss: 0.03490331768989563\n",
      "epoch: 8:  iteration: 2501:\t loss: 0.01768847554922104\n",
      "val loss:\t 0.027871951\n",
      "epoch: 8:  iteration: 2521:\t loss: 0.014500351622700691\n",
      "epoch: 8:  iteration: 2541:\t loss: 0.01995648816227913\n",
      "epoch: 8:  iteration: 2561:\t loss: 0.031379517167806625\n",
      "epoch: 8:  iteration: 2581:\t loss: 0.01839728094637394\n",
      "epoch: 8:  iteration: 2601:\t loss: 0.01661371812224388\n",
      "val loss:\t 0.01776974\n",
      "epoch: 8:  iteration: 2621:\t loss: 0.028915971517562866\n",
      "epoch: 8:  iteration: 2641:\t loss: 0.03673189878463745\n",
      "epoch: 8:  iteration: 2661:\t loss: 0.02177329920232296\n",
      "epoch: 8:  iteration: 2681:\t loss: 0.0342235192656517\n",
      "epoch: 8:  iteration: 2701:\t loss: 0.01921679824590683\n",
      "val loss:\t 0.021954756\n",
      "epoch: 8:  iteration: 2721:\t loss: 0.017051149159669876\n",
      "epoch: 8:  iteration: 2741:\t loss: 0.02300615981221199\n",
      "epoch: 8:  iteration: 2761:\t loss: 0.017195910215377808\n",
      "epoch: 8:  iteration: 2781:\t loss: 0.012822862714529037\n",
      "epoch: 8:  iteration: 2801:\t loss: 0.1456407755613327\n",
      "val loss:\t 0.020480247\n",
      "epoch: 8:  iteration: 2821:\t loss: 0.04927263408899307\n",
      "epoch: 8:  iteration: 2841:\t loss: 0.014704286120831966\n",
      "epoch: 8:  iteration: 2861:\t loss: 0.0190269872546196\n",
      "epoch: 8:  iteration: 2881:\t loss: 0.03467825800180435\n",
      "epoch: 8:  iteration: 2901:\t loss: 0.027187418192625046\n",
      "val loss:\t 0.018810123\n",
      "epoch: 8:  iteration: 2921:\t loss: 0.02980409935116768\n",
      "epoch: 8:  iteration: 2941:\t loss: 0.02351924031972885\n",
      "epoch: 8:  iteration: 2961:\t loss: 0.023604808375239372\n",
      "epoch: 8:  iteration: 2981:\t loss: 0.037667933851480484\n",
      "epoch: 8:  iteration: 3001:\t loss: 0.022548725828528404\n",
      "val loss:\t 0.031325676\n",
      "epoch: 8:  iteration: 3021:\t loss: 0.027593720704317093\n",
      "epoch: 8:  iteration: 3041:\t loss: 0.013833818957209587\n",
      "epoch: 8:  iteration: 3061:\t loss: 0.289822518825531\n",
      "epoch: 8:  iteration: 3081:\t loss: 0.021688569337129593\n",
      "epoch: 8:  iteration: 3101:\t loss: 0.03497681766748428\n",
      "val loss:\t 0.13317858\n",
      "epoch: 8:  iteration: 3121:\t loss: 0.02184951677918434\n",
      "epoch: 8:  iteration: 3141:\t loss: 0.05512392148375511\n",
      "epoch: 8:  iteration: 3161:\t loss: 0.02565007470548153\n",
      "epoch: 8:  iteration: 3181:\t loss: 0.02167673595249653\n",
      "epoch: 8:  iteration: 3201:\t loss: 0.02056659199297428\n",
      "val loss:\t 0.08492523\n",
      "epoch: 8:  iteration: 3221:\t loss: 0.027826549485325813\n",
      "epoch: 8:  iteration: 3241:\t loss: 0.026703964918851852\n",
      "epoch: 8:  iteration: 3261:\t loss: 0.03548351675271988\n",
      "epoch: 8:  iteration: 3281:\t loss: 0.03966006636619568\n",
      "epoch: 8:  iteration: 3301:\t loss: 0.04250572621822357\n",
      "val loss:\t 0.024451926\n",
      "epoch: 8:  iteration: 3321:\t loss: 0.03668864443898201\n",
      "epoch: 8:  iteration: 3341:\t loss: 0.017464902251958847\n",
      "epoch: 8:  iteration: 3361:\t loss: 0.02706294134259224\n",
      "epoch: 8:  iteration: 3381:\t loss: 0.026602670550346375\n",
      "epoch: 8:  iteration: 3401:\t loss: 0.016601013019680977\n",
      "val loss:\t 0.02045643\n",
      "epoch: 8:  iteration: 3421:\t loss: 0.020528366789221764\n",
      "epoch: 8:  iteration: 3441:\t loss: 0.01912454143166542\n",
      "epoch: 8:  iteration: 3461:\t loss: 0.017273738980293274\n",
      "epoch: 8:  iteration: 3481:\t loss: 0.07499600201845169\n",
      "epoch: 8:  iteration: 3501:\t loss: 0.016440734267234802\n",
      "val loss:\t 0.017887235\n",
      "epoch: 8:  iteration: 3521:\t loss: 0.030743170529603958\n",
      "epoch: 8:  iteration: 3541:\t loss: 0.027157573029398918\n",
      "epoch: 8:  iteration: 3561:\t loss: 0.02249852567911148\n",
      "epoch: 8:  iteration: 3581:\t loss: 0.02400331385433674\n",
      "epoch: 8:  iteration: 3601:\t loss: 0.027831649407744408\n",
      "val loss:\t 0.034788948\n",
      "epoch: 8:  iteration: 3621:\t loss: 0.032877117395401\n",
      "epoch: 8:  iteration: 3641:\t loss: 0.02813691645860672\n",
      "epoch: 8:  iteration: 3661:\t loss: 0.06432664394378662\n",
      "epoch: 8:  iteration: 3681:\t loss: 0.01646946556866169\n",
      "epoch: 8:  iteration: 3701:\t loss: 0.026461221277713776\n",
      "val loss:\t 0.047162168\n",
      "epoch: 8:  iteration: 3721:\t loss: 0.01662086695432663\n",
      "epoch: 8:  iteration: 3741:\t loss: 0.054025374352931976\n",
      "epoch: 8:  iteration: 3761:\t loss: 0.02168828248977661\n",
      "epoch: 8:  iteration: 3781:\t loss: 0.017479969188570976\n",
      "epoch: 8:  iteration: 3801:\t loss: 0.02753514237701893\n",
      "val loss:\t 0.01951053\n",
      "EarlyStopping counter: 4 out of 6\n",
      "----------------epoch end--------------------- 7\n",
      "|loss_train| 0.00023031566524878144\n",
      "|loss_test| 0.00019757793052121997\n",
      "epoch: 9:  iteration: 1:\t loss: 0.02223953790962696\n",
      "val loss:\t 0.035560653\n",
      "epoch: 9:  iteration: 21:\t loss: 0.020078789442777634\n",
      "epoch: 9:  iteration: 41:\t loss: 0.021225955337285995\n",
      "epoch: 9:  iteration: 61:\t loss: 0.01432417705655098\n",
      "epoch: 9:  iteration: 81:\t loss: 0.021824870258569717\n",
      "epoch: 9:  iteration: 101:\t loss: 0.039773307740688324\n",
      "val loss:\t 0.041105986\n",
      "epoch: 9:  iteration: 121:\t loss: 0.04324687272310257\n",
      "epoch: 9:  iteration: 141:\t loss: 0.025561660528182983\n",
      "epoch: 9:  iteration: 161:\t loss: 0.04249347746372223\n",
      "epoch: 9:  iteration: 181:\t loss: 0.018396876752376556\n",
      "epoch: 9:  iteration: 201:\t loss: 0.04399298503994942\n",
      "val loss:\t 0.030968623\n",
      "epoch: 9:  iteration: 221:\t loss: 0.032746367156505585\n",
      "epoch: 9:  iteration: 241:\t loss: 1.121254801750183\n",
      "epoch: 9:  iteration: 261:\t loss: 0.017134997993707657\n",
      "epoch: 9:  iteration: 281:\t loss: 0.017835227772593498\n",
      "epoch: 9:  iteration: 301:\t loss: 0.052475493401288986\n",
      "val loss:\t 0.042051934\n",
      "epoch: 9:  iteration: 321:\t loss: 0.019405176863074303\n",
      "epoch: 9:  iteration: 341:\t loss: 0.06479345262050629\n",
      "epoch: 9:  iteration: 361:\t loss: 0.031511783599853516\n",
      "epoch: 9:  iteration: 381:\t loss: 0.02637414261698723\n",
      "epoch: 9:  iteration: 401:\t loss: 0.036647729575634\n",
      "val loss:\t 0.025422238\n",
      "epoch: 9:  iteration: 421:\t loss: 0.02424977347254753\n",
      "epoch: 9:  iteration: 441:\t loss: 0.1399252861738205\n",
      "epoch: 9:  iteration: 461:\t loss: 0.03529667854309082\n",
      "epoch: 9:  iteration: 481:\t loss: 0.051867105066776276\n",
      "epoch: 9:  iteration: 501:\t loss: 0.02106378972530365\n",
      "val loss:\t 0.047688067\n",
      "epoch: 9:  iteration: 521:\t loss: 0.021763579919934273\n",
      "epoch: 9:  iteration: 541:\t loss: 0.030572935938835144\n",
      "epoch: 9:  iteration: 561:\t loss: 0.023967327550053596\n",
      "epoch: 9:  iteration: 581:\t loss: 0.07181893289089203\n",
      "epoch: 9:  iteration: 601:\t loss: 0.02261216752231121\n",
      "val loss:\t 0.020945499\n",
      "epoch: 9:  iteration: 621:\t loss: 0.01788998395204544\n",
      "epoch: 9:  iteration: 641:\t loss: 0.015004775486886501\n",
      "epoch: 9:  iteration: 661:\t loss: 0.028958700597286224\n",
      "epoch: 9:  iteration: 681:\t loss: 0.9967577457427979\n",
      "epoch: 9:  iteration: 701:\t loss: 0.019203780218958855\n",
      "val loss:\t 0.018972449\n",
      "epoch: 9:  iteration: 721:\t loss: 0.03227236866950989\n",
      "epoch: 9:  iteration: 741:\t loss: 0.050533365458250046\n",
      "epoch: 9:  iteration: 761:\t loss: 0.02186495251953602\n",
      "epoch: 9:  iteration: 781:\t loss: 0.10462410748004913\n",
      "epoch: 9:  iteration: 801:\t loss: 0.02002178505063057\n",
      "val loss:\t 0.05139672\n",
      "epoch: 9:  iteration: 821:\t loss: 0.031017281115055084\n",
      "epoch: 9:  iteration: 841:\t loss: 0.01744488999247551\n",
      "epoch: 9:  iteration: 861:\t loss: 0.014603975228965282\n",
      "epoch: 9:  iteration: 881:\t loss: 0.02657925896346569\n",
      "epoch: 9:  iteration: 901:\t loss: 0.019064322113990784\n",
      "val loss:\t 0.023416074\n",
      "epoch: 9:  iteration: 921:\t loss: 0.019009117037057877\n",
      "epoch: 9:  iteration: 941:\t loss: 0.03412119299173355\n",
      "epoch: 9:  iteration: 961:\t loss: 0.025381382554769516\n",
      "epoch: 9:  iteration: 981:\t loss: 0.020163606852293015\n",
      "epoch: 9:  iteration: 1001:\t loss: 0.04260179027915001\n",
      "val loss:\t 0.04292512\n",
      "epoch: 9:  iteration: 1021:\t loss: 0.02608318254351616\n",
      "epoch: 9:  iteration: 1041:\t loss: 0.032641176134347916\n",
      "epoch: 9:  iteration: 1061:\t loss: 0.05940772593021393\n",
      "epoch: 9:  iteration: 1081:\t loss: 0.027522319927811623\n",
      "epoch: 9:  iteration: 1101:\t loss: 0.01957852393388748\n",
      "val loss:\t 0.032823347\n",
      "epoch: 9:  iteration: 1121:\t loss: 0.03830503299832344\n",
      "epoch: 9:  iteration: 1141:\t loss: 0.028352167457342148\n",
      "epoch: 9:  iteration: 1161:\t loss: 0.015415208414196968\n",
      "epoch: 9:  iteration: 1181:\t loss: 0.10573916882276535\n",
      "epoch: 9:  iteration: 1201:\t loss: 0.023948414251208305\n",
      "val loss:\t 0.028513256\n",
      "epoch: 9:  iteration: 1221:\t loss: 0.0551365464925766\n",
      "epoch: 9:  iteration: 1241:\t loss: 0.02523050270974636\n",
      "epoch: 9:  iteration: 1261:\t loss: 0.021391404792666435\n",
      "epoch: 9:  iteration: 1281:\t loss: 0.021251406520605087\n",
      "epoch: 9:  iteration: 1301:\t loss: 0.041013963520526886\n",
      "val loss:\t 0.016559687\n",
      "epoch: 9:  iteration: 1321:\t loss: 0.022918183356523514\n",
      "epoch: 9:  iteration: 1341:\t loss: 0.025845728814601898\n",
      "epoch: 9:  iteration: 1361:\t loss: 0.14540746808052063\n",
      "epoch: 9:  iteration: 1381:\t loss: 0.046363625675439835\n",
      "epoch: 9:  iteration: 1401:\t loss: 0.019444812089204788\n",
      "val loss:\t 0.03015366\n",
      "epoch: 9:  iteration: 1421:\t loss: 0.023569192737340927\n",
      "epoch: 9:  iteration: 1441:\t loss: 0.020759541541337967\n",
      "epoch: 9:  iteration: 1461:\t loss: 0.05304601043462753\n",
      "epoch: 9:  iteration: 1481:\t loss: 0.05301586166024208\n",
      "epoch: 9:  iteration: 1501:\t loss: 0.023487437516450882\n",
      "val loss:\t 0.024963088\n",
      "epoch: 9:  iteration: 1521:\t loss: 0.02872249111533165\n",
      "epoch: 9:  iteration: 1541:\t loss: 0.017966363579034805\n",
      "epoch: 9:  iteration: 1561:\t loss: 0.0216220673173666\n",
      "epoch: 9:  iteration: 1581:\t loss: 0.03643210977315903\n",
      "epoch: 9:  iteration: 1601:\t loss: 0.021406017243862152\n",
      "val loss:\t 0.022515887\n",
      "epoch: 9:  iteration: 1621:\t loss: 0.02417922019958496\n",
      "epoch: 9:  iteration: 1641:\t loss: 0.025607703253626823\n",
      "epoch: 9:  iteration: 1661:\t loss: 0.020651085302233696\n",
      "epoch: 9:  iteration: 1681:\t loss: 0.032214000821113586\n",
      "epoch: 9:  iteration: 1701:\t loss: 0.0322960689663887\n",
      "val loss:\t 0.028288374\n",
      "epoch: 9:  iteration: 1721:\t loss: 0.027035294100642204\n",
      "epoch: 9:  iteration: 1741:\t loss: 0.042162567377090454\n",
      "epoch: 9:  iteration: 1761:\t loss: 0.044022053480148315\n",
      "epoch: 9:  iteration: 1781:\t loss: 0.03634805604815483\n",
      "epoch: 9:  iteration: 1801:\t loss: 0.046636734157800674\n",
      "val loss:\t 0.024054442\n",
      "epoch: 9:  iteration: 1821:\t loss: 0.03231964260339737\n",
      "epoch: 9:  iteration: 1841:\t loss: 0.028440464287996292\n",
      "epoch: 9:  iteration: 1861:\t loss: 0.033181995153427124\n",
      "epoch: 9:  iteration: 1881:\t loss: 0.021707218140363693\n",
      "epoch: 9:  iteration: 1901:\t loss: 0.02430889569222927\n",
      "val loss:\t 0.017998774\n",
      "epoch: 9:  iteration: 1921:\t loss: 0.03758490830659866\n",
      "epoch: 9:  iteration: 1941:\t loss: 0.029436957091093063\n",
      "epoch: 9:  iteration: 1961:\t loss: 0.026606382802128792\n",
      "epoch: 9:  iteration: 1981:\t loss: 0.10615483671426773\n",
      "epoch: 9:  iteration: 2001:\t loss: 0.03711161017417908\n",
      "val loss:\t 0.09337749\n",
      "epoch: 9:  iteration: 2021:\t loss: 0.018400821834802628\n",
      "epoch: 9:  iteration: 2041:\t loss: 0.019461574032902718\n",
      "epoch: 9:  iteration: 2061:\t loss: 0.03359353542327881\n",
      "epoch: 9:  iteration: 2081:\t loss: 0.015500242821872234\n",
      "epoch: 9:  iteration: 2101:\t loss: 0.05692407116293907\n",
      "val loss:\t 0.043196145\n",
      "epoch: 9:  iteration: 2121:\t loss: 0.02821824699640274\n",
      "epoch: 9:  iteration: 2141:\t loss: 0.04979390650987625\n",
      "epoch: 9:  iteration: 2161:\t loss: 0.018497789278626442\n",
      "epoch: 9:  iteration: 2181:\t loss: 0.011889830231666565\n",
      "epoch: 9:  iteration: 2201:\t loss: 0.014632584527134895\n",
      "val loss:\t 0.025114287\n",
      "epoch: 9:  iteration: 2221:\t loss: 0.02501220442354679\n",
      "epoch: 9:  iteration: 2241:\t loss: 0.035671085119247437\n",
      "epoch: 9:  iteration: 2261:\t loss: 0.0193028524518013\n",
      "epoch: 9:  iteration: 2281:\t loss: 0.017936348915100098\n",
      "epoch: 9:  iteration: 2301:\t loss: 0.029194356873631477\n",
      "val loss:\t 0.016866522\n",
      "epoch: 9:  iteration: 2321:\t loss: 0.01933370903134346\n",
      "epoch: 9:  iteration: 2341:\t loss: 0.017303280532360077\n",
      "epoch: 9:  iteration: 2361:\t loss: 0.016018373891711235\n",
      "epoch: 9:  iteration: 2381:\t loss: 0.026783954352140427\n",
      "epoch: 9:  iteration: 2401:\t loss: 0.01637757569551468\n",
      "val loss:\t 0.027803421\n",
      "epoch: 9:  iteration: 2421:\t loss: 0.05192352831363678\n",
      "epoch: 9:  iteration: 2441:\t loss: 0.01829359494149685\n",
      "epoch: 9:  iteration: 2461:\t loss: 0.0196068212389946\n",
      "epoch: 9:  iteration: 2481:\t loss: 0.02433522790670395\n",
      "epoch: 9:  iteration: 2501:\t loss: 1.2886359691619873\n",
      "val loss:\t 0.015652388\n",
      "epoch: 9:  iteration: 2521:\t loss: 0.03579895570874214\n",
      "epoch: 9:  iteration: 2541:\t loss: 0.02597292885184288\n",
      "epoch: 9:  iteration: 2561:\t loss: 0.023243147879838943\n",
      "epoch: 9:  iteration: 2581:\t loss: 0.03280404210090637\n",
      "epoch: 9:  iteration: 2601:\t loss: 0.04047190770506859\n",
      "val loss:\t 0.036692925\n",
      "epoch: 9:  iteration: 2621:\t loss: 0.02377302013337612\n",
      "epoch: 9:  iteration: 2641:\t loss: 0.026101477444171906\n",
      "epoch: 9:  iteration: 2661:\t loss: 0.047329872846603394\n",
      "epoch: 9:  iteration: 2681:\t loss: 0.05060415714979172\n",
      "epoch: 9:  iteration: 2701:\t loss: 0.02258925512433052\n",
      "val loss:\t 0.019251594\n",
      "epoch: 9:  iteration: 2721:\t loss: 0.026985520496964455\n",
      "epoch: 9:  iteration: 2741:\t loss: 0.021749507635831833\n",
      "epoch: 9:  iteration: 2761:\t loss: 0.026395969092845917\n",
      "epoch: 9:  iteration: 2781:\t loss: 0.02941647171974182\n",
      "epoch: 9:  iteration: 2801:\t loss: 0.019777391105890274\n",
      "val loss:\t 0.0209598\n",
      "epoch: 9:  iteration: 2821:\t loss: 0.016632039099931717\n",
      "epoch: 9:  iteration: 2841:\t loss: 0.022663775831460953\n",
      "epoch: 9:  iteration: 2861:\t loss: 0.021055398508906364\n",
      "epoch: 9:  iteration: 2881:\t loss: 0.025725584477186203\n",
      "epoch: 9:  iteration: 2901:\t loss: 0.029975779354572296\n",
      "val loss:\t 0.042053636\n",
      "epoch: 9:  iteration: 2921:\t loss: 0.024457808583974838\n",
      "epoch: 9:  iteration: 2941:\t loss: 0.01924249157309532\n",
      "epoch: 9:  iteration: 2961:\t loss: 0.023879753425717354\n",
      "epoch: 9:  iteration: 2981:\t loss: 0.025481179356575012\n",
      "epoch: 9:  iteration: 3001:\t loss: 0.04202603921294212\n",
      "val loss:\t 0.026368517\n",
      "epoch: 9:  iteration: 3021:\t loss: 0.02193734422326088\n",
      "epoch: 9:  iteration: 3041:\t loss: 0.01938823238015175\n",
      "epoch: 9:  iteration: 3061:\t loss: 0.06019047647714615\n",
      "epoch: 9:  iteration: 3081:\t loss: 0.024541303515434265\n",
      "epoch: 9:  iteration: 3101:\t loss: 0.025638073682785034\n",
      "val loss:\t 0.033500113\n",
      "epoch: 9:  iteration: 3121:\t loss: 0.023783957585692406\n",
      "epoch: 9:  iteration: 3141:\t loss: 0.020737309008836746\n",
      "epoch: 9:  iteration: 3161:\t loss: 0.026350634172558784\n",
      "epoch: 9:  iteration: 3181:\t loss: 0.017271798104047775\n",
      "epoch: 9:  iteration: 3201:\t loss: 0.022002503275871277\n",
      "val loss:\t 0.03097514\n",
      "epoch: 9:  iteration: 3221:\t loss: 0.017881982028484344\n",
      "epoch: 9:  iteration: 3241:\t loss: 0.12911921739578247\n",
      "epoch: 9:  iteration: 3261:\t loss: 0.01910809800028801\n",
      "epoch: 9:  iteration: 3281:\t loss: 0.02641981840133667\n",
      "epoch: 9:  iteration: 3301:\t loss: 0.03678883612155914\n",
      "val loss:\t 0.022608921\n",
      "epoch: 9:  iteration: 3321:\t loss: 0.030531544238328934\n",
      "epoch: 9:  iteration: 3341:\t loss: 0.019863449037075043\n",
      "epoch: 9:  iteration: 3361:\t loss: 0.02555183321237564\n",
      "epoch: 9:  iteration: 3381:\t loss: 0.055279701948165894\n",
      "epoch: 9:  iteration: 3401:\t loss: 0.039803892374038696\n",
      "val loss:\t 0.032874092\n",
      "epoch: 9:  iteration: 3421:\t loss: 0.01847725547850132\n",
      "epoch: 9:  iteration: 3441:\t loss: 0.04401790350675583\n",
      "epoch: 9:  iteration: 3461:\t loss: 0.014148066751658916\n",
      "epoch: 9:  iteration: 3481:\t loss: 0.10222186148166656\n",
      "epoch: 9:  iteration: 3501:\t loss: 0.022349027916789055\n",
      "val loss:\t 0.021879677\n",
      "epoch: 9:  iteration: 3521:\t loss: 0.04554539918899536\n",
      "epoch: 9:  iteration: 3541:\t loss: 0.019300799816846848\n",
      "epoch: 9:  iteration: 3561:\t loss: 0.02027301862835884\n",
      "epoch: 9:  iteration: 3581:\t loss: 0.01752026006579399\n",
      "epoch: 9:  iteration: 3601:\t loss: 0.02209450490772724\n",
      "val loss:\t 0.01767539\n",
      "epoch: 9:  iteration: 3621:\t loss: 0.021637417376041412\n",
      "epoch: 9:  iteration: 3641:\t loss: 0.041153088212013245\n",
      "epoch: 9:  iteration: 3661:\t loss: 0.01833208091557026\n",
      "epoch: 9:  iteration: 3681:\t loss: 0.10874272882938385\n",
      "epoch: 9:  iteration: 3701:\t loss: 0.030032750219106674\n",
      "val loss:\t 0.021916982\n",
      "epoch: 9:  iteration: 3721:\t loss: 0.019107695668935776\n",
      "epoch: 9:  iteration: 3741:\t loss: 0.027576036751270294\n",
      "epoch: 9:  iteration: 3761:\t loss: 0.037415631115436554\n",
      "epoch: 9:  iteration: 3781:\t loss: 0.01717665046453476\n",
      "epoch: 9:  iteration: 3801:\t loss: 0.005878733936697245\n",
      "val loss:\t 0.022799516\n",
      "Validation loss decreased (0.006672 --> 0.005879).  Saving model ...\n",
      "----------------epoch end--------------------- 8\n",
      "|loss_train| 0.0001317576679866761\n",
      "|loss_test| 0.0001031897627399303\n",
      "epoch: 10:  iteration: 1:\t loss: 0.015968669205904007\n",
      "val loss:\t 0.016240241\n",
      "epoch: 10:  iteration: 21:\t loss: 0.022096682339906693\n",
      "epoch: 10:  iteration: 41:\t loss: 0.07229704409837723\n",
      "epoch: 10:  iteration: 61:\t loss: 0.032084569334983826\n",
      "epoch: 10:  iteration: 81:\t loss: 0.03445690870285034\n",
      "epoch: 10:  iteration: 101:\t loss: 0.03130383417010307\n",
      "val loss:\t 0.029798083\n",
      "epoch: 10:  iteration: 121:\t loss: 0.022509094327688217\n",
      "epoch: 10:  iteration: 141:\t loss: 0.04792728275060654\n",
      "epoch: 10:  iteration: 161:\t loss: 0.023554544895887375\n",
      "epoch: 10:  iteration: 181:\t loss: 0.028194386512041092\n",
      "epoch: 10:  iteration: 201:\t loss: 0.016590658575296402\n",
      "val loss:\t 0.022802833\n",
      "epoch: 10:  iteration: 221:\t loss: 0.027278173714876175\n",
      "epoch: 10:  iteration: 241:\t loss: 0.024535885080695152\n",
      "epoch: 10:  iteration: 261:\t loss: 0.02069135196506977\n",
      "epoch: 10:  iteration: 281:\t loss: 0.04278564453125\n",
      "epoch: 10:  iteration: 301:\t loss: 0.01388788316398859\n",
      "val loss:\t 0.02707601\n",
      "epoch: 10:  iteration: 321:\t loss: 0.01776484213769436\n",
      "epoch: 10:  iteration: 341:\t loss: 0.030052190646529198\n",
      "epoch: 10:  iteration: 361:\t loss: 0.015231207013130188\n",
      "epoch: 10:  iteration: 381:\t loss: 0.0331660695374012\n",
      "epoch: 10:  iteration: 401:\t loss: 0.025073960423469543\n",
      "val loss:\t 0.0339804\n",
      "epoch: 10:  iteration: 421:\t loss: 0.016201628372073174\n",
      "epoch: 10:  iteration: 441:\t loss: 0.02270154468715191\n",
      "epoch: 10:  iteration: 461:\t loss: 0.03128157556056976\n",
      "epoch: 10:  iteration: 481:\t loss: 0.02062578685581684\n",
      "epoch: 10:  iteration: 501:\t loss: 0.02653106488287449\n",
      "val loss:\t 0.022470333\n",
      "epoch: 10:  iteration: 521:\t loss: 0.02151941880583763\n",
      "epoch: 10:  iteration: 541:\t loss: 0.02817334607243538\n",
      "epoch: 10:  iteration: 561:\t loss: 0.04154735431075096\n",
      "epoch: 10:  iteration: 581:\t loss: 0.02433699555695057\n",
      "epoch: 10:  iteration: 601:\t loss: 0.033181920647621155\n",
      "val loss:\t 0.020422503\n",
      "epoch: 10:  iteration: 621:\t loss: 0.019300198182463646\n",
      "epoch: 10:  iteration: 641:\t loss: 0.01932055875658989\n",
      "epoch: 10:  iteration: 661:\t loss: 0.01550412829965353\n",
      "epoch: 10:  iteration: 681:\t loss: 0.015746302902698517\n",
      "epoch: 10:  iteration: 701:\t loss: 0.020410526543855667\n",
      "val loss:\t 0.022627886\n",
      "epoch: 10:  iteration: 721:\t loss: 0.018926573917269707\n",
      "epoch: 10:  iteration: 741:\t loss: 0.03980834409594536\n",
      "epoch: 10:  iteration: 761:\t loss: 0.0252266526222229\n",
      "epoch: 10:  iteration: 781:\t loss: 0.022204171866178513\n",
      "epoch: 10:  iteration: 801:\t loss: 0.03140733018517494\n",
      "val loss:\t 0.02294342\n",
      "epoch: 10:  iteration: 821:\t loss: 0.01847512647509575\n",
      "epoch: 10:  iteration: 841:\t loss: 0.022137712687253952\n",
      "epoch: 10:  iteration: 861:\t loss: 0.02525455504655838\n",
      "epoch: 10:  iteration: 881:\t loss: 0.04858323931694031\n",
      "epoch: 10:  iteration: 901:\t loss: 0.024333663284778595\n",
      "val loss:\t 0.02047662\n",
      "epoch: 10:  iteration: 921:\t loss: 0.025802399963140488\n",
      "epoch: 10:  iteration: 941:\t loss: 0.016458436846733093\n",
      "epoch: 10:  iteration: 961:\t loss: 0.038767170161008835\n",
      "epoch: 10:  iteration: 981:\t loss: 0.02320447936654091\n",
      "epoch: 10:  iteration: 1001:\t loss: 0.017136678099632263\n",
      "val loss:\t 0.024085985\n",
      "epoch: 10:  iteration: 1021:\t loss: 0.044075340032577515\n",
      "epoch: 10:  iteration: 1041:\t loss: 0.020202312618494034\n",
      "epoch: 10:  iteration: 1061:\t loss: 0.02526029571890831\n",
      "epoch: 10:  iteration: 1081:\t loss: 0.04502229392528534\n",
      "epoch: 10:  iteration: 1101:\t loss: 0.0233711376786232\n",
      "val loss:\t 0.017749995\n",
      "epoch: 10:  iteration: 1121:\t loss: 0.05253193899989128\n",
      "epoch: 10:  iteration: 1141:\t loss: 0.024522103369235992\n",
      "epoch: 10:  iteration: 1161:\t loss: 0.02664666622877121\n",
      "epoch: 10:  iteration: 1181:\t loss: 0.028266385197639465\n",
      "epoch: 10:  iteration: 1201:\t loss: 0.021570023149251938\n",
      "val loss:\t 0.016796008\n",
      "epoch: 10:  iteration: 1221:\t loss: 0.02305574342608452\n",
      "epoch: 10:  iteration: 1241:\t loss: 0.025191375985741615\n",
      "epoch: 10:  iteration: 1261:\t loss: 0.017618441954255104\n",
      "epoch: 10:  iteration: 1281:\t loss: 0.028349105268716812\n",
      "epoch: 10:  iteration: 1301:\t loss: 0.02617814391851425\n",
      "val loss:\t 0.02675003\n",
      "epoch: 10:  iteration: 1321:\t loss: 0.04119681566953659\n",
      "epoch: 10:  iteration: 1341:\t loss: 0.027432149276137352\n",
      "epoch: 10:  iteration: 1361:\t loss: 0.05628921464085579\n",
      "epoch: 10:  iteration: 1381:\t loss: 0.026237571612000465\n",
      "epoch: 10:  iteration: 1401:\t loss: 0.1784529834985733\n",
      "val loss:\t 0.014549767\n",
      "epoch: 10:  iteration: 1421:\t loss: 0.022436238825321198\n",
      "epoch: 10:  iteration: 1441:\t loss: 0.035752072930336\n",
      "epoch: 10:  iteration: 1461:\t loss: 0.021374734118580818\n",
      "epoch: 10:  iteration: 1481:\t loss: 0.02034531533718109\n",
      "epoch: 10:  iteration: 1501:\t loss: 0.024314451962709427\n",
      "val loss:\t 0.03071606\n",
      "epoch: 10:  iteration: 1521:\t loss: 0.02392314374446869\n",
      "epoch: 10:  iteration: 1541:\t loss: 0.026173900812864304\n",
      "epoch: 10:  iteration: 1561:\t loss: 0.031060706824064255\n",
      "epoch: 10:  iteration: 1581:\t loss: 0.22345951199531555\n",
      "epoch: 10:  iteration: 1601:\t loss: 0.03606931120157242\n",
      "val loss:\t 0.016718466\n",
      "epoch: 10:  iteration: 1621:\t loss: 0.04199649393558502\n",
      "epoch: 10:  iteration: 1641:\t loss: 0.03348036855459213\n",
      "epoch: 10:  iteration: 1661:\t loss: 0.02328142523765564\n",
      "epoch: 10:  iteration: 1681:\t loss: 0.02951471507549286\n",
      "epoch: 10:  iteration: 1701:\t loss: 0.02098117396235466\n",
      "val loss:\t 0.025337342\n",
      "epoch: 10:  iteration: 1721:\t loss: 0.034026701003313065\n",
      "epoch: 10:  iteration: 1741:\t loss: 0.023189179599285126\n",
      "epoch: 10:  iteration: 1761:\t loss: 0.014354843646287918\n",
      "epoch: 10:  iteration: 1781:\t loss: 0.0455637127161026\n",
      "epoch: 10:  iteration: 1801:\t loss: 0.05548694357275963\n",
      "val loss:\t 0.02181882\n",
      "epoch: 10:  iteration: 1821:\t loss: 0.033964455127716064\n",
      "epoch: 10:  iteration: 1841:\t loss: 0.020892197266221046\n",
      "epoch: 10:  iteration: 1861:\t loss: 0.014219313859939575\n",
      "epoch: 10:  iteration: 1881:\t loss: 0.02055564895272255\n",
      "epoch: 10:  iteration: 1901:\t loss: 0.015415645204484463\n",
      "val loss:\t 0.014404957\n",
      "epoch: 10:  iteration: 1921:\t loss: 0.02136184833943844\n",
      "epoch: 10:  iteration: 1941:\t loss: 0.02219330333173275\n",
      "epoch: 10:  iteration: 1961:\t loss: 0.023269031196832657\n",
      "epoch: 10:  iteration: 1981:\t loss: 0.023326518014073372\n",
      "epoch: 10:  iteration: 2001:\t loss: 0.10936933755874634\n",
      "val loss:\t 0.02617821\n",
      "epoch: 10:  iteration: 2021:\t loss: 0.026539672166109085\n",
      "epoch: 10:  iteration: 2041:\t loss: 0.04627346247434616\n",
      "epoch: 10:  iteration: 2061:\t loss: 0.047934144735336304\n",
      "epoch: 10:  iteration: 2081:\t loss: 0.01910817250609398\n",
      "epoch: 10:  iteration: 2101:\t loss: 0.020126156508922577\n",
      "val loss:\t 0.033883482\n",
      "epoch: 10:  iteration: 2121:\t loss: 0.03182510659098625\n",
      "epoch: 10:  iteration: 2141:\t loss: 0.029950108379125595\n",
      "epoch: 10:  iteration: 2161:\t loss: 0.058590203523635864\n",
      "epoch: 10:  iteration: 2181:\t loss: 0.05857325717806816\n",
      "epoch: 10:  iteration: 2201:\t loss: 0.022711031138896942\n",
      "val loss:\t 0.024563821\n",
      "epoch: 10:  iteration: 2221:\t loss: 0.02587551437318325\n",
      "epoch: 10:  iteration: 2241:\t loss: 0.08523017168045044\n",
      "epoch: 10:  iteration: 2261:\t loss: 0.024894045665860176\n",
      "epoch: 10:  iteration: 2281:\t loss: 0.039924152195453644\n",
      "epoch: 10:  iteration: 2301:\t loss: 0.029623622074723244\n",
      "val loss:\t 0.024137195\n",
      "epoch: 10:  iteration: 2321:\t loss: 0.0295921191573143\n",
      "epoch: 10:  iteration: 2341:\t loss: 0.020283814519643784\n",
      "epoch: 10:  iteration: 2361:\t loss: 0.020515186712145805\n",
      "epoch: 10:  iteration: 2381:\t loss: 0.07231205701828003\n",
      "epoch: 10:  iteration: 2401:\t loss: 0.0701872929930687\n",
      "val loss:\t 0.015962329\n",
      "epoch: 10:  iteration: 2421:\t loss: 0.017427772283554077\n",
      "epoch: 10:  iteration: 2441:\t loss: 0.02059381827712059\n",
      "epoch: 10:  iteration: 2461:\t loss: 0.01927095092833042\n",
      "epoch: 10:  iteration: 2481:\t loss: 0.014029096812009811\n",
      "epoch: 10:  iteration: 2501:\t loss: 0.07058673352003098\n",
      "val loss:\t 0.042582605\n",
      "epoch: 10:  iteration: 2521:\t loss: 0.01825086586177349\n",
      "epoch: 10:  iteration: 2541:\t loss: 0.01870015449821949\n",
      "epoch: 10:  iteration: 2561:\t loss: 0.03484800085425377\n",
      "epoch: 10:  iteration: 2581:\t loss: 0.017804332077503204\n",
      "epoch: 10:  iteration: 2601:\t loss: 0.04751366749405861\n",
      "val loss:\t 0.013773016\n",
      "epoch: 10:  iteration: 2621:\t loss: 0.02728581801056862\n",
      "epoch: 10:  iteration: 2641:\t loss: 0.14220766723155975\n",
      "epoch: 10:  iteration: 2661:\t loss: 0.025079119950532913\n",
      "epoch: 10:  iteration: 2681:\t loss: 0.02003026008605957\n",
      "epoch: 10:  iteration: 2701:\t loss: 0.02536173164844513\n",
      "val loss:\t 0.027821884\n",
      "epoch: 10:  iteration: 2721:\t loss: 0.01619320921599865\n",
      "epoch: 10:  iteration: 2741:\t loss: 0.024545680731534958\n",
      "epoch: 10:  iteration: 2761:\t loss: 0.03713291510939598\n",
      "epoch: 10:  iteration: 2781:\t loss: 0.043691523373126984\n",
      "epoch: 10:  iteration: 2801:\t loss: 0.01888457126915455\n",
      "val loss:\t 0.019138813\n",
      "epoch: 10:  iteration: 2821:\t loss: 0.030399039387702942\n",
      "epoch: 10:  iteration: 2841:\t loss: 0.030882518738508224\n",
      "epoch: 10:  iteration: 2861:\t loss: 0.08704936504364014\n",
      "epoch: 10:  iteration: 2881:\t loss: 0.038361843675374985\n",
      "epoch: 10:  iteration: 2901:\t loss: 0.04320017248392105\n",
      "val loss:\t 0.033717662\n",
      "epoch: 10:  iteration: 2921:\t loss: 0.06656889617443085\n",
      "epoch: 10:  iteration: 2941:\t loss: 0.024770617485046387\n",
      "epoch: 10:  iteration: 2961:\t loss: 0.02328610047698021\n",
      "epoch: 10:  iteration: 2981:\t loss: 0.03736458718776703\n",
      "epoch: 10:  iteration: 3001:\t loss: 0.02867501974105835\n",
      "val loss:\t 0.037767224\n",
      "epoch: 10:  iteration: 3021:\t loss: 0.0555078499019146\n",
      "epoch: 10:  iteration: 3041:\t loss: 0.07017393410205841\n",
      "epoch: 10:  iteration: 3061:\t loss: 0.0294338446110487\n",
      "epoch: 10:  iteration: 3081:\t loss: 0.024366222321987152\n",
      "epoch: 10:  iteration: 3101:\t loss: 0.022685637697577477\n",
      "val loss:\t 0.013095947\n",
      "epoch: 10:  iteration: 3121:\t loss: 0.028920717537403107\n",
      "epoch: 10:  iteration: 3141:\t loss: 0.028818560764193535\n",
      "epoch: 10:  iteration: 3161:\t loss: 0.03211880475282669\n",
      "epoch: 10:  iteration: 3181:\t loss: 0.01902613788843155\n",
      "epoch: 10:  iteration: 3201:\t loss: 0.04080226272344589\n",
      "val loss:\t 0.043486424\n",
      "epoch: 10:  iteration: 3221:\t loss: 0.026449231430888176\n",
      "epoch: 10:  iteration: 3241:\t loss: 0.02787736989557743\n",
      "epoch: 10:  iteration: 3261:\t loss: 0.034537069499492645\n",
      "epoch: 10:  iteration: 3281:\t loss: 0.07251378893852234\n",
      "epoch: 10:  iteration: 3301:\t loss: 0.02561819925904274\n",
      "val loss:\t 0.03251902\n",
      "epoch: 10:  iteration: 3321:\t loss: 0.059724655002355576\n",
      "epoch: 10:  iteration: 3341:\t loss: 0.06599538028240204\n",
      "epoch: 10:  iteration: 3361:\t loss: 0.027990136295557022\n",
      "epoch: 10:  iteration: 3381:\t loss: 0.016121936962008476\n",
      "epoch: 10:  iteration: 3401:\t loss: 0.022580131888389587\n",
      "val loss:\t 0.042135008\n",
      "epoch: 10:  iteration: 3421:\t loss: 0.030168499797582626\n",
      "epoch: 10:  iteration: 3441:\t loss: 0.021103719249367714\n",
      "epoch: 10:  iteration: 3461:\t loss: 0.03500180318951607\n",
      "epoch: 10:  iteration: 3481:\t loss: 0.04492370784282684\n",
      "epoch: 10:  iteration: 3501:\t loss: 0.029072819277644157\n",
      "val loss:\t 0.031194326\n",
      "epoch: 10:  iteration: 3521:\t loss: 0.014309762045741081\n",
      "epoch: 10:  iteration: 3541:\t loss: 0.032938793301582336\n",
      "epoch: 10:  iteration: 3561:\t loss: 0.022303003817796707\n",
      "epoch: 10:  iteration: 3581:\t loss: 0.025640714913606644\n",
      "epoch: 10:  iteration: 3601:\t loss: 0.024584181606769562\n",
      "val loss:\t 0.022286847\n",
      "epoch: 10:  iteration: 3621:\t loss: 0.03189589083194733\n",
      "epoch: 10:  iteration: 3641:\t loss: 0.06422410905361176\n",
      "epoch: 10:  iteration: 3661:\t loss: 0.021966032683849335\n",
      "epoch: 10:  iteration: 3681:\t loss: 0.016046646982431412\n",
      "epoch: 10:  iteration: 3701:\t loss: 0.03673937916755676\n",
      "val loss:\t 0.028485611\n",
      "epoch: 10:  iteration: 3721:\t loss: 0.031340986490249634\n",
      "epoch: 10:  iteration: 3741:\t loss: 0.03378147631883621\n",
      "epoch: 10:  iteration: 3761:\t loss: 0.021377071738243103\n",
      "epoch: 10:  iteration: 3781:\t loss: 0.014738427475094795\n",
      "epoch: 10:  iteration: 3801:\t loss: 0.01801970973610878\n",
      "val loss:\t 0.017533459\n",
      "EarlyStopping counter: 1 out of 6\n",
      "----------------epoch end--------------------- 9\n",
      "|loss_train| 8.063002314884216e-05\n",
      "|loss_test| 0.00780522869899869\n",
      "epoch: 11:  iteration: 1:\t loss: 0.014647653326392174\n",
      "val loss:\t 0.016513452\n",
      "epoch: 11:  iteration: 21:\t loss: 0.021145105361938477\n",
      "epoch: 11:  iteration: 41:\t loss: 0.026895370334386826\n",
      "epoch: 11:  iteration: 61:\t loss: 0.021609095856547356\n",
      "epoch: 11:  iteration: 81:\t loss: 0.03292398154735565\n",
      "epoch: 11:  iteration: 101:\t loss: 0.0229145847260952\n",
      "val loss:\t 0.022843108\n",
      "epoch: 11:  iteration: 121:\t loss: 0.04933033883571625\n",
      "epoch: 11:  iteration: 141:\t loss: 0.026021305471658707\n",
      "epoch: 11:  iteration: 161:\t loss: 0.02487725019454956\n",
      "epoch: 11:  iteration: 181:\t loss: 0.025665096938610077\n",
      "epoch: 11:  iteration: 201:\t loss: 0.018691236153244972\n",
      "val loss:\t 0.021798301\n",
      "epoch: 11:  iteration: 221:\t loss: 0.03329114988446236\n",
      "epoch: 11:  iteration: 241:\t loss: 0.031093701720237732\n",
      "epoch: 11:  iteration: 261:\t loss: 0.02410627156496048\n",
      "epoch: 11:  iteration: 281:\t loss: 0.04267815127968788\n",
      "epoch: 11:  iteration: 301:\t loss: 0.05999622493982315\n",
      "val loss:\t 0.018175887\n",
      "epoch: 11:  iteration: 321:\t loss: 0.024301502853631973\n",
      "epoch: 11:  iteration: 341:\t loss: 0.0725780725479126\n",
      "epoch: 11:  iteration: 361:\t loss: 0.02226440981030464\n",
      "epoch: 11:  iteration: 381:\t loss: 0.01754867658019066\n",
      "epoch: 11:  iteration: 401:\t loss: 0.021276414394378662\n",
      "val loss:\t 0.030975765\n",
      "epoch: 11:  iteration: 421:\t loss: 0.025469761341810226\n",
      "epoch: 11:  iteration: 441:\t loss: 0.01543355081230402\n",
      "epoch: 11:  iteration: 461:\t loss: 0.02615804225206375\n",
      "epoch: 11:  iteration: 481:\t loss: 0.022259622812271118\n",
      "epoch: 11:  iteration: 501:\t loss: 0.02484034188091755\n",
      "val loss:\t 0.033233903\n",
      "epoch: 11:  iteration: 521:\t loss: 0.03055587038397789\n",
      "epoch: 11:  iteration: 541:\t loss: 0.025763312354683876\n",
      "epoch: 11:  iteration: 561:\t loss: 0.030769994482398033\n",
      "epoch: 11:  iteration: 581:\t loss: 0.022766808047890663\n",
      "epoch: 11:  iteration: 601:\t loss: 0.014976262114942074\n",
      "val loss:\t 0.022695104\n",
      "epoch: 11:  iteration: 621:\t loss: 0.03844098746776581\n",
      "epoch: 11:  iteration: 641:\t loss: 0.04828985780477524\n",
      "epoch: 11:  iteration: 661:\t loss: 0.050916872918605804\n",
      "epoch: 11:  iteration: 681:\t loss: 0.027085665613412857\n",
      "epoch: 11:  iteration: 701:\t loss: 0.021080302074551582\n",
      "val loss:\t 0.02700884\n",
      "epoch: 11:  iteration: 721:\t loss: 0.048238128423690796\n",
      "epoch: 11:  iteration: 741:\t loss: 0.02029184252023697\n",
      "epoch: 11:  iteration: 761:\t loss: 0.05012345314025879\n",
      "epoch: 11:  iteration: 781:\t loss: 0.030473219230771065\n",
      "epoch: 11:  iteration: 801:\t loss: 0.0349237322807312\n",
      "val loss:\t 0.021670308\n",
      "epoch: 11:  iteration: 821:\t loss: 0.44068968296051025\n",
      "epoch: 11:  iteration: 841:\t loss: 0.06300930678844452\n",
      "epoch: 11:  iteration: 861:\t loss: 0.031187565997242928\n",
      "epoch: 11:  iteration: 881:\t loss: 0.031018760055303574\n",
      "epoch: 11:  iteration: 901:\t loss: 0.015500733628869057\n",
      "val loss:\t 0.025507791\n",
      "epoch: 11:  iteration: 921:\t loss: 0.017830615863204002\n",
      "epoch: 11:  iteration: 941:\t loss: 0.02767205238342285\n",
      "epoch: 11:  iteration: 961:\t loss: 0.023236580193042755\n",
      "epoch: 11:  iteration: 981:\t loss: 0.027352724224328995\n",
      "epoch: 11:  iteration: 1001:\t loss: 0.016556328162550926\n",
      "val loss:\t 0.026431853\n",
      "epoch: 11:  iteration: 1021:\t loss: 0.042989060282707214\n",
      "epoch: 11:  iteration: 1041:\t loss: 0.18998177349567413\n",
      "epoch: 11:  iteration: 1061:\t loss: 0.03277453035116196\n",
      "epoch: 11:  iteration: 1081:\t loss: 0.030511287972331047\n",
      "epoch: 11:  iteration: 1101:\t loss: 0.03680882975459099\n",
      "val loss:\t 0.018853491\n",
      "epoch: 11:  iteration: 1121:\t loss: 0.026370475068688393\n",
      "epoch: 11:  iteration: 1141:\t loss: 0.01893249899148941\n",
      "epoch: 11:  iteration: 1161:\t loss: 0.01822255738079548\n",
      "epoch: 11:  iteration: 1181:\t loss: 0.04254131764173508\n",
      "epoch: 11:  iteration: 1201:\t loss: 0.026676718145608902\n",
      "val loss:\t 0.022013599\n",
      "epoch: 11:  iteration: 1221:\t loss: 0.029516488313674927\n",
      "epoch: 11:  iteration: 1241:\t loss: 0.03546534478664398\n",
      "epoch: 11:  iteration: 1261:\t loss: 0.018612606450915337\n",
      "epoch: 11:  iteration: 1281:\t loss: 0.02001963183283806\n",
      "epoch: 11:  iteration: 1301:\t loss: 0.01952001079916954\n",
      "val loss:\t 0.0155605795\n",
      "epoch: 11:  iteration: 1321:\t loss: 0.026727136224508286\n",
      "epoch: 11:  iteration: 1341:\t loss: 0.023155368864536285\n",
      "epoch: 11:  iteration: 1361:\t loss: 0.04731985181570053\n",
      "epoch: 11:  iteration: 1381:\t loss: 0.026490215212106705\n",
      "epoch: 11:  iteration: 1401:\t loss: 0.03442033380270004\n",
      "val loss:\t 0.041118894\n",
      "epoch: 11:  iteration: 1421:\t loss: 0.031553395092487335\n",
      "epoch: 11:  iteration: 1441:\t loss: 0.020214302465319633\n",
      "epoch: 11:  iteration: 1461:\t loss: 0.01808132976293564\n",
      "epoch: 11:  iteration: 1481:\t loss: 0.031234070658683777\n",
      "epoch: 11:  iteration: 1501:\t loss: 0.01642109826207161\n",
      "val loss:\t 0.029960483\n",
      "epoch: 11:  iteration: 1521:\t loss: 1.1056673526763916\n",
      "epoch: 11:  iteration: 1541:\t loss: 0.027963045984506607\n",
      "epoch: 11:  iteration: 1561:\t loss: 0.028279270976781845\n",
      "epoch: 11:  iteration: 1581:\t loss: 0.028040369972586632\n",
      "epoch: 11:  iteration: 1601:\t loss: 0.0729110985994339\n",
      "val loss:\t 0.063901976\n",
      "epoch: 11:  iteration: 1621:\t loss: 0.06066220998764038\n",
      "epoch: 11:  iteration: 1641:\t loss: 0.03364541381597519\n",
      "epoch: 11:  iteration: 1661:\t loss: 0.03162384033203125\n",
      "epoch: 11:  iteration: 1681:\t loss: 0.024794451892375946\n",
      "epoch: 11:  iteration: 1701:\t loss: 0.01529945433139801\n",
      "val loss:\t 0.024588637\n",
      "epoch: 11:  iteration: 1721:\t loss: 0.0184173621237278\n",
      "epoch: 11:  iteration: 1741:\t loss: 0.026087254285812378\n",
      "epoch: 11:  iteration: 1761:\t loss: 0.27393603324890137\n",
      "epoch: 11:  iteration: 1781:\t loss: 0.02278968319296837\n",
      "epoch: 11:  iteration: 1801:\t loss: 0.021842803806066513\n",
      "val loss:\t 0.01481766\n",
      "epoch: 11:  iteration: 1821:\t loss: 0.017756657674908638\n",
      "epoch: 11:  iteration: 1841:\t loss: 0.025417983531951904\n",
      "epoch: 11:  iteration: 1861:\t loss: 0.04182399436831474\n",
      "epoch: 11:  iteration: 1881:\t loss: 0.02095482498407364\n",
      "epoch: 11:  iteration: 1901:\t loss: 0.02242114208638668\n",
      "val loss:\t 0.060274087\n",
      "epoch: 11:  iteration: 1921:\t loss: 0.02267952635884285\n",
      "epoch: 11:  iteration: 1941:\t loss: 0.02108108252286911\n",
      "epoch: 11:  iteration: 1961:\t loss: 0.04006914421916008\n",
      "epoch: 11:  iteration: 1981:\t loss: 0.02389322593808174\n",
      "epoch: 11:  iteration: 2001:\t loss: 0.017032131552696228\n",
      "val loss:\t 0.038859088\n",
      "epoch: 11:  iteration: 2021:\t loss: 0.06756268441677094\n",
      "epoch: 11:  iteration: 2041:\t loss: 0.02795208990573883\n",
      "epoch: 11:  iteration: 2061:\t loss: 0.02488280087709427\n",
      "epoch: 11:  iteration: 2081:\t loss: 0.022744877263903618\n",
      "epoch: 11:  iteration: 2101:\t loss: 0.06982188671827316\n",
      "val loss:\t 0.016691947\n",
      "epoch: 11:  iteration: 2121:\t loss: 0.01837942749261856\n",
      "epoch: 11:  iteration: 2141:\t loss: 0.022854730486869812\n",
      "epoch: 11:  iteration: 2161:\t loss: 0.0785670280456543\n",
      "epoch: 11:  iteration: 2181:\t loss: 0.025479238480329514\n",
      "epoch: 11:  iteration: 2201:\t loss: 0.02285652421414852\n",
      "val loss:\t 0.020042198\n",
      "epoch: 11:  iteration: 2221:\t loss: 0.02721349149942398\n",
      "epoch: 11:  iteration: 2241:\t loss: 0.028942011296749115\n",
      "epoch: 11:  iteration: 2261:\t loss: 0.025167372077703476\n",
      "epoch: 11:  iteration: 2281:\t loss: 0.028084561228752136\n",
      "epoch: 11:  iteration: 2301:\t loss: 0.02494044229388237\n",
      "val loss:\t 0.025819223\n",
      "epoch: 11:  iteration: 2321:\t loss: 0.037051744759082794\n",
      "epoch: 11:  iteration: 2341:\t loss: 0.0220674779266119\n",
      "epoch: 11:  iteration: 2361:\t loss: 0.025226734578609467\n",
      "epoch: 11:  iteration: 2381:\t loss: 0.024847835302352905\n",
      "epoch: 11:  iteration: 2401:\t loss: 0.016295883804559708\n",
      "val loss:\t 0.027351977\n",
      "epoch: 11:  iteration: 2421:\t loss: 0.01899772509932518\n",
      "epoch: 11:  iteration: 2441:\t loss: 0.029250219464302063\n",
      "epoch: 11:  iteration: 2461:\t loss: 0.04404306039214134\n",
      "epoch: 11:  iteration: 2481:\t loss: 0.04695618897676468\n",
      "epoch: 11:  iteration: 2501:\t loss: 0.02656186744570732\n",
      "val loss:\t 0.020244949\n",
      "epoch: 11:  iteration: 2521:\t loss: 0.03930438309907913\n",
      "epoch: 11:  iteration: 2541:\t loss: 0.031354982405900955\n",
      "epoch: 11:  iteration: 2561:\t loss: 0.03362526744604111\n",
      "epoch: 11:  iteration: 2581:\t loss: 0.018940698355436325\n",
      "epoch: 11:  iteration: 2601:\t loss: 0.024501852691173553\n",
      "val loss:\t 0.03373434\n",
      "epoch: 11:  iteration: 2621:\t loss: 0.039566732943058014\n",
      "epoch: 11:  iteration: 2641:\t loss: 0.056712664663791656\n",
      "epoch: 11:  iteration: 2661:\t loss: 0.017347071319818497\n",
      "epoch: 11:  iteration: 2681:\t loss: 0.031693194061517715\n",
      "epoch: 11:  iteration: 2701:\t loss: 0.062204428017139435\n",
      "val loss:\t 0.031819977\n",
      "epoch: 11:  iteration: 2721:\t loss: 0.020462851971387863\n",
      "epoch: 11:  iteration: 2741:\t loss: 0.022966384887695312\n",
      "epoch: 11:  iteration: 2761:\t loss: 0.023961925879120827\n",
      "epoch: 11:  iteration: 2781:\t loss: 0.0455014705657959\n",
      "epoch: 11:  iteration: 2801:\t loss: 0.07784906029701233\n",
      "val loss:\t 0.035244375\n",
      "epoch: 11:  iteration: 2821:\t loss: 0.019263435155153275\n",
      "epoch: 11:  iteration: 2841:\t loss: 0.02956436574459076\n",
      "epoch: 11:  iteration: 2861:\t loss: 0.021931195631623268\n",
      "epoch: 11:  iteration: 2881:\t loss: 0.02419629693031311\n",
      "epoch: 11:  iteration: 2901:\t loss: 0.024392426013946533\n",
      "val loss:\t 0.02616008\n",
      "epoch: 11:  iteration: 2921:\t loss: 0.030054323375225067\n",
      "epoch: 11:  iteration: 2941:\t loss: 0.0228613018989563\n",
      "epoch: 11:  iteration: 2961:\t loss: 0.016145288944244385\n",
      "epoch: 11:  iteration: 2981:\t loss: 0.01562688872218132\n",
      "epoch: 11:  iteration: 3001:\t loss: 0.03843129426240921\n",
      "val loss:\t 0.030727228\n",
      "epoch: 11:  iteration: 3021:\t loss: 0.02186768501996994\n",
      "epoch: 11:  iteration: 3041:\t loss: 0.03460415452718735\n",
      "epoch: 11:  iteration: 3061:\t loss: 0.02038416638970375\n",
      "epoch: 11:  iteration: 3081:\t loss: 0.06042427942156792\n",
      "epoch: 11:  iteration: 3101:\t loss: 0.027930350974202156\n",
      "val loss:\t 0.042284474\n",
      "epoch: 11:  iteration: 3121:\t loss: 0.03743775933980942\n",
      "epoch: 11:  iteration: 3141:\t loss: 0.018673667684197426\n",
      "epoch: 11:  iteration: 3161:\t loss: 0.026713132858276367\n",
      "epoch: 11:  iteration: 3181:\t loss: 0.018338168039917946\n",
      "epoch: 11:  iteration: 3201:\t loss: 0.020503569394350052\n",
      "val loss:\t 0.020395556\n",
      "epoch: 11:  iteration: 3221:\t loss: 0.022562701255083084\n",
      "epoch: 11:  iteration: 3241:\t loss: 0.03759223222732544\n",
      "epoch: 11:  iteration: 3261:\t loss: 0.045449499040842056\n",
      "epoch: 11:  iteration: 3281:\t loss: 0.023432008922100067\n",
      "epoch: 11:  iteration: 3301:\t loss: 0.021161522716283798\n",
      "val loss:\t 0.03995817\n",
      "epoch: 11:  iteration: 3321:\t loss: 0.025808190926909447\n",
      "epoch: 11:  iteration: 3341:\t loss: 0.023063957691192627\n",
      "epoch: 11:  iteration: 3361:\t loss: 0.034778617322444916\n",
      "epoch: 11:  iteration: 3381:\t loss: 0.01605738140642643\n",
      "epoch: 11:  iteration: 3401:\t loss: 0.01702139526605606\n",
      "val loss:\t 0.03443075\n",
      "epoch: 11:  iteration: 3421:\t loss: 0.04177805036306381\n",
      "epoch: 11:  iteration: 3441:\t loss: 0.04654423147439957\n",
      "epoch: 11:  iteration: 3461:\t loss: 0.0180419459939003\n",
      "epoch: 11:  iteration: 3481:\t loss: 0.026356859132647514\n",
      "epoch: 11:  iteration: 3501:\t loss: 0.017965227365493774\n",
      "val loss:\t 0.042887084\n",
      "epoch: 11:  iteration: 3521:\t loss: 0.031094606965780258\n",
      "epoch: 11:  iteration: 3541:\t loss: 0.025380585342645645\n",
      "epoch: 11:  iteration: 3561:\t loss: 0.0322810634970665\n",
      "epoch: 11:  iteration: 3581:\t loss: 0.050307005643844604\n",
      "epoch: 11:  iteration: 3601:\t loss: 0.014766920357942581\n",
      "val loss:\t 0.052595366\n",
      "epoch: 11:  iteration: 3621:\t loss: 0.02018751949071884\n",
      "epoch: 11:  iteration: 3641:\t loss: 0.031104842200875282\n",
      "epoch: 11:  iteration: 3661:\t loss: 0.021368052810430527\n",
      "epoch: 11:  iteration: 3681:\t loss: 0.02331922948360443\n",
      "epoch: 11:  iteration: 3701:\t loss: 0.03508614003658295\n",
      "val loss:\t 0.069727734\n",
      "epoch: 11:  iteration: 3721:\t loss: 0.028063815087080002\n",
      "epoch: 11:  iteration: 3741:\t loss: 0.017115961760282516\n",
      "epoch: 11:  iteration: 3761:\t loss: 0.05064725875854492\n",
      "epoch: 11:  iteration: 3781:\t loss: 0.01699625700712204\n",
      "epoch: 11:  iteration: 3801:\t loss: 0.030119763687253\n",
      "val loss:\t 0.01724901\n",
      "EarlyStopping counter: 2 out of 6\n",
      "----------------epoch end--------------------- 10\n",
      "|loss_train| 0.00021373032359406352\n",
      "|loss_test| 0.007888220250606537\n",
      "epoch: 12:  iteration: 1:\t loss: 0.07199731469154358\n",
      "val loss:\t 0.022380404\n",
      "epoch: 12:  iteration: 21:\t loss: 0.014109181240200996\n",
      "epoch: 12:  iteration: 41:\t loss: 0.0307401642203331\n",
      "epoch: 12:  iteration: 61:\t loss: 0.014802678488194942\n",
      "epoch: 12:  iteration: 81:\t loss: 0.06598327308893204\n",
      "epoch: 12:  iteration: 101:\t loss: 0.01906188763678074\n",
      "val loss:\t 0.035314996\n",
      "epoch: 12:  iteration: 121:\t loss: 0.03502777963876724\n",
      "epoch: 12:  iteration: 141:\t loss: 0.031129684299230576\n",
      "epoch: 12:  iteration: 161:\t loss: 0.022611573338508606\n",
      "epoch: 12:  iteration: 181:\t loss: 0.04185526445508003\n",
      "epoch: 12:  iteration: 201:\t loss: 0.02281789481639862\n",
      "val loss:\t 0.044045016\n",
      "epoch: 12:  iteration: 221:\t loss: 0.024381741881370544\n",
      "epoch: 12:  iteration: 241:\t loss: 0.020061703398823738\n",
      "epoch: 12:  iteration: 261:\t loss: 0.02857111394405365\n",
      "epoch: 12:  iteration: 281:\t loss: 0.0563393272459507\n",
      "epoch: 12:  iteration: 301:\t loss: 0.04065097123384476\n",
      "val loss:\t 0.024182813\n",
      "epoch: 12:  iteration: 321:\t loss: 0.020320523530244827\n",
      "epoch: 12:  iteration: 341:\t loss: 0.04258980602025986\n",
      "epoch: 12:  iteration: 361:\t loss: 0.031920790672302246\n",
      "epoch: 12:  iteration: 381:\t loss: 0.023694369941949844\n",
      "epoch: 12:  iteration: 401:\t loss: 0.020011937245726585\n",
      "val loss:\t 0.04142814\n",
      "epoch: 12:  iteration: 421:\t loss: 0.013452071696519852\n",
      "epoch: 12:  iteration: 441:\t loss: 0.01926177367568016\n",
      "epoch: 12:  iteration: 461:\t loss: 0.01862078532576561\n",
      "epoch: 12:  iteration: 481:\t loss: 0.016799140721559525\n",
      "epoch: 12:  iteration: 501:\t loss: 0.023795586079359055\n",
      "val loss:\t 0.01931802\n",
      "epoch: 12:  iteration: 521:\t loss: 0.021264279261231422\n",
      "epoch: 12:  iteration: 541:\t loss: 0.04088733345270157\n",
      "epoch: 12:  iteration: 561:\t loss: 0.03593128174543381\n",
      "epoch: 12:  iteration: 581:\t loss: 0.03909319266676903\n",
      "epoch: 12:  iteration: 601:\t loss: 0.049250420182943344\n",
      "val loss:\t 0.021804636\n",
      "epoch: 12:  iteration: 621:\t loss: 0.04821108654141426\n",
      "epoch: 12:  iteration: 641:\t loss: 0.027877356857061386\n",
      "epoch: 12:  iteration: 661:\t loss: 0.02548699639737606\n",
      "epoch: 12:  iteration: 681:\t loss: 0.019510244950652122\n",
      "epoch: 12:  iteration: 701:\t loss: 0.01907971501350403\n",
      "val loss:\t 0.018619595\n",
      "epoch: 12:  iteration: 721:\t loss: 0.026340000331401825\n",
      "epoch: 12:  iteration: 741:\t loss: 0.01957414299249649\n",
      "epoch: 12:  iteration: 761:\t loss: 0.019496532157063484\n",
      "epoch: 12:  iteration: 781:\t loss: 0.03230724483728409\n",
      "epoch: 12:  iteration: 801:\t loss: 0.021404806524515152\n",
      "val loss:\t 0.023916602\n",
      "epoch: 12:  iteration: 821:\t loss: 0.016227971762418747\n",
      "epoch: 12:  iteration: 841:\t loss: 0.02423059567809105\n",
      "epoch: 12:  iteration: 861:\t loss: 0.025614969432353973\n",
      "epoch: 12:  iteration: 881:\t loss: 0.027908585965633392\n",
      "epoch: 12:  iteration: 901:\t loss: 0.039659641683101654\n",
      "val loss:\t 0.018142745\n",
      "epoch: 12:  iteration: 921:\t loss: 0.024514593183994293\n",
      "epoch: 12:  iteration: 941:\t loss: 0.017923172563314438\n",
      "epoch: 12:  iteration: 961:\t loss: 0.025101326406002045\n",
      "epoch: 12:  iteration: 981:\t loss: 0.02487376146018505\n",
      "epoch: 12:  iteration: 1001:\t loss: 0.02577844075858593\n",
      "val loss:\t 0.029445013\n",
      "epoch: 12:  iteration: 1021:\t loss: 0.020300569012761116\n",
      "epoch: 12:  iteration: 1041:\t loss: 0.025234907865524292\n",
      "epoch: 12:  iteration: 1061:\t loss: 0.05095961317420006\n",
      "epoch: 12:  iteration: 1081:\t loss: 0.01832421123981476\n",
      "epoch: 12:  iteration: 1101:\t loss: 0.014376876875758171\n",
      "val loss:\t 0.037581805\n",
      "epoch: 12:  iteration: 1121:\t loss: 0.030177857726812363\n",
      "epoch: 12:  iteration: 1141:\t loss: 0.022856129333376884\n",
      "epoch: 12:  iteration: 1161:\t loss: 0.09243344515562057\n",
      "epoch: 12:  iteration: 1181:\t loss: 0.03314640372991562\n",
      "epoch: 12:  iteration: 1201:\t loss: 0.02949254959821701\n",
      "val loss:\t 0.019185677\n",
      "epoch: 12:  iteration: 1221:\t loss: 0.033760156482458115\n",
      "epoch: 12:  iteration: 1241:\t loss: 0.0369701087474823\n",
      "epoch: 12:  iteration: 1261:\t loss: 0.01378658227622509\n",
      "epoch: 12:  iteration: 1281:\t loss: 0.02132451720535755\n",
      "epoch: 12:  iteration: 1301:\t loss: 0.01674279198050499\n",
      "val loss:\t 0.03807722\n",
      "epoch: 12:  iteration: 1321:\t loss: 0.02394019067287445\n",
      "epoch: 12:  iteration: 1341:\t loss: 0.01611749827861786\n",
      "epoch: 12:  iteration: 1361:\t loss: 0.010883977636694908\n",
      "epoch: 12:  iteration: 1381:\t loss: 0.03789181262254715\n",
      "epoch: 12:  iteration: 1401:\t loss: 0.015014175325632095\n",
      "val loss:\t 0.01921987\n",
      "epoch: 12:  iteration: 1421:\t loss: 0.045411959290504456\n",
      "epoch: 12:  iteration: 1441:\t loss: 0.024868857115507126\n",
      "epoch: 12:  iteration: 1461:\t loss: 0.016170606017112732\n",
      "epoch: 12:  iteration: 1481:\t loss: 0.030275367200374603\n",
      "epoch: 12:  iteration: 1501:\t loss: 0.02500879392027855\n",
      "val loss:\t 0.033059254\n",
      "epoch: 12:  iteration: 1521:\t loss: 0.043497391045093536\n",
      "epoch: 12:  iteration: 1541:\t loss: 0.021367240697145462\n",
      "epoch: 12:  iteration: 1561:\t loss: 0.025519710034132004\n",
      "epoch: 12:  iteration: 1581:\t loss: 0.020997414365410805\n",
      "epoch: 12:  iteration: 1601:\t loss: 0.01973549649119377\n",
      "val loss:\t 0.029349707\n",
      "epoch: 12:  iteration: 1621:\t loss: 0.0211397185921669\n",
      "epoch: 12:  iteration: 1641:\t loss: 0.017005300149321556\n",
      "epoch: 12:  iteration: 1661:\t loss: 0.03220941126346588\n",
      "epoch: 12:  iteration: 1681:\t loss: 0.02993040904402733\n",
      "epoch: 12:  iteration: 1701:\t loss: 0.021652013063430786\n",
      "val loss:\t 0.021869991\n",
      "epoch: 12:  iteration: 1721:\t loss: 0.018622709438204765\n",
      "epoch: 12:  iteration: 1741:\t loss: 0.028194712474942207\n",
      "epoch: 12:  iteration: 1761:\t loss: 0.04878966882824898\n",
      "epoch: 12:  iteration: 1781:\t loss: 0.041154906153678894\n",
      "epoch: 12:  iteration: 1801:\t loss: 0.018921008333563805\n",
      "val loss:\t 0.024599357\n",
      "epoch: 12:  iteration: 1821:\t loss: 0.035034433007240295\n",
      "epoch: 12:  iteration: 1841:\t loss: 0.04451644420623779\n",
      "epoch: 12:  iteration: 1861:\t loss: 0.023473598062992096\n",
      "epoch: 12:  iteration: 1881:\t loss: 0.01658882386982441\n",
      "epoch: 12:  iteration: 1901:\t loss: 0.02327963337302208\n",
      "val loss:\t 0.01788791\n",
      "epoch: 12:  iteration: 1921:\t loss: 0.027673933655023575\n",
      "epoch: 12:  iteration: 1941:\t loss: 0.014650898054242134\n",
      "epoch: 12:  iteration: 1961:\t loss: 0.014595701359212399\n",
      "epoch: 12:  iteration: 1981:\t loss: 0.06206412613391876\n",
      "epoch: 12:  iteration: 2001:\t loss: 0.026392094790935516\n",
      "val loss:\t 0.02582594\n",
      "epoch: 12:  iteration: 2021:\t loss: 0.026408985257148743\n",
      "epoch: 12:  iteration: 2041:\t loss: 0.02236221730709076\n",
      "epoch: 12:  iteration: 2061:\t loss: 0.020597215741872787\n",
      "epoch: 12:  iteration: 2081:\t loss: 0.029174335300922394\n",
      "epoch: 12:  iteration: 2101:\t loss: 0.025704775005578995\n",
      "val loss:\t 0.026060866\n",
      "epoch: 12:  iteration: 2121:\t loss: 0.017283476889133453\n",
      "epoch: 12:  iteration: 2141:\t loss: 0.024016769602894783\n",
      "epoch: 12:  iteration: 2161:\t loss: 0.024556415155529976\n",
      "epoch: 12:  iteration: 2181:\t loss: 0.01531338132917881\n",
      "epoch: 12:  iteration: 2201:\t loss: 0.019985999912023544\n",
      "val loss:\t 0.024525128\n",
      "epoch: 12:  iteration: 2221:\t loss: 0.02079516462981701\n",
      "epoch: 12:  iteration: 2241:\t loss: 0.023592879995703697\n",
      "epoch: 12:  iteration: 2261:\t loss: 0.01968155801296234\n",
      "epoch: 12:  iteration: 2281:\t loss: 0.02192574180662632\n",
      "epoch: 12:  iteration: 2301:\t loss: 0.02078922465443611\n",
      "val loss:\t 0.03325288\n",
      "epoch: 12:  iteration: 2321:\t loss: 0.01702965423464775\n",
      "epoch: 12:  iteration: 2341:\t loss: 0.04992649331688881\n",
      "epoch: 12:  iteration: 2361:\t loss: 0.024906989187002182\n",
      "epoch: 12:  iteration: 2381:\t loss: 0.031100384891033173\n",
      "epoch: 12:  iteration: 2401:\t loss: 0.028249267488718033\n",
      "val loss:\t 0.018978924\n",
      "epoch: 12:  iteration: 2421:\t loss: 0.020514190196990967\n",
      "epoch: 12:  iteration: 2441:\t loss: 0.028757646679878235\n",
      "epoch: 12:  iteration: 2461:\t loss: 0.04812183976173401\n",
      "epoch: 12:  iteration: 2481:\t loss: 0.020167948678135872\n",
      "epoch: 12:  iteration: 2501:\t loss: 0.029279407113790512\n",
      "val loss:\t 0.021910023\n",
      "epoch: 12:  iteration: 2521:\t loss: 0.043866097927093506\n",
      "epoch: 12:  iteration: 2541:\t loss: 0.015507069416344166\n",
      "epoch: 12:  iteration: 2561:\t loss: 0.05108759552240372\n",
      "epoch: 12:  iteration: 2581:\t loss: 0.022226693108677864\n",
      "epoch: 12:  iteration: 2601:\t loss: 0.03276122733950615\n",
      "val loss:\t 0.023847457\n",
      "epoch: 12:  iteration: 2621:\t loss: 0.03590729087591171\n",
      "epoch: 12:  iteration: 2641:\t loss: 0.030105266720056534\n",
      "epoch: 12:  iteration: 2661:\t loss: 0.036737628281116486\n",
      "epoch: 12:  iteration: 2681:\t loss: 0.048928115516901016\n",
      "epoch: 12:  iteration: 2701:\t loss: 0.4451235234737396\n",
      "val loss:\t 0.03683713\n",
      "epoch: 12:  iteration: 2721:\t loss: 0.09684301912784576\n",
      "epoch: 12:  iteration: 2741:\t loss: 0.02902763895690441\n",
      "epoch: 12:  iteration: 2761:\t loss: 0.036099255084991455\n",
      "epoch: 12:  iteration: 2781:\t loss: 0.017287563532590866\n",
      "epoch: 12:  iteration: 2801:\t loss: 0.022511713206768036\n",
      "val loss:\t 0.03418633\n",
      "epoch: 12:  iteration: 2821:\t loss: 0.018543722108006477\n",
      "epoch: 12:  iteration: 2841:\t loss: 0.019063621759414673\n",
      "epoch: 12:  iteration: 2861:\t loss: 0.0361664742231369\n",
      "epoch: 12:  iteration: 2881:\t loss: 0.01925765722990036\n",
      "epoch: 12:  iteration: 2901:\t loss: 0.04105132445693016\n",
      "val loss:\t 0.027760074\n",
      "epoch: 12:  iteration: 2921:\t loss: 0.03453904017806053\n",
      "epoch: 12:  iteration: 2941:\t loss: 0.014382774010300636\n",
      "epoch: 12:  iteration: 2961:\t loss: 0.03354974091053009\n",
      "epoch: 12:  iteration: 2981:\t loss: 0.06291419267654419\n",
      "epoch: 12:  iteration: 3001:\t loss: 0.023008376359939575\n",
      "val loss:\t 0.1408668\n",
      "epoch: 12:  iteration: 3021:\t loss: 0.04442849010229111\n",
      "epoch: 12:  iteration: 3041:\t loss: 0.028897076845169067\n",
      "epoch: 12:  iteration: 3061:\t loss: 0.019024701789021492\n",
      "epoch: 12:  iteration: 3081:\t loss: 0.02919721230864525\n",
      "epoch: 12:  iteration: 3101:\t loss: 0.018487144261598587\n",
      "val loss:\t 0.020757256\n",
      "epoch: 12:  iteration: 3121:\t loss: 0.028523536399006844\n",
      "epoch: 12:  iteration: 3141:\t loss: 0.028541982173919678\n",
      "epoch: 12:  iteration: 3161:\t loss: 0.019392121583223343\n",
      "epoch: 12:  iteration: 3181:\t loss: 0.06740589439868927\n",
      "epoch: 12:  iteration: 3201:\t loss: 0.01633668690919876\n",
      "val loss:\t 0.031922083\n",
      "epoch: 12:  iteration: 3221:\t loss: 0.05859382450580597\n",
      "epoch: 12:  iteration: 3241:\t loss: 0.017014697194099426\n",
      "epoch: 12:  iteration: 3261:\t loss: 0.016400286927819252\n",
      "epoch: 12:  iteration: 3281:\t loss: 0.02074083685874939\n",
      "epoch: 12:  iteration: 3301:\t loss: 0.035887882113456726\n",
      "val loss:\t 0.017618097\n",
      "epoch: 12:  iteration: 3321:\t loss: 0.02981751412153244\n",
      "epoch: 12:  iteration: 3341:\t loss: 0.016960930079221725\n",
      "epoch: 12:  iteration: 3361:\t loss: 0.04550056904554367\n",
      "epoch: 12:  iteration: 3381:\t loss: 0.024224722757935524\n",
      "epoch: 12:  iteration: 3401:\t loss: 0.03389294445514679\n",
      "val loss:\t 0.023461785\n",
      "epoch: 12:  iteration: 3421:\t loss: 0.05784401297569275\n",
      "epoch: 12:  iteration: 3441:\t loss: 0.025851311162114143\n",
      "epoch: 12:  iteration: 3461:\t loss: 0.0192152988165617\n",
      "epoch: 12:  iteration: 3481:\t loss: 0.05377791076898575\n",
      "epoch: 12:  iteration: 3501:\t loss: 0.019634805619716644\n",
      "val loss:\t 0.016477033\n",
      "epoch: 12:  iteration: 3521:\t loss: 0.0338594913482666\n",
      "epoch: 12:  iteration: 3541:\t loss: 0.037613626569509506\n",
      "epoch: 12:  iteration: 3561:\t loss: 0.03419375419616699\n",
      "epoch: 12:  iteration: 3581:\t loss: 0.019649319350719452\n",
      "epoch: 12:  iteration: 3601:\t loss: 0.03328971564769745\n",
      "val loss:\t 0.024188831\n",
      "epoch: 12:  iteration: 3621:\t loss: 0.02299332246184349\n",
      "epoch: 12:  iteration: 3641:\t loss: 0.024089526385068893\n",
      "epoch: 12:  iteration: 3661:\t loss: 0.0316280722618103\n",
      "epoch: 12:  iteration: 3681:\t loss: 0.02129402384161949\n",
      "epoch: 12:  iteration: 3701:\t loss: 0.029536781832575798\n",
      "val loss:\t 0.04250806\n",
      "epoch: 12:  iteration: 3721:\t loss: 0.01905905082821846\n",
      "epoch: 12:  iteration: 3741:\t loss: 0.023927751928567886\n",
      "epoch: 12:  iteration: 3761:\t loss: 0.02339998632669449\n",
      "epoch: 12:  iteration: 3781:\t loss: 0.017567357048392296\n",
      "epoch: 12:  iteration: 3801:\t loss: 0.0066681415773928165\n",
      "val loss:\t 0.02221263\n",
      "EarlyStopping counter: 3 out of 6\n",
      "----------------epoch end--------------------- 11\n",
      "|loss_train| 2.856982064258773e-05\n",
      "|loss_test| 0.007883191108703613\n",
      "epoch: 13:  iteration: 1:\t loss: 0.040819201618433\n",
      "val loss:\t 0.02830249\n",
      "epoch: 13:  iteration: 21:\t loss: 0.019930902868509293\n",
      "epoch: 13:  iteration: 41:\t loss: 0.025693126022815704\n",
      "epoch: 13:  iteration: 61:\t loss: 0.023230314254760742\n",
      "epoch: 13:  iteration: 81:\t loss: 0.020747851580381393\n",
      "epoch: 13:  iteration: 101:\t loss: 0.026873115450143814\n",
      "val loss:\t 0.021088704\n",
      "epoch: 13:  iteration: 121:\t loss: 0.01476904097944498\n",
      "epoch: 13:  iteration: 141:\t loss: 0.01927335187792778\n",
      "epoch: 13:  iteration: 161:\t loss: 0.01420634239912033\n",
      "epoch: 13:  iteration: 181:\t loss: 0.0317307785153389\n",
      "epoch: 13:  iteration: 201:\t loss: 0.029570577666163445\n",
      "val loss:\t 0.027723096\n",
      "epoch: 13:  iteration: 221:\t loss: 0.028421424329280853\n",
      "epoch: 13:  iteration: 241:\t loss: 0.04270840436220169\n",
      "epoch: 13:  iteration: 261:\t loss: 0.017260760068893433\n",
      "epoch: 13:  iteration: 281:\t loss: 0.016588641330599785\n",
      "epoch: 13:  iteration: 301:\t loss: 0.016256552189588547\n",
      "val loss:\t 0.022521086\n",
      "epoch: 13:  iteration: 321:\t loss: 0.031814124435186386\n",
      "epoch: 13:  iteration: 341:\t loss: 0.015947772189974785\n",
      "epoch: 13:  iteration: 361:\t loss: 0.021529221907258034\n",
      "epoch: 13:  iteration: 381:\t loss: 0.03064252808690071\n",
      "epoch: 13:  iteration: 401:\t loss: 0.01915622688829899\n",
      "val loss:\t 0.05153846\n",
      "epoch: 13:  iteration: 421:\t loss: 0.02038254588842392\n",
      "epoch: 13:  iteration: 441:\t loss: 0.0403955839574337\n",
      "epoch: 13:  iteration: 461:\t loss: 0.01775399222970009\n",
      "epoch: 13:  iteration: 481:\t loss: 0.018363885581493378\n",
      "epoch: 13:  iteration: 501:\t loss: 0.015010049566626549\n",
      "val loss:\t 0.020515269\n",
      "epoch: 13:  iteration: 521:\t loss: 0.024195771664381027\n",
      "epoch: 13:  iteration: 541:\t loss: 0.03785756230354309\n",
      "epoch: 13:  iteration: 561:\t loss: 0.023032043129205704\n",
      "epoch: 13:  iteration: 581:\t loss: 0.026309248059988022\n",
      "epoch: 13:  iteration: 601:\t loss: 0.022898247465491295\n",
      "val loss:\t 0.015463052\n",
      "epoch: 13:  iteration: 621:\t loss: 0.02045673131942749\n",
      "epoch: 13:  iteration: 641:\t loss: 0.035671819001436234\n",
      "epoch: 13:  iteration: 661:\t loss: 0.026473361998796463\n",
      "epoch: 13:  iteration: 681:\t loss: 0.01673213019967079\n",
      "epoch: 13:  iteration: 701:\t loss: 0.024386605247855186\n",
      "val loss:\t 0.030988779\n",
      "epoch: 13:  iteration: 721:\t loss: 0.06399217993021011\n",
      "epoch: 13:  iteration: 741:\t loss: 0.01619526371359825\n",
      "epoch: 13:  iteration: 761:\t loss: 0.016674775630235672\n",
      "epoch: 13:  iteration: 781:\t loss: 0.034779712557792664\n",
      "epoch: 13:  iteration: 801:\t loss: 0.02565799653530121\n",
      "val loss:\t 0.017848104\n",
      "epoch: 13:  iteration: 821:\t loss: 0.022644178941845894\n",
      "epoch: 13:  iteration: 841:\t loss: 0.013616004027426243\n",
      "epoch: 13:  iteration: 861:\t loss: 0.03964047133922577\n",
      "epoch: 13:  iteration: 881:\t loss: 0.024956047534942627\n",
      "epoch: 13:  iteration: 901:\t loss: 0.03199903666973114\n",
      "val loss:\t 0.023937233\n",
      "epoch: 13:  iteration: 921:\t loss: 0.0211680568754673\n",
      "epoch: 13:  iteration: 941:\t loss: 0.019369065761566162\n",
      "epoch: 13:  iteration: 961:\t loss: 0.01844477280974388\n",
      "epoch: 13:  iteration: 981:\t loss: 0.028252460062503815\n",
      "epoch: 13:  iteration: 1001:\t loss: 0.022948680445551872\n",
      "val loss:\t 0.025578959\n",
      "epoch: 13:  iteration: 1021:\t loss: 0.02740657888352871\n",
      "epoch: 13:  iteration: 1041:\t loss: 0.02167239412665367\n",
      "epoch: 13:  iteration: 1061:\t loss: 0.02694336697459221\n",
      "epoch: 13:  iteration: 1081:\t loss: 0.06434010714292526\n",
      "epoch: 13:  iteration: 1101:\t loss: 0.013090109452605247\n",
      "val loss:\t 0.036046088\n",
      "epoch: 13:  iteration: 1121:\t loss: 0.038527339696884155\n",
      "epoch: 13:  iteration: 1141:\t loss: 0.023529808968305588\n",
      "epoch: 13:  iteration: 1161:\t loss: 0.0339478962123394\n",
      "epoch: 13:  iteration: 1181:\t loss: 0.027272365987300873\n",
      "epoch: 13:  iteration: 1201:\t loss: 0.026768382638692856\n",
      "val loss:\t 0.019687466\n",
      "epoch: 13:  iteration: 1221:\t loss: 0.0321236178278923\n",
      "epoch: 13:  iteration: 1241:\t loss: 0.05667638033628464\n",
      "epoch: 13:  iteration: 1261:\t loss: 0.053053997457027435\n",
      "epoch: 13:  iteration: 1281:\t loss: 0.018114065751433372\n",
      "epoch: 13:  iteration: 1301:\t loss: 0.02041824907064438\n",
      "val loss:\t 0.017346328\n",
      "epoch: 13:  iteration: 1321:\t loss: 0.018394287675619125\n",
      "epoch: 13:  iteration: 1341:\t loss: 0.024510571733117104\n",
      "epoch: 13:  iteration: 1361:\t loss: 0.033908773213624954\n",
      "epoch: 13:  iteration: 1381:\t loss: 0.07176848500967026\n",
      "epoch: 13:  iteration: 1401:\t loss: 0.01937679760158062\n",
      "val loss:\t 0.024836026\n",
      "epoch: 13:  iteration: 1421:\t loss: 0.02002498134970665\n",
      "epoch: 13:  iteration: 1441:\t loss: 0.014844989404082298\n",
      "epoch: 13:  iteration: 1461:\t loss: 0.01947907730937004\n",
      "epoch: 13:  iteration: 1481:\t loss: 0.045931488275527954\n",
      "epoch: 13:  iteration: 1501:\t loss: 0.02800321765244007\n",
      "val loss:\t 0.027004728\n",
      "epoch: 13:  iteration: 1521:\t loss: 0.039393410086631775\n",
      "epoch: 13:  iteration: 1541:\t loss: 0.016259819269180298\n",
      "epoch: 13:  iteration: 1561:\t loss: 0.04365217685699463\n",
      "epoch: 13:  iteration: 1581:\t loss: 0.016212385147809982\n",
      "epoch: 13:  iteration: 1601:\t loss: 0.024304542690515518\n",
      "val loss:\t 0.023269344\n",
      "epoch: 13:  iteration: 1621:\t loss: 0.06454413384199142\n",
      "epoch: 13:  iteration: 1641:\t loss: 0.03014911524951458\n",
      "epoch: 13:  iteration: 1661:\t loss: 0.04262254387140274\n",
      "epoch: 13:  iteration: 1681:\t loss: 0.021319087594747543\n",
      "epoch: 13:  iteration: 1701:\t loss: 0.027243856340646744\n",
      "val loss:\t 0.023721557\n",
      "epoch: 13:  iteration: 1721:\t loss: 0.0209871344268322\n",
      "epoch: 13:  iteration: 1741:\t loss: 0.02599310874938965\n",
      "epoch: 13:  iteration: 1761:\t loss: 0.04300308600068092\n",
      "epoch: 13:  iteration: 1781:\t loss: 0.01786443218588829\n",
      "epoch: 13:  iteration: 1801:\t loss: 0.03149209916591644\n",
      "val loss:\t 0.020669557\n",
      "epoch: 13:  iteration: 1821:\t loss: 0.07198178023099899\n",
      "epoch: 13:  iteration: 1841:\t loss: 0.024092629551887512\n",
      "epoch: 13:  iteration: 1861:\t loss: 0.03081914782524109\n",
      "epoch: 13:  iteration: 1881:\t loss: 0.031668175011873245\n",
      "epoch: 13:  iteration: 1901:\t loss: 0.01621345616877079\n",
      "val loss:\t 0.018663831\n",
      "epoch: 13:  iteration: 1921:\t loss: 0.016598660498857498\n",
      "epoch: 13:  iteration: 1941:\t loss: 0.04899487644433975\n",
      "epoch: 13:  iteration: 1961:\t loss: 0.02155405282974243\n",
      "epoch: 13:  iteration: 1981:\t loss: 0.020951047539711\n",
      "epoch: 13:  iteration: 2001:\t loss: 0.020768238231539726\n",
      "val loss:\t 0.034910597\n",
      "epoch: 13:  iteration: 2021:\t loss: 0.05829254537820816\n",
      "epoch: 13:  iteration: 2041:\t loss: 0.025978881865739822\n",
      "epoch: 13:  iteration: 2061:\t loss: 0.04948396980762482\n",
      "epoch: 13:  iteration: 2081:\t loss: 0.06695525348186493\n",
      "epoch: 13:  iteration: 2101:\t loss: 0.017358023673295975\n",
      "val loss:\t 0.02669197\n",
      "epoch: 13:  iteration: 2121:\t loss: 0.0338522233068943\n",
      "epoch: 13:  iteration: 2141:\t loss: 0.02124093472957611\n",
      "epoch: 13:  iteration: 2161:\t loss: 0.05715346708893776\n",
      "epoch: 13:  iteration: 2181:\t loss: 0.020551754161715508\n",
      "epoch: 13:  iteration: 2201:\t loss: 0.01734977588057518\n",
      "val loss:\t 0.025613083\n",
      "epoch: 13:  iteration: 2221:\t loss: 0.023329677060246468\n",
      "epoch: 13:  iteration: 2241:\t loss: 0.0331965908408165\n",
      "epoch: 13:  iteration: 2261:\t loss: 0.028225015848875046\n",
      "epoch: 13:  iteration: 2281:\t loss: 0.03800683468580246\n",
      "epoch: 13:  iteration: 2301:\t loss: 0.020204365253448486\n",
      "val loss:\t 0.020012906\n",
      "epoch: 13:  iteration: 2321:\t loss: 0.02887888438999653\n",
      "epoch: 13:  iteration: 2341:\t loss: 0.015035288408398628\n",
      "epoch: 13:  iteration: 2361:\t loss: 0.04090645909309387\n",
      "epoch: 13:  iteration: 2381:\t loss: 0.018973948433995247\n",
      "epoch: 13:  iteration: 2401:\t loss: 0.05583985149860382\n",
      "val loss:\t 0.019960035\n",
      "epoch: 13:  iteration: 2421:\t loss: 0.045637890696525574\n",
      "epoch: 13:  iteration: 2441:\t loss: 0.016270073130726814\n",
      "epoch: 13:  iteration: 2461:\t loss: 0.03668571263551712\n",
      "epoch: 13:  iteration: 2481:\t loss: 0.023260189220309258\n",
      "epoch: 13:  iteration: 2501:\t loss: 0.020091108977794647\n",
      "val loss:\t 0.03678765\n",
      "epoch: 13:  iteration: 2521:\t loss: 0.0373106449842453\n",
      "epoch: 13:  iteration: 2541:\t loss: 0.02931119129061699\n",
      "epoch: 13:  iteration: 2561:\t loss: 0.015253174118697643\n",
      "epoch: 13:  iteration: 2581:\t loss: 0.1130388155579567\n",
      "epoch: 13:  iteration: 2601:\t loss: 0.01861177757382393\n",
      "val loss:\t 0.04285361\n",
      "epoch: 13:  iteration: 2621:\t loss: 0.045131854712963104\n",
      "epoch: 13:  iteration: 2641:\t loss: 0.29433679580688477\n",
      "epoch: 13:  iteration: 2661:\t loss: 0.02647656947374344\n",
      "epoch: 13:  iteration: 2681:\t loss: 0.026530606672167778\n",
      "epoch: 13:  iteration: 2701:\t loss: 0.021842125803232193\n",
      "val loss:\t 0.037994005\n",
      "epoch: 13:  iteration: 2721:\t loss: 0.033002499490976334\n",
      "epoch: 13:  iteration: 2741:\t loss: 0.0161973275244236\n",
      "epoch: 13:  iteration: 2761:\t loss: 0.016655053943395615\n",
      "epoch: 13:  iteration: 2781:\t loss: 0.03397968411445618\n",
      "epoch: 13:  iteration: 2801:\t loss: 0.02354666218161583\n",
      "val loss:\t 0.01595036\n",
      "epoch: 13:  iteration: 2821:\t loss: 0.016555901616811752\n",
      "epoch: 13:  iteration: 2841:\t loss: 0.016088202595710754\n",
      "epoch: 13:  iteration: 2861:\t loss: 0.06445495784282684\n",
      "epoch: 13:  iteration: 2881:\t loss: 0.027976129204034805\n",
      "epoch: 13:  iteration: 2901:\t loss: 0.021242797374725342\n",
      "val loss:\t 0.03181111\n",
      "epoch: 13:  iteration: 2921:\t loss: 0.02585511840879917\n",
      "epoch: 13:  iteration: 2941:\t loss: 0.019105706363916397\n",
      "epoch: 13:  iteration: 2961:\t loss: 0.016256624832749367\n",
      "epoch: 13:  iteration: 2981:\t loss: 0.01569797843694687\n",
      "epoch: 13:  iteration: 3001:\t loss: 0.046020857989788055\n",
      "val loss:\t 0.014098322\n",
      "epoch: 13:  iteration: 3021:\t loss: 0.01260343287140131\n",
      "epoch: 13:  iteration: 3041:\t loss: 0.06852052360773087\n",
      "epoch: 13:  iteration: 3061:\t loss: 0.026915889233350754\n",
      "epoch: 13:  iteration: 3081:\t loss: 0.045666102319955826\n",
      "epoch: 13:  iteration: 3101:\t loss: 0.033126384019851685\n",
      "val loss:\t 0.06511527\n",
      "epoch: 13:  iteration: 3121:\t loss: 0.04340028762817383\n",
      "epoch: 13:  iteration: 3141:\t loss: 0.02084435522556305\n",
      "epoch: 13:  iteration: 3161:\t loss: 0.040647197514772415\n",
      "epoch: 13:  iteration: 3181:\t loss: 0.038389068096876144\n",
      "epoch: 13:  iteration: 3201:\t loss: 0.04741952568292618\n",
      "val loss:\t 0.02477777\n",
      "epoch: 13:  iteration: 3221:\t loss: 0.02516120672225952\n",
      "epoch: 13:  iteration: 3241:\t loss: 0.022367868572473526\n",
      "epoch: 13:  iteration: 3261:\t loss: 0.017592083662748337\n",
      "epoch: 13:  iteration: 3281:\t loss: 0.028846191242337227\n",
      "epoch: 13:  iteration: 3301:\t loss: 0.026125691831111908\n",
      "val loss:\t 0.019597795\n",
      "epoch: 13:  iteration: 3321:\t loss: 0.024569306522607803\n",
      "epoch: 13:  iteration: 3341:\t loss: 0.02808029018342495\n",
      "epoch: 13:  iteration: 3361:\t loss: 0.025341879576444626\n",
      "epoch: 13:  iteration: 3381:\t loss: 0.020027682185173035\n",
      "epoch: 13:  iteration: 3401:\t loss: 0.05984663963317871\n",
      "val loss:\t 0.030381138\n",
      "epoch: 13:  iteration: 3421:\t loss: 0.014444978907704353\n",
      "epoch: 13:  iteration: 3441:\t loss: 0.02069525048136711\n",
      "epoch: 13:  iteration: 3461:\t loss: 0.014123031869530678\n",
      "epoch: 13:  iteration: 3481:\t loss: 0.02287869155406952\n",
      "epoch: 13:  iteration: 3501:\t loss: 0.033243682235479355\n",
      "val loss:\t 0.031100735\n",
      "epoch: 13:  iteration: 3521:\t loss: 0.020172934979200363\n",
      "epoch: 13:  iteration: 3541:\t loss: 0.037161827087402344\n",
      "epoch: 13:  iteration: 3561:\t loss: 0.01633823662996292\n",
      "epoch: 13:  iteration: 3581:\t loss: 0.06251569092273712\n",
      "epoch: 13:  iteration: 3601:\t loss: 0.017916392534971237\n",
      "val loss:\t 0.02152294\n",
      "epoch: 13:  iteration: 3621:\t loss: 0.5608193874359131\n",
      "epoch: 13:  iteration: 3641:\t loss: 0.02497977390885353\n",
      "epoch: 13:  iteration: 3661:\t loss: 0.016188764944672585\n",
      "epoch: 13:  iteration: 3681:\t loss: 0.03663080185651779\n",
      "epoch: 13:  iteration: 3701:\t loss: 0.030452854931354523\n",
      "val loss:\t 0.015705977\n",
      "epoch: 13:  iteration: 3721:\t loss: 0.01946989633142948\n",
      "epoch: 13:  iteration: 3741:\t loss: 0.023358916863799095\n",
      "epoch: 13:  iteration: 3761:\t loss: 0.01681312546133995\n",
      "epoch: 13:  iteration: 3781:\t loss: 0.04811530560255051\n",
      "epoch: 13:  iteration: 3801:\t loss: 0.028832372277975082\n",
      "val loss:\t 0.023121834\n",
      "EarlyStopping counter: 4 out of 6\n",
      "----------------epoch end--------------------- 12\n",
      "|loss_train| 0.0005118048284202814\n",
      "|loss_test| 0.000532032223418355\n",
      "epoch: 14:  iteration: 1:\t loss: 0.019815539941191673\n",
      "val loss:\t 0.028778415\n",
      "epoch: 14:  iteration: 21:\t loss: 0.02172631025314331\n",
      "epoch: 14:  iteration: 41:\t loss: 0.018374638631939888\n",
      "epoch: 14:  iteration: 61:\t loss: 0.03484637662768364\n",
      "epoch: 14:  iteration: 81:\t loss: 0.018669817596673965\n",
      "epoch: 14:  iteration: 101:\t loss: 0.0891038030385971\n",
      "val loss:\t 0.019812472\n",
      "epoch: 14:  iteration: 121:\t loss: 0.028693364933133125\n",
      "epoch: 14:  iteration: 141:\t loss: 0.025891244411468506\n",
      "epoch: 14:  iteration: 161:\t loss: 0.01834229938685894\n",
      "epoch: 14:  iteration: 181:\t loss: 0.0417533814907074\n",
      "epoch: 14:  iteration: 201:\t loss: 0.015878453850746155\n",
      "val loss:\t 0.017625043\n",
      "epoch: 14:  iteration: 221:\t loss: 0.02113441191613674\n",
      "epoch: 14:  iteration: 241:\t loss: 0.038551315665245056\n",
      "epoch: 14:  iteration: 261:\t loss: 0.020245950669050217\n",
      "epoch: 14:  iteration: 281:\t loss: 0.01917611062526703\n",
      "epoch: 14:  iteration: 301:\t loss: 0.021653201431035995\n",
      "val loss:\t 0.020864418\n",
      "epoch: 14:  iteration: 321:\t loss: 0.013632982969284058\n",
      "epoch: 14:  iteration: 341:\t loss: 0.027634575963020325\n",
      "epoch: 14:  iteration: 361:\t loss: 0.034537702798843384\n",
      "epoch: 14:  iteration: 381:\t loss: 0.02037152089178562\n",
      "epoch: 14:  iteration: 401:\t loss: 0.019254278391599655\n",
      "val loss:\t 0.1254822\n",
      "epoch: 14:  iteration: 421:\t loss: 0.03484305739402771\n",
      "epoch: 14:  iteration: 441:\t loss: 0.017422467470169067\n",
      "epoch: 14:  iteration: 461:\t loss: 0.03411278873682022\n",
      "epoch: 14:  iteration: 481:\t loss: 0.03261524438858032\n",
      "epoch: 14:  iteration: 501:\t loss: 0.024240663275122643\n",
      "val loss:\t 0.021681603\n",
      "epoch: 14:  iteration: 521:\t loss: 0.04011991620063782\n",
      "epoch: 14:  iteration: 541:\t loss: 0.019945455715060234\n",
      "epoch: 14:  iteration: 561:\t loss: 0.021845266222953796\n",
      "epoch: 14:  iteration: 581:\t loss: 0.03362602740526199\n",
      "epoch: 14:  iteration: 601:\t loss: 0.028299419209361076\n",
      "val loss:\t 0.02957204\n",
      "epoch: 14:  iteration: 621:\t loss: 0.029002860188484192\n",
      "epoch: 14:  iteration: 641:\t loss: 0.030371086671948433\n",
      "epoch: 14:  iteration: 661:\t loss: 0.14130069315433502\n",
      "epoch: 14:  iteration: 681:\t loss: 0.05072278901934624\n",
      "epoch: 14:  iteration: 701:\t loss: 0.026961306110024452\n",
      "val loss:\t 0.035272952\n",
      "epoch: 14:  iteration: 721:\t loss: 0.022122863680124283\n",
      "epoch: 14:  iteration: 741:\t loss: 0.02034555934369564\n",
      "epoch: 14:  iteration: 761:\t loss: 0.031689710915088654\n",
      "epoch: 14:  iteration: 781:\t loss: 0.02846439741551876\n",
      "epoch: 14:  iteration: 801:\t loss: 0.02397536300122738\n",
      "val loss:\t 0.019322999\n",
      "epoch: 14:  iteration: 821:\t loss: 0.024808544665575027\n",
      "epoch: 14:  iteration: 841:\t loss: 0.0274264607578516\n",
      "epoch: 14:  iteration: 861:\t loss: 0.020597856491804123\n",
      "epoch: 14:  iteration: 881:\t loss: 0.04121934995055199\n",
      "epoch: 14:  iteration: 901:\t loss: 0.03721803426742554\n",
      "val loss:\t 0.015865741\n",
      "epoch: 14:  iteration: 921:\t loss: 0.016718875616788864\n",
      "epoch: 14:  iteration: 941:\t loss: 0.014942249283194542\n",
      "epoch: 14:  iteration: 961:\t loss: 0.01659082993865013\n",
      "epoch: 14:  iteration: 981:\t loss: 0.03019217774271965\n",
      "epoch: 14:  iteration: 1001:\t loss: 0.03633912280201912\n",
      "val loss:\t 0.02385407\n",
      "epoch: 14:  iteration: 1021:\t loss: 0.019526448100805283\n",
      "epoch: 14:  iteration: 1041:\t loss: 0.027634596452116966\n",
      "epoch: 14:  iteration: 1061:\t loss: 0.019927898421883583\n",
      "epoch: 14:  iteration: 1081:\t loss: 0.013582173734903336\n",
      "epoch: 14:  iteration: 1101:\t loss: 0.015382340177893639\n",
      "val loss:\t 0.025978474\n",
      "epoch: 14:  iteration: 1121:\t loss: 0.02505703829228878\n",
      "epoch: 14:  iteration: 1141:\t loss: 0.028699031099677086\n",
      "epoch: 14:  iteration: 1161:\t loss: 0.019631871953606606\n",
      "epoch: 14:  iteration: 1181:\t loss: 0.4557592272758484\n",
      "epoch: 14:  iteration: 1201:\t loss: 0.02074536308646202\n",
      "val loss:\t 0.035901606\n",
      "epoch: 14:  iteration: 1221:\t loss: 0.017165038734674454\n",
      "epoch: 14:  iteration: 1241:\t loss: 0.019515052437782288\n",
      "epoch: 14:  iteration: 1261:\t loss: 0.022345680743455887\n",
      "epoch: 14:  iteration: 1281:\t loss: 0.03169021010398865\n",
      "epoch: 14:  iteration: 1301:\t loss: 0.020056212320923805\n",
      "val loss:\t 0.02358856\n",
      "epoch: 14:  iteration: 1321:\t loss: 0.038102056831121445\n",
      "epoch: 14:  iteration: 1341:\t loss: 0.024346476420760155\n",
      "epoch: 14:  iteration: 1361:\t loss: 0.1406467854976654\n",
      "epoch: 14:  iteration: 1381:\t loss: 0.023308664560317993\n",
      "epoch: 14:  iteration: 1401:\t loss: 0.04586128890514374\n",
      "val loss:\t 0.02230347\n",
      "epoch: 14:  iteration: 1421:\t loss: 0.02752925455570221\n",
      "epoch: 14:  iteration: 1441:\t loss: 0.03262782841920853\n",
      "epoch: 14:  iteration: 1461:\t loss: 0.024982664734125137\n",
      "epoch: 14:  iteration: 1481:\t loss: 0.0340937003493309\n",
      "epoch: 14:  iteration: 1501:\t loss: 0.029721537604928017\n",
      "val loss:\t 0.01931836\n",
      "epoch: 14:  iteration: 1521:\t loss: 0.03134215995669365\n",
      "epoch: 14:  iteration: 1541:\t loss: 0.013912668451666832\n",
      "epoch: 14:  iteration: 1561:\t loss: 0.025790460407733917\n",
      "epoch: 14:  iteration: 1581:\t loss: 0.034527551382780075\n",
      "epoch: 14:  iteration: 1601:\t loss: 0.02583928406238556\n",
      "val loss:\t 0.020108785\n",
      "epoch: 14:  iteration: 1621:\t loss: 0.06090772524476051\n",
      "epoch: 14:  iteration: 1641:\t loss: 0.0200524739921093\n",
      "epoch: 14:  iteration: 1661:\t loss: 0.0476132333278656\n",
      "epoch: 14:  iteration: 1681:\t loss: 0.016496121883392334\n",
      "epoch: 14:  iteration: 1701:\t loss: 0.018604855984449387\n",
      "val loss:\t 0.025873\n",
      "epoch: 14:  iteration: 1721:\t loss: 0.05532611161470413\n",
      "epoch: 14:  iteration: 1741:\t loss: 0.02622416615486145\n",
      "epoch: 14:  iteration: 1761:\t loss: 0.033355679363012314\n",
      "epoch: 14:  iteration: 1781:\t loss: 0.2738705277442932\n",
      "epoch: 14:  iteration: 1801:\t loss: 0.021924152970314026\n",
      "val loss:\t 0.021623803\n",
      "epoch: 14:  iteration: 1821:\t loss: 0.01916118524968624\n",
      "epoch: 14:  iteration: 1841:\t loss: 0.02680714800953865\n",
      "epoch: 14:  iteration: 1861:\t loss: 0.016293009743094444\n",
      "epoch: 14:  iteration: 1881:\t loss: 0.032977983355522156\n",
      "epoch: 14:  iteration: 1901:\t loss: 0.021769355982542038\n",
      "val loss:\t 0.039052874\n",
      "epoch: 14:  iteration: 1921:\t loss: 0.020469870418310165\n",
      "epoch: 14:  iteration: 1941:\t loss: 0.031397365033626556\n",
      "epoch: 14:  iteration: 1961:\t loss: 0.020225737243890762\n",
      "epoch: 14:  iteration: 1981:\t loss: 0.019597027450799942\n",
      "epoch: 14:  iteration: 2001:\t loss: 0.035685621201992035\n",
      "val loss:\t 0.01839376\n",
      "epoch: 14:  iteration: 2021:\t loss: 0.7010781168937683\n",
      "epoch: 14:  iteration: 2041:\t loss: 0.031106455251574516\n",
      "epoch: 14:  iteration: 2061:\t loss: 0.018769066780805588\n",
      "epoch: 14:  iteration: 2081:\t loss: 0.01849059760570526\n",
      "epoch: 14:  iteration: 2101:\t loss: 0.024607140570878983\n",
      "val loss:\t 0.0476171\n",
      "epoch: 14:  iteration: 2121:\t loss: 0.027368105947971344\n",
      "epoch: 14:  iteration: 2141:\t loss: 0.029920443892478943\n",
      "epoch: 14:  iteration: 2161:\t loss: 0.024963095784187317\n",
      "epoch: 14:  iteration: 2181:\t loss: 0.02524477243423462\n",
      "epoch: 14:  iteration: 2201:\t loss: 0.04979592561721802\n",
      "val loss:\t 0.025674336\n",
      "epoch: 14:  iteration: 2221:\t loss: 0.15141381323337555\n",
      "epoch: 14:  iteration: 2241:\t loss: 0.025632403790950775\n",
      "epoch: 14:  iteration: 2261:\t loss: 0.02142365090548992\n",
      "epoch: 14:  iteration: 2281:\t loss: 0.023284677416086197\n",
      "epoch: 14:  iteration: 2301:\t loss: 0.032239995896816254\n",
      "val loss:\t 0.01308482\n",
      "epoch: 14:  iteration: 2321:\t loss: 0.011626524850726128\n",
      "epoch: 14:  iteration: 2341:\t loss: 0.02527722716331482\n",
      "epoch: 14:  iteration: 2361:\t loss: 0.024425476789474487\n",
      "epoch: 14:  iteration: 2381:\t loss: 0.03978300094604492\n",
      "epoch: 14:  iteration: 2401:\t loss: 0.0302786435931921\n",
      "val loss:\t 0.81059\n",
      "epoch: 14:  iteration: 2421:\t loss: 0.022264761850237846\n",
      "epoch: 14:  iteration: 2441:\t loss: 0.019805539399385452\n",
      "epoch: 14:  iteration: 2461:\t loss: 0.018523721024394035\n",
      "epoch: 14:  iteration: 2481:\t loss: 0.03055676445364952\n",
      "epoch: 14:  iteration: 2501:\t loss: 0.029775327071547508\n",
      "val loss:\t 0.024551682\n",
      "epoch: 14:  iteration: 2521:\t loss: 0.035886939615011215\n",
      "epoch: 14:  iteration: 2541:\t loss: 0.12862738966941833\n",
      "epoch: 14:  iteration: 2561:\t loss: 0.035321857780218124\n",
      "epoch: 14:  iteration: 2581:\t loss: 0.03962229937314987\n",
      "epoch: 14:  iteration: 2601:\t loss: 0.041013263165950775\n",
      "val loss:\t 0.049223155\n",
      "epoch: 14:  iteration: 2621:\t loss: 0.06202960014343262\n",
      "epoch: 14:  iteration: 2641:\t loss: 0.020152397453784943\n",
      "epoch: 14:  iteration: 2661:\t loss: 0.026364456862211227\n",
      "epoch: 14:  iteration: 2681:\t loss: 0.026663877069950104\n",
      "epoch: 14:  iteration: 2701:\t loss: 0.05060931295156479\n",
      "val loss:\t 0.019381149\n",
      "epoch: 14:  iteration: 2721:\t loss: 0.04210982844233513\n",
      "epoch: 14:  iteration: 2741:\t loss: 0.04425925388932228\n",
      "epoch: 14:  iteration: 2761:\t loss: 0.020048195496201515\n",
      "epoch: 14:  iteration: 2781:\t loss: 0.024495571851730347\n",
      "epoch: 14:  iteration: 2801:\t loss: 0.02073134295642376\n",
      "val loss:\t 0.01776198\n",
      "epoch: 14:  iteration: 2821:\t loss: 0.06304003298282623\n",
      "epoch: 14:  iteration: 2841:\t loss: 0.03925568610429764\n",
      "epoch: 14:  iteration: 2861:\t loss: 0.035444408655166626\n",
      "epoch: 14:  iteration: 2881:\t loss: 0.031001709401607513\n",
      "epoch: 14:  iteration: 2901:\t loss: 0.02668382227420807\n",
      "val loss:\t 0.02058366\n",
      "epoch: 14:  iteration: 2921:\t loss: 0.031087497249245644\n",
      "epoch: 14:  iteration: 2941:\t loss: 0.027438685297966003\n",
      "epoch: 14:  iteration: 2961:\t loss: 0.028076274320483208\n",
      "epoch: 14:  iteration: 2981:\t loss: 0.04140593856573105\n",
      "epoch: 14:  iteration: 3001:\t loss: 0.02591998130083084\n",
      "val loss:\t 0.030589575\n",
      "epoch: 14:  iteration: 3021:\t loss: 0.026057712733745575\n",
      "epoch: 14:  iteration: 3041:\t loss: 0.026235278695821762\n",
      "epoch: 14:  iteration: 3061:\t loss: 0.017935777083039284\n",
      "epoch: 14:  iteration: 3081:\t loss: 0.026606738567352295\n",
      "epoch: 14:  iteration: 3101:\t loss: 0.03311256691813469\n",
      "val loss:\t 0.013315922\n",
      "epoch: 14:  iteration: 3121:\t loss: 0.01996862143278122\n",
      "epoch: 14:  iteration: 3141:\t loss: 0.021158255636692047\n",
      "epoch: 14:  iteration: 3161:\t loss: 0.02696564421057701\n",
      "epoch: 14:  iteration: 3181:\t loss: 0.1037544310092926\n",
      "epoch: 14:  iteration: 3201:\t loss: 0.02013903670012951\n",
      "val loss:\t 0.06078727\n",
      "epoch: 14:  iteration: 3221:\t loss: 0.029120471328496933\n",
      "epoch: 14:  iteration: 3241:\t loss: 0.030495908111333847\n",
      "epoch: 14:  iteration: 3261:\t loss: 0.025095690041780472\n",
      "epoch: 14:  iteration: 3281:\t loss: 0.01955743134021759\n",
      "epoch: 14:  iteration: 3301:\t loss: 0.02061288058757782\n",
      "val loss:\t 0.01820828\n",
      "epoch: 14:  iteration: 3321:\t loss: 0.035726044327020645\n",
      "epoch: 14:  iteration: 3341:\t loss: 0.019957343116402626\n",
      "epoch: 14:  iteration: 3361:\t loss: 0.09361860156059265\n",
      "epoch: 14:  iteration: 3381:\t loss: 0.03840065002441406\n",
      "epoch: 14:  iteration: 3401:\t loss: 0.022088291123509407\n",
      "val loss:\t 0.030271407\n",
      "epoch: 14:  iteration: 3421:\t loss: 0.02065413072705269\n",
      "epoch: 14:  iteration: 3441:\t loss: 0.03136304393410683\n",
      "epoch: 14:  iteration: 3461:\t loss: 0.0360107496380806\n",
      "epoch: 14:  iteration: 3481:\t loss: 0.022978678345680237\n",
      "epoch: 14:  iteration: 3501:\t loss: 0.023206952959299088\n",
      "val loss:\t 0.074459195\n",
      "epoch: 14:  iteration: 3521:\t loss: 0.02820737473666668\n",
      "epoch: 14:  iteration: 3541:\t loss: 0.02977207861840725\n",
      "epoch: 14:  iteration: 3561:\t loss: 0.016416586935520172\n",
      "epoch: 14:  iteration: 3581:\t loss: 0.020015034824609756\n",
      "epoch: 14:  iteration: 3601:\t loss: 0.03321235626935959\n",
      "val loss:\t 0.024652917\n",
      "epoch: 14:  iteration: 3621:\t loss: 0.019262854009866714\n",
      "epoch: 14:  iteration: 3641:\t loss: 0.02281726337969303\n",
      "epoch: 14:  iteration: 3661:\t loss: 0.029192930087447166\n",
      "epoch: 14:  iteration: 3681:\t loss: 0.042038943618535995\n",
      "epoch: 14:  iteration: 3701:\t loss: 0.019723977893590927\n",
      "val loss:\t 0.0152450185\n",
      "epoch: 14:  iteration: 3721:\t loss: 0.02317994087934494\n",
      "epoch: 14:  iteration: 3741:\t loss: 0.038056034594774246\n",
      "epoch: 14:  iteration: 3761:\t loss: 0.026764942333102226\n",
      "epoch: 14:  iteration: 3781:\t loss: 0.024617208167910576\n",
      "epoch: 14:  iteration: 3801:\t loss: 0.013675090856850147\n",
      "val loss:\t 0.028620625\n",
      "EarlyStopping counter: 5 out of 6\n",
      "----------------epoch end--------------------- 13\n",
      "|loss_train| 0.0002140084543498233\n",
      "|loss_test| 0.0001192850322695449\n",
      "epoch: 15:  iteration: 1:\t loss: 0.10276605188846588\n",
      "val loss:\t 0.02801346\n",
      "epoch: 15:  iteration: 21:\t loss: 0.015697497874498367\n",
      "epoch: 15:  iteration: 41:\t loss: 0.02888602390885353\n",
      "epoch: 15:  iteration: 61:\t loss: 0.024171479046344757\n",
      "epoch: 15:  iteration: 81:\t loss: 0.03142901882529259\n",
      "epoch: 15:  iteration: 101:\t loss: 0.02021242491900921\n",
      "val loss:\t 0.01897528\n",
      "epoch: 15:  iteration: 121:\t loss: 0.050482265651226044\n",
      "epoch: 15:  iteration: 141:\t loss: 0.023852920159697533\n",
      "epoch: 15:  iteration: 161:\t loss: 0.015734704211354256\n",
      "epoch: 15:  iteration: 181:\t loss: 0.056291740387678146\n",
      "epoch: 15:  iteration: 201:\t loss: 0.015977319329977036\n",
      "val loss:\t 0.08906394\n",
      "epoch: 15:  iteration: 221:\t loss: 0.028413813561201096\n",
      "epoch: 15:  iteration: 241:\t loss: 0.045255232602357864\n",
      "epoch: 15:  iteration: 261:\t loss: 0.06088237836956978\n",
      "epoch: 15:  iteration: 281:\t loss: 0.035225242376327515\n",
      "epoch: 15:  iteration: 301:\t loss: 0.01361131016165018\n",
      "val loss:\t 0.023788974\n",
      "epoch: 15:  iteration: 321:\t loss: 0.025973528623580933\n",
      "epoch: 15:  iteration: 341:\t loss: 0.017581483349204063\n",
      "epoch: 15:  iteration: 361:\t loss: 0.015488151460886002\n",
      "epoch: 15:  iteration: 381:\t loss: 0.023013954982161522\n",
      "epoch: 15:  iteration: 401:\t loss: 0.01702948659658432\n",
      "val loss:\t 0.022518165\n",
      "epoch: 15:  iteration: 421:\t loss: 0.02015092223882675\n",
      "epoch: 15:  iteration: 441:\t loss: 0.03378254920244217\n",
      "epoch: 15:  iteration: 461:\t loss: 0.07994382083415985\n",
      "epoch: 15:  iteration: 481:\t loss: 0.0323348194360733\n",
      "epoch: 15:  iteration: 501:\t loss: 0.061094980686903\n",
      "val loss:\t 0.022054484\n",
      "epoch: 15:  iteration: 521:\t loss: 0.024858104065060616\n",
      "epoch: 15:  iteration: 541:\t loss: 0.024020977318286896\n",
      "epoch: 15:  iteration: 561:\t loss: 0.021593600511550903\n",
      "epoch: 15:  iteration: 581:\t loss: 0.015391068533062935\n",
      "epoch: 15:  iteration: 601:\t loss: 0.017835531383752823\n",
      "val loss:\t 0.027381305\n",
      "epoch: 15:  iteration: 621:\t loss: 0.034459762275218964\n",
      "epoch: 15:  iteration: 641:\t loss: 0.02831709198653698\n",
      "epoch: 15:  iteration: 661:\t loss: 0.03728747367858887\n",
      "epoch: 15:  iteration: 681:\t loss: 0.017272423952817917\n",
      "epoch: 15:  iteration: 701:\t loss: 0.018236912786960602\n",
      "val loss:\t 0.025680464\n",
      "epoch: 15:  iteration: 721:\t loss: 0.015432516112923622\n",
      "epoch: 15:  iteration: 741:\t loss: 0.0340690016746521\n",
      "epoch: 15:  iteration: 761:\t loss: 0.02464636228978634\n",
      "epoch: 15:  iteration: 781:\t loss: 0.029355261474847794\n",
      "epoch: 15:  iteration: 801:\t loss: 0.02153436653316021\n",
      "val loss:\t 0.029942552\n",
      "epoch: 15:  iteration: 821:\t loss: 0.019293993711471558\n",
      "epoch: 15:  iteration: 841:\t loss: 0.019350266084074974\n",
      "epoch: 15:  iteration: 861:\t loss: 0.0458342507481575\n",
      "epoch: 15:  iteration: 881:\t loss: 0.020712802186608315\n",
      "epoch: 15:  iteration: 901:\t loss: 0.027720684185624123\n",
      "val loss:\t 0.02378048\n",
      "epoch: 15:  iteration: 921:\t loss: 0.029005873948335648\n",
      "epoch: 15:  iteration: 941:\t loss: 0.023730125278234482\n",
      "epoch: 15:  iteration: 961:\t loss: 0.03430241346359253\n",
      "epoch: 15:  iteration: 981:\t loss: 0.03846137225627899\n",
      "epoch: 15:  iteration: 1001:\t loss: 0.053307242691516876\n",
      "val loss:\t 0.027101979\n",
      "epoch: 15:  iteration: 1021:\t loss: 0.025174787268042564\n",
      "epoch: 15:  iteration: 1041:\t loss: 0.03313928842544556\n",
      "epoch: 15:  iteration: 1061:\t loss: 0.030403854325413704\n",
      "epoch: 15:  iteration: 1081:\t loss: 0.022055819630622864\n",
      "epoch: 15:  iteration: 1101:\t loss: 0.0371488519012928\n",
      "val loss:\t 0.023628466\n",
      "epoch: 15:  iteration: 1121:\t loss: 0.026946477591991425\n",
      "epoch: 15:  iteration: 1141:\t loss: 0.028111327439546585\n",
      "epoch: 15:  iteration: 1161:\t loss: 0.02583302929997444\n",
      "epoch: 15:  iteration: 1181:\t loss: 0.0341033935546875\n",
      "epoch: 15:  iteration: 1201:\t loss: 0.06280986964702606\n",
      "val loss:\t 0.023259703\n",
      "epoch: 15:  iteration: 1221:\t loss: 0.026010945439338684\n",
      "epoch: 15:  iteration: 1241:\t loss: 0.040845222771167755\n",
      "epoch: 15:  iteration: 1261:\t loss: 0.023602750152349472\n",
      "epoch: 15:  iteration: 1281:\t loss: 0.02503928728401661\n",
      "epoch: 15:  iteration: 1301:\t loss: 0.02878955379128456\n",
      "val loss:\t 0.042775847\n",
      "epoch: 15:  iteration: 1321:\t loss: 0.04889317601919174\n",
      "epoch: 15:  iteration: 1341:\t loss: 0.020574558526277542\n",
      "epoch: 15:  iteration: 1361:\t loss: 0.03247648477554321\n",
      "epoch: 15:  iteration: 1381:\t loss: 0.011768557131290436\n",
      "epoch: 15:  iteration: 1401:\t loss: 0.057961128652095795\n",
      "val loss:\t 0.02106488\n",
      "epoch: 15:  iteration: 1421:\t loss: 0.03236621990799904\n",
      "epoch: 15:  iteration: 1441:\t loss: 0.02073383703827858\n",
      "epoch: 15:  iteration: 1461:\t loss: 0.023891177028417587\n",
      "epoch: 15:  iteration: 1481:\t loss: 0.04146565496921539\n",
      "epoch: 15:  iteration: 1501:\t loss: 0.025149643421173096\n",
      "val loss:\t 0.018809848\n",
      "epoch: 15:  iteration: 1521:\t loss: 0.028663529083132744\n",
      "epoch: 15:  iteration: 1541:\t loss: 0.027859970927238464\n",
      "epoch: 15:  iteration: 1561:\t loss: 0.030853325501084328\n",
      "epoch: 15:  iteration: 1581:\t loss: 0.017280884087085724\n",
      "epoch: 15:  iteration: 1601:\t loss: 0.0577465295791626\n",
      "val loss:\t 0.028592257\n",
      "epoch: 15:  iteration: 1621:\t loss: 0.02570735663175583\n",
      "epoch: 15:  iteration: 1641:\t loss: 0.02305128611624241\n",
      "epoch: 15:  iteration: 1661:\t loss: 0.033339209854602814\n",
      "epoch: 15:  iteration: 1681:\t loss: 0.016667572781443596\n",
      "epoch: 15:  iteration: 1701:\t loss: 0.04750572144985199\n",
      "val loss:\t 0.019421093\n",
      "epoch: 15:  iteration: 1721:\t loss: 0.01961592212319374\n",
      "epoch: 15:  iteration: 1741:\t loss: 0.02583547681570053\n",
      "epoch: 15:  iteration: 1761:\t loss: 0.02351519837975502\n",
      "epoch: 15:  iteration: 1781:\t loss: 0.06565521657466888\n",
      "epoch: 15:  iteration: 1801:\t loss: 0.02634480595588684\n",
      "val loss:\t 0.020284394\n",
      "epoch: 15:  iteration: 1821:\t loss: 0.04600526764988899\n",
      "epoch: 15:  iteration: 1841:\t loss: 0.01857769675552845\n",
      "epoch: 15:  iteration: 1861:\t loss: 0.038832198828458786\n",
      "epoch: 15:  iteration: 1881:\t loss: 0.03928707540035248\n",
      "epoch: 15:  iteration: 1901:\t loss: 0.030008692294359207\n",
      "val loss:\t 0.094446644\n",
      "epoch: 15:  iteration: 1921:\t loss: 0.018588021397590637\n",
      "epoch: 15:  iteration: 1941:\t loss: 0.02326231822371483\n",
      "epoch: 15:  iteration: 1961:\t loss: 0.03568922355771065\n",
      "epoch: 15:  iteration: 1981:\t loss: 0.02368331141769886\n",
      "epoch: 15:  iteration: 2001:\t loss: 0.0403817743062973\n",
      "val loss:\t 0.013220843\n",
      "epoch: 15:  iteration: 2021:\t loss: 0.061553604900836945\n",
      "epoch: 15:  iteration: 2041:\t loss: 0.020735356956720352\n",
      "epoch: 15:  iteration: 2061:\t loss: 0.06479894369840622\n",
      "epoch: 15:  iteration: 2081:\t loss: 0.022379674017429352\n",
      "epoch: 15:  iteration: 2101:\t loss: 0.021304354071617126\n",
      "val loss:\t 0.024724964\n",
      "epoch: 15:  iteration: 2121:\t loss: 0.04314987361431122\n",
      "epoch: 15:  iteration: 2141:\t loss: 0.029187031090259552\n",
      "epoch: 15:  iteration: 2161:\t loss: 0.016508974134922028\n",
      "epoch: 15:  iteration: 2181:\t loss: 0.0458943173289299\n",
      "epoch: 15:  iteration: 2201:\t loss: 0.03116307407617569\n",
      "val loss:\t 0.058860406\n",
      "epoch: 15:  iteration: 2221:\t loss: 0.041495226323604584\n",
      "epoch: 15:  iteration: 2241:\t loss: 0.025163378566503525\n",
      "epoch: 15:  iteration: 2261:\t loss: 0.022625461220741272\n",
      "epoch: 15:  iteration: 2281:\t loss: 0.03243514150381088\n",
      "epoch: 15:  iteration: 2301:\t loss: 0.03172475844621658\n",
      "val loss:\t 0.028147226\n",
      "epoch: 15:  iteration: 2321:\t loss: 0.027510225772857666\n",
      "epoch: 15:  iteration: 2341:\t loss: 0.030584197491407394\n",
      "epoch: 15:  iteration: 2361:\t loss: 0.020204922184348106\n",
      "epoch: 15:  iteration: 2381:\t loss: 0.01842861995100975\n",
      "epoch: 15:  iteration: 2401:\t loss: 0.01677791029214859\n",
      "val loss:\t 0.028649962\n",
      "epoch: 15:  iteration: 2421:\t loss: 0.019014153629541397\n",
      "epoch: 15:  iteration: 2441:\t loss: 0.043152451515197754\n",
      "epoch: 15:  iteration: 2461:\t loss: 0.04253905639052391\n",
      "epoch: 15:  iteration: 2481:\t loss: 0.02225003018975258\n",
      "epoch: 15:  iteration: 2501:\t loss: 0.03343292325735092\n",
      "val loss:\t 0.014796156\n",
      "epoch: 15:  iteration: 2521:\t loss: 0.09978140890598297\n",
      "epoch: 15:  iteration: 2541:\t loss: 0.05840623006224632\n",
      "epoch: 15:  iteration: 2561:\t loss: 0.01598954014480114\n",
      "epoch: 15:  iteration: 2581:\t loss: 0.025512220337986946\n",
      "epoch: 15:  iteration: 2601:\t loss: 0.022554827854037285\n",
      "val loss:\t 0.023410939\n",
      "epoch: 15:  iteration: 2621:\t loss: 0.06614901125431061\n",
      "epoch: 15:  iteration: 2641:\t loss: 0.02898329310119152\n",
      "epoch: 15:  iteration: 2661:\t loss: 0.016197003424167633\n",
      "epoch: 15:  iteration: 2681:\t loss: 0.01903732493519783\n",
      "epoch: 15:  iteration: 2701:\t loss: 0.018235042691230774\n",
      "val loss:\t 0.026612904\n",
      "epoch: 15:  iteration: 2721:\t loss: 0.021012073382735252\n",
      "epoch: 15:  iteration: 2741:\t loss: 0.055168695747852325\n",
      "epoch: 15:  iteration: 2761:\t loss: 0.01794563978910446\n",
      "epoch: 15:  iteration: 2781:\t loss: 0.03611300140619278\n",
      "epoch: 15:  iteration: 2801:\t loss: 0.0280547384172678\n",
      "val loss:\t 0.027612746\n",
      "epoch: 15:  iteration: 2821:\t loss: 0.021979426965117455\n",
      "epoch: 15:  iteration: 2841:\t loss: 0.02111690305173397\n",
      "epoch: 15:  iteration: 2861:\t loss: 0.01854027807712555\n",
      "epoch: 15:  iteration: 2881:\t loss: 0.031040942296385765\n",
      "epoch: 15:  iteration: 2901:\t loss: 0.02017027512192726\n",
      "val loss:\t 0.03683065\n",
      "epoch: 15:  iteration: 2921:\t loss: 0.02222122810781002\n",
      "epoch: 15:  iteration: 2941:\t loss: 0.023275751620531082\n",
      "epoch: 15:  iteration: 2961:\t loss: 0.018683671951293945\n",
      "epoch: 15:  iteration: 2981:\t loss: 0.024743327870965004\n",
      "epoch: 15:  iteration: 3001:\t loss: 0.04793477803468704\n",
      "val loss:\t 0.029437086\n",
      "epoch: 15:  iteration: 3021:\t loss: 0.02981949970126152\n",
      "epoch: 15:  iteration: 3041:\t loss: 0.03527836874127388\n",
      "epoch: 15:  iteration: 3061:\t loss: 0.021468406543135643\n",
      "epoch: 15:  iteration: 3081:\t loss: 0.051219627261161804\n",
      "epoch: 15:  iteration: 3101:\t loss: 0.012645812705159187\n",
      "val loss:\t 0.031539395\n",
      "epoch: 15:  iteration: 3121:\t loss: 0.029996410012245178\n",
      "epoch: 15:  iteration: 3141:\t loss: 0.020820926874876022\n",
      "epoch: 15:  iteration: 3161:\t loss: 0.02108236774802208\n",
      "epoch: 15:  iteration: 3181:\t loss: 0.022684380412101746\n",
      "epoch: 15:  iteration: 3201:\t loss: 0.06491416692733765\n",
      "val loss:\t 0.022835786\n",
      "epoch: 15:  iteration: 3221:\t loss: 0.023337095975875854\n",
      "epoch: 15:  iteration: 3241:\t loss: 0.019624190405011177\n",
      "epoch: 15:  iteration: 3261:\t loss: 0.05848241597414017\n",
      "epoch: 15:  iteration: 3281:\t loss: 0.042559877038002014\n",
      "epoch: 15:  iteration: 3301:\t loss: 0.01735558733344078\n",
      "val loss:\t 0.018732637\n",
      "epoch: 15:  iteration: 3321:\t loss: 0.04611794278025627\n",
      "epoch: 15:  iteration: 3341:\t loss: 0.01725959964096546\n",
      "epoch: 15:  iteration: 3361:\t loss: 0.02193400077521801\n",
      "epoch: 15:  iteration: 3381:\t loss: 0.028443310409784317\n",
      "epoch: 15:  iteration: 3401:\t loss: 0.012716002762317657\n",
      "val loss:\t 0.015294978\n",
      "epoch: 15:  iteration: 3421:\t loss: 0.03782424330711365\n",
      "epoch: 15:  iteration: 3441:\t loss: 0.020980913192033768\n",
      "epoch: 15:  iteration: 3461:\t loss: 0.018641192466020584\n",
      "epoch: 15:  iteration: 3481:\t loss: 0.06296490132808685\n",
      "epoch: 15:  iteration: 3501:\t loss: 0.017005227506160736\n",
      "val loss:\t 0.020671152\n",
      "epoch: 15:  iteration: 3521:\t loss: 0.048534393310546875\n",
      "epoch: 15:  iteration: 3541:\t loss: 0.020414505153894424\n",
      "epoch: 15:  iteration: 3561:\t loss: 0.014395134523510933\n",
      "epoch: 15:  iteration: 3581:\t loss: 0.02446826547384262\n",
      "epoch: 15:  iteration: 3601:\t loss: 0.024155564606189728\n",
      "val loss:\t 0.025006294\n",
      "epoch: 15:  iteration: 3621:\t loss: 0.020156875252723694\n",
      "epoch: 15:  iteration: 3641:\t loss: 0.022136187180876732\n",
      "epoch: 15:  iteration: 3661:\t loss: 0.026758652180433273\n",
      "epoch: 15:  iteration: 3681:\t loss: 0.04869620129466057\n",
      "epoch: 15:  iteration: 3701:\t loss: 0.01704905927181244\n",
      "val loss:\t 0.034012236\n",
      "epoch: 15:  iteration: 3721:\t loss: 0.023222897201776505\n",
      "epoch: 15:  iteration: 3741:\t loss: 0.0307864211499691\n",
      "epoch: 15:  iteration: 3761:\t loss: 0.03638962656259537\n",
      "epoch: 15:  iteration: 3781:\t loss: 0.03412383049726486\n",
      "epoch: 15:  iteration: 3801:\t loss: 0.012453390285372734\n",
      "val loss:\t 0.018067423\n",
      "EarlyStopping counter: 6 out of 6\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "# Accuracy_Score = accuracy_score(prediction, y_res)\n",
    "loss_count= []\n",
    "global_loss_train = []\n",
    "global_loss_test = []\n",
    "for epoch in range(epochs):\n",
    "    for i,(x,y) in enumerate(train_loader):\n",
    "        batch_x = Variable(x.cuda(device=device_ids[0])) # torch.Size([128,1,64,60])\n",
    "        batch_y = Variable(y.cuda(device=device_ids[0]))\n",
    "        # 获取最后输出\n",
    "        out = model(batch_x.float()) # torch.Size([128,3])\n",
    "        # print(np.shape(out))\n",
    "        # 获取损失\n",
    "        loss = loss_func(out,batch_y)\n",
    "\n",
    "        opt.zero_grad()  # \n",
    "        loss.backward() # 误差反向传播，计算参数更新值\n",
    "        opt.step() # 将参数更新值施加到net的parmeters上\n",
    "        if i%20 == 0:\n",
    "            temp = loss.cpu()\n",
    "            loss_count.append(temp.detach().numpy())\n",
    "            print('epoch: {}: '.format(epoch+1),'iteration: {}:\\t'.format(i+1),'loss:', loss.item())\n",
    "            torch.save(model.state_dict(),r'../cnn_model/cnn_torch/ret_20_pred_checkpoint.pt')\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            for a,b in val_loader:\n",
    "                val_x = Variable(a.cuda(device=device_ids[0]))\n",
    "                val_y = Variable(b.cuda(device=device_ids[0]))\n",
    "                out = model(val_x)\n",
    "\n",
    "                accuracy = loss_func(out, val_y)\n",
    "                print('val loss:\\t',accuracy.cpu().detach().numpy())\n",
    "                break\n",
    "    early_stopping(loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        # 结束模型训练\n",
    "        break\n",
    "    if epoch % 1 == 0:\n",
    "        print('----------------epoch end---------------------', epoch)\n",
    "        prediction_train = model(batch_x)\n",
    "        loss_train = loss_func(prediction_train, batch_y.squeeze().long())\n",
    "        global_loss_train.append(loss_train.cpu().detach().numpy())\n",
    "        print('|loss_train|', loss_train.cpu().item())\n",
    "        for a,b in test_loader:\n",
    "            test_x = Variable(a.cuda(device=device_ids[0]))\n",
    "            test_y = Variable(b.cuda(device=device_ids[0]))\n",
    "            prediction_test = model(test_x)\n",
    "            loss_test = loss_func(prediction_test, test_y.squeeze().long())\n",
    "            global_loss_test.append(loss_test.cpu().detach().numpy())\n",
    "            print('|loss_test|', loss_test.cpu().item())\n",
    "            break    \n",
    "model.load_state_dict(torch.load('../cnn_model/cnn_torch/ret_20_pred_checkpoint.pt'))\n",
    "plt.figure('PyTorch_CNN_Loss')\n",
    "plt.plot(loss_count,label='Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "129a7e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(global_loss_test) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, global_loss_train, 'bo', label='Train')\n",
    "plt.plot(epochs, global_loss_test, 'r', label='Val')\n",
    "plt.legend()\n",
    "plt.title('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c4aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|loss_test| 0.00012804733705706894\n",
      "|loss_test| 0.00010490341810509562\n",
      "|loss_test| 0.00011349951091688126\n",
      "|loss_test| 0.015572338365018368\n",
      "|loss_test| 0.00012829412298742682\n",
      "|loss_test| 0.007843105122447014\n",
      "|loss_test| 0.00010233531065750867\n",
      "|loss_test| 0.007853399030864239\n",
      "|loss_test| 0.00014569262566510588\n",
      "|loss_test| 0.0001208672983921133\n",
      "|loss_test| 0.007845070213079453\n",
      "|loss_test| 0.031216304749250412\n",
      "|loss_test| 0.00014160758291836828\n",
      "|loss_test| 0.007864118553698063\n",
      "|loss_test| 0.00012176661402918398\n",
      "|loss_test| 0.00011510700278449804\n",
      "|loss_test| 0.007860618643462658\n",
      "|loss_test| 0.0001187820962513797\n",
      "|loss_test| 0.00013398032751865685\n",
      "|loss_test| 0.00011104786972282454\n",
      "|loss_test| 0.00011249647650402039\n",
      "|loss_test| 9.496074198978022e-05\n",
      "|loss_test| 0.00010178674710914493\n",
      "|loss_test| 0.0001252337679034099\n",
      "|loss_test| 0.007838600315153599\n",
      "|loss_test| 0.07021061331033707\n",
      "|loss_test| 0.015566709451377392\n",
      "|loss_test| 0.00010614660277497023\n",
      "|loss_test| 0.00011973798245890066\n",
      "|loss_test| 0.0001094521940103732\n",
      "|loss_test| 0.00011888332664966583\n",
      "|loss_test| 0.00785562489181757\n",
      "|loss_test| 0.00010363290493842214\n",
      "|loss_test| 0.00011684803757816553\n",
      "|loss_test| 0.00012991005496587604\n",
      "|loss_test| 0.00015241335495375097\n",
      "|loss_test| 0.007878362201154232\n",
      "|loss_test| 0.007846185937523842\n",
      "|loss_test| 9.979233436752111e-05\n",
      "|loss_test| 0.00011692975385813043\n",
      "|loss_test| 0.00011195520346518606\n",
      "|loss_test| 0.00010853361163754016\n",
      "|loss_test| 0.00013573233445640653\n",
      "|loss_test| 0.00011226216884097084\n",
      "|loss_test| 0.0001268307532882318\n",
      "|loss_test| 0.007896159775555134\n",
      "|loss_test| 0.00012627954129129648\n",
      "|loss_test| 0.015605045482516289\n",
      "|loss_test| 0.00013199722161516547\n",
      "|loss_test| 0.00011208135401830077\n",
      "|loss_test| 0.0001050112841767259\n",
      "|loss_test| 0.023337868973612785\n",
      "|loss_test| 0.007855016738176346\n",
      "|loss_test| 0.007834913209080696\n",
      "|loss_test| 0.007854918017983437\n",
      "|loss_test| 0.00012728141155093908\n",
      "|loss_test| 0.00785272940993309\n",
      "|loss_test| 0.015623997896909714\n",
      "|loss_test| 0.00011434931366238743\n",
      "|loss_test| 0.00010870017285924405\n",
      "|loss_test| 0.031186167150735855\n",
      "|loss_test| 0.00011925996659556404\n",
      "|loss_test| 0.0001019998817355372\n",
      "|loss_test| 0.015576833859086037\n",
      "|loss_test| 0.00012159770994912833\n",
      "|loss_test| 0.007852498441934586\n",
      "|loss_test| 0.00011006675777025521\n",
      "|loss_test| 0.00016440883337054402\n",
      "|loss_test| 9.984374628402293e-05\n",
      "|loss_test| 0.00012529041850939393\n",
      "|loss_test| 0.007852040231227875\n",
      "|loss_test| 0.00013496822793968022\n",
      "|loss_test| 0.03122209943830967\n",
      "|loss_test| 0.00013092430890537798\n",
      "|loss_test| 0.03121686913073063\n",
      "|loss_test| 0.00012920075096189976\n",
      "|loss_test| 0.00786895863711834\n",
      "|loss_test| 0.00014838420611340553\n",
      "|loss_test| 0.0001252218644367531\n",
      "|loss_test| 0.00011231198732275516\n",
      "|loss_test| 0.00785741861909628\n",
      "|loss_test| 0.00012261643132660538\n",
      "|loss_test| 0.0001203517458634451\n",
      "|loss_test| 0.007870875298976898\n",
      "|loss_test| 0.00012478051939979196\n",
      "|loss_test| 0.00014823934179730713\n",
      "|loss_test| 0.00013868887617718428\n",
      "|loss_test| 0.00013835445861332119\n",
      "|loss_test| 0.00012673443416133523\n",
      "|loss_test| 0.00010387579095549881\n",
      "|loss_test| 0.00010322171146981418\n",
      "|loss_test| 0.007855250500142574\n",
      "|loss_test| 0.031233221292495728\n",
      "|loss_test| 0.007866567932069302\n",
      "|loss_test| 0.00011800917854998261\n",
      "|loss_test| 0.0001169190218206495\n",
      "|loss_test| 0.015570465475320816\n",
      "|loss_test| 0.03122260794043541\n",
      "|loss_test| 0.0001172686752397567\n",
      "|loss_test| 0.007854674942791462\n",
      "|loss_test| 0.00013856380246579647\n",
      "|loss_test| 0.0311872698366642\n",
      "|loss_test| 0.00011973902292083949\n",
      "|loss_test| 0.0001465556852053851\n",
      "|loss_test| 0.00010680607374524698\n",
      "|loss_test| 0.015557197853922844\n",
      "|loss_test| 0.00011696348519762978\n",
      "|loss_test| 0.00012272092862986028\n",
      "|loss_test| 0.00011314517178107053\n",
      "|loss_test| 0.00014989962801337242\n",
      "|loss_test| 0.007869369350373745\n",
      "|loss_test| 0.0001167360387626104\n",
      "|loss_test| 0.007842873223125935\n",
      "|loss_test| 0.007868854328989983\n",
      "|loss_test| 0.00011128065671073273\n",
      "|loss_test| 0.00010612700134515762\n",
      "|loss_test| 0.0078628184273839\n",
      "|loss_test| 0.00014098852989263833\n",
      "|loss_test| 0.007869110442698002\n",
      "|loss_test| 9.984211646951735e-05\n",
      "|loss_test| 0.00786641240119934\n",
      "|loss_test| 0.01556893065571785\n",
      "|loss_test| 0.015625208616256714\n",
      "|loss_test| 0.007876320742070675\n",
      "|loss_test| 0.10133900493383408\n",
      "|loss_test| 0.03122364915907383\n",
      "|loss_test| 0.00011585275933612138\n",
      "|loss_test| 0.00010819176532095298\n",
      "|loss_test| 0.0001249622437171638\n",
      "|loss_test| 0.007848262786865234\n",
      "|loss_test| 0.007848975248634815\n",
      "|loss_test| 0.007859538309276104\n",
      "|loss_test| 0.00010168338485527784\n",
      "|loss_test| 9.636255708755925e-05\n",
      "|loss_test| 0.00784391537308693\n",
      "|loss_test| 0.0001330722006969154\n",
      "|loss_test| 0.007875471375882626\n",
      "|loss_test| 0.00010214888607151806\n",
      "|loss_test| 0.007833415642380714\n",
      "|loss_test| 0.0001172107586171478\n",
      "|loss_test| 0.007845996879041195\n",
      "|loss_test| 0.00012042016896884888\n",
      "|loss_test| 0.00013360085722524673\n",
      "|loss_test| 0.00010229917825199664\n",
      "|loss_test| 0.00012941512977704406\n",
      "|loss_test| 0.03127625584602356\n",
      "|loss_test| 0.00785352848470211\n",
      "|loss_test| 0.0001418714236933738\n",
      "|loss_test| 0.00011069876927649602\n",
      "|loss_test| 0.03122524358332157\n",
      "|loss_test| 0.0001050326754921116\n",
      "|loss_test| 0.0001253561640623957\n",
      "|loss_test| 0.00010031192505266517\n",
      "|loss_test| 0.015603207051753998\n",
      "|loss_test| 0.00010948583076242357\n",
      "|loss_test| 0.00784784834831953\n",
      "|loss_test| 0.00012815065565519035\n",
      "|loss_test| 0.007844359613955021\n",
      "|loss_test| 0.00012389858602546155\n",
      "|loss_test| 0.00013292449875734746\n",
      "|loss_test| 0.00012743101979140192\n",
      "|loss_test| 0.03126206621527672\n",
      "|loss_test| 0.007838706485927105\n",
      "|loss_test| 0.03123307228088379\n",
      "|loss_test| 0.007873998954892159\n",
      "|loss_test| 0.00011735601583495736\n",
      "|loss_test| 0.007852432318031788\n",
      "|loss_test| 0.00012501460150815547\n",
      "|loss_test| 0.00013755378313362598\n",
      "|loss_test| 0.00011311576963635162\n",
      "|loss_test| 0.02323611080646515\n",
      "|loss_test| 0.007836396805942059\n",
      "|loss_test| 0.00011156435357406735\n",
      "|loss_test| 0.00010166452557314187\n",
      "|loss_test| 0.007851045578718185\n",
      "|loss_test| 0.00012845468882005662\n",
      "|loss_test| 9.734884952194989e-05\n",
      "|loss_test| 0.00785914808511734\n",
      "|loss_test| 0.00011580633872654289\n",
      "|loss_test| 0.00012512528337538242\n",
      "|loss_test| 0.0001008203107630834\n",
      "|loss_test| 0.00012286443961784244\n",
      "|loss_test| 9.589226101525128e-05\n",
      "|loss_test| 0.015542355366051197\n",
      "|loss_test| 0.00014532863860949874\n",
      "|loss_test| 0.00012036048428853974\n",
      "|loss_test| 0.00786007009446621\n",
      "|loss_test| 0.007870890200138092\n",
      "|loss_test| 0.007842072285711765\n",
      "|loss_test| 0.00013412581756711006\n",
      "|loss_test| 0.00013317985576577485\n",
      "|loss_test| 0.007861653342843056\n",
      "|loss_test| 0.01561099011451006\n",
      "|loss_test| 0.00012612357386387885\n",
      "|loss_test| 0.007873310707509518\n",
      "|loss_test| 0.015574934892356396\n",
      "|loss_test| 0.00010430358088342473\n",
      "|loss_test| 0.007835893891751766\n",
      "|loss_test| 0.007871986366808414\n",
      "|loss_test| 0.015586727298796177\n",
      "|loss_test| 0.0001244182203663513\n",
      "|loss_test| 0.007858109660446644\n",
      "|loss_test| 0.00012922286987304688\n",
      "|loss_test| 0.00784189160913229\n",
      "|loss_test| 0.00010933067824225873\n",
      "|loss_test| 0.007865780964493752\n",
      "|loss_test| 0.00012543713091872633\n",
      "|loss_test| 0.007842236198484898\n",
      "|loss_test| 0.00013462375500239432\n",
      "|loss_test| 0.00784066691994667\n",
      "|loss_test| 0.007853946648538113\n",
      "|loss_test| 0.007868437096476555\n",
      "|loss_test| 0.0001207163295475766\n",
      "|loss_test| 0.0001397483138134703\n",
      "|loss_test| 0.007851887494325638\n",
      "|loss_test| 0.03123604878783226\n",
      "|loss_test| 0.00011319040640955791\n",
      "|loss_test| 0.00012691336451098323\n",
      "|loss_test| 0.00010582877439446747\n",
      "|loss_test| 0.00010497516632312909\n",
      "|loss_test| 0.015573957934975624\n",
      "|loss_test| 0.015572814270853996\n",
      "|loss_test| 0.007856420241296291\n",
      "|loss_test| 0.00014206371270120144\n",
      "|loss_test| 0.007832571864128113\n",
      "|loss_test| 0.007878128439188004\n",
      "|loss_test| 0.00010916302562691271\n",
      "|loss_test| 0.00786378514021635\n",
      "|loss_test| 0.007859501987695694\n",
      "|loss_test| 0.007883992977440357\n",
      "|loss_test| 0.015574149787425995\n",
      "|loss_test| 9.142128692474216e-05\n",
      "|loss_test| 0.0001040300412569195\n",
      "|loss_test| 0.00012635602615773678\n",
      "|loss_test| 0.00011030452878912911\n",
      "|loss_test| 0.007856055162847042\n",
      "|loss_test| 0.015607968904078007\n",
      "|loss_test| 0.007853508926928043\n",
      "|loss_test| 0.007848796434700489\n",
      "|loss_test| 0.0001130172677221708\n",
      "|loss_test| 0.00011678192822728306\n",
      "|loss_test| 9.927664359565824e-05\n",
      "|loss_test| 0.00014716535224579275\n",
      "|loss_test| 0.00012045272160321474\n",
      "|loss_test| 0.00011866045679198578\n",
      "|loss_test| 0.00012394518125802279\n",
      "|loss_test| 0.0001175775978481397\n",
      "|loss_test| 0.00011201402958249673\n",
      "|loss_test| 0.00013816959108226\n",
      "|loss_test| 0.00784019473940134\n",
      "|loss_test| 0.00010294708772562444\n",
      "|loss_test| 0.031266532838344574\n",
      "|loss_test| 0.007857031188905239\n",
      "|loss_test| 0.13260221481323242\n",
      "|loss_test| 0.00012731642345897853\n",
      "|loss_test| 0.015589629299938679\n",
      "|loss_test| 0.00013151834718883038\n",
      "|loss_test| 0.00011149446072522551\n",
      "|loss_test| 9.877431148197502e-05\n",
      "|loss_test| 0.015587163157761097\n",
      "|loss_test| 0.00014163210289552808\n",
      "|loss_test| 0.015611078590154648\n",
      "|loss_test| 0.7805886268615723\n",
      "|loss_test| 0.00011751180136343464\n",
      "|loss_test| 0.00012799911201000214\n",
      "|loss_test| 0.00013884756481274962\n",
      "|loss_test| 0.007863911800086498\n",
      "|loss_test| 0.007841639220714569\n",
      "|loss_test| 0.00012288725702092052\n",
      "|loss_test| 0.00012009711645077914\n",
      "|loss_test| 0.00012958529987372458\n",
      "|loss_test| 0.00011071823973907158\n",
      "|loss_test| 0.038971494883298874\n",
      "|loss_test| 0.00010536523041082546\n",
      "|loss_test| 0.00013310505892150104\n",
      "|loss_test| 0.00013783504255115986\n",
      "|loss_test| 0.007844195701181889\n",
      "|loss_test| 0.007859624922275543\n",
      "|loss_test| 0.00010509501589694992\n",
      "|loss_test| 0.015587096102535725\n",
      "|loss_test| 0.00012304293341003358\n",
      "|loss_test| 0.00010984969412675127\n",
      "|loss_test| 0.00012393746874295175\n",
      "|loss_test| 0.00010211586049990728\n",
      "|loss_test| 0.007874447852373123\n",
      "|loss_test| 0.00012924260227009654\n",
      "|loss_test| 0.007869260385632515\n",
      "|loss_test| 0.00012919151049572974\n",
      "|loss_test| 0.007846342399716377\n",
      "|loss_test| 9.59213066380471e-05\n",
      "|loss_test| 0.00785077828913927\n",
      "|loss_test| 0.03118722513318062\n",
      "|loss_test| 0.00786087941378355\n",
      "|loss_test| 0.007859992794692516\n",
      "|loss_test| 0.1481134295463562\n",
      "|loss_test| 0.015605863183736801\n",
      "|loss_test| 0.00013655144721269608\n",
      "|loss_test| 0.00015153229469433427\n",
      "|loss_test| 0.00010522110824240372\n",
      "|loss_test| 0.00010756006668088958\n",
      "|loss_test| 0.00010540970833972096\n",
      "|loss_test| 0.00012219371274113655\n",
      "|loss_test| 0.00014138896949589252\n",
      "|loss_test| 0.00012474542018026114\n",
      "|loss_test| 0.00012036818952765316\n",
      "|loss_test| 0.007854714058339596\n",
      "|loss_test| 0.031231414526700974\n",
      "|loss_test| 0.007875634357333183\n",
      "|loss_test| 0.00011265338980592787\n",
      "|loss_test| 0.031210819259285927\n",
      "|loss_test| 0.00010032477439381182\n",
      "|loss_test| 0.00011534317309269682\n",
      "|loss_test| 0.023348068818449974\n",
      "|loss_test| 0.007862551137804985\n",
      "|loss_test| 0.007848205976188183\n",
      "|loss_test| 0.00013491891149897128\n",
      "|loss_test| 0.00011746094969566911\n",
      "|loss_test| 0.00011557351535884663\n",
      "|loss_test| 0.031245451420545578\n",
      "|loss_test| 0.007848539389669895\n",
      "|loss_test| 0.00011379050556570292\n",
      "|loss_test| 0.0001082766248146072\n",
      "|loss_test| 0.00010441075573908165\n",
      "|loss_test| 9.614265582058579e-05\n",
      "|loss_test| 0.007837075740098953\n",
      "|loss_test| 0.015583468601107597\n",
      "|loss_test| 0.007838243618607521\n",
      "|loss_test| 0.00011994552914984524\n",
      "|loss_test| 0.00011627242201939225\n",
      "|loss_test| 9.764028072822839e-05\n",
      "|loss_test| 0.00010994069452863187\n",
      "|loss_test| 0.00010558957001194358\n",
      "|loss_test| 0.00012135067663621157\n",
      "|loss_test| 0.00010443114297231659\n",
      "|loss_test| 0.007892378605902195\n",
      "|loss_test| 0.00012714916374534369\n",
      "|loss_test| 0.0001081423761206679\n",
      "|loss_test| 0.00011888996232300997\n",
      "|loss_test| 0.00012400085688568652\n",
      "|loss_test| 0.031197436153888702\n",
      "|loss_test| 0.00010902177746174857\n",
      "|loss_test| 0.007878256030380726\n",
      "|loss_test| 0.031201224774122238\n",
      "|loss_test| 0.007849308662116528\n",
      "|loss_test| 0.0001160197498393245\n",
      "|loss_test| 9.811439667828381e-05\n",
      "|loss_test| 0.00014313064457383007\n",
      "|loss_test| 0.00013547709386330098\n",
      "|loss_test| 0.007848707027733326\n",
      "|loss_test| 0.00011183042079210281\n",
      "|loss_test| 0.007869000546634197\n",
      "|loss_test| 9.62417179835029e-05\n",
      "|loss_test| 0.00011224939953535795\n",
      "|loss_test| 0.00010030133125837892\n",
      "|loss_test| 0.0078886104747653\n",
      "|loss_test| 0.00011622336023719981\n",
      "|loss_test| 0.0001323619217146188\n",
      "|loss_test| 0.00012078703730367124\n",
      "|loss_test| 0.00784766674041748\n",
      "|loss_test| 0.007874424569308758\n",
      "|loss_test| 0.00011599410208873451\n",
      "|loss_test| 0.00011595369142014533\n",
      "|loss_test| 0.007842782884836197\n",
      "|loss_test| 0.03128359839320183\n",
      "|loss_test| 0.00010784331243485212\n",
      "|loss_test| 0.00011851294402731583\n",
      "|loss_test| 0.0001278796698898077\n",
      "|loss_test| 0.00011612201342359185\n",
      "|loss_test| 0.03893318027257919\n",
      "|loss_test| 0.007920580916106701\n",
      "|loss_test| 0.00010982724779751152\n",
      "|loss_test| 0.0001401551708113402\n",
      "|loss_test| 0.000127287523355335\n",
      "|loss_test| 0.00011004681437043473\n",
      "|loss_test| 0.015609631314873695\n",
      "|loss_test| 0.0001067627381416969\n",
      "|loss_test| 0.007865076884627342\n",
      "|loss_test| 0.007831570692360401\n",
      "|loss_test| 0.007856935262680054\n",
      "|loss_test| 0.00010840976028703153\n",
      "|loss_test| 0.00011961588461417705\n",
      "|loss_test| 0.007855836302042007\n",
      "|loss_test| 0.0001231677015312016\n",
      "|loss_test| 0.00012042111484333873\n",
      "|loss_test| 0.01555844396352768\n",
      "|loss_test| 0.00012961642642039806\n",
      "|loss_test| 0.00011342498328303918\n",
      "|loss_test| 0.0078582176938653\n",
      "|loss_test| 0.00012453552335500717\n",
      "|loss_test| 0.00010544272663537413\n",
      "|loss_test| 0.00011288269161013886\n",
      "|loss_test| 0.00014426582492887974\n",
      "|loss_test| 0.00010272492363583297\n",
      "|loss_test| 0.0001125097187468782\n",
      "|loss_test| 0.00011555157107068226\n",
      "|loss_test| 0.00786228571087122\n",
      "|loss_test| 0.00010546405974309891\n",
      "|loss_test| 0.00010596970241749659\n",
      "|loss_test| 0.007845435291528702\n",
      "|loss_test| 0.00012012491060886532\n",
      "|loss_test| 0.00011075138172600418\n",
      "|loss_test| 0.03127732500433922\n",
      "|loss_test| 0.00013244341243989766\n",
      "|loss_test| 0.062255315482616425\n",
      "|loss_test| 0.00013533138553611934\n",
      "|loss_test| 0.062404315918684006\n",
      "|loss_test| 0.00011005628039129078\n",
      "|loss_test| 0.00012658332707360387\n",
      "|loss_test| 0.00786998588591814\n",
      "|loss_test| 0.03118993155658245\n",
      "|loss_test| 0.007828425616025925\n",
      "|loss_test| 0.00011604426254052669\n",
      "|loss_test| 0.0001237257820321247\n",
      "|loss_test| 9.505904745310545e-05\n",
      "|loss_test| 0.0001086424890672788\n",
      "|loss_test| 9.747975855134428e-05\n",
      "|loss_test| 0.023335635662078857\n",
      "|loss_test| 0.015583986416459084\n",
      "|loss_test| 0.03899205103516579\n",
      "|loss_test| 0.007829928770661354\n",
      "|loss_test| 0.007870938628911972\n",
      "|loss_test| 0.00011286548397038132\n",
      "|loss_test| 0.007841069251298904\n",
      "|loss_test| 0.00785084068775177\n",
      "|loss_test| 0.00786752998828888\n",
      "|loss_test| 0.007833143696188927\n",
      "|loss_test| 7.344631740124896e-05\n",
      "|loss_test| 0.0001271921064471826\n",
      "|loss_test| 0.00784414354711771\n",
      "|loss_test| 0.0001147804141510278\n",
      "|loss_test| 0.00010794034460559487\n",
      "|loss_test| 0.00012018476991215721\n",
      "|loss_test| 0.00010857054439838976\n",
      "|loss_test| 0.00012698330101557076\n",
      "|loss_test| 0.007867143489420414\n",
      "|loss_test| 0.007837955839931965\n",
      "|loss_test| 0.00010942771768895909\n",
      "|loss_test| 0.007848166860640049\n",
      "|loss_test| 0.07023278623819351\n",
      "|loss_test| 0.01565413735806942\n",
      "|loss_test| 0.03897577151656151\n",
      "|loss_test| 0.00010721676517277956\n",
      "|loss_test| 9.280184167437255e-05\n",
      "|loss_test| 0.00012456192052923143\n",
      "|loss_test| 0.00013590438175015152\n",
      "|loss_test| 0.0001484550884924829\n",
      "|loss_test| 0.0001208442117786035\n",
      "|loss_test| 0.00011347141116857529\n",
      "|loss_test| 0.00010692557407310233\n",
      "|loss_test| 0.00011872431787196547\n",
      "|loss_test| 0.0001226771855726838\n",
      "|loss_test| 0.007875321432948112\n",
      "|loss_test| 9.327866428066045e-05\n",
      "|loss_test| 0.015570391900837421\n",
      "|loss_test| 0.007859250530600548\n",
      "|loss_test| 0.00786654930561781\n",
      "|loss_test| 0.00010528235725359991\n",
      "|loss_test| 0.007857009768486023\n",
      "|loss_test| 0.00012390145275276154\n",
      "|loss_test| 0.00783412903547287\n",
      "|loss_test| 0.000133578636450693\n",
      "|loss_test| 0.00010604473936837167\n",
      "|loss_test| 0.007836956530809402\n",
      "|loss_test| 0.015596415847539902\n",
      "|loss_test| 0.007889915257692337\n",
      "|loss_test| 0.00011584528692765161\n",
      "|loss_test| 0.00013137116911821067\n",
      "|loss_test| 0.00010319221473764628\n",
      "|loss_test| 0.007883094251155853\n",
      "|loss_test| 0.00786612369120121\n",
      "|loss_test| 0.0001173808122985065\n",
      "|loss_test| 0.00014108556206338108\n",
      "|loss_test| 0.00013425156066659838\n",
      "|loss_test| 0.007852697744965553\n",
      "|loss_test| 0.00010800384916365147\n",
      "|loss_test| 0.015592735260725021\n",
      "|loss_test| 0.015564320608973503\n",
      "|loss_test| 0.00012661097571253777\n",
      "|loss_test| 0.00011593071394599974\n",
      "|loss_test| 0.007890594191849232\n",
      "|loss_test| 0.01561293751001358\n",
      "|loss_test| 0.007859637960791588\n",
      "|loss_test| 0.00010939942148979753\n",
      "|loss_test| 0.03897029533982277\n",
      "|loss_test| 0.00787649117410183\n",
      "|loss_test| 0.00011351841385476291\n",
      "|loss_test| 0.007846842519938946\n",
      "|loss_test| 0.00011165184696437791\n",
      "|loss_test| 0.00011234523844905198\n",
      "|loss_test| 0.00010195549111813307\n",
      "|loss_test| 0.00012133071140851825\n",
      "|loss_test| 0.21060286462306976\n",
      "|loss_test| 0.015606236644089222\n",
      "|loss_test| 0.015619348734617233\n",
      "|loss_test| 0.0001278366835322231\n",
      "|loss_test| 0.00785661581903696\n",
      "|loss_test| 0.00010148352885153145\n",
      "|loss_test| 0.00016251203487627208\n",
      "|loss_test| 0.00013194374332670122\n",
      "|loss_test| 0.007876386865973473\n",
      "|loss_test| 0.00015153360436670482\n",
      "|loss_test| 0.031225157901644707\n",
      "|loss_test| 0.007868638262152672\n",
      "|loss_test| 0.0001279326097574085\n",
      "|loss_test| 9.451161895412952e-05\n",
      "|loss_test| 0.0001258509000763297\n",
      "|loss_test| 0.0001271852815989405\n",
      "|loss_test| 0.00011440902017056942\n",
      "|loss_test| 9.393635991727933e-05\n",
      "|loss_test| 0.00013651704648509622\n",
      "|loss_test| 0.0779050812125206\n",
      "|loss_test| 0.00787338800728321\n",
      "|loss_test| 0.007832465693354607\n",
      "|loss_test| 0.00010956486221402884\n",
      "|loss_test| 0.015556308440864086\n",
      "|loss_test| 0.00013812609540764242\n",
      "|loss_test| 0.00010655421647243202\n",
      "|loss_test| 0.00013346693594940007\n",
      "|loss_test| 9.887666965369135e-05\n",
      "|loss_test| 0.031222641468048096\n",
      "|loss_test| 0.00014673320401925594\n",
      "|loss_test| 0.00011358828487573192\n",
      "|loss_test| 0.031186949461698532\n",
      "|loss_test| 0.007862999103963375\n",
      "|loss_test| 0.0001123180118156597\n",
      "|loss_test| 0.007845805026590824\n",
      "|loss_test| 0.007862723432481289\n",
      "|loss_test| 0.007846714928746223\n",
      "|loss_test| 0.00011243291373830289\n",
      "|loss_test| 0.00013598189980257303\n",
      "|loss_test| 0.20282885432243347\n",
      "|loss_test| 0.0001409348624292761\n",
      "|loss_test| 0.00010811073298100382\n",
      "|loss_test| 0.00011119700502604246\n",
      "|loss_test| 0.007886212319135666\n",
      "|loss_test| 0.00011808686394942924\n",
      "|loss_test| 0.00012447562767192721\n",
      "|loss_test| 0.007867816835641861\n",
      "|loss_test| 0.01559472270309925\n",
      "|loss_test| 0.000113799782411661\n",
      "|loss_test| 0.00012343647540546954\n",
      "|loss_test| 0.00010459554323460907\n",
      "|loss_test| 0.00013751091319136322\n",
      "|loss_test| 0.007852940820157528\n",
      "|loss_test| 0.00012557822628878057\n",
      "|loss_test| 0.015581355430185795\n",
      "|loss_test| 0.0078550074249506\n",
      "|loss_test| 0.07016827911138535\n",
      "|loss_test| 0.015583276748657227\n",
      "|loss_test| 0.00010216036753263324\n",
      "|loss_test| 0.007867353036999702\n",
      "|loss_test| 9.451343066757545e-05\n",
      "|loss_test| 0.00012258595961611718\n",
      "|loss_test| 0.00012278868234716356\n",
      "|loss_test| 0.0001196001612697728\n",
      "|loss_test| 0.007863957434892654\n",
      "|loss_test| 0.0001372279948554933\n",
      "|loss_test| 0.0001257598923984915\n",
      "|loss_test| 9.457525447942317e-05\n",
      "|loss_test| 0.007827467285096645\n",
      "|loss_test| 0.00785348191857338\n",
      "|loss_test| 0.031184237450361252\n",
      "|loss_test| 0.0001430970150977373\n",
      "|loss_test| 0.00010954766912618652\n",
      "|loss_test| 0.007887355051934719\n",
      "|loss_test| 8.648067887406796e-05\n",
      "|loss_test| 0.00012323565897531807\n",
      "|loss_test| 0.0001284551981370896\n",
      "|loss_test| 0.00011236331192776561\n",
      "|loss_test| 0.007889866828918457\n",
      "|loss_test| 0.00012210864224471152\n",
      "|loss_test| 0.00786626897752285\n",
      "|loss_test| 0.007862217724323273\n",
      "|loss_test| 0.1949484795331955\n",
      "|loss_test| 0.0001391163532389328\n",
      "|loss_test| 0.00013603873958345503\n",
      "|loss_test| 0.0001291007356485352\n",
      "|loss_test| 0.00782937090843916\n",
      "|loss_test| 0.0389297790825367\n",
      "|loss_test| 0.00011606539192143828\n",
      "|loss_test| 0.00010344422480557114\n",
      "|loss_test| 0.023303229361772537\n",
      "|loss_test| 0.00013857887824997306\n",
      "|loss_test| 0.015607369132339954\n",
      "|loss_test| 0.00013711853534914553\n",
      "|loss_test| 0.00015073767281137407\n",
      "|loss_test| 0.00011517697566887364\n",
      "|loss_test| 0.00016186543507501483\n",
      "|loss_test| 0.00785423070192337\n",
      "|loss_test| 0.00013233363279141486\n",
      "|loss_test| 0.007858208380639553\n",
      "|loss_test| 0.00011462510155979544\n",
      "|loss_test| 9.626435348764062e-05\n",
      "|loss_test| 0.00011446865391917527\n",
      "|loss_test| 0.00013285140448715538\n",
      "|loss_test| 0.00013199637760408223\n",
      "|loss_test| 0.00010721336730057374\n",
      "|loss_test| 9.218804916599765e-05\n",
      "|loss_test| 0.00784340687096119\n",
      "|loss_test| 0.03895988687872887\n",
      "|loss_test| 0.00010769601067295298\n",
      "|loss_test| 0.00014699589519295841\n",
      "|loss_test| 0.007839604280889034\n",
      "|loss_test| 0.07015163451433182\n",
      "|loss_test| 0.0001422243076376617\n",
      "|loss_test| 0.00010621992259984836\n",
      "|loss_test| 0.015587742440402508\n",
      "|loss_test| 0.0078456811606884\n",
      "|loss_test| 0.007851822301745415\n",
      "|loss_test| 0.00013218182721175253\n",
      "|loss_test| 0.00012482222518883646\n",
      "|loss_test| 0.00784896221011877\n",
      "|loss_test| 0.01560396421700716\n",
      "|loss_test| 0.00011464029375929385\n",
      "|loss_test| 0.04670163616538048\n",
      "|loss_test| 0.007868016138672829\n",
      "|loss_test| 0.00012044899631291628\n",
      "|loss_test| 0.00012962463370058686\n",
      "|loss_test| 0.007887687534093857\n",
      "|loss_test| 0.00784918200224638\n",
      "|loss_test| 0.00013256390229798853\n",
      "|loss_test| 0.031192243099212646\n",
      "|loss_test| 0.007843739353120327\n",
      "|loss_test| 0.0001420061307726428\n",
      "|loss_test| 0.031174851581454277\n",
      "|loss_test| 0.07019338756799698\n",
      "|loss_test| 0.007858701050281525\n",
      "|loss_test| 0.0001162724438472651\n",
      "|loss_test| 0.00012600395712070167\n",
      "|loss_test| 0.0312078595161438\n",
      "|loss_test| 0.007840222679078579\n",
      "|loss_test| 9.71383269643411e-05\n",
      "|loss_test| 0.007838907651603222\n",
      "|loss_test| 0.00014474829367827624\n",
      "|loss_test| 0.007873964495956898\n",
      "|loss_test| 0.00010675513476599008\n",
      "|loss_test| 0.007831037975847721\n",
      "|loss_test| 0.0001416114391759038\n",
      "|loss_test| 0.00013905898958910257\n",
      "|loss_test| 0.01556334737688303\n",
      "|loss_test| 9.13976546144113e-05\n",
      "|loss_test| 0.00013632449554279447\n",
      "|loss_test| 0.0001265031169168651\n",
      "|loss_test| 9.695538028609008e-05\n",
      "|loss_test| 0.007853137329220772\n",
      "|loss_test| 0.0001337358553428203\n",
      "|loss_test| 0.007860338315367699\n",
      "|loss_test| 0.00010053154255729169\n",
      "|loss_test| 0.00014274631394073367\n",
      "|loss_test| 0.015550314448773861\n",
      "|loss_test| 0.007871556095778942\n",
      "|loss_test| 0.00014520311378873885\n",
      "|loss_test| 0.0001099122891901061\n",
      "|loss_test| 0.007825969718396664\n",
      "|loss_test| 0.00011973088840022683\n",
      "|loss_test| 0.007856258191168308\n",
      "|loss_test| 0.007855546660721302\n",
      "|loss_test| 0.007852612994611263\n",
      "|loss_test| 0.00011721804912667722\n",
      "|loss_test| 0.00013620490790344775\n",
      "|loss_test| 0.00011757288302760571\n",
      "|loss_test| 0.02337057515978813\n",
      "|loss_test| 0.007862661965191364\n",
      "|loss_test| 0.00012744072591885924\n",
      "|loss_test| 9.531739488011226e-05\n",
      "|loss_test| 0.007857369258999825\n",
      "|loss_test| 0.00785309262573719\n",
      "|loss_test| 0.007871587760746479\n",
      "|loss_test| 0.007839038036763668\n",
      "|loss_test| 0.04669100418686867\n",
      "|loss_test| 0.00012142320338170975\n",
      "|loss_test| 0.007883609272539616\n",
      "|loss_test| 0.00010090556315844879\n",
      "|loss_test| 0.00011695446301018819\n",
      "|loss_test| 0.015609696507453918\n",
      "|loss_test| 9.916962153511122e-05\n",
      "|loss_test| 0.015590440481901169\n",
      "|loss_test| 0.015601092018187046\n",
      "|loss_test| 0.03886733204126358\n",
      "|loss_test| 0.007846606895327568\n",
      "|loss_test| 0.007833016104996204\n",
      "|loss_test| 0.00012522007455118\n",
      "|loss_test| 0.00011220112355658785\n",
      "|loss_test| 0.015610841102898121\n",
      "|loss_test| 9.381123527418822e-05\n",
      "|loss_test| 0.00012298949877731502\n",
      "|loss_test| 0.007837699726223946\n",
      "|loss_test| 0.00010734364332165569\n",
      "|loss_test| 0.00010193861089646816\n",
      "|loss_test| 0.007850352674722672\n",
      "|loss_test| 0.00010685744928196073\n",
      "|loss_test| 0.007856784388422966\n",
      "|loss_test| 0.00012651325960177928\n",
      "|loss_test| 0.00010044410009868443\n",
      "|loss_test| 0.0001267336483579129\n",
      "|loss_test| 0.00011969098704867065\n",
      "|loss_test| 0.015579499304294586\n",
      "|loss_test| 0.00011509584146551788\n",
      "|loss_test| 0.00011500888649607077\n",
      "|loss_test| 0.00010996291530318558\n",
      "|loss_test| 0.00014358019689098\n",
      "|loss_test| 0.007867799140512943\n",
      "|loss_test| 0.0001248375920113176\n",
      "|loss_test| 0.00010804991325130686\n",
      "|loss_test| 0.00015021045692265034\n",
      "|loss_test| 0.00787738710641861\n",
      "|loss_test| 0.007869203574955463\n",
      "|loss_test| 0.10919256508350372\n",
      "|loss_test| 0.00011069159518228844\n",
      "|loss_test| 0.10124888271093369\n",
      "|loss_test| 0.015573843382298946\n",
      "|loss_test| 0.00012576658627949655\n",
      "|loss_test| 0.007845666259527206\n",
      "|loss_test| 0.00010976259363815188\n",
      "|loss_test| 0.007849498651921749\n",
      "|loss_test| 0.00013178520021028817\n",
      "|loss_test| 0.00010858560563065112\n",
      "|loss_test| 0.01559147797524929\n",
      "|loss_test| 0.007880068384110928\n",
      "|loss_test| 0.00010248175385640934\n",
      "|loss_test| 0.00012662552762776613\n",
      "|loss_test| 0.03124297223985195\n",
      "|loss_test| 0.007870680652558804\n",
      "|loss_test| 0.03893556818366051\n",
      "|loss_test| 0.00784574169665575\n",
      "|loss_test| 0.00012473433162085712\n",
      "|loss_test| 0.00012430004426278174\n",
      "|loss_test| 0.00012427900219336152\n",
      "|loss_test| 0.00010864828072953969\n",
      "|loss_test| 0.007858852855861187\n",
      "|loss_test| 0.00011498958338052034\n",
      "|loss_test| 0.0001165076027973555\n",
      "|loss_test| 9.429259080206975e-05\n",
      "|loss_test| 0.00014803549856878817\n",
      "|loss_test| 0.00785097200423479\n",
      "|loss_test| 0.007839939557015896\n",
      "|loss_test| 0.00011677952716127038\n",
      "|loss_test| 0.00785028375685215\n",
      "|loss_test| 0.0155738340690732\n",
      "|loss_test| 0.00010518757335375994\n",
      "|loss_test| 0.00012154800788266584\n",
      "|loss_test| 0.00011954097863053903\n",
      "|loss_test| 0.00011633387475740165\n",
      "|loss_test| 0.0001451916468795389\n",
      "|loss_test| 0.015600460581481457\n",
      "|loss_test| 0.00010544464748818427\n",
      "|loss_test| 0.00011700866161845624\n",
      "|loss_test| 0.015575462952256203\n",
      "|loss_test| 0.00011982711293967441\n",
      "|loss_test| 0.015631718561053276\n",
      "|loss_test| 0.007858010940253735\n",
      "|loss_test| 0.00013077254698146135\n",
      "|loss_test| 0.007856743410229683\n",
      "|loss_test| 0.00012441449507605284\n",
      "|loss_test| 0.00013031366688665003\n",
      "|loss_test| 0.00012015231186524034\n",
      "|loss_test| 0.00011964209988946095\n",
      "|loss_test| 0.00011748266115318984\n",
      "|loss_test| 0.015609621070325375\n",
      "|loss_test| 0.19504432380199432\n",
      "|loss_test| 0.007846619002521038\n",
      "|loss_test| 0.00011270995310042053\n",
      "|loss_test| 0.015561716631054878\n",
      "|loss_test| 0.007844285108149052\n",
      "|loss_test| 0.00014686955546494573\n",
      "|loss_test| 0.031207699328660965\n",
      "|loss_test| 0.00012890160724055022\n",
      "|loss_test| 0.007853073067963123\n",
      "|loss_test| 0.007853236980736256\n",
      "|loss_test| 0.00011416623601689935\n",
      "|loss_test| 0.00010446400847285986\n",
      "|loss_test| 0.03895300254225731\n",
      "|loss_test| 0.00011698438902385533\n",
      "|loss_test| 0.00011139330308651552\n",
      "|loss_test| 0.03895116597414017\n",
      "|loss_test| 0.015584397129714489\n",
      "|loss_test| 0.00013477123866323382\n",
      "|loss_test| 0.00011943309073103592\n",
      "|loss_test| 0.007858647033572197\n",
      "|loss_test| 0.00011207387433387339\n",
      "|loss_test| 0.00010476359602762386\n",
      "|loss_test| 0.007862191647291183\n",
      "|loss_test| 0.007835136726498604\n",
      "|loss_test| 0.0001462954969611019\n",
      "|loss_test| 0.039013080298900604\n",
      "|loss_test| 9.453149687033147e-05\n",
      "|loss_test| 0.007832261733710766\n",
      "|loss_test| 0.015599089674651623\n",
      "|loss_test| 0.015622502192854881\n",
      "|loss_test| 0.00012104030611226335\n",
      "|loss_test| 0.015602082014083862\n",
      "|loss_test| 0.00011356750474078581\n",
      "|loss_test| 0.00011219900625292212\n",
      "|loss_test| 0.01559438556432724\n",
      "|loss_test| 0.07017223536968231\n",
      "|loss_test| 0.015579239465296268\n",
      "|loss_test| 0.00014715582074131817\n",
      "|loss_test| 0.00011225443449802697\n",
      "|loss_test| 0.015597044490277767\n",
      "|loss_test| 0.000125095306430012\n",
      "|loss_test| 0.00012023559975204989\n",
      "|loss_test| 0.00012051701196469367\n",
      "|loss_test| 0.007860912941396236\n",
      "|loss_test| 0.00010729099449235946\n",
      "|loss_test| 0.02335003949701786\n",
      "|loss_test| 0.007862583734095097\n",
      "|loss_test| 0.00010972981544909999\n",
      "|loss_test| 0.00010398862650617957\n",
      "|loss_test| 0.00010226490849163383\n",
      "|loss_test| 0.00013239742838777602\n",
      "|loss_test| 0.00011904337588930503\n",
      "|loss_test| 0.031230326741933823\n",
      "|loss_test| 0.00011462314432719722\n",
      "|loss_test| 0.00014861347153782845\n",
      "|loss_test| 0.00012687942944467068\n",
      "|loss_test| 0.000122483164886944\n",
      "|loss_test| 0.007864734157919884\n",
      "|loss_test| 0.0001070922298822552\n",
      "|loss_test| 0.007855812087655067\n",
      "|loss_test| 0.00012812363274861127\n",
      "|loss_test| 0.00011153510422445834\n",
      "|loss_test| 0.015579280443489552\n",
      "|loss_test| 0.007877055555582047\n",
      "|loss_test| 0.00010337747517041862\n",
      "|loss_test| 0.00010030774865299463\n",
      "|loss_test| 0.0311789121478796\n",
      "|loss_test| 0.03898327052593231\n",
      "|loss_test| 0.1325390636920929\n",
      "|loss_test| 0.00010683467553462833\n",
      "|loss_test| 0.031245032325387\n",
      "|loss_test| 0.00010663201101124287\n",
      "|loss_test| 0.0001248094777110964\n",
      "|loss_test| 0.07015261054039001\n",
      "|loss_test| 0.0001429800468031317\n",
      "|loss_test| 0.00010343728354200721\n",
      "|loss_test| 0.00011794903548434377\n",
      "|loss_test| 0.007852614857256413\n",
      "|loss_test| 0.007888374850153923\n",
      "|loss_test| 0.0001361514878226444\n",
      "|loss_test| 0.00014650286175310612\n",
      "|loss_test| 0.00011183237802470103\n",
      "|loss_test| 0.00012204441009089351\n",
      "|loss_test| 0.00011811501462943852\n",
      "|loss_test| 0.015609304420650005\n",
      "|loss_test| 0.00010693673539208248\n",
      "|loss_test| 0.03895387798547745\n",
      "|loss_test| 0.00013411554391495883\n",
      "|loss_test| 0.03125632926821709\n",
      "|loss_test| 0.007832521572709084\n",
      "|loss_test| 0.00013045259402133524\n",
      "|loss_test| 0.00011329134576953948\n",
      "|loss_test| 0.00011715483560692519\n",
      "|loss_test| 0.00011994645319646224\n",
      "|loss_test| 0.00012725481064990163\n",
      "|loss_test| 0.00011137552792206407\n",
      "|loss_test| 0.007853244431316853\n",
      "|loss_test| 9.868550841929391e-05\n",
      "|loss_test| 0.015586763620376587\n",
      "|loss_test| 0.007842597551643848\n",
      "|loss_test| 0.00011522011482156813\n",
      "|loss_test| 0.00012288475409150124\n",
      "|loss_test| 0.00012415678065735847\n",
      "|loss_test| 0.015619976446032524\n",
      "|loss_test| 0.007866961881518364\n",
      "|loss_test| 0.007847974076867104\n",
      "|loss_test| 0.0001275060058105737\n",
      "|loss_test| 0.007853547111153603\n",
      "|loss_test| 0.015583507716655731\n",
      "|loss_test| 0.0001268488704226911\n",
      "|loss_test| 0.00010768275387817994\n",
      "|loss_test| 0.00010017085151048377\n",
      "|loss_test| 0.00011989930499112234\n",
      "|loss_test| 0.00012277507630642503\n",
      "|loss_test| 0.0001356709108222276\n",
      "|loss_test| 0.007856011390686035\n",
      "|loss_test| 0.00010884449875447899\n",
      "|loss_test| 0.00015078135766088963\n",
      "|loss_test| 0.007859569974243641\n",
      "|loss_test| 0.007862452417612076\n",
      "|loss_test| 0.023291096091270447\n",
      "|loss_test| 0.00011501212429720908\n",
      "|loss_test| 0.015607052482664585\n",
      "|loss_test| 0.00012396271631587297\n",
      "|loss_test| 0.00011501173139549792\n",
      "|loss_test| 0.0001170234609162435\n",
      "|loss_test| 0.015583399683237076\n",
      "|loss_test| 0.015598148107528687\n",
      "|loss_test| 0.00010917660256382078\n",
      "|loss_test| 0.04670261964201927\n",
      "|loss_test| 9.17381257750094e-05\n",
      "|loss_test| 0.00785843376070261\n",
      "|loss_test| 0.03903115913271904\n",
      "|loss_test| 0.00013785890769213438\n",
      "|loss_test| 0.007869306020438671\n",
      "|loss_test| 0.007859190925955772\n",
      "|loss_test| 0.007875808514654636\n",
      "|loss_test| 0.00011087155871791765\n",
      "|loss_test| 0.015613860450685024\n",
      "|loss_test| 0.00011224334593862295\n",
      "|loss_test| 0.00010333136015105993\n",
      "|loss_test| 0.00011924836144316941\n",
      "|loss_test| 0.00011766335228458047\n",
      "|loss_test| 0.00014807289699092507\n",
      "|loss_test| 0.00010239687981083989\n",
      "|loss_test| 0.007850347086787224\n",
      "|loss_test| 0.0001184980064863339\n",
      "|loss_test| 0.00011197017738595605\n",
      "|loss_test| 0.007853042334318161\n",
      "|loss_test| 0.00011896480282302946\n",
      "|loss_test| 0.00010204274440184236\n",
      "|loss_test| 0.01561882346868515\n",
      "|loss_test| 0.00010555832704994828\n",
      "|loss_test| 0.007863212376832962\n",
      "|loss_test| 0.00012746357242576778\n",
      "|loss_test| 0.0001172461052192375\n",
      "|loss_test| 0.00011353615263942629\n",
      "|loss_test| 0.007854308933019638\n",
      "|loss_test| 0.00011466976866358891\n",
      "|loss_test| 0.00011283831554464996\n",
      "|loss_test| 0.007872174493968487\n",
      "|loss_test| 0.007839437574148178\n",
      "|loss_test| 0.00011910486500710249\n",
      "|loss_test| 0.0001298341667279601\n",
      "|loss_test| 0.00014902607654221356\n",
      "|loss_test| 0.01560627669095993\n",
      "|loss_test| 0.0001337177091045305\n",
      "|loss_test| 0.007853480987250805\n",
      "|loss_test| 0.00010691162606235594\n",
      "|loss_test| 0.00010886888048844412\n",
      "|loss_test| 0.0001201653722091578\n",
      "|loss_test| 0.03904172405600548\n",
      "|loss_test| 0.007863512262701988\n",
      "|loss_test| 0.0001214335352415219\n",
      "|loss_test| 0.00010591311729513109\n",
      "|loss_test| 0.13260667026042938\n",
      "|loss_test| 0.00013448996469378471\n",
      "|loss_test| 0.00014311849372461438\n",
      "|loss_test| 9.678163041826338e-05\n",
      "|loss_test| 0.00011981102579738945\n",
      "|loss_test| 0.007854561321437359\n",
      "|loss_test| 0.015594042837619781\n",
      "|loss_test| 0.00014211121015250683\n",
      "|loss_test| 0.00010382778418716043\n",
      "|loss_test| 9.765707363840193e-05\n",
      "|loss_test| 0.0078510083258152\n",
      "|loss_test| 0.0001235838426509872\n",
      "|loss_test| 0.00011236850696150213\n",
      "|loss_test| 0.00012233098095748574\n",
      "|loss_test| 0.00010033709986601025\n",
      "|loss_test| 0.007837551645934582\n",
      "|loss_test| 0.00013777229469269514\n",
      "|loss_test| 0.00787219125777483\n",
      "|loss_test| 0.023368896916508675\n",
      "|loss_test| 0.00011598897253861651\n",
      "|loss_test| 0.00011647374049061909\n",
      "|loss_test| 0.007879971526563168\n",
      "|loss_test| 0.015602057799696922\n",
      "|loss_test| 0.038958050310611725\n",
      "|loss_test| 0.00012866046745330095\n",
      "|loss_test| 0.00011302709026494995\n",
      "|loss_test| 0.00011421574890846387\n",
      "|loss_test| 0.007882371544837952\n",
      "|loss_test| 0.00012066934868926182\n",
      "|loss_test| 0.00010009610559791327\n",
      "|loss_test| 0.00013909526751376688\n",
      "|loss_test| 0.00014354847371578217\n",
      "|loss_test| 0.015576541423797607\n",
      "|loss_test| 0.01557591836899519\n",
      "|loss_test| 0.0001372791302856058\n",
      "|loss_test| 0.00011687744699884206\n",
      "|loss_test| 0.00013081973884254694\n",
      "|loss_test| 0.00011312823335174471\n",
      "|loss_test| 0.00011014976917067543\n",
      "|loss_test| 0.0001194296419271268\n",
      "|loss_test| 0.00012870028149336576\n",
      "|loss_test| 0.00010169767483603209\n",
      "|loss_test| 0.031220022588968277\n",
      "|loss_test| 0.015588803216814995\n",
      "|loss_test| 0.038958027958869934\n",
      "|loss_test| 0.00786739680916071\n",
      "|loss_test| 0.00011606975749600679\n",
      "|loss_test| 0.039005402475595474\n",
      "|loss_test| 0.01563250459730625\n",
      "|loss_test| 0.0001313378452323377\n",
      "|loss_test| 0.0001275028334930539\n",
      "|loss_test| 0.007870284840464592\n",
      "|loss_test| 0.00011415664630476385\n",
      "|loss_test| 0.00016352374223060906\n",
      "|loss_test| 0.00010607315925881267\n",
      "|loss_test| 0.00010396854486316442\n",
      "|loss_test| 0.00010589369048830122\n",
      "|loss_test| 0.00011789212294388562\n",
      "|loss_test| 0.00012163962674094364\n",
      "|loss_test| 0.00011441406968515366\n",
      "|loss_test| 0.007834106683731079\n",
      "|loss_test| 0.00012281315866857767\n",
      "|loss_test| 0.00011005353735527024\n",
      "|loss_test| 0.0001265670289285481\n",
      "|loss_test| 0.0001083587558241561\n",
      "|loss_test| 0.0156066520139575\n",
      "|loss_test| 0.0001290163054363802\n",
      "|loss_test| 0.007845588959753513\n",
      "|loss_test| 0.007857708260416985\n",
      "|loss_test| 0.00784876849502325\n",
      "|loss_test| 0.015600334852933884\n",
      "|loss_test| 0.03897429630160332\n",
      "|loss_test| 0.00010628777090460062\n",
      "|loss_test| 0.00011281772458460182\n",
      "|loss_test| 0.03897767886519432\n",
      "|loss_test| 0.00010007284436142072\n",
      "|loss_test| 0.038989413529634476\n",
      "|loss_test| 0.007837832905352116\n",
      "|loss_test| 0.0001049803031492047\n",
      "|loss_test| 0.00011561260907910764\n",
      "|loss_test| 0.00012554004206322134\n",
      "|loss_test| 0.007842499762773514\n",
      "|loss_test| 0.00783465150743723\n",
      "|loss_test| 0.0001134630583692342\n",
      "|loss_test| 0.00784839317202568\n",
      "|loss_test| 0.0001231713395100087\n",
      "|loss_test| 0.031236276030540466\n",
      "|loss_test| 0.0001477334153605625\n",
      "|loss_test| 0.00013486713578458875\n",
      "|loss_test| 0.00011303336941637099\n",
      "|loss_test| 0.007870858535170555\n",
      "|loss_test| 0.00012239957868587226\n",
      "|loss_test| 0.00011984032607870176\n",
      "|loss_test| 0.007870280183851719\n",
      "|loss_test| 0.00011633158283075318\n",
      "|loss_test| 0.007841262966394424\n",
      "|loss_test| 0.00010813328844960779\n",
      "|loss_test| 8.516598609276116e-05\n",
      "|loss_test| 0.00012243328092154115\n",
      "|loss_test| 0.007858725264668465\n",
      "|loss_test| 0.0001173956407001242\n",
      "|loss_test| 0.0001376433065161109\n",
      "|loss_test| 0.00011843226820928976\n",
      "|loss_test| 0.007904496043920517\n",
      "|loss_test| 0.00010043166548712179\n",
      "|loss_test| 0.007837876677513123\n",
      "|loss_test| 0.00786654558032751\n",
      "|loss_test| 0.00011027710570488125\n",
      "|loss_test| 0.0001118063009926118\n",
      "|loss_test| 0.00010116593330167234\n",
      "|loss_test| 0.00787484459578991\n",
      "|loss_test| 8.0044825153891e-05\n",
      "|loss_test| 0.007852915674448013\n",
      "|loss_test| 0.00011758733307942748\n",
      "|loss_test| 0.00010284782183589414\n",
      "|loss_test| 0.07017964869737625\n",
      "|loss_test| 0.007861245423555374\n",
      "|loss_test| 9.45872743614018e-05\n",
      "|loss_test| 0.046659015119075775\n",
      "|loss_test| 0.015588108450174332\n",
      "|loss_test| 0.0001072596205631271\n",
      "|loss_test| 0.00011065573198720813\n",
      "|loss_test| 0.007850844413042068\n",
      "|loss_test| 0.007852556183934212\n",
      "|loss_test| 0.007872533984482288\n",
      "|loss_test| 0.00014089301112107933\n",
      "|loss_test| 0.0001123181646107696\n",
      "|loss_test| 0.0312034972012043\n",
      "|loss_test| 0.00011832042946480215\n",
      "|loss_test| 0.00014014512998983264\n",
      "|loss_test| 0.015595887787640095\n",
      "|loss_test| 8.386288391193375e-05\n",
      "|loss_test| 0.00786670297384262\n",
      "|loss_test| 0.0001125350026995875\n",
      "|loss_test| 0.0001111018646042794\n",
      "|loss_test| 0.00011932526831515133\n",
      "|loss_test| 0.007849915884435177\n",
      "|loss_test| 0.00013627814769279212\n",
      "|loss_test| 0.015577653422951698\n",
      "|loss_test| 0.00014534160436596721\n",
      "|loss_test| 0.00011010225716745481\n",
      "|loss_test| 0.007842319086194038\n",
      "|loss_test| 0.00014837563503533602\n",
      "|loss_test| 9.618287003831938e-05\n",
      "|loss_test| 0.00010917901818174869\n",
      "|loss_test| 0.00010248884063912556\n",
      "|loss_test| 0.03894495218992233\n",
      "|loss_test| 0.00010883554932661355\n",
      "|loss_test| 0.00015885659377090633\n",
      "|loss_test| 9.590212721377611e-05\n",
      "|loss_test| 0.00012648884148802608\n",
      "|loss_test| 0.00016203949053306133\n",
      "|loss_test| 0.00011930646724067628\n",
      "|loss_test| 0.0001268148043891415\n",
      "|loss_test| 0.0001140414024121128\n",
      "|loss_test| 0.07017181813716888\n",
      "|loss_test| 0.00011045921564800665\n",
      "|loss_test| 0.00013134935579728335\n",
      "|loss_test| 0.00014553809887729585\n",
      "|loss_test| 0.00013652605412062258\n",
      "|loss_test| 0.007865650579333305\n",
      "|loss_test| 0.015580440871417522\n",
      "|loss_test| 0.00014182057930156589\n",
      "|loss_test| 0.0001560471428092569\n",
      "|loss_test| 0.00785027164965868\n",
      "|loss_test| 0.00012755831994581968\n",
      "|loss_test| 0.007856584154069424\n",
      "|loss_test| 0.007846369408071041\n",
      "|loss_test| 0.00015681931108701974\n",
      "|loss_test| 0.04668109118938446\n",
      "|loss_test| 0.00011542653373908252\n",
      "|loss_test| 0.00786533858627081\n",
      "|loss_test| 0.0001228855544468388\n",
      "|loss_test| 0.00012228259583935142\n",
      "|loss_test| 0.0001152316908701323\n",
      "|loss_test| 0.00012387071910779923\n",
      "|loss_test| 0.007853011600673199\n",
      "|loss_test| 0.015562091954052448\n",
      "|loss_test| 0.00011999066919088364\n",
      "|loss_test| 0.00010355336416978389\n",
      "|loss_test| 0.00010389326780568808\n",
      "|loss_test| 0.0001196868033730425\n",
      "|loss_test| 0.00012169616820756346\n",
      "|loss_test| 0.007884606719017029\n",
      "|loss_test| 0.12481360882520676\n",
      "|loss_test| 0.00011204921611351892\n",
      "|loss_test| 0.007877844385802746\n",
      "|loss_test| 0.0001269238709937781\n",
      "|loss_test| 0.07024651020765305\n",
      "|loss_test| 0.00011678159353323281\n",
      "|loss_test| 0.0001296232221648097\n",
      "|loss_test| 0.007863379083573818\n",
      "|loss_test| 0.00014103908324614167\n",
      "|loss_test| 0.2963034212589264\n",
      "|loss_test| 0.03125472739338875\n",
      "|loss_test| 0.007844675332307816\n",
      "|loss_test| 0.00012745305139105767\n",
      "|loss_test| 0.00010425756045151502\n",
      "|loss_test| 0.00011955520312767476\n",
      "|loss_test| 0.00783882662653923\n",
      "|loss_test| 0.00011899582023033872\n",
      "|loss_test| 0.007865022867918015\n",
      "|loss_test| 0.031199706718325615\n",
      "|loss_test| 0.007841412909328938\n",
      "|loss_test| 0.00012770415924023837\n",
      "|loss_test| 0.015603218227624893\n",
      "|loss_test| 0.00013380841119214892\n",
      "|loss_test| 0.00015690240252297372\n",
      "|loss_test| 0.00014602119335904717\n",
      "|loss_test| 0.007850590161979198\n",
      "|loss_test| 0.031212903559207916\n",
      "|loss_test| 0.007842584513127804\n",
      "|loss_test| 0.0001054763633874245\n",
      "|loss_test| 0.007872804999351501\n",
      "|loss_test| 0.00013229915930423886\n",
      "|loss_test| 0.031250301748514175\n",
      "|loss_test| 0.00013061671052128077\n",
      "|loss_test| 0.007848137058317661\n",
      "|loss_test| 0.01561305858194828\n",
      "|loss_test| 0.007874895818531513\n",
      "|loss_test| 0.0001022127689793706\n",
      "|loss_test| 0.00013429475075099617\n",
      "|loss_test| 0.00010634765203576535\n",
      "|loss_test| 0.00012832098582293838\n",
      "|loss_test| 0.007853556424379349\n",
      "|loss_test| 0.031200995668768883\n",
      "|loss_test| 0.01564040780067444\n",
      "|loss_test| 0.007852020673453808\n",
      "|loss_test| 0.00012763361155521125\n",
      "|loss_test| 0.015603134408593178\n",
      "|loss_test| 0.007835755124688148\n",
      "|loss_test| 0.00010374830162618309\n",
      "|loss_test| 0.00013067678082734346\n",
      "|loss_test| 0.007864751853048801\n",
      "|loss_test| 0.00013134957407601178\n",
      "|loss_test| 0.00010895341983996332\n",
      "|loss_test| 0.007874826900660992\n",
      "|loss_test| 0.00011645172344287857\n",
      "|loss_test| 0.00011437378270784393\n",
      "|loss_test| 0.0001351694663753733\n",
      "|loss_test| 0.038974862545728683\n",
      "|loss_test| 0.007850555703043938\n",
      "|loss_test| 0.015572957694530487\n",
      "|loss_test| 0.00010045445378636941\n",
      "|loss_test| 0.007854518480598927\n",
      "|loss_test| 0.007861355319619179\n",
      "|loss_test| 0.007841250859200954\n",
      "|loss_test| 0.007878672331571579\n",
      "|loss_test| 0.00013169957674108446\n",
      "|loss_test| 0.00013040867634117603\n",
      "|loss_test| 0.046708639711141586\n",
      "|loss_test| 0.007871255278587341\n",
      "|loss_test| 0.0001264961319975555\n",
      "|loss_test| 0.039013464003801346\n",
      "|loss_test| 0.00012955081183463335\n",
      "|loss_test| 0.007836796343326569\n",
      "|loss_test| 0.00011145720782224089\n",
      "|loss_test| 0.00013018358731642365\n",
      "|loss_test| 0.00012567082012537867\n",
      "|loss_test| 0.00011438952060416341\n",
      "|loss_test| 0.00012105660425731912\n",
      "|loss_test| 0.0001429379335604608\n",
      "|loss_test| 0.007855072617530823\n",
      "|loss_test| 0.007874716073274612\n",
      "|loss_test| 0.031228045001626015\n",
      "|loss_test| 0.00010580792149994522\n",
      "|loss_test| 0.0001166918664239347\n",
      "|loss_test| 0.00012641919602174312\n",
      "|loss_test| 9.451455844100565e-05\n",
      "|loss_test| 0.00013957268674857914\n",
      "|loss_test| 0.03895077109336853\n",
      "|loss_test| 0.00012754290946759284\n",
      "|loss_test| 0.03889459744095802\n",
      "|loss_test| 0.015617810189723969\n",
      "|loss_test| 0.015569357201457024\n",
      "|loss_test| 0.015640536323189735\n",
      "|loss_test| 0.00010751956870080903\n",
      "|loss_test| 0.00010231113265035674\n",
      "|loss_test| 0.007839104160666466\n",
      "|loss_test| 0.0001236452371813357\n",
      "|loss_test| 0.007867123000323772\n",
      "|loss_test| 0.00011309435649309307\n",
      "|loss_test| 9.934569243341684e-05\n",
      "|loss_test| 0.007858983241021633\n",
      "|loss_test| 0.07792533189058304\n",
      "|loss_test| 0.00012296164641156793\n",
      "|loss_test| 0.00010771178494906053\n",
      "|loss_test| 0.00013292839867062867\n",
      "|loss_test| 0.007860616780817509\n",
      "|loss_test| 9.440936264581978e-05\n",
      "|loss_test| 0.0001221558777615428\n",
      "|loss_test| 0.00788569450378418\n",
      "|loss_test| 0.000115171518700663\n",
      "|loss_test| 0.00013384988415054977\n",
      "|loss_test| 0.00010634372301865369\n",
      "|loss_test| 0.00012567464727908373\n",
      "|loss_test| 0.00011233856639591977\n",
      "|loss_test| 0.00011847355926875025\n",
      "|loss_test| 0.0001265650789719075\n",
      "|loss_test| 0.0001075115505955182\n",
      "|loss_test| 0.015635447576642036\n",
      "|loss_test| 0.00010664379806257784\n",
      "|loss_test| 0.00011748856923077255\n",
      "|loss_test| 0.00012431075447238982\n",
      "|loss_test| 0.00011974941298831254\n",
      "|loss_test| 0.00785287655889988\n",
      "|loss_test| 0.0001229179324582219\n",
      "|loss_test| 0.00014147648471407592\n",
      "|loss_test| 0.00010820497845998034\n",
      "|loss_test| 0.00011336331954225898\n",
      "|loss_test| 0.00012396892998367548\n",
      "|loss_test| 0.007845108397305012\n",
      "|loss_test| 0.0001427348906872794\n",
      "|loss_test| 0.015575893223285675\n",
      "|loss_test| 0.00011688671656884253\n",
      "|loss_test| 0.00011260248720645905\n",
      "|loss_test| 0.007854164578020573\n",
      "|loss_test| 0.0001344672782579437\n",
      "|loss_test| 0.00782801304012537\n",
      "|loss_test| 0.1950991153717041\n",
      "|loss_test| 0.00012101681204512715\n",
      "|loss_test| 0.00011423120304243639\n",
      "|loss_test| 0.00013163569383323193\n",
      "|loss_test| 9.91262641036883e-05\n",
      "|loss_test| 0.00013416628644336015\n",
      "|loss_test| 0.0001486942928750068\n",
      "|loss_test| 0.007850577123463154\n",
      "|loss_test| 0.00010605310671962798\n",
      "|loss_test| 0.007846878841519356\n",
      "|loss_test| 0.00012975576100870967\n",
      "|loss_test| 0.015594357624650002\n",
      "|loss_test| 9.000214049592614e-05\n",
      "|loss_test| 0.007877640426158905\n",
      "|loss_test| 0.00012983137276023626\n",
      "|loss_test| 0.00010764000762719661\n",
      "|loss_test| 0.00011613294191192836\n",
      "|loss_test| 0.0078518595546484\n",
      "|loss_test| 0.015591686591506004\n",
      "|loss_test| 0.00014030092279426754\n",
      "|loss_test| 0.1950954645872116\n",
      "|loss_test| 0.007834106683731079\n",
      "|loss_test| 0.00010827140795299783\n",
      "|loss_test| 0.007893373258411884\n",
      "|loss_test| 0.00012485377374105155\n",
      "|loss_test| 0.0001342891773674637\n",
      "|loss_test| 0.007856703363358974\n",
      "|loss_test| 0.0001574515044922009\n",
      "|loss_test| 0.000108594264020212\n",
      "|loss_test| 0.015623685903847218\n",
      "|loss_test| 0.00010183094855165109\n",
      "|loss_test| 0.031221406534314156\n",
      "|loss_test| 0.00786848645657301\n",
      "|loss_test| 0.00011730226106010377\n",
      "|loss_test| 0.007870623841881752\n",
      "|loss_test| 0.007869673892855644\n",
      "|loss_test| 9.614093869458884e-05\n",
      "|loss_test| 8.257239824160933e-05\n",
      "|loss_test| 0.00012531505490187556\n",
      "|loss_test| 0.00012603348295670003\n",
      "|loss_test| 0.0001403172209393233\n",
      "|loss_test| 0.007853114977478981\n",
      "|loss_test| 0.00013412100088316947\n",
      "|loss_test| 0.07800737768411636\n",
      "|loss_test| 9.246218542102724e-05\n",
      "|loss_test| 0.00011356585309840739\n",
      "|loss_test| 0.0001116455823648721\n",
      "|loss_test| 0.0001259775017388165\n",
      "|loss_test| 0.1950068473815918\n",
      "|loss_test| 0.0001030012354021892\n",
      "|loss_test| 0.0001359138695988804\n",
      "|loss_test| 0.007850762456655502\n",
      "|loss_test| 0.00011662684846669436\n",
      "|loss_test| 0.00010221902630291879\n",
      "|loss_test| 0.00011006748536601663\n",
      "|loss_test| 0.12477967888116837\n",
      "|loss_test| 0.00011961904965573922\n",
      "|loss_test| 0.00014325397205539048\n",
      "|loss_test| 0.007891158573329449\n",
      "|loss_test| 0.00010504671081434935\n",
      "|loss_test| 0.015595484524965286\n",
      "|loss_test| 0.0001270615466637537\n",
      "|loss_test| 0.007844031788408756\n",
      "|loss_test| 0.007822999730706215\n",
      "|loss_test| 0.00012512534158304334\n",
      "|loss_test| 0.00011569634079933167\n",
      "|loss_test| 0.00014093764184508473\n",
      "|loss_test| 0.00011642031313385814\n",
      "|loss_test| 0.00012327005970291793\n",
      "|loss_test| 0.00013169967860449106\n",
      "|loss_test| 9.908158972393721e-05\n",
      "|loss_test| 0.007864361628890038\n",
      "|loss_test| 0.00012991426046937704\n",
      "|loss_test| 0.007850440219044685\n",
      "|loss_test| 0.007849322631955147\n",
      "|loss_test| 0.00012800400145351887\n",
      "|loss_test| 0.00011402818199712783\n",
      "|loss_test| 0.00012184135994175449\n",
      "|loss_test| 0.0001299926807405427\n",
      "|loss_test| 0.11669427156448364\n",
      "|loss_test| 0.007855185307562351\n",
      "|loss_test| 0.007845602929592133\n",
      "|loss_test| 0.031205907464027405\n",
      "|loss_test| 0.023352157324552536\n",
      "|loss_test| 0.03122098371386528\n",
      "|loss_test| 0.007851296104490757\n",
      "|loss_test| 9.722109098220244e-05\n",
      "|loss_test| 0.00010775904229376465\n",
      "|loss_test| 0.00010663999273674563\n",
      "|loss_test| 0.023335624486207962\n",
      "|loss_test| 9.052485984284431e-05\n",
      "|loss_test| 0.038963962346315384\n",
      "|loss_test| 0.015599040314555168\n",
      "|loss_test| 0.00012006225006189197\n",
      "|loss_test| 0.00785589125007391\n",
      "|loss_test| 0.00010698652477003634\n",
      "|loss_test| 0.00011977779649896547\n",
      "|loss_test| 0.00011555508535820991\n",
      "|loss_test| 0.00012253550812602043\n",
      "|loss_test| 0.0001026064419420436\n",
      "|loss_test| 0.0001518622157163918\n",
      "|loss_test| 0.00011718478344846517\n",
      "|loss_test| 0.07021673768758774\n",
      "|loss_test| 0.007845821790397167\n",
      "|loss_test| 0.0001081263690139167\n",
      "|loss_test| 0.0001113017788156867\n",
      "|loss_test| 0.00011791771976277232\n",
      "|loss_test| 0.0001358571753371507\n",
      "|loss_test| 0.015606839209794998\n",
      "|loss_test| 0.00010309097706340253\n",
      "|loss_test| 0.03108115866780281\n",
      "|loss_test| 0.015604191459715366\n",
      "|loss_test| 0.00011750208796001971\n",
      "|loss_test| 0.00010750129877123982\n",
      "|loss_test| 0.0001389526587445289\n",
      "|loss_test| 0.038962699472904205\n",
      "|loss_test| 0.00011360128701198846\n",
      "|loss_test| 0.007839423604309559\n",
      "|loss_test| 0.00013245310401543975\n",
      "|loss_test| 0.00011407758574932814\n",
      "|loss_test| 0.00010437572200316936\n",
      "|loss_test| 0.00012592555140145123\n",
      "|loss_test| 0.00014959636610001326\n",
      "|loss_test| 0.007856630720198154\n",
      "|loss_test| 0.00011550425551831722\n",
      "|loss_test| 0.0001223270082846284\n",
      "|loss_test| 0.00013830150419380516\n",
      "|loss_test| 0.00010508808918530121\n",
      "|loss_test| 0.00012127470836276188\n",
      "|loss_test| 0.007852189242839813\n",
      "|loss_test| 0.0001068574856617488\n",
      "|loss_test| 0.007853440940380096\n",
      "|loss_test| 0.00011715409345924854\n",
      "|loss_test| 0.0001113891412387602\n",
      "|loss_test| 0.00784597359597683\n",
      "|loss_test| 0.00011957428796449676\n",
      "|loss_test| 0.00017497972294222564\n",
      "|loss_test| 0.00010395768185844645\n",
      "|loss_test| 0.00011038334923796356\n",
      "|loss_test| 0.07024835050106049\n",
      "|loss_test| 0.007834289222955704\n",
      "|loss_test| 0.1480967402458191\n",
      "|loss_test| 0.00012277468340471387\n",
      "|loss_test| 0.00010528468556003645\n",
      "|loss_test| 0.007828808389604092\n",
      "|loss_test| 0.00014185519830789417\n",
      "|loss_test| 0.00788162462413311\n",
      "|loss_test| 0.0001247926993528381\n",
      "|loss_test| 0.00010902510985033587\n",
      "|loss_test| 9.974835120374337e-05\n",
      "|loss_test| 0.00012726765999104828\n",
      "|loss_test| 0.00010419028694741428\n",
      "|loss_test| 0.007842079736292362\n",
      "|loss_test| 0.00011421147064538673\n",
      "|loss_test| 0.007875842973589897\n",
      "|loss_test| 0.007862580940127373\n",
      "|loss_test| 0.007860202342271805\n",
      "|loss_test| 0.031194739043712616\n",
      "|loss_test| 0.00012650949065573514\n",
      "|loss_test| 0.00014048648881725967\n",
      "|loss_test| 0.007846014574170113\n",
      "|loss_test| 0.0001124958653235808\n",
      "|loss_test| 0.015568993985652924\n",
      "|loss_test| 0.007839709520339966\n",
      "|loss_test| 0.00785814505070448\n",
      "|loss_test| 0.038977183401584625\n",
      "|loss_test| 0.00011334008740959689\n",
      "|loss_test| 0.00788439903408289\n",
      "|loss_test| 0.00788026675581932\n",
      "|loss_test| 0.00785162765532732\n",
      "|loss_test| 0.0078321173787117\n",
      "|loss_test| 0.00011277181329205632\n",
      "|loss_test| 0.038964930921792984\n",
      "|loss_test| 0.00011405873374314979\n",
      "|loss_test| 0.007836357690393925\n",
      "|loss_test| 0.00012644306116271764\n",
      "|loss_test| 0.00011896278010681272\n",
      "|loss_test| 0.007856437936425209\n",
      "|loss_test| 0.007840397767722607\n",
      "|loss_test| 0.00010168112203245983\n",
      "|loss_test| 0.00013976727495901287\n",
      "|loss_test| 0.0001100640365621075\n",
      "|loss_test| 0.07795701920986176\n",
      "|loss_test| 0.02333897352218628\n",
      "|loss_test| 0.007881425321102142\n",
      "|loss_test| 0.000110547014628537\n",
      "|loss_test| 0.007849905639886856\n",
      "|loss_test| 0.015579898841679096\n",
      "|loss_test| 0.031216954812407494\n",
      "|loss_test| 9.75488219410181e-05\n",
      "|loss_test| 0.00014114781515672803\n",
      "|loss_test| 0.0001222308783326298\n",
      "|loss_test| 0.007860646583139896\n",
      "|loss_test| 0.007849324494600296\n",
      "|loss_test| 0.00010885641677305102\n",
      "|loss_test| 0.015592601150274277\n",
      "|loss_test| 0.00010808322986122221\n",
      "|loss_test| 0.0001342112955171615\n",
      "|loss_test| 0.00014904438285157084\n",
      "|loss_test| 0.007859990000724792\n",
      "|loss_test| 0.00010648294119164348\n",
      "|loss_test| 0.00012475333642214537\n",
      "|loss_test| 0.00011935980000998825\n",
      "|loss_test| 0.00010095212928717956\n",
      "|loss_test| 0.00014346832176670432\n",
      "|loss_test| 0.00013403061893768609\n",
      "|loss_test| 0.007867870852351189\n",
      "|loss_test| 0.00011473576887510717\n",
      "|loss_test| 0.00011314944276819006\n",
      "|loss_test| 0.00783692579716444\n",
      "|loss_test| 0.007847591303288937\n",
      "|loss_test| 0.015580281615257263\n",
      "|loss_test| 0.007854127325117588\n",
      "|loss_test| 0.0001131026801886037\n",
      "|loss_test| 0.007842307910323143\n",
      "|loss_test| 0.007878601551055908\n",
      "|loss_test| 0.00014838887727819383\n",
      "|loss_test| 0.015658482909202576\n",
      "|loss_test| 0.00012028180935885757\n",
      "|loss_test| 0.007874671369791031\n",
      "|loss_test| 0.00010713150550145656\n",
      "|loss_test| 0.023348640650510788\n",
      "|loss_test| 0.00011147114855702966\n",
      "|loss_test| 0.00010557099449215457\n",
      "|loss_test| 0.0001279900607187301\n",
      "|loss_test| 0.00011523740249685943\n",
      "|loss_test| 0.00011977761460002512\n",
      "|loss_test| 0.007860243320465088\n",
      "|loss_test| 0.00017062280676327646\n",
      "|loss_test| 0.00012201487697893754\n",
      "|loss_test| 0.07019849866628647\n",
      "|loss_test| 0.00012017735571134835\n",
      "|loss_test| 0.007864466868340969\n",
      "|loss_test| 0.00014712831762153655\n",
      "|loss_test| 0.00010860856855288148\n",
      "|loss_test| 0.007856959477066994\n",
      "|loss_test| 0.07017258554697037\n",
      "|loss_test| 0.00011210005322936922\n",
      "|loss_test| 0.007873276248574257\n",
      "|loss_test| 0.007845045998692513\n",
      "|loss_test| 9.982957999454811e-05\n",
      "|loss_test| 0.00012772955233231187\n",
      "|loss_test| 0.0001576244249008596\n",
      "|loss_test| 0.00014146024477668107\n",
      "|loss_test| 0.007869579829275608\n",
      "|loss_test| 0.0001282016164623201\n",
      "|loss_test| 0.00011231035750824958\n",
      "|loss_test| 9.43913619266823e-05\n",
      "|loss_test| 0.00011518222163431346\n",
      "|loss_test| 0.00013752657105214894\n",
      "|loss_test| 0.07796255499124527\n",
      "|loss_test| 0.00011682286276482046\n",
      "|loss_test| 0.12482109665870667\n",
      "|loss_test| 0.007845140062272549\n",
      "|loss_test| 0.00782968383282423\n",
      "|loss_test| 0.007848219946026802\n",
      "|loss_test| 9.865233732853085e-05\n",
      "|loss_test| 0.00012557904119603336\n",
      "|loss_test| 0.03895081952214241\n",
      "|loss_test| 0.07789742946624756\n",
      "|loss_test| 0.007840009406208992\n",
      "|loss_test| 0.00014917354565113783\n",
      "|loss_test| 0.031192658469080925\n",
      "|loss_test| 0.0001085889816749841\n",
      "|loss_test| 0.00012390839401632547\n",
      "|loss_test| 0.00011525121954036877\n",
      "|loss_test| 0.0001207074528792873\n",
      "|loss_test| 0.00011820487270597368\n",
      "|loss_test| 0.00010890266275964677\n",
      "|loss_test| 0.00014892690523993224\n",
      "|loss_test| 0.00010484203812666237\n",
      "|loss_test| 0.00010681991261662915\n",
      "|loss_test| 0.007841686718165874\n",
      "|loss_test| 0.00011521065607666969\n",
      "|loss_test| 0.00011065795843023807\n",
      "|loss_test| 0.07782424241304398\n",
      "|loss_test| 0.039010465145111084\n",
      "|loss_test| 0.031227560713887215\n",
      "|loss_test| 0.00010861398186534643\n",
      "|loss_test| 0.00783458724617958\n",
      "|loss_test| 0.00012314177001826465\n",
      "|loss_test| 0.007840177975594997\n",
      "|loss_test| 0.01554878056049347\n",
      "|loss_test| 0.031195631250739098\n",
      "|loss_test| 0.007874286733567715\n",
      "|loss_test| 0.00011703653581207618\n",
      "|loss_test| 0.00011759257904486731\n",
      "|loss_test| 0.015575026161968708\n",
      "|loss_test| 0.12482883036136627\n",
      "|loss_test| 0.00011850551527459174\n",
      "|loss_test| 0.00010763913451228291\n",
      "|loss_test| 0.007870391942560673\n",
      "|loss_test| 0.0001290647778660059\n",
      "|loss_test| 0.015575756318867207\n",
      "|loss_test| 0.00013327458873391151\n",
      "|loss_test| 0.00013874893193133175\n",
      "|loss_test| 0.07019678503274918\n",
      "|loss_test| 0.00015891338989604264\n",
      "|loss_test| 0.00013146945275366306\n",
      "|loss_test| 0.015614354982972145\n",
      "|loss_test| 0.03122011572122574\n",
      "|loss_test| 0.00011741842899937183\n",
      "|loss_test| 0.007856770418584347\n",
      "|loss_test| 0.015607347711920738\n",
      "|loss_test| 0.023368868976831436\n",
      "|loss_test| 0.0001268708292627707\n",
      "|loss_test| 0.00014177520642988384\n",
      "|loss_test| 0.02338310144841671\n",
      "|loss_test| 0.0078656654804945\n",
      "|loss_test| 0.015562192536890507\n",
      "|loss_test| 0.007860278710722923\n",
      "|loss_test| 9.925648191710934e-05\n",
      "|loss_test| 0.00014069408643990755\n",
      "|loss_test| 0.00010495030437596142\n",
      "|loss_test| 9.830494673224166e-05\n",
      "|loss_test| 0.00011985067976638675\n",
      "|loss_test| 0.015625065192580223\n",
      "|loss_test| 0.00010785721678985283\n",
      "|loss_test| 0.00011855216871481389\n",
      "|loss_test| 0.00014176871627569199\n",
      "|loss_test| 0.0001359027373837307\n",
      "|loss_test| 0.007840787060558796\n",
      "|loss_test| 0.007852801121771336\n",
      "|loss_test| 0.00012890253856312484\n",
      "|loss_test| 0.015602347441017628\n",
      "|loss_test| 0.015616826713085175\n",
      "|loss_test| 0.007842733524739742\n",
      "|loss_test| 0.03893395885825157\n",
      "|loss_test| 0.007864291779696941\n",
      "|loss_test| 0.0001347227080259472\n",
      "|loss_test| 0.007862381637096405\n",
      "|loss_test| 0.0001464096421841532\n",
      "|loss_test| 0.0001227629545610398\n",
      "|loss_test| 0.0001078396599041298\n",
      "|loss_test| 0.00012281551607884467\n",
      "|loss_test| 0.00011230378004256636\n",
      "|loss_test| 0.00013297933037392795\n",
      "|loss_test| 0.00012520674499683082\n",
      "|loss_test| 0.00013759138528257608\n",
      "|loss_test| 0.015656471252441406\n",
      "|loss_test| 0.0001295843394473195\n",
      "|loss_test| 0.00014480898971669376\n",
      "|loss_test| 0.03122885897755623\n",
      "|loss_test| 0.00011100353731308132\n",
      "|loss_test| 0.0001017056783894077\n",
      "|loss_test| 0.007843556813895702\n",
      "|loss_test| 0.00782991573214531\n",
      "|loss_test| 0.007847213186323643\n",
      "|loss_test| 0.00787687860429287\n",
      "|loss_test| 0.00012994362623430789\n",
      "|loss_test| 0.007851429283618927\n",
      "|loss_test| 0.031221024692058563\n",
      "|loss_test| 0.007868987508118153\n",
      "|loss_test| 0.00012065703776897863\n",
      "|loss_test| 0.007873693481087685\n",
      "|loss_test| 0.00010916252358583733\n",
      "|loss_test| 0.00787037331610918\n",
      "|loss_test| 0.007856695912778378\n",
      "|loss_test| 0.00013660149124916643\n",
      "|loss_test| 0.03117855079472065\n",
      "|loss_test| 0.00012142010382376611\n",
      "|loss_test| 0.07794278860092163\n",
      "|loss_test| 0.00010862914496101439\n",
      "|loss_test| 0.00011996085231658071\n",
      "|loss_test| 0.031216051429510117\n",
      "|loss_test| 0.00011330602137604728\n",
      "|loss_test| 0.0001107383577618748\n",
      "|loss_test| 0.007843905128538609\n",
      "|loss_test| 0.0701901987195015\n",
      "|loss_test| 0.0001071499427780509\n",
      "|loss_test| 0.007867395877838135\n",
      "|loss_test| 0.00011697041190927848\n",
      "|loss_test| 0.007860955782234669\n",
      "|loss_test| 0.01562101673334837\n",
      "|loss_test| 0.007868626154959202\n",
      "|loss_test| 0.015608311630785465\n",
      "|loss_test| 0.00016179974772967398\n",
      "|loss_test| 0.03898977115750313\n",
      "|loss_test| 0.007849756628274918\n",
      "|loss_test| 0.00013412941189017147\n",
      "|loss_test| 0.015575156547129154\n",
      "|loss_test| 0.00011796301259892061\n",
      "|loss_test| 0.007867556065320969\n",
      "|loss_test| 0.00786732416599989\n",
      "|loss_test| 0.031018614768981934\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../cnn_model/cnn_torch/ret_20_pred_checkpoint.pt'))\n",
    "global_loss_test = []\n",
    "\n",
    "prediction = []\n",
    "y_res = []\n",
    "for a,b in test_loader:\n",
    "    test_x = Variable(a.cuda(device=device_ids[0]))\n",
    "    test_y = Variable(b.cuda(device=device_ids[0]))\n",
    "    prediction_test = model(test_x)\n",
    "    loss_test = loss_func(prediction_test, test_y.squeeze().long())\n",
    "    global_loss_test.append(loss_test.cpu().detach().numpy())\n",
    "\n",
    "    prediction.extend(prediction_test.cpu().detach().numpy().tolist())\n",
    "    y_res.extend(np.array(b).tolist())\n",
    "    print('|loss_test|', loss_test.cpu().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea6153c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.00788334, dtype=float32),\n",
       " array(0.04637275, dtype=float32),\n",
       " array(0.00058536, dtype=float32),\n",
       " array(0.00019132, dtype=float32),\n",
       " array(7.429613e-05, dtype=float32),\n",
       " array(0.00029939, dtype=float32),\n",
       " array(0.00016641, dtype=float32),\n",
       " array(0.00019758, dtype=float32),\n",
       " array(0.00010319, dtype=float32),\n",
       " array(0.00780523, dtype=float32),\n",
       " array(0.00788822, dtype=float32),\n",
       " array(0.00788319, dtype=float32),\n",
       " array(0.00053203, dtype=float32),\n",
       " array(0.00011929, dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f60cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
