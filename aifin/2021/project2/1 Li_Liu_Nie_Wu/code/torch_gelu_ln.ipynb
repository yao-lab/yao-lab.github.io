{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os.path as op\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "IMAGE_WIDTH = {5: 15, 20: 60, 60: 180}\n",
    "IMAGE_HEIGHT = {5: 32, 20: 64, 60: 96}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = np.arange(1993,2001,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793019, 64, 60)\n",
      "(793019, 8)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "label_df = []\n",
    "for year in year_list:\n",
    "    images.append(np.memmap(op.join(\"./monthly_20d\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), dtype=np.uint8, mode='r').reshape(\n",
    "                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20])))\n",
    "    label_df.append(pd.read_feather(op.join(\"./monthly_20d\", f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\")))\n",
    "    \n",
    "images = np.concatenate(images)\n",
    "label_df = pd.concat(label_df)\n",
    "\n",
    "print(images.shape)\n",
    "print(label_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img, label):\n",
    "        self.img = torch.Tensor(img.copy())\n",
    "        self.label = torch.Tensor(label)\n",
    "        self.len = len(img)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(images, (label_df.Ret_20d > 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_ratio = 0.7\n",
    "train_dataset, val_dataset = random_split(dataset, [int(dataset.len*train_val_ratio), dataset.len-int(dataset.len*train_val_ratio)], \\\n",
    "                                           generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_gelu_ln(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.LayerNorm([64, 27, 60]),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.LayerNorm([128, 10, 60]),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.LayerNorm([256, 7, 60]),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(46080, 2),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1,64,60)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.reshape(-1,46080)\n",
    "        x = self.fc1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_gelu_ln = Net_gelu_ln().cuda()\n",
    "net_gelu_ln.apply(init_weights)\n",
    "net_gelu_ln = nn.DataParallel(net_gelu_ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, net, loss_fn, optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    current = 0\n",
    "    net.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        y_pred = net(X)\n",
    "        loss = loss_fn(y_pred, y.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        total_loss = (len(X) * running_loss + total_loss * current) / (len(X) + current)\n",
    "        current += len(X)\n",
    "        if batch % 50 == 49:\n",
    "            print(f\"batch: {batch+1} loss: {running_loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        running_loss = 0.0\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(dataloader, net, loss_fn):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    current = 0\n",
    "    net.eval()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        y_pred = net(X)\n",
    "        loss = loss_fn(y_pred, y.long())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        total_loss = (len(X) * running_loss + total_loss * current) / (len(X) + current)\n",
    "        current += len(X)\n",
    "        running_loss = 0.0\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.load('/home/clidg/proj_2/pt/baseline_epoch_10_train_0.6865865240322523_eval_0.686580_.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.740813  [ 6400/555113]\n",
      "batch: 100 loss: 0.763624  [12800/555113]\n",
      "batch: 150 loss: 0.730428  [19200/555113]\n",
      "batch: 200 loss: 0.745340  [25600/555113]\n",
      "batch: 250 loss: 0.721366  [32000/555113]\n",
      "batch: 300 loss: 0.733007  [38400/555113]\n",
      "batch: 350 loss: 0.731935  [44800/555113]\n",
      "batch: 400 loss: 0.735802  [51200/555113]\n",
      "batch: 450 loss: 0.701158  [57600/555113]\n",
      "batch: 500 loss: 0.734969  [64000/555113]\n",
      "batch: 550 loss: 0.758405  [70400/555113]\n",
      "batch: 600 loss: 0.697841  [76800/555113]\n",
      "batch: 650 loss: 0.752321  [83200/555113]\n",
      "batch: 700 loss: 0.716045  [89600/555113]\n",
      "batch: 750 loss: 0.743313  [96000/555113]\n",
      "batch: 800 loss: 0.759599  [102400/555113]\n",
      "batch: 850 loss: 0.705442  [108800/555113]\n",
      "batch: 900 loss: 0.680175  [115200/555113]\n",
      "batch: 950 loss: 0.729599  [121600/555113]\n",
      "batch: 1000 loss: 0.766683  [128000/555113]\n",
      "batch: 1050 loss: 0.711922  [134400/555113]\n",
      "batch: 1100 loss: 0.725565  [140800/555113]\n",
      "batch: 1150 loss: 0.703207  [147200/555113]\n",
      "batch: 1200 loss: 0.712221  [153600/555113]\n",
      "batch: 1250 loss: 0.704188  [160000/555113]\n",
      "batch: 1300 loss: 0.719594  [166400/555113]\n",
      "batch: 1350 loss: 0.699065  [172800/555113]\n",
      "batch: 1400 loss: 0.749915  [179200/555113]\n",
      "batch: 1450 loss: 0.691364  [185600/555113]\n",
      "batch: 1500 loss: 0.738205  [192000/555113]\n",
      "batch: 1550 loss: 0.716491  [198400/555113]\n",
      "batch: 1600 loss: 0.720106  [204800/555113]\n",
      "batch: 1650 loss: 0.699856  [211200/555113]\n",
      "batch: 1700 loss: 0.715313  [217600/555113]\n",
      "batch: 1750 loss: 0.693653  [224000/555113]\n",
      "batch: 1800 loss: 0.695355  [230400/555113]\n",
      "batch: 1850 loss: 0.680619  [236800/555113]\n",
      "batch: 1900 loss: 0.682240  [243200/555113]\n",
      "batch: 1950 loss: 0.699393  [249600/555113]\n",
      "batch: 2000 loss: 0.696599  [256000/555113]\n",
      "batch: 2050 loss: 0.708720  [262400/555113]\n",
      "batch: 2100 loss: 0.707417  [268800/555113]\n",
      "batch: 2150 loss: 0.728458  [275200/555113]\n",
      "batch: 2200 loss: 0.689148  [281600/555113]\n",
      "batch: 2250 loss: 0.700257  [288000/555113]\n",
      "batch: 2300 loss: 0.712288  [294400/555113]\n",
      "batch: 2350 loss: 0.670001  [300800/555113]\n",
      "batch: 2400 loss: 0.723994  [307200/555113]\n",
      "batch: 2450 loss: 0.692779  [313600/555113]\n",
      "batch: 2500 loss: 0.718262  [320000/555113]\n",
      "batch: 2550 loss: 0.683758  [326400/555113]\n",
      "batch: 2600 loss: 0.697977  [332800/555113]\n",
      "batch: 2650 loss: 0.688364  [339200/555113]\n",
      "batch: 2700 loss: 0.711683  [345600/555113]\n",
      "batch: 2750 loss: 0.676207  [352000/555113]\n",
      "batch: 2800 loss: 0.713413  [358400/555113]\n",
      "batch: 2850 loss: 0.695110  [364800/555113]\n",
      "batch: 2900 loss: 0.708265  [371200/555113]\n",
      "batch: 2950 loss: 0.715717  [377600/555113]\n",
      "batch: 3000 loss: 0.701170  [384000/555113]\n",
      "batch: 3050 loss: 0.696934  [390400/555113]\n",
      "batch: 3100 loss: 0.677838  [396800/555113]\n",
      "batch: 3150 loss: 0.678787  [403200/555113]\n",
      "batch: 3200 loss: 0.698016  [409600/555113]\n",
      "batch: 3250 loss: 0.702222  [416000/555113]\n",
      "batch: 3300 loss: 0.690691  [422400/555113]\n",
      "batch: 3350 loss: 0.694710  [428800/555113]\n",
      "batch: 3400 loss: 0.676542  [435200/555113]\n",
      "batch: 3450 loss: 0.707039  [441600/555113]\n",
      "batch: 3500 loss: 0.711226  [448000/555113]\n",
      "batch: 3550 loss: 0.684838  [454400/555113]\n",
      "batch: 3600 loss: 0.712714  [460800/555113]\n",
      "batch: 3650 loss: 0.686688  [467200/555113]\n",
      "batch: 3700 loss: 0.713593  [473600/555113]\n",
      "batch: 3750 loss: 0.700591  [480000/555113]\n",
      "batch: 3800 loss: 0.689846  [486400/555113]\n",
      "batch: 3850 loss: 0.705983  [492800/555113]\n",
      "batch: 3900 loss: 0.713531  [499200/555113]\n",
      "batch: 3950 loss: 0.696750  [505600/555113]\n",
      "batch: 4000 loss: 0.717049  [512000/555113]\n",
      "batch: 4050 loss: 0.695462  [518400/555113]\n",
      "batch: 4100 loss: 0.713567  [524800/555113]\n",
      "batch: 4150 loss: 0.698511  [531200/555113]\n",
      "batch: 4200 loss: 0.684660  [537600/555113]\n",
      "batch: 4250 loss: 0.685171  [544000/555113]\n",
      "batch: 4300 loss: 0.684748  [550400/555113]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.715358  [ 6400/555113]\n",
      "batch: 100 loss: 0.699364  [12800/555113]\n",
      "batch: 150 loss: 0.699198  [19200/555113]\n",
      "batch: 200 loss: 0.705875  [25600/555113]\n",
      "batch: 250 loss: 0.706544  [32000/555113]\n",
      "batch: 300 loss: 0.706339  [38400/555113]\n",
      "batch: 350 loss: 0.704335  [44800/555113]\n",
      "batch: 400 loss: 0.682812  [51200/555113]\n",
      "batch: 450 loss: 0.685154  [57600/555113]\n",
      "batch: 500 loss: 0.689189  [64000/555113]\n",
      "batch: 550 loss: 0.683264  [70400/555113]\n",
      "batch: 600 loss: 0.683714  [76800/555113]\n",
      "batch: 650 loss: 0.717706  [83200/555113]\n",
      "batch: 700 loss: 0.685513  [89600/555113]\n",
      "batch: 750 loss: 0.690515  [96000/555113]\n",
      "batch: 800 loss: 0.700285  [102400/555113]\n",
      "batch: 850 loss: 0.690388  [108800/555113]\n",
      "batch: 900 loss: 0.694240  [115200/555113]\n",
      "batch: 950 loss: 0.701415  [121600/555113]\n",
      "batch: 1000 loss: 0.701885  [128000/555113]\n",
      "batch: 1050 loss: 0.672857  [134400/555113]\n",
      "batch: 1100 loss: 0.700639  [140800/555113]\n",
      "batch: 1150 loss: 0.702733  [147200/555113]\n",
      "batch: 1200 loss: 0.700381  [153600/555113]\n",
      "batch: 1250 loss: 0.695379  [160000/555113]\n",
      "batch: 1300 loss: 0.691719  [166400/555113]\n",
      "batch: 1350 loss: 0.686291  [172800/555113]\n",
      "batch: 1400 loss: 0.698538  [179200/555113]\n",
      "batch: 1450 loss: 0.684220  [185600/555113]\n",
      "batch: 1500 loss: 0.685799  [192000/555113]\n",
      "batch: 1550 loss: 0.693017  [198400/555113]\n",
      "batch: 1600 loss: 0.683257  [204800/555113]\n",
      "batch: 1650 loss: 0.677900  [211200/555113]\n",
      "batch: 1700 loss: 0.693074  [217600/555113]\n",
      "batch: 1750 loss: 0.693165  [224000/555113]\n",
      "batch: 1800 loss: 0.675605  [230400/555113]\n",
      "batch: 1850 loss: 0.694674  [236800/555113]\n",
      "batch: 1900 loss: 0.695552  [243200/555113]\n",
      "batch: 1950 loss: 0.691200  [249600/555113]\n",
      "batch: 2000 loss: 0.700577  [256000/555113]\n",
      "batch: 2050 loss: 0.702917  [262400/555113]\n",
      "batch: 2100 loss: 0.687604  [268800/555113]\n",
      "batch: 2150 loss: 0.694949  [275200/555113]\n",
      "batch: 2200 loss: 0.695933  [281600/555113]\n",
      "batch: 2250 loss: 0.678585  [288000/555113]\n",
      "batch: 2300 loss: 0.706790  [294400/555113]\n",
      "batch: 2350 loss: 0.688423  [300800/555113]\n",
      "batch: 2400 loss: 0.687865  [307200/555113]\n",
      "batch: 2450 loss: 0.676992  [313600/555113]\n",
      "batch: 2500 loss: 0.721328  [320000/555113]\n",
      "batch: 2550 loss: 0.693852  [326400/555113]\n",
      "batch: 2600 loss: 0.670048  [332800/555113]\n",
      "batch: 2650 loss: 0.701516  [339200/555113]\n",
      "batch: 2700 loss: 0.700945  [345600/555113]\n",
      "batch: 2750 loss: 0.684491  [352000/555113]\n",
      "batch: 2800 loss: 0.700439  [358400/555113]\n",
      "batch: 2850 loss: 0.694453  [364800/555113]\n",
      "batch: 2900 loss: 0.698539  [371200/555113]\n",
      "batch: 2950 loss: 0.685627  [377600/555113]\n",
      "batch: 3000 loss: 0.700051  [384000/555113]\n",
      "batch: 3050 loss: 0.683752  [390400/555113]\n",
      "batch: 3100 loss: 0.680780  [396800/555113]\n",
      "batch: 3150 loss: 0.682415  [403200/555113]\n",
      "batch: 3200 loss: 0.701934  [409600/555113]\n",
      "batch: 3250 loss: 0.674380  [416000/555113]\n",
      "batch: 3300 loss: 0.695206  [422400/555113]\n",
      "batch: 3350 loss: 0.688537  [428800/555113]\n",
      "batch: 3400 loss: 0.701553  [435200/555113]\n",
      "batch: 3450 loss: 0.690480  [441600/555113]\n",
      "batch: 3500 loss: 0.677975  [448000/555113]\n",
      "batch: 3550 loss: 0.688903  [454400/555113]\n",
      "batch: 3600 loss: 0.670557  [460800/555113]\n",
      "batch: 3650 loss: 0.687766  [467200/555113]\n",
      "batch: 3700 loss: 0.724435  [473600/555113]\n",
      "batch: 3750 loss: 0.674759  [480000/555113]\n",
      "batch: 3800 loss: 0.695227  [486400/555113]\n",
      "batch: 3850 loss: 0.669495  [492800/555113]\n",
      "batch: 3900 loss: 0.705415  [499200/555113]\n",
      "batch: 3950 loss: 0.691137  [505600/555113]\n",
      "batch: 4000 loss: 0.696918  [512000/555113]\n",
      "batch: 4050 loss: 0.713291  [518400/555113]\n",
      "batch: 4100 loss: 0.689619  [524800/555113]\n",
      "batch: 4150 loss: 0.697211  [531200/555113]\n",
      "batch: 4200 loss: 0.688359  [537600/555113]\n",
      "batch: 4250 loss: 0.677122  [544000/555113]\n",
      "batch: 4300 loss: 0.714054  [550400/555113]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.686324  [ 6400/555113]\n",
      "batch: 100 loss: 0.687928  [12800/555113]\n",
      "batch: 150 loss: 0.695149  [19200/555113]\n",
      "batch: 200 loss: 0.707824  [25600/555113]\n",
      "batch: 250 loss: 0.692109  [32000/555113]\n",
      "batch: 300 loss: 0.694893  [38400/555113]\n",
      "batch: 350 loss: 0.698496  [44800/555113]\n",
      "batch: 400 loss: 0.694911  [51200/555113]\n",
      "batch: 450 loss: 0.688476  [57600/555113]\n",
      "batch: 500 loss: 0.702490  [64000/555113]\n",
      "batch: 550 loss: 0.688493  [70400/555113]\n",
      "batch: 600 loss: 0.705745  [76800/555113]\n",
      "batch: 650 loss: 0.689865  [83200/555113]\n",
      "batch: 700 loss: 0.697916  [89600/555113]\n",
      "batch: 750 loss: 0.678922  [96000/555113]\n",
      "batch: 800 loss: 0.690929  [102400/555113]\n",
      "batch: 850 loss: 0.709035  [108800/555113]\n",
      "batch: 900 loss: 0.700109  [115200/555113]\n",
      "batch: 950 loss: 0.696817  [121600/555113]\n",
      "batch: 1000 loss: 0.678466  [128000/555113]\n",
      "batch: 1050 loss: 0.701140  [134400/555113]\n",
      "batch: 1100 loss: 0.685687  [140800/555113]\n",
      "batch: 1150 loss: 0.688113  [147200/555113]\n",
      "batch: 1200 loss: 0.677837  [153600/555113]\n",
      "batch: 1250 loss: 0.687357  [160000/555113]\n",
      "batch: 1300 loss: 0.692717  [166400/555113]\n",
      "batch: 1350 loss: 0.683587  [172800/555113]\n",
      "batch: 1400 loss: 0.696744  [179200/555113]\n",
      "batch: 1450 loss: 0.702670  [185600/555113]\n",
      "batch: 1500 loss: 0.665715  [192000/555113]\n",
      "batch: 1550 loss: 0.690480  [198400/555113]\n",
      "batch: 1600 loss: 0.698924  [204800/555113]\n",
      "batch: 1650 loss: 0.704836  [211200/555113]\n",
      "batch: 1700 loss: 0.695765  [217600/555113]\n",
      "batch: 1750 loss: 0.689683  [224000/555113]\n",
      "batch: 1800 loss: 0.701927  [230400/555113]\n",
      "batch: 1850 loss: 0.693814  [236800/555113]\n",
      "batch: 1900 loss: 0.690192  [243200/555113]\n",
      "batch: 1950 loss: 0.703400  [249600/555113]\n",
      "batch: 2000 loss: 0.690904  [256000/555113]\n",
      "batch: 2050 loss: 0.685698  [262400/555113]\n",
      "batch: 2100 loss: 0.681552  [268800/555113]\n",
      "batch: 2150 loss: 0.684287  [275200/555113]\n",
      "batch: 2200 loss: 0.708177  [281600/555113]\n",
      "batch: 2250 loss: 0.682723  [288000/555113]\n",
      "batch: 2300 loss: 0.683863  [294400/555113]\n",
      "batch: 2350 loss: 0.692283  [300800/555113]\n",
      "batch: 2400 loss: 0.690225  [307200/555113]\n",
      "batch: 2450 loss: 0.699465  [313600/555113]\n",
      "batch: 2500 loss: 0.695681  [320000/555113]\n",
      "batch: 2550 loss: 0.680228  [326400/555113]\n",
      "batch: 2600 loss: 0.708473  [332800/555113]\n",
      "batch: 2650 loss: 0.682054  [339200/555113]\n",
      "batch: 2700 loss: 0.682322  [345600/555113]\n",
      "batch: 2750 loss: 0.677470  [352000/555113]\n",
      "batch: 2800 loss: 0.697841  [358400/555113]\n",
      "batch: 2850 loss: 0.683125  [364800/555113]\n",
      "batch: 2900 loss: 0.680417  [371200/555113]\n",
      "batch: 2950 loss: 0.697529  [377600/555113]\n",
      "batch: 3000 loss: 0.703171  [384000/555113]\n",
      "batch: 3050 loss: 0.699430  [390400/555113]\n",
      "batch: 3100 loss: 0.679395  [396800/555113]\n",
      "batch: 3150 loss: 0.677441  [403200/555113]\n",
      "batch: 3200 loss: 0.675666  [409600/555113]\n",
      "batch: 3250 loss: 0.694444  [416000/555113]\n",
      "batch: 3300 loss: 0.677588  [422400/555113]\n",
      "batch: 3350 loss: 0.694082  [428800/555113]\n",
      "batch: 3400 loss: 0.706473  [435200/555113]\n",
      "batch: 3450 loss: 0.699804  [441600/555113]\n",
      "batch: 3500 loss: 0.702883  [448000/555113]\n",
      "batch: 3550 loss: 0.675545  [454400/555113]\n",
      "batch: 3600 loss: 0.680058  [460800/555113]\n",
      "batch: 3650 loss: 0.683691  [467200/555113]\n",
      "batch: 3700 loss: 0.695166  [473600/555113]\n",
      "batch: 3750 loss: 0.702126  [480000/555113]\n",
      "batch: 3800 loss: 0.694517  [486400/555113]\n",
      "batch: 3850 loss: 0.699399  [492800/555113]\n",
      "batch: 3900 loss: 0.681714  [499200/555113]\n",
      "batch: 3950 loss: 0.694752  [505600/555113]\n",
      "batch: 4000 loss: 0.690737  [512000/555113]\n",
      "batch: 4050 loss: 0.688767  [518400/555113]\n",
      "batch: 4100 loss: 0.698268  [524800/555113]\n",
      "batch: 4150 loss: 0.701179  [531200/555113]\n",
      "batch: 4200 loss: 0.694095  [537600/555113]\n",
      "batch: 4250 loss: 0.698117  [544000/555113]\n",
      "batch: 4300 loss: 0.675805  [550400/555113]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.682456  [ 6400/555113]\n",
      "batch: 100 loss: 0.703119  [12800/555113]\n",
      "batch: 150 loss: 0.694274  [19200/555113]\n",
      "batch: 200 loss: 0.683088  [25600/555113]\n",
      "batch: 250 loss: 0.684539  [32000/555113]\n",
      "batch: 300 loss: 0.686624  [38400/555113]\n",
      "batch: 350 loss: 0.689429  [44800/555113]\n",
      "batch: 400 loss: 0.706509  [51200/555113]\n",
      "batch: 450 loss: 0.691643  [57600/555113]\n",
      "batch: 500 loss: 0.670613  [64000/555113]\n",
      "batch: 550 loss: 0.697783  [70400/555113]\n",
      "batch: 600 loss: 0.677188  [76800/555113]\n",
      "batch: 650 loss: 0.678829  [83200/555113]\n",
      "batch: 700 loss: 0.687267  [89600/555113]\n",
      "batch: 750 loss: 0.691143  [96000/555113]\n",
      "batch: 800 loss: 0.690103  [102400/555113]\n",
      "batch: 850 loss: 0.686318  [108800/555113]\n",
      "batch: 900 loss: 0.697045  [115200/555113]\n",
      "batch: 950 loss: 0.691333  [121600/555113]\n",
      "batch: 1000 loss: 0.697684  [128000/555113]\n",
      "batch: 1050 loss: 0.694182  [134400/555113]\n",
      "batch: 1100 loss: 0.682810  [140800/555113]\n",
      "batch: 1150 loss: 0.704601  [147200/555113]\n",
      "batch: 1200 loss: 0.692227  [153600/555113]\n",
      "batch: 1250 loss: 0.682693  [160000/555113]\n",
      "batch: 1300 loss: 0.689642  [166400/555113]\n",
      "batch: 1350 loss: 0.680235  [172800/555113]\n",
      "batch: 1400 loss: 0.689534  [179200/555113]\n",
      "batch: 1450 loss: 0.677011  [185600/555113]\n",
      "batch: 1500 loss: 0.697980  [192000/555113]\n",
      "batch: 1550 loss: 0.707068  [198400/555113]\n",
      "batch: 1600 loss: 0.692941  [204800/555113]\n",
      "batch: 1650 loss: 0.693015  [211200/555113]\n",
      "batch: 1700 loss: 0.678990  [217600/555113]\n",
      "batch: 1750 loss: 0.692691  [224000/555113]\n",
      "batch: 1800 loss: 0.700523  [230400/555113]\n",
      "batch: 1850 loss: 0.695547  [236800/555113]\n",
      "batch: 1900 loss: 0.702595  [243200/555113]\n",
      "batch: 1950 loss: 0.691181  [249600/555113]\n",
      "batch: 2000 loss: 0.676842  [256000/555113]\n",
      "batch: 2050 loss: 0.673388  [262400/555113]\n",
      "batch: 2100 loss: 0.700068  [268800/555113]\n",
      "batch: 2150 loss: 0.707382  [275200/555113]\n",
      "batch: 2200 loss: 0.690002  [281600/555113]\n",
      "batch: 2250 loss: 0.686285  [288000/555113]\n",
      "batch: 2300 loss: 0.692180  [294400/555113]\n",
      "batch: 2350 loss: 0.694803  [300800/555113]\n",
      "batch: 2400 loss: 0.688863  [307200/555113]\n",
      "batch: 2450 loss: 0.700575  [313600/555113]\n",
      "batch: 2500 loss: 0.682278  [320000/555113]\n",
      "batch: 2550 loss: 0.673495  [326400/555113]\n",
      "batch: 2600 loss: 0.674002  [332800/555113]\n",
      "batch: 2650 loss: 0.679112  [339200/555113]\n",
      "batch: 2700 loss: 0.687794  [345600/555113]\n",
      "batch: 2750 loss: 0.696307  [352000/555113]\n",
      "batch: 2800 loss: 0.676258  [358400/555113]\n",
      "batch: 2850 loss: 0.701953  [364800/555113]\n",
      "batch: 2900 loss: 0.693711  [371200/555113]\n",
      "batch: 2950 loss: 0.698958  [377600/555113]\n",
      "batch: 3000 loss: 0.693875  [384000/555113]\n",
      "batch: 3050 loss: 0.688561  [390400/555113]\n",
      "batch: 3100 loss: 0.688437  [396800/555113]\n",
      "batch: 3150 loss: 0.675035  [403200/555113]\n",
      "batch: 3200 loss: 0.678488  [409600/555113]\n",
      "batch: 3250 loss: 0.698935  [416000/555113]\n",
      "batch: 3300 loss: 0.688897  [422400/555113]\n",
      "batch: 3350 loss: 0.695414  [428800/555113]\n",
      "batch: 3400 loss: 0.681688  [435200/555113]\n",
      "batch: 3450 loss: 0.685056  [441600/555113]\n",
      "batch: 3500 loss: 0.703328  [448000/555113]\n",
      "batch: 3550 loss: 0.678912  [454400/555113]\n",
      "batch: 3600 loss: 0.707844  [460800/555113]\n",
      "batch: 3650 loss: 0.681612  [467200/555113]\n",
      "batch: 3700 loss: 0.696205  [473600/555113]\n",
      "batch: 3750 loss: 0.691101  [480000/555113]\n",
      "batch: 3800 loss: 0.684877  [486400/555113]\n",
      "batch: 3850 loss: 0.687050  [492800/555113]\n",
      "batch: 3900 loss: 0.698429  [499200/555113]\n",
      "batch: 3950 loss: 0.698400  [505600/555113]\n",
      "batch: 4000 loss: 0.698387  [512000/555113]\n",
      "batch: 4050 loss: 0.688168  [518400/555113]\n",
      "batch: 4100 loss: 0.707599  [524800/555113]\n",
      "batch: 4150 loss: 0.684227  [531200/555113]\n",
      "batch: 4200 loss: 0.696768  [537600/555113]\n",
      "batch: 4250 loss: 0.666586  [544000/555113]\n",
      "batch: 4300 loss: 0.700515  [550400/555113]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.682518  [ 6400/555113]\n",
      "batch: 100 loss: 0.679642  [12800/555113]\n",
      "batch: 150 loss: 0.690925  [19200/555113]\n",
      "batch: 200 loss: 0.683224  [25600/555113]\n",
      "batch: 250 loss: 0.677487  [32000/555113]\n",
      "batch: 300 loss: 0.695484  [38400/555113]\n",
      "batch: 350 loss: 0.703846  [44800/555113]\n",
      "batch: 400 loss: 0.677107  [51200/555113]\n",
      "batch: 450 loss: 0.693907  [57600/555113]\n",
      "batch: 500 loss: 0.665992  [64000/555113]\n",
      "batch: 550 loss: 0.686103  [70400/555113]\n",
      "batch: 600 loss: 0.671140  [76800/555113]\n",
      "batch: 650 loss: 0.683647  [83200/555113]\n",
      "batch: 700 loss: 0.685773  [89600/555113]\n",
      "batch: 750 loss: 0.699117  [96000/555113]\n",
      "batch: 800 loss: 0.690668  [102400/555113]\n",
      "batch: 850 loss: 0.696832  [108800/555113]\n",
      "batch: 900 loss: 0.691858  [115200/555113]\n",
      "batch: 950 loss: 0.677401  [121600/555113]\n",
      "batch: 1000 loss: 0.685832  [128000/555113]\n",
      "batch: 1050 loss: 0.690462  [134400/555113]\n",
      "batch: 1100 loss: 0.695347  [140800/555113]\n",
      "batch: 1150 loss: 0.669861  [147200/555113]\n",
      "batch: 1200 loss: 0.703951  [153600/555113]\n",
      "batch: 1250 loss: 0.690604  [160000/555113]\n",
      "batch: 1300 loss: 0.675123  [166400/555113]\n",
      "batch: 1350 loss: 0.683144  [172800/555113]\n",
      "batch: 1400 loss: 0.680958  [179200/555113]\n",
      "batch: 1450 loss: 0.679360  [185600/555113]\n",
      "batch: 1500 loss: 0.685834  [192000/555113]\n",
      "batch: 1550 loss: 0.693826  [198400/555113]\n",
      "batch: 1600 loss: 0.691663  [204800/555113]\n",
      "batch: 1650 loss: 0.686959  [211200/555113]\n",
      "batch: 1700 loss: 0.675990  [217600/555113]\n",
      "batch: 1750 loss: 0.678610  [224000/555113]\n",
      "batch: 1800 loss: 0.679400  [230400/555113]\n",
      "batch: 1850 loss: 0.695986  [236800/555113]\n",
      "batch: 1900 loss: 0.705158  [243200/555113]\n",
      "batch: 1950 loss: 0.681862  [249600/555113]\n",
      "batch: 2000 loss: 0.694300  [256000/555113]\n",
      "batch: 2050 loss: 0.693941  [262400/555113]\n",
      "batch: 2100 loss: 0.690472  [268800/555113]\n",
      "batch: 2150 loss: 0.686238  [275200/555113]\n",
      "batch: 2200 loss: 0.683224  [281600/555113]\n",
      "batch: 2250 loss: 0.695650  [288000/555113]\n",
      "batch: 2300 loss: 0.705967  [294400/555113]\n",
      "batch: 2350 loss: 0.695288  [300800/555113]\n",
      "batch: 2400 loss: 0.688131  [307200/555113]\n",
      "batch: 2450 loss: 0.686255  [313600/555113]\n",
      "batch: 2500 loss: 0.667327  [320000/555113]\n",
      "batch: 2550 loss: 0.668463  [326400/555113]\n",
      "batch: 2600 loss: 0.695344  [332800/555113]\n",
      "batch: 2650 loss: 0.682440  [339200/555113]\n",
      "batch: 2700 loss: 0.678843  [345600/555113]\n",
      "batch: 2750 loss: 0.711895  [352000/555113]\n",
      "batch: 2800 loss: 0.689474  [358400/555113]\n",
      "batch: 2850 loss: 0.672654  [364800/555113]\n",
      "batch: 2900 loss: 0.687853  [371200/555113]\n",
      "batch: 2950 loss: 0.689588  [377600/555113]\n",
      "batch: 3000 loss: 0.663923  [384000/555113]\n",
      "batch: 3050 loss: 0.685624  [390400/555113]\n",
      "batch: 3100 loss: 0.686042  [396800/555113]\n",
      "batch: 3150 loss: 0.671126  [403200/555113]\n",
      "batch: 3200 loss: 0.673102  [409600/555113]\n",
      "batch: 3250 loss: 0.686132  [416000/555113]\n",
      "batch: 3300 loss: 0.715856  [422400/555113]\n",
      "batch: 3350 loss: 0.690679  [428800/555113]\n",
      "batch: 3400 loss: 0.687048  [435200/555113]\n",
      "batch: 3450 loss: 0.678535  [441600/555113]\n",
      "batch: 3500 loss: 0.691447  [448000/555113]\n",
      "batch: 3550 loss: 0.673136  [454400/555113]\n",
      "batch: 3600 loss: 0.683556  [460800/555113]\n",
      "batch: 3650 loss: 0.678630  [467200/555113]\n",
      "batch: 3700 loss: 0.698718  [473600/555113]\n",
      "batch: 3750 loss: 0.678469  [480000/555113]\n",
      "batch: 3800 loss: 0.686358  [486400/555113]\n",
      "batch: 3850 loss: 0.699869  [492800/555113]\n",
      "batch: 3900 loss: 0.678052  [499200/555113]\n",
      "batch: 3950 loss: 0.682890  [505600/555113]\n",
      "batch: 4000 loss: 0.699460  [512000/555113]\n",
      "batch: 4050 loss: 0.690134  [518400/555113]\n",
      "batch: 4100 loss: 0.691369  [524800/555113]\n",
      "batch: 4150 loss: 0.692112  [531200/555113]\n",
      "batch: 4200 loss: 0.683788  [537600/555113]\n",
      "batch: 4250 loss: 0.701777  [544000/555113]\n",
      "batch: 4300 loss: 0.698697  [550400/555113]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.684322  [ 6400/555113]\n",
      "batch: 100 loss: 0.687417  [12800/555113]\n",
      "batch: 150 loss: 0.669171  [19200/555113]\n",
      "batch: 200 loss: 0.682631  [25600/555113]\n",
      "batch: 250 loss: 0.677563  [32000/555113]\n",
      "batch: 300 loss: 0.672924  [38400/555113]\n",
      "batch: 350 loss: 0.676106  [44800/555113]\n",
      "batch: 400 loss: 0.679795  [51200/555113]\n",
      "batch: 450 loss: 0.691457  [57600/555113]\n",
      "batch: 500 loss: 0.692810  [64000/555113]\n",
      "batch: 550 loss: 0.688685  [70400/555113]\n",
      "batch: 600 loss: 0.681132  [76800/555113]\n",
      "batch: 650 loss: 0.681683  [83200/555113]\n",
      "batch: 700 loss: 0.679998  [89600/555113]\n",
      "batch: 750 loss: 0.690096  [96000/555113]\n",
      "batch: 800 loss: 0.664965  [102400/555113]\n",
      "batch: 850 loss: 0.691491  [108800/555113]\n",
      "batch: 900 loss: 0.699670  [115200/555113]\n",
      "batch: 950 loss: 0.695721  [121600/555113]\n",
      "batch: 1000 loss: 0.672204  [128000/555113]\n",
      "batch: 1050 loss: 0.684063  [134400/555113]\n",
      "batch: 1100 loss: 0.688590  [140800/555113]\n",
      "batch: 1150 loss: 0.670185  [147200/555113]\n",
      "batch: 1200 loss: 0.695019  [153600/555113]\n",
      "batch: 1250 loss: 0.701229  [160000/555113]\n",
      "batch: 1300 loss: 0.671890  [166400/555113]\n",
      "batch: 1350 loss: 0.688521  [172800/555113]\n",
      "batch: 1400 loss: 0.664994  [179200/555113]\n",
      "batch: 1450 loss: 0.692631  [185600/555113]\n",
      "batch: 1500 loss: 0.685515  [192000/555113]\n",
      "batch: 1550 loss: 0.693163  [198400/555113]\n",
      "batch: 1600 loss: 0.692649  [204800/555113]\n",
      "batch: 1650 loss: 0.694176  [211200/555113]\n",
      "batch: 1700 loss: 0.696470  [217600/555113]\n",
      "batch: 1750 loss: 0.669817  [224000/555113]\n",
      "batch: 1800 loss: 0.682891  [230400/555113]\n",
      "batch: 1850 loss: 0.687471  [236800/555113]\n",
      "batch: 1900 loss: 0.693231  [243200/555113]\n",
      "batch: 1950 loss: 0.676206  [249600/555113]\n",
      "batch: 2000 loss: 0.704640  [256000/555113]\n",
      "batch: 2050 loss: 0.694267  [262400/555113]\n",
      "batch: 2100 loss: 0.682190  [268800/555113]\n",
      "batch: 2150 loss: 0.687876  [275200/555113]\n",
      "batch: 2200 loss: 0.670558  [281600/555113]\n",
      "batch: 2250 loss: 0.688756  [288000/555113]\n",
      "batch: 2300 loss: 0.676379  [294400/555113]\n",
      "batch: 2350 loss: 0.677405  [300800/555113]\n",
      "batch: 2400 loss: 0.680160  [307200/555113]\n",
      "batch: 2450 loss: 0.688953  [313600/555113]\n",
      "batch: 2500 loss: 0.715005  [320000/555113]\n",
      "batch: 2550 loss: 0.671323  [326400/555113]\n",
      "batch: 2600 loss: 0.696936  [332800/555113]\n",
      "batch: 2650 loss: 0.679546  [339200/555113]\n",
      "batch: 2700 loss: 0.668326  [345600/555113]\n",
      "batch: 2750 loss: 0.707142  [352000/555113]\n",
      "batch: 2800 loss: 0.699190  [358400/555113]\n",
      "batch: 2850 loss: 0.708357  [364800/555113]\n",
      "batch: 2900 loss: 0.710150  [371200/555113]\n",
      "batch: 2950 loss: 0.688936  [377600/555113]\n",
      "batch: 3000 loss: 0.672452  [384000/555113]\n",
      "batch: 3050 loss: 0.687498  [390400/555113]\n",
      "batch: 3100 loss: 0.668967  [396800/555113]\n",
      "batch: 3150 loss: 0.689538  [403200/555113]\n",
      "batch: 3200 loss: 0.698837  [409600/555113]\n",
      "batch: 3250 loss: 0.681058  [416000/555113]\n",
      "batch: 3300 loss: 0.696818  [422400/555113]\n",
      "batch: 3350 loss: 0.691953  [428800/555113]\n",
      "batch: 3400 loss: 0.669222  [435200/555113]\n",
      "batch: 3450 loss: 0.685695  [441600/555113]\n",
      "batch: 3500 loss: 0.683029  [448000/555113]\n",
      "batch: 3550 loss: 0.680424  [454400/555113]\n",
      "batch: 3600 loss: 0.674871  [460800/555113]\n",
      "batch: 3650 loss: 0.687572  [467200/555113]\n",
      "batch: 3700 loss: 0.662391  [473600/555113]\n",
      "batch: 3750 loss: 0.696879  [480000/555113]\n",
      "batch: 3800 loss: 0.676587  [486400/555113]\n",
      "batch: 3850 loss: 0.682721  [492800/555113]\n",
      "batch: 3900 loss: 0.696331  [499200/555113]\n",
      "batch: 3950 loss: 0.686478  [505600/555113]\n",
      "batch: 4000 loss: 0.695305  [512000/555113]\n",
      "batch: 4050 loss: 0.695942  [518400/555113]\n",
      "batch: 4100 loss: 0.685902  [524800/555113]\n",
      "batch: 4150 loss: 0.677863  [531200/555113]\n",
      "batch: 4200 loss: 0.699768  [537600/555113]\n",
      "batch: 4250 loss: 0.697756  [544000/555113]\n",
      "batch: 4300 loss: 0.689045  [550400/555113]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.656907  [ 6400/555113]\n",
      "batch: 100 loss: 0.672649  [12800/555113]\n",
      "batch: 150 loss: 0.683703  [19200/555113]\n",
      "batch: 200 loss: 0.679760  [25600/555113]\n",
      "batch: 250 loss: 0.666734  [32000/555113]\n",
      "batch: 300 loss: 0.697387  [38400/555113]\n",
      "batch: 350 loss: 0.695963  [44800/555113]\n",
      "batch: 400 loss: 0.682024  [51200/555113]\n",
      "batch: 450 loss: 0.669888  [57600/555113]\n",
      "batch: 500 loss: 0.690012  [64000/555113]\n",
      "batch: 550 loss: 0.680698  [70400/555113]\n",
      "batch: 600 loss: 0.675244  [76800/555113]\n",
      "batch: 650 loss: 0.690885  [83200/555113]\n",
      "batch: 700 loss: 0.681814  [89600/555113]\n",
      "batch: 750 loss: 0.675499  [96000/555113]\n",
      "batch: 800 loss: 0.660833  [102400/555113]\n",
      "batch: 850 loss: 0.687250  [108800/555113]\n",
      "batch: 900 loss: 0.692439  [115200/555113]\n",
      "batch: 950 loss: 0.690138  [121600/555113]\n",
      "batch: 1000 loss: 0.676944  [128000/555113]\n",
      "batch: 1050 loss: 0.683839  [134400/555113]\n",
      "batch: 1100 loss: 0.679937  [140800/555113]\n",
      "batch: 1150 loss: 0.696313  [147200/555113]\n",
      "batch: 1200 loss: 0.683870  [153600/555113]\n",
      "batch: 1250 loss: 0.673923  [160000/555113]\n",
      "batch: 1300 loss: 0.680736  [166400/555113]\n",
      "batch: 1350 loss: 0.701544  [172800/555113]\n",
      "batch: 1400 loss: 0.678860  [179200/555113]\n",
      "batch: 1450 loss: 0.698988  [185600/555113]\n",
      "batch: 1500 loss: 0.698652  [192000/555113]\n",
      "batch: 1550 loss: 0.671846  [198400/555113]\n",
      "batch: 1600 loss: 0.692460  [204800/555113]\n",
      "batch: 1650 loss: 0.675749  [211200/555113]\n",
      "batch: 1700 loss: 0.683078  [217600/555113]\n",
      "batch: 1750 loss: 0.700522  [224000/555113]\n",
      "batch: 1800 loss: 0.671200  [230400/555113]\n",
      "batch: 1850 loss: 0.686810  [236800/555113]\n",
      "batch: 1900 loss: 0.668510  [243200/555113]\n",
      "batch: 1950 loss: 0.694031  [249600/555113]\n",
      "batch: 2000 loss: 0.702923  [256000/555113]\n",
      "batch: 2050 loss: 0.685693  [262400/555113]\n",
      "batch: 2100 loss: 0.677414  [268800/555113]\n",
      "batch: 2150 loss: 0.701407  [275200/555113]\n",
      "batch: 2200 loss: 0.692948  [281600/555113]\n",
      "batch: 2250 loss: 0.689791  [288000/555113]\n",
      "batch: 2300 loss: 0.687675  [294400/555113]\n",
      "batch: 2350 loss: 0.691680  [300800/555113]\n",
      "batch: 2400 loss: 0.681165  [307200/555113]\n",
      "batch: 2450 loss: 0.655722  [313600/555113]\n",
      "batch: 2500 loss: 0.688598  [320000/555113]\n",
      "batch: 2550 loss: 0.675833  [326400/555113]\n",
      "batch: 2600 loss: 0.676436  [332800/555113]\n",
      "batch: 2650 loss: 0.696623  [339200/555113]\n",
      "batch: 2700 loss: 0.668293  [345600/555113]\n",
      "batch: 2750 loss: 0.692804  [352000/555113]\n",
      "batch: 2800 loss: 0.679048  [358400/555113]\n",
      "batch: 2850 loss: 0.690770  [364800/555113]\n",
      "batch: 2900 loss: 0.676285  [371200/555113]\n",
      "batch: 2950 loss: 0.699174  [377600/555113]\n",
      "batch: 3000 loss: 0.676086  [384000/555113]\n",
      "batch: 3050 loss: 0.693581  [390400/555113]\n",
      "batch: 3100 loss: 0.681433  [396800/555113]\n",
      "batch: 3150 loss: 0.656712  [403200/555113]\n",
      "batch: 3200 loss: 0.675645  [409600/555113]\n",
      "batch: 3250 loss: 0.693091  [416000/555113]\n",
      "batch: 3300 loss: 0.687452  [422400/555113]\n",
      "batch: 3350 loss: 0.689328  [428800/555113]\n",
      "batch: 3400 loss: 0.696589  [435200/555113]\n",
      "batch: 3450 loss: 0.692705  [441600/555113]\n",
      "batch: 3500 loss: 0.671442  [448000/555113]\n",
      "batch: 3550 loss: 0.698553  [454400/555113]\n",
      "batch: 3600 loss: 0.692457  [460800/555113]\n",
      "batch: 3650 loss: 0.678945  [467200/555113]\n",
      "batch: 3700 loss: 0.680070  [473600/555113]\n",
      "batch: 3750 loss: 0.701128  [480000/555113]\n",
      "batch: 3800 loss: 0.680975  [486400/555113]\n",
      "batch: 3850 loss: 0.684784  [492800/555113]\n",
      "batch: 3900 loss: 0.707239  [499200/555113]\n",
      "batch: 3950 loss: 0.691755  [505600/555113]\n",
      "batch: 4000 loss: 0.666463  [512000/555113]\n",
      "batch: 4050 loss: 0.679517  [518400/555113]\n",
      "batch: 4100 loss: 0.664423  [524800/555113]\n",
      "batch: 4150 loss: 0.663298  [531200/555113]\n",
      "batch: 4200 loss: 0.695227  [537600/555113]\n",
      "batch: 4250 loss: 0.685485  [544000/555113]\n",
      "batch: 4300 loss: 0.677641  [550400/555113]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.685559  [ 6400/555113]\n",
      "batch: 100 loss: 0.685250  [12800/555113]\n",
      "batch: 150 loss: 0.701164  [19200/555113]\n",
      "batch: 200 loss: 0.697700  [25600/555113]\n",
      "batch: 250 loss: 0.697810  [32000/555113]\n",
      "batch: 300 loss: 0.685116  [38400/555113]\n",
      "batch: 350 loss: 0.683941  [44800/555113]\n",
      "batch: 400 loss: 0.676301  [51200/555113]\n",
      "batch: 450 loss: 0.698091  [57600/555113]\n",
      "batch: 500 loss: 0.697849  [64000/555113]\n",
      "batch: 550 loss: 0.690138  [70400/555113]\n",
      "batch: 600 loss: 0.679161  [76800/555113]\n",
      "batch: 650 loss: 0.679137  [83200/555113]\n",
      "batch: 700 loss: 0.697941  [89600/555113]\n",
      "batch: 750 loss: 0.705668  [96000/555113]\n",
      "batch: 800 loss: 0.677676  [102400/555113]\n",
      "batch: 850 loss: 0.677815  [108800/555113]\n",
      "batch: 900 loss: 0.687564  [115200/555113]\n",
      "batch: 950 loss: 0.689302  [121600/555113]\n",
      "batch: 1000 loss: 0.677338  [128000/555113]\n",
      "batch: 1050 loss: 0.690695  [134400/555113]\n",
      "batch: 1100 loss: 0.675399  [140800/555113]\n",
      "batch: 1150 loss: 0.647275  [147200/555113]\n",
      "batch: 1200 loss: 0.704617  [153600/555113]\n",
      "batch: 1250 loss: 0.693301  [160000/555113]\n",
      "batch: 1300 loss: 0.686502  [166400/555113]\n",
      "batch: 1350 loss: 0.682319  [172800/555113]\n",
      "batch: 1400 loss: 0.688940  [179200/555113]\n",
      "batch: 1450 loss: 0.717309  [185600/555113]\n",
      "batch: 1500 loss: 0.710536  [192000/555113]\n",
      "batch: 1550 loss: 0.673021  [198400/555113]\n",
      "batch: 1600 loss: 0.696334  [204800/555113]\n",
      "batch: 1650 loss: 0.675038  [211200/555113]\n",
      "batch: 1700 loss: 0.682895  [217600/555113]\n",
      "batch: 1750 loss: 0.672036  [224000/555113]\n",
      "batch: 1800 loss: 0.684110  [230400/555113]\n",
      "batch: 1850 loss: 0.692414  [236800/555113]\n",
      "batch: 1900 loss: 0.691739  [243200/555113]\n",
      "batch: 1950 loss: 0.688440  [249600/555113]\n",
      "batch: 2000 loss: 0.659395  [256000/555113]\n",
      "batch: 2050 loss: 0.670408  [262400/555113]\n",
      "batch: 2100 loss: 0.694371  [268800/555113]\n",
      "batch: 2150 loss: 0.672666  [275200/555113]\n",
      "batch: 2200 loss: 0.692235  [281600/555113]\n",
      "batch: 2250 loss: 0.692270  [288000/555113]\n",
      "batch: 2300 loss: 0.688723  [294400/555113]\n",
      "batch: 2350 loss: 0.680412  [300800/555113]\n",
      "batch: 2400 loss: 0.672855  [307200/555113]\n",
      "batch: 2450 loss: 0.717440  [313600/555113]\n",
      "batch: 2500 loss: 0.683225  [320000/555113]\n",
      "batch: 2550 loss: 0.688274  [326400/555113]\n",
      "batch: 2600 loss: 0.693352  [332800/555113]\n",
      "batch: 2650 loss: 0.685681  [339200/555113]\n",
      "batch: 2700 loss: 0.673044  [345600/555113]\n",
      "batch: 2750 loss: 0.672572  [352000/555113]\n",
      "batch: 2800 loss: 0.686327  [358400/555113]\n",
      "batch: 2850 loss: 0.679991  [364800/555113]\n",
      "batch: 2900 loss: 0.695831  [371200/555113]\n",
      "batch: 2950 loss: 0.677619  [377600/555113]\n",
      "batch: 3000 loss: 0.698782  [384000/555113]\n",
      "batch: 3050 loss: 0.681520  [390400/555113]\n",
      "batch: 3100 loss: 0.676601  [396800/555113]\n",
      "batch: 3150 loss: 0.686465  [403200/555113]\n",
      "batch: 3200 loss: 0.691401  [409600/555113]\n",
      "batch: 3250 loss: 0.695200  [416000/555113]\n",
      "batch: 3300 loss: 0.677198  [422400/555113]\n",
      "batch: 3350 loss: 0.690405  [428800/555113]\n",
      "batch: 3400 loss: 0.688215  [435200/555113]\n",
      "batch: 3450 loss: 0.665335  [441600/555113]\n",
      "batch: 3500 loss: 0.682768  [448000/555113]\n",
      "batch: 3550 loss: 0.665723  [454400/555113]\n",
      "batch: 3600 loss: 0.688977  [460800/555113]\n",
      "batch: 3650 loss: 0.699147  [467200/555113]\n",
      "batch: 3700 loss: 0.661592  [473600/555113]\n",
      "batch: 3750 loss: 0.675779  [480000/555113]\n",
      "batch: 3800 loss: 0.693582  [486400/555113]\n",
      "batch: 3850 loss: 0.663605  [492800/555113]\n",
      "batch: 3900 loss: 0.689085  [499200/555113]\n",
      "batch: 3950 loss: 0.701831  [505600/555113]\n",
      "batch: 4000 loss: 0.695049  [512000/555113]\n",
      "batch: 4050 loss: 0.674296  [518400/555113]\n",
      "batch: 4100 loss: 0.692693  [524800/555113]\n",
      "batch: 4150 loss: 0.697636  [531200/555113]\n",
      "batch: 4200 loss: 0.687293  [537600/555113]\n",
      "batch: 4250 loss: 0.675773  [544000/555113]\n",
      "batch: 4300 loss: 0.684872  [550400/555113]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.695571  [ 6400/555113]\n",
      "batch: 100 loss: 0.667306  [12800/555113]\n",
      "batch: 150 loss: 0.713790  [19200/555113]\n",
      "batch: 200 loss: 0.672299  [25600/555113]\n",
      "batch: 250 loss: 0.698612  [32000/555113]\n",
      "batch: 300 loss: 0.693487  [38400/555113]\n",
      "batch: 350 loss: 0.671620  [44800/555113]\n",
      "batch: 400 loss: 0.684100  [51200/555113]\n",
      "batch: 450 loss: 0.663498  [57600/555113]\n",
      "batch: 500 loss: 0.680524  [64000/555113]\n",
      "batch: 550 loss: 0.673341  [70400/555113]\n",
      "batch: 600 loss: 0.693405  [76800/555113]\n",
      "batch: 650 loss: 0.669797  [83200/555113]\n",
      "batch: 700 loss: 0.696573  [89600/555113]\n",
      "batch: 750 loss: 0.665288  [96000/555113]\n",
      "batch: 800 loss: 0.680579  [102400/555113]\n",
      "batch: 850 loss: 0.680863  [108800/555113]\n",
      "batch: 900 loss: 0.692358  [115200/555113]\n",
      "batch: 950 loss: 0.701689  [121600/555113]\n",
      "batch: 1000 loss: 0.690220  [128000/555113]\n",
      "batch: 1050 loss: 0.685857  [134400/555113]\n",
      "batch: 1100 loss: 0.689642  [140800/555113]\n",
      "batch: 1150 loss: 0.693130  [147200/555113]\n",
      "batch: 1200 loss: 0.677322  [153600/555113]\n",
      "batch: 1250 loss: 0.702743  [160000/555113]\n",
      "batch: 1300 loss: 0.690142  [166400/555113]\n",
      "batch: 1350 loss: 0.696845  [172800/555113]\n",
      "batch: 1400 loss: 0.703547  [179200/555113]\n",
      "batch: 1450 loss: 0.663735  [185600/555113]\n",
      "batch: 1500 loss: 0.678052  [192000/555113]\n",
      "batch: 1550 loss: 0.688976  [198400/555113]\n",
      "batch: 1600 loss: 0.698281  [204800/555113]\n",
      "batch: 1650 loss: 0.679556  [211200/555113]\n",
      "batch: 1700 loss: 0.685100  [217600/555113]\n",
      "batch: 1750 loss: 0.660029  [224000/555113]\n",
      "batch: 1800 loss: 0.668289  [230400/555113]\n",
      "batch: 1850 loss: 0.674885  [236800/555113]\n",
      "batch: 1900 loss: 0.686598  [243200/555113]\n",
      "batch: 1950 loss: 0.678994  [249600/555113]\n",
      "batch: 2000 loss: 0.688606  [256000/555113]\n",
      "batch: 2050 loss: 0.684311  [262400/555113]\n",
      "batch: 2100 loss: 0.691125  [268800/555113]\n",
      "batch: 2150 loss: 0.672323  [275200/555113]\n",
      "batch: 2200 loss: 0.681626  [281600/555113]\n",
      "batch: 2250 loss: 0.678458  [288000/555113]\n",
      "batch: 2300 loss: 0.698181  [294400/555113]\n",
      "batch: 2350 loss: 0.709519  [300800/555113]\n",
      "batch: 2400 loss: 0.686292  [307200/555113]\n",
      "batch: 2450 loss: 0.657307  [313600/555113]\n",
      "batch: 2500 loss: 0.676287  [320000/555113]\n",
      "batch: 2550 loss: 0.692550  [326400/555113]\n",
      "batch: 2600 loss: 0.680619  [332800/555113]\n",
      "batch: 2650 loss: 0.692881  [339200/555113]\n",
      "batch: 2700 loss: 0.666634  [345600/555113]\n",
      "batch: 2750 loss: 0.683880  [352000/555113]\n",
      "batch: 2800 loss: 0.666129  [358400/555113]\n",
      "batch: 2850 loss: 0.672638  [364800/555113]\n",
      "batch: 2900 loss: 0.668871  [371200/555113]\n",
      "batch: 2950 loss: 0.689794  [377600/555113]\n",
      "batch: 3000 loss: 0.686720  [384000/555113]\n",
      "batch: 3050 loss: 0.665535  [390400/555113]\n",
      "batch: 3100 loss: 0.675165  [396800/555113]\n",
      "batch: 3150 loss: 0.656986  [403200/555113]\n",
      "batch: 3200 loss: 0.683324  [409600/555113]\n",
      "batch: 3250 loss: 0.702572  [416000/555113]\n",
      "batch: 3300 loss: 0.698824  [422400/555113]\n",
      "batch: 3350 loss: 0.697642  [428800/555113]\n",
      "batch: 3400 loss: 0.697619  [435200/555113]\n",
      "batch: 3450 loss: 0.697922  [441600/555113]\n",
      "batch: 3500 loss: 0.667179  [448000/555113]\n",
      "batch: 3550 loss: 0.689184  [454400/555113]\n",
      "batch: 3600 loss: 0.665711  [460800/555113]\n",
      "batch: 3650 loss: 0.703444  [467200/555113]\n",
      "batch: 3700 loss: 0.688447  [473600/555113]\n",
      "batch: 3750 loss: 0.669513  [480000/555113]\n",
      "batch: 3800 loss: 0.671558  [486400/555113]\n",
      "batch: 3850 loss: 0.683175  [492800/555113]\n",
      "batch: 3900 loss: 0.669763  [499200/555113]\n",
      "batch: 3950 loss: 0.665920  [505600/555113]\n",
      "batch: 4000 loss: 0.690612  [512000/555113]\n",
      "batch: 4050 loss: 0.705204  [518400/555113]\n",
      "batch: 4100 loss: 0.697018  [524800/555113]\n",
      "batch: 4150 loss: 0.718591  [531200/555113]\n",
      "batch: 4200 loss: 0.692307  [537600/555113]\n",
      "batch: 4250 loss: 0.679800  [544000/555113]\n",
      "batch: 4300 loss: 0.697835  [550400/555113]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.670543  [ 6400/555113]\n",
      "batch: 100 loss: 0.666741  [12800/555113]\n",
      "batch: 150 loss: 0.685615  [19200/555113]\n",
      "batch: 200 loss: 0.703703  [25600/555113]\n",
      "batch: 250 loss: 0.700236  [32000/555113]\n",
      "batch: 300 loss: 0.684772  [38400/555113]\n",
      "batch: 350 loss: 0.685337  [44800/555113]\n",
      "batch: 400 loss: 0.693508  [51200/555113]\n",
      "batch: 450 loss: 0.694585  [57600/555113]\n",
      "batch: 500 loss: 0.686240  [64000/555113]\n",
      "batch: 550 loss: 0.669762  [70400/555113]\n",
      "batch: 600 loss: 0.682102  [76800/555113]\n",
      "batch: 650 loss: 0.676296  [83200/555113]\n",
      "batch: 700 loss: 0.653885  [89600/555113]\n",
      "batch: 750 loss: 0.693920  [96000/555113]\n",
      "batch: 800 loss: 0.692881  [102400/555113]\n",
      "batch: 850 loss: 0.675650  [108800/555113]\n",
      "batch: 900 loss: 0.677125  [115200/555113]\n",
      "batch: 950 loss: 0.693756  [121600/555113]\n",
      "batch: 1000 loss: 0.698087  [128000/555113]\n",
      "batch: 1050 loss: 0.680625  [134400/555113]\n",
      "batch: 1100 loss: 0.707151  [140800/555113]\n",
      "batch: 1150 loss: 0.699697  [147200/555113]\n",
      "batch: 1200 loss: 0.668665  [153600/555113]\n",
      "batch: 1250 loss: 0.680032  [160000/555113]\n",
      "batch: 1300 loss: 0.671819  [166400/555113]\n",
      "batch: 1350 loss: 0.702287  [172800/555113]\n",
      "batch: 1400 loss: 0.680830  [179200/555113]\n",
      "batch: 1450 loss: 0.667686  [185600/555113]\n",
      "batch: 1500 loss: 0.687520  [192000/555113]\n",
      "batch: 1550 loss: 0.674436  [198400/555113]\n",
      "batch: 1600 loss: 0.693179  [204800/555113]\n",
      "batch: 1650 loss: 0.692806  [211200/555113]\n",
      "batch: 1700 loss: 0.678039  [217600/555113]\n",
      "batch: 1750 loss: 0.685514  [224000/555113]\n",
      "batch: 1800 loss: 0.685167  [230400/555113]\n",
      "batch: 1850 loss: 0.688766  [236800/555113]\n",
      "batch: 1900 loss: 0.672297  [243200/555113]\n",
      "batch: 1950 loss: 0.669834  [249600/555113]\n",
      "batch: 2000 loss: 0.690255  [256000/555113]\n",
      "batch: 2050 loss: 0.683354  [262400/555113]\n",
      "batch: 2100 loss: 0.677930  [268800/555113]\n",
      "batch: 2150 loss: 0.682573  [275200/555113]\n",
      "batch: 2200 loss: 0.634152  [281600/555113]\n",
      "batch: 2250 loss: 0.698327  [288000/555113]\n",
      "batch: 2300 loss: 0.667288  [294400/555113]\n",
      "batch: 2350 loss: 0.689753  [300800/555113]\n",
      "batch: 2400 loss: 0.700489  [307200/555113]\n",
      "batch: 2450 loss: 0.688139  [313600/555113]\n",
      "batch: 2500 loss: 0.696908  [320000/555113]\n",
      "batch: 2550 loss: 0.687072  [326400/555113]\n",
      "batch: 2600 loss: 0.686345  [332800/555113]\n",
      "batch: 2650 loss: 0.714635  [339200/555113]\n",
      "batch: 2700 loss: 0.678319  [345600/555113]\n",
      "batch: 2750 loss: 0.698028  [352000/555113]\n",
      "batch: 2800 loss: 0.700312  [358400/555113]\n",
      "batch: 2850 loss: 0.666045  [364800/555113]\n",
      "batch: 2900 loss: 0.685079  [371200/555113]\n",
      "batch: 2950 loss: 0.699272  [377600/555113]\n",
      "batch: 3000 loss: 0.685906  [384000/555113]\n",
      "batch: 3050 loss: 0.669333  [390400/555113]\n",
      "batch: 3100 loss: 0.676636  [396800/555113]\n",
      "batch: 3150 loss: 0.685842  [403200/555113]\n",
      "batch: 3200 loss: 0.708315  [409600/555113]\n",
      "batch: 3250 loss: 0.693982  [416000/555113]\n",
      "batch: 3300 loss: 0.677520  [422400/555113]\n",
      "batch: 3350 loss: 0.675732  [428800/555113]\n",
      "batch: 3400 loss: 0.699640  [435200/555113]\n",
      "batch: 3450 loss: 0.687930  [441600/555113]\n",
      "batch: 3500 loss: 0.710020  [448000/555113]\n",
      "batch: 3550 loss: 0.681615  [454400/555113]\n",
      "batch: 3600 loss: 0.672076  [460800/555113]\n",
      "batch: 3650 loss: 0.663499  [467200/555113]\n",
      "batch: 3700 loss: 0.674671  [473600/555113]\n",
      "batch: 3750 loss: 0.680353  [480000/555113]\n",
      "batch: 3800 loss: 0.688559  [486400/555113]\n",
      "batch: 3850 loss: 0.671375  [492800/555113]\n",
      "batch: 3900 loss: 0.675070  [499200/555113]\n",
      "batch: 3950 loss: 0.676695  [505600/555113]\n",
      "batch: 4000 loss: 0.677844  [512000/555113]\n",
      "batch: 4050 loss: 0.696895  [518400/555113]\n",
      "batch: 4100 loss: 0.697672  [524800/555113]\n",
      "batch: 4150 loss: 0.692644  [531200/555113]\n",
      "batch: 4200 loss: 0.690173  [537600/555113]\n",
      "batch: 4250 loss: 0.672339  [544000/555113]\n",
      "batch: 4300 loss: 0.691592  [550400/555113]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.653997  [ 6400/555113]\n",
      "batch: 100 loss: 0.685995  [12800/555113]\n",
      "batch: 150 loss: 0.675136  [19200/555113]\n",
      "batch: 200 loss: 0.663725  [25600/555113]\n",
      "batch: 250 loss: 0.679771  [32000/555113]\n",
      "batch: 300 loss: 0.689249  [38400/555113]\n",
      "batch: 350 loss: 0.688542  [44800/555113]\n",
      "batch: 400 loss: 0.678399  [51200/555113]\n",
      "batch: 450 loss: 0.664123  [57600/555113]\n",
      "batch: 500 loss: 0.675509  [64000/555113]\n",
      "batch: 550 loss: 0.673441  [70400/555113]\n",
      "batch: 600 loss: 0.669532  [76800/555113]\n",
      "batch: 650 loss: 0.667970  [83200/555113]\n",
      "batch: 700 loss: 0.657681  [89600/555113]\n",
      "batch: 750 loss: 0.688833  [96000/555113]\n",
      "batch: 800 loss: 0.689094  [102400/555113]\n",
      "batch: 850 loss: 0.667788  [108800/555113]\n",
      "batch: 900 loss: 0.697628  [115200/555113]\n",
      "batch: 950 loss: 0.663376  [121600/555113]\n",
      "batch: 1000 loss: 0.673505  [128000/555113]\n",
      "batch: 1050 loss: 0.668840  [134400/555113]\n",
      "batch: 1100 loss: 0.669628  [140800/555113]\n",
      "batch: 1150 loss: 0.674991  [147200/555113]\n",
      "batch: 1200 loss: 0.677937  [153600/555113]\n",
      "batch: 1250 loss: 0.675922  [160000/555113]\n",
      "batch: 1300 loss: 0.698198  [166400/555113]\n",
      "batch: 1350 loss: 0.694797  [172800/555113]\n",
      "batch: 1400 loss: 0.658468  [179200/555113]\n",
      "batch: 1450 loss: 0.678691  [185600/555113]\n",
      "batch: 1500 loss: 0.634827  [192000/555113]\n",
      "batch: 1550 loss: 0.690306  [198400/555113]\n",
      "batch: 1600 loss: 0.692405  [204800/555113]\n",
      "batch: 1650 loss: 0.670045  [211200/555113]\n",
      "batch: 1700 loss: 0.689960  [217600/555113]\n",
      "batch: 1750 loss: 0.655808  [224000/555113]\n",
      "batch: 1800 loss: 0.691459  [230400/555113]\n",
      "batch: 1850 loss: 0.679110  [236800/555113]\n",
      "batch: 1900 loss: 0.693974  [243200/555113]\n",
      "batch: 1950 loss: 0.678020  [249600/555113]\n",
      "batch: 2000 loss: 0.658170  [256000/555113]\n",
      "batch: 2050 loss: 0.665349  [262400/555113]\n",
      "batch: 2100 loss: 0.658269  [268800/555113]\n",
      "batch: 2150 loss: 0.705688  [275200/555113]\n",
      "batch: 2200 loss: 0.671656  [281600/555113]\n",
      "batch: 2250 loss: 0.675797  [288000/555113]\n",
      "batch: 2300 loss: 0.691326  [294400/555113]\n",
      "batch: 2350 loss: 0.714550  [300800/555113]\n",
      "batch: 2400 loss: 0.670831  [307200/555113]\n",
      "batch: 2450 loss: 0.673305  [313600/555113]\n",
      "batch: 2500 loss: 0.679350  [320000/555113]\n",
      "batch: 2550 loss: 0.673495  [326400/555113]\n",
      "batch: 2600 loss: 0.683643  [332800/555113]\n",
      "batch: 2650 loss: 0.688678  [339200/555113]\n",
      "batch: 2700 loss: 0.678870  [345600/555113]\n",
      "batch: 2750 loss: 0.692395  [352000/555113]\n",
      "batch: 2800 loss: 0.688853  [358400/555113]\n",
      "batch: 2850 loss: 0.667956  [364800/555113]\n",
      "batch: 2900 loss: 0.684489  [371200/555113]\n",
      "batch: 2950 loss: 0.683143  [377600/555113]\n",
      "batch: 3000 loss: 0.689244  [384000/555113]\n",
      "batch: 3050 loss: 0.677613  [390400/555113]\n",
      "batch: 3100 loss: 0.681521  [396800/555113]\n",
      "batch: 3150 loss: 0.722897  [403200/555113]\n",
      "batch: 3200 loss: 0.679975  [409600/555113]\n",
      "batch: 3250 loss: 0.680402  [416000/555113]\n",
      "batch: 3300 loss: 0.694100  [422400/555113]\n",
      "batch: 3350 loss: 0.662249  [428800/555113]\n",
      "batch: 3400 loss: 0.680204  [435200/555113]\n",
      "batch: 3450 loss: 0.683094  [441600/555113]\n",
      "batch: 3500 loss: 0.686433  [448000/555113]\n",
      "batch: 3550 loss: 0.672777  [454400/555113]\n",
      "batch: 3600 loss: 0.689034  [460800/555113]\n",
      "batch: 3650 loss: 0.683305  [467200/555113]\n",
      "batch: 3700 loss: 0.679400  [473600/555113]\n",
      "batch: 3750 loss: 0.687491  [480000/555113]\n",
      "batch: 3800 loss: 0.705795  [486400/555113]\n",
      "batch: 3850 loss: 0.680719  [492800/555113]\n",
      "batch: 3900 loss: 0.676939  [499200/555113]\n",
      "batch: 3950 loss: 0.693668  [505600/555113]\n",
      "batch: 4000 loss: 0.703749  [512000/555113]\n",
      "batch: 4050 loss: 0.700024  [518400/555113]\n",
      "batch: 4100 loss: 0.690637  [524800/555113]\n",
      "batch: 4150 loss: 0.678937  [531200/555113]\n",
      "batch: 4200 loss: 0.662260  [537600/555113]\n",
      "batch: 4250 loss: 0.687179  [544000/555113]\n",
      "batch: 4300 loss: 0.679335  [550400/555113]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.694901  [ 6400/555113]\n",
      "batch: 100 loss: 0.682456  [12800/555113]\n",
      "batch: 150 loss: 0.670444  [19200/555113]\n",
      "batch: 200 loss: 0.685024  [25600/555113]\n",
      "batch: 250 loss: 0.696377  [32000/555113]\n",
      "batch: 300 loss: 0.664848  [38400/555113]\n",
      "batch: 350 loss: 0.679605  [44800/555113]\n",
      "batch: 400 loss: 0.650347  [51200/555113]\n",
      "batch: 450 loss: 0.679383  [57600/555113]\n",
      "batch: 500 loss: 0.702290  [64000/555113]\n",
      "batch: 550 loss: 0.668720  [70400/555113]\n",
      "batch: 600 loss: 0.668185  [76800/555113]\n",
      "batch: 650 loss: 0.660383  [83200/555113]\n",
      "batch: 700 loss: 0.663802  [89600/555113]\n",
      "batch: 750 loss: 0.661770  [96000/555113]\n",
      "batch: 800 loss: 0.714144  [102400/555113]\n",
      "batch: 850 loss: 0.665345  [108800/555113]\n",
      "batch: 900 loss: 0.679242  [115200/555113]\n",
      "batch: 950 loss: 0.686235  [121600/555113]\n",
      "batch: 1000 loss: 0.674974  [128000/555113]\n",
      "batch: 1050 loss: 0.667467  [134400/555113]\n",
      "batch: 1100 loss: 0.696808  [140800/555113]\n",
      "batch: 1150 loss: 0.692475  [147200/555113]\n",
      "batch: 1200 loss: 0.681087  [153600/555113]\n",
      "batch: 1250 loss: 0.650416  [160000/555113]\n",
      "batch: 1300 loss: 0.681310  [166400/555113]\n",
      "batch: 1350 loss: 0.695139  [172800/555113]\n",
      "batch: 1400 loss: 0.681670  [179200/555113]\n",
      "batch: 1450 loss: 0.662525  [185600/555113]\n",
      "batch: 1500 loss: 0.668680  [192000/555113]\n",
      "batch: 1550 loss: 0.703719  [198400/555113]\n",
      "batch: 1600 loss: 0.672402  [204800/555113]\n",
      "batch: 1650 loss: 0.693725  [211200/555113]\n",
      "batch: 1700 loss: 0.705583  [217600/555113]\n",
      "batch: 1750 loss: 0.682258  [224000/555113]\n",
      "batch: 1800 loss: 0.694361  [230400/555113]\n",
      "batch: 1850 loss: 0.662239  [236800/555113]\n",
      "batch: 1900 loss: 0.692464  [243200/555113]\n",
      "batch: 1950 loss: 0.661195  [249600/555113]\n",
      "batch: 2000 loss: 0.670353  [256000/555113]\n",
      "batch: 2050 loss: 0.683090  [262400/555113]\n",
      "batch: 2100 loss: 0.655559  [268800/555113]\n",
      "batch: 2150 loss: 0.708104  [275200/555113]\n",
      "batch: 2200 loss: 0.679643  [281600/555113]\n",
      "batch: 2250 loss: 0.678432  [288000/555113]\n",
      "batch: 2300 loss: 0.672707  [294400/555113]\n",
      "batch: 2350 loss: 0.671234  [300800/555113]\n",
      "batch: 2400 loss: 0.688837  [307200/555113]\n",
      "batch: 2450 loss: 0.694552  [313600/555113]\n",
      "batch: 2500 loss: 0.712358  [320000/555113]\n",
      "batch: 2550 loss: 0.648014  [326400/555113]\n",
      "batch: 2600 loss: 0.686385  [332800/555113]\n",
      "batch: 2650 loss: 0.691097  [339200/555113]\n",
      "batch: 2700 loss: 0.720715  [345600/555113]\n",
      "batch: 2750 loss: 0.673167  [352000/555113]\n",
      "batch: 2800 loss: 0.695850  [358400/555113]\n",
      "batch: 2850 loss: 0.683450  [364800/555113]\n",
      "batch: 2900 loss: 0.681047  [371200/555113]\n",
      "batch: 2950 loss: 0.662134  [377600/555113]\n",
      "batch: 3000 loss: 0.676586  [384000/555113]\n",
      "batch: 3050 loss: 0.675143  [390400/555113]\n",
      "batch: 3100 loss: 0.705788  [396800/555113]\n",
      "batch: 3150 loss: 0.691748  [403200/555113]\n",
      "batch: 3200 loss: 0.690696  [409600/555113]\n",
      "batch: 3250 loss: 0.695386  [416000/555113]\n",
      "batch: 3300 loss: 0.664487  [422400/555113]\n",
      "batch: 3350 loss: 0.663696  [428800/555113]\n",
      "batch: 3400 loss: 0.697370  [435200/555113]\n",
      "batch: 3450 loss: 0.686056  [441600/555113]\n",
      "batch: 3500 loss: 0.694395  [448000/555113]\n",
      "batch: 3550 loss: 0.679230  [454400/555113]\n",
      "batch: 3600 loss: 0.683946  [460800/555113]\n",
      "batch: 3650 loss: 0.690463  [467200/555113]\n",
      "batch: 3700 loss: 0.667214  [473600/555113]\n",
      "batch: 3750 loss: 0.676686  [480000/555113]\n",
      "batch: 3800 loss: 0.689656  [486400/555113]\n",
      "batch: 3850 loss: 0.681164  [492800/555113]\n",
      "batch: 3900 loss: 0.681139  [499200/555113]\n",
      "batch: 3950 loss: 0.695771  [505600/555113]\n",
      "batch: 4000 loss: 0.651222  [512000/555113]\n",
      "batch: 4050 loss: 0.659306  [518400/555113]\n",
      "batch: 4100 loss: 0.666454  [524800/555113]\n",
      "batch: 4150 loss: 0.722980  [531200/555113]\n",
      "batch: 4200 loss: 0.673999  [537600/555113]\n",
      "batch: 4250 loss: 0.673832  [544000/555113]\n",
      "batch: 4300 loss: 0.689288  [550400/555113]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.679112  [ 6400/555113]\n",
      "batch: 100 loss: 0.658680  [12800/555113]\n",
      "batch: 150 loss: 0.652122  [19200/555113]\n",
      "batch: 200 loss: 0.684812  [25600/555113]\n",
      "batch: 250 loss: 0.679258  [32000/555113]\n",
      "batch: 300 loss: 0.663065  [38400/555113]\n",
      "batch: 350 loss: 0.674601  [44800/555113]\n",
      "batch: 400 loss: 0.698565  [51200/555113]\n",
      "batch: 450 loss: 0.646455  [57600/555113]\n",
      "batch: 500 loss: 0.657482  [64000/555113]\n",
      "batch: 550 loss: 0.681283  [70400/555113]\n",
      "batch: 600 loss: 0.650306  [76800/555113]\n",
      "batch: 650 loss: 0.689267  [83200/555113]\n",
      "batch: 700 loss: 0.701869  [89600/555113]\n",
      "batch: 750 loss: 0.672550  [96000/555113]\n",
      "batch: 800 loss: 0.662405  [102400/555113]\n",
      "batch: 850 loss: 0.661913  [108800/555113]\n",
      "batch: 900 loss: 0.660511  [115200/555113]\n",
      "batch: 950 loss: 0.656505  [121600/555113]\n",
      "batch: 1000 loss: 0.693605  [128000/555113]\n",
      "batch: 1050 loss: 0.670263  [134400/555113]\n",
      "batch: 1100 loss: 0.654991  [140800/555113]\n",
      "batch: 1150 loss: 0.682391  [147200/555113]\n",
      "batch: 1200 loss: 0.695400  [153600/555113]\n",
      "batch: 1250 loss: 0.670743  [160000/555113]\n",
      "batch: 1300 loss: 0.672494  [166400/555113]\n",
      "batch: 1350 loss: 0.666795  [172800/555113]\n",
      "batch: 1400 loss: 0.668779  [179200/555113]\n",
      "batch: 1450 loss: 0.651657  [185600/555113]\n",
      "batch: 1500 loss: 0.653720  [192000/555113]\n",
      "batch: 1550 loss: 0.679304  [198400/555113]\n",
      "batch: 1600 loss: 0.694388  [204800/555113]\n",
      "batch: 1650 loss: 0.677932  [211200/555113]\n",
      "batch: 1700 loss: 0.678342  [217600/555113]\n",
      "batch: 1750 loss: 0.692021  [224000/555113]\n",
      "batch: 1800 loss: 0.687418  [230400/555113]\n",
      "batch: 1850 loss: 0.682477  [236800/555113]\n",
      "batch: 1900 loss: 0.683352  [243200/555113]\n",
      "batch: 1950 loss: 0.665505  [249600/555113]\n",
      "batch: 2000 loss: 0.685732  [256000/555113]\n",
      "batch: 2050 loss: 0.666591  [262400/555113]\n",
      "batch: 2100 loss: 0.687230  [268800/555113]\n",
      "batch: 2150 loss: 0.671149  [275200/555113]\n",
      "batch: 2200 loss: 0.647653  [281600/555113]\n",
      "batch: 2250 loss: 0.666535  [288000/555113]\n",
      "batch: 2300 loss: 0.686113  [294400/555113]\n",
      "batch: 2350 loss: 0.682970  [300800/555113]\n",
      "batch: 2400 loss: 0.672315  [307200/555113]\n",
      "batch: 2450 loss: 0.664159  [313600/555113]\n",
      "batch: 2500 loss: 0.651520  [320000/555113]\n",
      "batch: 2550 loss: 0.689528  [326400/555113]\n",
      "batch: 2600 loss: 0.682960  [332800/555113]\n",
      "batch: 2650 loss: 0.679091  [339200/555113]\n",
      "batch: 2700 loss: 0.663128  [345600/555113]\n",
      "batch: 2750 loss: 0.683616  [352000/555113]\n",
      "batch: 2800 loss: 0.676588  [358400/555113]\n",
      "batch: 2850 loss: 0.678238  [364800/555113]\n",
      "batch: 2900 loss: 0.699266  [371200/555113]\n",
      "batch: 2950 loss: 0.682088  [377600/555113]\n",
      "batch: 3000 loss: 0.694229  [384000/555113]\n",
      "batch: 3050 loss: 0.691812  [390400/555113]\n",
      "batch: 3100 loss: 0.703782  [396800/555113]\n",
      "batch: 3150 loss: 0.665624  [403200/555113]\n",
      "batch: 3200 loss: 0.685524  [409600/555113]\n",
      "batch: 3250 loss: 0.696751  [416000/555113]\n",
      "batch: 3300 loss: 0.690290  [422400/555113]\n",
      "batch: 3350 loss: 0.698037  [428800/555113]\n",
      "batch: 3400 loss: 0.683064  [435200/555113]\n",
      "batch: 3450 loss: 0.660563  [441600/555113]\n",
      "batch: 3500 loss: 0.664332  [448000/555113]\n",
      "batch: 3550 loss: 0.667256  [454400/555113]\n",
      "batch: 3600 loss: 0.667120  [460800/555113]\n",
      "batch: 3650 loss: 0.663190  [467200/555113]\n",
      "batch: 3700 loss: 0.700242  [473600/555113]\n",
      "batch: 3750 loss: 0.664372  [480000/555113]\n",
      "batch: 3800 loss: 0.671325  [486400/555113]\n",
      "batch: 3850 loss: 0.723273  [492800/555113]\n",
      "batch: 3900 loss: 0.658074  [499200/555113]\n",
      "batch: 3950 loss: 0.675974  [505600/555113]\n",
      "batch: 4000 loss: 0.667962  [512000/555113]\n",
      "batch: 4050 loss: 0.673656  [518400/555113]\n",
      "batch: 4100 loss: 0.658211  [524800/555113]\n",
      "batch: 4150 loss: 0.671136  [531200/555113]\n",
      "batch: 4200 loss: 0.642726  [537600/555113]\n",
      "batch: 4250 loss: 0.688272  [544000/555113]\n",
      "batch: 4300 loss: 0.673338  [550400/555113]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.687938  [ 6400/555113]\n",
      "batch: 100 loss: 0.687787  [12800/555113]\n",
      "batch: 150 loss: 0.686352  [19200/555113]\n",
      "batch: 200 loss: 0.716928  [25600/555113]\n",
      "batch: 250 loss: 0.666174  [32000/555113]\n",
      "batch: 300 loss: 0.641924  [38400/555113]\n",
      "batch: 350 loss: 0.690227  [44800/555113]\n",
      "batch: 400 loss: 0.665652  [51200/555113]\n",
      "batch: 450 loss: 0.682712  [57600/555113]\n",
      "batch: 500 loss: 0.680521  [64000/555113]\n",
      "batch: 550 loss: 0.658399  [70400/555113]\n",
      "batch: 600 loss: 0.701363  [76800/555113]\n",
      "batch: 650 loss: 0.672210  [83200/555113]\n",
      "batch: 700 loss: 0.674195  [89600/555113]\n",
      "batch: 750 loss: 0.689263  [96000/555113]\n",
      "batch: 800 loss: 0.708276  [102400/555113]\n",
      "batch: 850 loss: 0.666688  [108800/555113]\n",
      "batch: 900 loss: 0.680182  [115200/555113]\n",
      "batch: 950 loss: 0.684920  [121600/555113]\n",
      "batch: 1000 loss: 0.672606  [128000/555113]\n",
      "batch: 1050 loss: 0.688914  [134400/555113]\n",
      "batch: 1100 loss: 0.695548  [140800/555113]\n",
      "batch: 1150 loss: 0.688721  [147200/555113]\n",
      "batch: 1200 loss: 0.686202  [153600/555113]\n",
      "batch: 1250 loss: 0.645280  [160000/555113]\n",
      "batch: 1300 loss: 0.663958  [166400/555113]\n",
      "batch: 1350 loss: 0.702088  [172800/555113]\n",
      "batch: 1400 loss: 0.673177  [179200/555113]\n",
      "batch: 1450 loss: 0.672053  [185600/555113]\n",
      "batch: 1500 loss: 0.660753  [192000/555113]\n",
      "batch: 1550 loss: 0.670344  [198400/555113]\n",
      "batch: 1600 loss: 0.678896  [204800/555113]\n",
      "batch: 1650 loss: 0.678365  [211200/555113]\n",
      "batch: 1700 loss: 0.672264  [217600/555113]\n",
      "batch: 1750 loss: 0.658645  [224000/555113]\n",
      "batch: 1800 loss: 0.666414  [230400/555113]\n",
      "batch: 1850 loss: 0.666462  [236800/555113]\n",
      "batch: 1900 loss: 0.682137  [243200/555113]\n",
      "batch: 1950 loss: 0.666557  [249600/555113]\n",
      "batch: 2000 loss: 0.680010  [256000/555113]\n",
      "batch: 2050 loss: 0.681434  [262400/555113]\n",
      "batch: 2100 loss: 0.665453  [268800/555113]\n",
      "batch: 2150 loss: 0.673643  [275200/555113]\n",
      "batch: 2200 loss: 0.680119  [281600/555113]\n",
      "batch: 2250 loss: 0.687604  [288000/555113]\n",
      "batch: 2300 loss: 0.676643  [294400/555113]\n",
      "batch: 2350 loss: 0.659427  [300800/555113]\n",
      "batch: 2400 loss: 0.706704  [307200/555113]\n",
      "batch: 2450 loss: 0.665514  [313600/555113]\n",
      "batch: 2500 loss: 0.689190  [320000/555113]\n",
      "batch: 2550 loss: 0.665451  [326400/555113]\n",
      "batch: 2600 loss: 0.684129  [332800/555113]\n",
      "batch: 2650 loss: 0.663912  [339200/555113]\n",
      "batch: 2700 loss: 0.675280  [345600/555113]\n",
      "batch: 2750 loss: 0.662269  [352000/555113]\n",
      "batch: 2800 loss: 0.662118  [358400/555113]\n",
      "batch: 2850 loss: 0.662744  [364800/555113]\n",
      "batch: 2900 loss: 0.676072  [371200/555113]\n",
      "batch: 2950 loss: 0.673334  [377600/555113]\n",
      "batch: 3000 loss: 0.686351  [384000/555113]\n",
      "batch: 3050 loss: 0.655995  [390400/555113]\n",
      "batch: 3100 loss: 0.673357  [396800/555113]\n",
      "batch: 3150 loss: 0.695833  [403200/555113]\n",
      "batch: 3200 loss: 0.631700  [409600/555113]\n",
      "batch: 3250 loss: 0.697293  [416000/555113]\n",
      "batch: 3300 loss: 0.719606  [422400/555113]\n",
      "batch: 3350 loss: 0.687541  [428800/555113]\n",
      "batch: 3400 loss: 0.699422  [435200/555113]\n",
      "batch: 3450 loss: 0.685269  [441600/555113]\n",
      "batch: 3500 loss: 0.676715  [448000/555113]\n",
      "batch: 3550 loss: 0.680500  [454400/555113]\n",
      "batch: 3600 loss: 0.655232  [460800/555113]\n",
      "batch: 3650 loss: 0.658337  [467200/555113]\n",
      "batch: 3700 loss: 0.660580  [473600/555113]\n",
      "batch: 3750 loss: 0.674822  [480000/555113]\n",
      "batch: 3800 loss: 0.660178  [486400/555113]\n",
      "batch: 3850 loss: 0.658122  [492800/555113]\n",
      "batch: 3900 loss: 0.665500  [499200/555113]\n",
      "batch: 3950 loss: 0.696314  [505600/555113]\n",
      "batch: 4000 loss: 0.684583  [512000/555113]\n",
      "batch: 4050 loss: 0.669902  [518400/555113]\n",
      "batch: 4100 loss: 0.671658  [524800/555113]\n",
      "batch: 4150 loss: 0.665731  [531200/555113]\n",
      "batch: 4200 loss: 0.664823  [537600/555113]\n",
      "batch: 4250 loss: 0.682946  [544000/555113]\n",
      "batch: 4300 loss: 0.689653  [550400/555113]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.673916  [ 6400/555113]\n",
      "batch: 100 loss: 0.621037  [12800/555113]\n",
      "batch: 150 loss: 0.653399  [19200/555113]\n",
      "batch: 200 loss: 0.688293  [25600/555113]\n",
      "batch: 250 loss: 0.662181  [32000/555113]\n",
      "batch: 300 loss: 0.678024  [38400/555113]\n",
      "batch: 350 loss: 0.671017  [44800/555113]\n",
      "batch: 400 loss: 0.680060  [51200/555113]\n",
      "batch: 450 loss: 0.666247  [57600/555113]\n",
      "batch: 500 loss: 0.663633  [64000/555113]\n",
      "batch: 550 loss: 0.688878  [70400/555113]\n",
      "batch: 600 loss: 0.698052  [76800/555113]\n",
      "batch: 650 loss: 0.677315  [83200/555113]\n",
      "batch: 700 loss: 0.665485  [89600/555113]\n",
      "batch: 750 loss: 0.667298  [96000/555113]\n",
      "batch: 800 loss: 0.686078  [102400/555113]\n",
      "batch: 850 loss: 0.665110  [108800/555113]\n",
      "batch: 900 loss: 0.694271  [115200/555113]\n",
      "batch: 950 loss: 0.679963  [121600/555113]\n",
      "batch: 1000 loss: 0.653198  [128000/555113]\n",
      "batch: 1050 loss: 0.681097  [134400/555113]\n",
      "batch: 1100 loss: 0.657362  [140800/555113]\n",
      "batch: 1150 loss: 0.684219  [147200/555113]\n",
      "batch: 1200 loss: 0.661361  [153600/555113]\n",
      "batch: 1250 loss: 0.661661  [160000/555113]\n",
      "batch: 1300 loss: 0.694024  [166400/555113]\n",
      "batch: 1350 loss: 0.683593  [172800/555113]\n",
      "batch: 1400 loss: 0.659504  [179200/555113]\n",
      "batch: 1450 loss: 0.664434  [185600/555113]\n",
      "batch: 1500 loss: 0.683973  [192000/555113]\n",
      "batch: 1550 loss: 0.643292  [198400/555113]\n",
      "batch: 1600 loss: 0.676530  [204800/555113]\n",
      "batch: 1650 loss: 0.671575  [211200/555113]\n",
      "batch: 1700 loss: 0.685562  [217600/555113]\n",
      "batch: 1750 loss: 0.645839  [224000/555113]\n",
      "batch: 1800 loss: 0.689056  [230400/555113]\n",
      "batch: 1850 loss: 0.657797  [236800/555113]\n",
      "batch: 1900 loss: 0.704595  [243200/555113]\n",
      "batch: 1950 loss: 0.682655  [249600/555113]\n",
      "batch: 2000 loss: 0.692586  [256000/555113]\n",
      "batch: 2050 loss: 0.687239  [262400/555113]\n",
      "batch: 2100 loss: 0.696043  [268800/555113]\n",
      "batch: 2150 loss: 0.659664  [275200/555113]\n",
      "batch: 2200 loss: 0.663025  [281600/555113]\n",
      "batch: 2250 loss: 0.675794  [288000/555113]\n",
      "batch: 2300 loss: 0.712046  [294400/555113]\n",
      "batch: 2350 loss: 0.692596  [300800/555113]\n",
      "batch: 2400 loss: 0.664228  [307200/555113]\n",
      "batch: 2450 loss: 0.688290  [313600/555113]\n",
      "batch: 2500 loss: 0.713804  [320000/555113]\n",
      "batch: 2550 loss: 0.677210  [326400/555113]\n",
      "batch: 2600 loss: 0.671171  [332800/555113]\n",
      "batch: 2650 loss: 0.661793  [339200/555113]\n",
      "batch: 2700 loss: 0.678362  [345600/555113]\n",
      "batch: 2750 loss: 0.698745  [352000/555113]\n",
      "batch: 2800 loss: 0.682937  [358400/555113]\n",
      "batch: 2850 loss: 0.682360  [364800/555113]\n",
      "batch: 2900 loss: 0.682479  [371200/555113]\n",
      "batch: 2950 loss: 0.651318  [377600/555113]\n",
      "batch: 3000 loss: 0.696041  [384000/555113]\n",
      "batch: 3050 loss: 0.660513  [390400/555113]\n",
      "batch: 3100 loss: 0.664576  [396800/555113]\n",
      "batch: 3150 loss: 0.677903  [403200/555113]\n",
      "batch: 3200 loss: 0.660642  [409600/555113]\n",
      "batch: 3250 loss: 0.665492  [416000/555113]\n",
      "batch: 3300 loss: 0.711775  [422400/555113]\n",
      "batch: 3350 loss: 0.657972  [428800/555113]\n",
      "batch: 3400 loss: 0.654492  [435200/555113]\n",
      "batch: 3450 loss: 0.709839  [441600/555113]\n",
      "batch: 3500 loss: 0.680733  [448000/555113]\n",
      "batch: 3550 loss: 0.656715  [454400/555113]\n",
      "batch: 3600 loss: 0.641402  [460800/555113]\n",
      "batch: 3650 loss: 0.648958  [467200/555113]\n",
      "batch: 3700 loss: 0.681999  [473600/555113]\n",
      "batch: 3750 loss: 0.698988  [480000/555113]\n",
      "batch: 3800 loss: 0.646030  [486400/555113]\n",
      "batch: 3850 loss: 0.651080  [492800/555113]\n",
      "batch: 3900 loss: 0.691930  [499200/555113]\n",
      "batch: 3950 loss: 0.670556  [505600/555113]\n",
      "batch: 4000 loss: 0.678648  [512000/555113]\n",
      "batch: 4050 loss: 0.695752  [518400/555113]\n",
      "batch: 4100 loss: 0.675965  [524800/555113]\n",
      "batch: 4150 loss: 0.668988  [531200/555113]\n",
      "batch: 4200 loss: 0.685709  [537600/555113]\n",
      "batch: 4250 loss: 0.698681  [544000/555113]\n",
      "batch: 4300 loss: 0.693680  [550400/555113]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net_gelu_ln.parameters(), lr=1e-5)\n",
    "\n",
    "start_epoch = 0\n",
    "min_val_loss = 1e9\n",
    "last_min_ind = -1\n",
    "early_stopping_epoch = 5\n",
    "\n",
    "epochs = 100\n",
    "for t in range(start_epoch, epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train_loop(train_dataloader, net_gelu_ln, loss_fn, optimizer)\n",
    "    eval_loss = eval_loop(val_dataloader, net_gelu_ln, loss_fn)\n",
    "    torch.save(net_gelu_ln, 'pt/'+'gelu_ln_epoch_{}_train_{:5f}_eval_{:5f}_.pt'.format(t+1, train_loss, eval_loss)) \n",
    "    if eval_loss < min_val_loss:\n",
    "        last_min_ind = t\n",
    "        min_val_loss = eval_loss\n",
    "    elif t - last_min_ind >= early_stopping_epoch:\n",
    "        break\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
