{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os.path as op\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "IMAGE_WIDTH = {5: 15, 20: 60, 60: 180}\n",
    "IMAGE_HEIGHT = {5: 32, 20: 64, 60: 96}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = np.arange(1993,2001,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793019, 64, 60)\n",
      "(793019, 8)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "label_df = []\n",
    "for year in year_list:\n",
    "    images.append(np.memmap(op.join(\"./monthly_20d\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), dtype=np.uint8, mode='r').reshape(\n",
    "                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20])))\n",
    "    label_df.append(pd.read_feather(op.join(\"./monthly_20d\", f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\")))\n",
    "    \n",
    "images = np.concatenate(images)\n",
    "label_df = pd.concat(label_df)\n",
    "\n",
    "print(images.shape)\n",
    "print(label_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img, label):\n",
    "        self.img = torch.Tensor(img.copy())\n",
    "        self.label = torch.Tensor(label)\n",
    "        self.len = len(img)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(images, (label_df.Ret_20d > 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_ratio = 0.7\n",
    "train_dataset, val_dataset = random_split(dataset, [int(dataset.len*train_val_ratio), dataset.len-int(dataset.len*train_val_ratio)], \\\n",
    "                                           generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_gelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(46080, 2),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1,64,60)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.reshape(-1,46080)\n",
    "        x = self.fc1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_gelu = Net_gelu().cuda()\n",
    "net_gelu.apply(init_weights)\n",
    "net_gelu = nn.DataParallel(net_gelu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, net, loss_fn, optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    current = 0\n",
    "    net.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        y_pred = net(X)\n",
    "        loss = loss_fn(y_pred, y.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        total_loss = (len(X) * running_loss + total_loss * current) / (len(X) + current)\n",
    "        current += len(X)\n",
    "        if batch % 50 == 49:\n",
    "            print(f\"batch: {batch+1} loss: {running_loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        running_loss = 0.0\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(dataloader, net, loss_fn):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    current = 0\n",
    "    net.eval()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        y_pred = net(X)\n",
    "        loss = loss_fn(y_pred, y.long())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        total_loss = (len(X) * running_loss + total_loss * current) / (len(X) + current)\n",
    "        current += len(X)\n",
    "        running_loss = 0.0\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.731998  [ 6400/555113]\n",
      "batch: 100 loss: 0.766788  [12800/555113]\n",
      "batch: 150 loss: 0.750340  [19200/555113]\n",
      "batch: 200 loss: 0.674930  [25600/555113]\n",
      "batch: 250 loss: 0.752008  [32000/555113]\n",
      "batch: 300 loss: 0.736955  [38400/555113]\n",
      "batch: 350 loss: 0.761990  [44800/555113]\n",
      "batch: 400 loss: 0.808216  [51200/555113]\n",
      "batch: 450 loss: 0.749531  [57600/555113]\n",
      "batch: 500 loss: 0.730752  [64000/555113]\n",
      "batch: 550 loss: 0.799859  [70400/555113]\n",
      "batch: 600 loss: 0.731940  [76800/555113]\n",
      "batch: 650 loss: 0.745575  [83200/555113]\n",
      "batch: 700 loss: 0.784669  [89600/555113]\n",
      "batch: 750 loss: 0.761608  [96000/555113]\n",
      "batch: 800 loss: 0.744638  [102400/555113]\n",
      "batch: 850 loss: 0.773485  [108800/555113]\n",
      "batch: 900 loss: 0.714151  [115200/555113]\n",
      "batch: 950 loss: 0.780457  [121600/555113]\n",
      "batch: 1000 loss: 0.763319  [128000/555113]\n",
      "batch: 1050 loss: 0.762076  [134400/555113]\n",
      "batch: 1100 loss: 0.745966  [140800/555113]\n",
      "batch: 1150 loss: 0.721784  [147200/555113]\n",
      "batch: 1200 loss: 0.786690  [153600/555113]\n",
      "batch: 1250 loss: 0.748423  [160000/555113]\n",
      "batch: 1300 loss: 0.716193  [166400/555113]\n",
      "batch: 1350 loss: 0.679058  [172800/555113]\n",
      "batch: 1400 loss: 0.792966  [179200/555113]\n",
      "batch: 1450 loss: 0.737630  [185600/555113]\n",
      "batch: 1500 loss: 0.749672  [192000/555113]\n",
      "batch: 1550 loss: 0.724173  [198400/555113]\n",
      "batch: 1600 loss: 0.732764  [204800/555113]\n",
      "batch: 1650 loss: 0.751868  [211200/555113]\n",
      "batch: 1700 loss: 0.743702  [217600/555113]\n",
      "batch: 1750 loss: 0.704670  [224000/555113]\n",
      "batch: 1800 loss: 0.741231  [230400/555113]\n",
      "batch: 1850 loss: 0.736875  [236800/555113]\n",
      "batch: 1900 loss: 0.747223  [243200/555113]\n",
      "batch: 1950 loss: 0.695850  [249600/555113]\n",
      "batch: 2000 loss: 0.743322  [256000/555113]\n",
      "batch: 2050 loss: 0.752109  [262400/555113]\n",
      "batch: 2100 loss: 0.756375  [268800/555113]\n",
      "batch: 2150 loss: 0.718195  [275200/555113]\n",
      "batch: 2200 loss: 0.757596  [281600/555113]\n",
      "batch: 2250 loss: 0.775040  [288000/555113]\n",
      "batch: 2300 loss: 0.761250  [294400/555113]\n",
      "batch: 2350 loss: 0.739174  [300800/555113]\n",
      "batch: 2400 loss: 0.696701  [307200/555113]\n",
      "batch: 2450 loss: 0.735078  [313600/555113]\n",
      "batch: 2500 loss: 0.765304  [320000/555113]\n",
      "batch: 2550 loss: 0.714840  [326400/555113]\n",
      "batch: 2600 loss: 0.726941  [332800/555113]\n",
      "batch: 2650 loss: 0.715724  [339200/555113]\n",
      "batch: 2700 loss: 0.738946  [345600/555113]\n",
      "batch: 2750 loss: 0.750441  [352000/555113]\n",
      "batch: 2800 loss: 0.774317  [358400/555113]\n",
      "batch: 2850 loss: 0.741551  [364800/555113]\n",
      "batch: 2900 loss: 0.746970  [371200/555113]\n",
      "batch: 2950 loss: 0.765816  [377600/555113]\n",
      "batch: 3000 loss: 0.755195  [384000/555113]\n",
      "batch: 3050 loss: 0.758588  [390400/555113]\n",
      "batch: 3100 loss: 0.732903  [396800/555113]\n",
      "batch: 3150 loss: 0.710358  [403200/555113]\n",
      "batch: 3200 loss: 0.704065  [409600/555113]\n",
      "batch: 3250 loss: 0.723048  [416000/555113]\n",
      "batch: 3300 loss: 0.716780  [422400/555113]\n",
      "batch: 3350 loss: 0.721932  [428800/555113]\n",
      "batch: 3400 loss: 0.733437  [435200/555113]\n",
      "batch: 3450 loss: 0.726051  [441600/555113]\n",
      "batch: 3500 loss: 0.710949  [448000/555113]\n",
      "batch: 3550 loss: 0.723311  [454400/555113]\n",
      "batch: 3600 loss: 0.722280  [460800/555113]\n",
      "batch: 3650 loss: 0.715981  [467200/555113]\n",
      "batch: 3700 loss: 0.745658  [473600/555113]\n",
      "batch: 3750 loss: 0.715390  [480000/555113]\n",
      "batch: 3800 loss: 0.707592  [486400/555113]\n",
      "batch: 3850 loss: 0.777851  [492800/555113]\n",
      "batch: 3900 loss: 0.732542  [499200/555113]\n",
      "batch: 3950 loss: 0.737198  [505600/555113]\n",
      "batch: 4000 loss: 0.702617  [512000/555113]\n",
      "batch: 4050 loss: 0.763176  [518400/555113]\n",
      "batch: 4100 loss: 0.714090  [524800/555113]\n",
      "batch: 4150 loss: 0.747766  [531200/555113]\n",
      "batch: 4200 loss: 0.749519  [537600/555113]\n",
      "batch: 4250 loss: 0.750429  [544000/555113]\n",
      "batch: 4300 loss: 0.697863  [550400/555113]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.725334  [ 6400/555113]\n",
      "batch: 100 loss: 0.723324  [12800/555113]\n",
      "batch: 150 loss: 0.760288  [19200/555113]\n",
      "batch: 200 loss: 0.738995  [25600/555113]\n",
      "batch: 250 loss: 0.749442  [32000/555113]\n",
      "batch: 300 loss: 0.713978  [38400/555113]\n",
      "batch: 350 loss: 0.782279  [44800/555113]\n",
      "batch: 400 loss: 0.689968  [51200/555113]\n",
      "batch: 450 loss: 0.713056  [57600/555113]\n",
      "batch: 500 loss: 0.730321  [64000/555113]\n",
      "batch: 550 loss: 0.705239  [70400/555113]\n",
      "batch: 600 loss: 0.663458  [76800/555113]\n",
      "batch: 650 loss: 0.716853  [83200/555113]\n",
      "batch: 700 loss: 0.726782  [89600/555113]\n",
      "batch: 750 loss: 0.739947  [96000/555113]\n",
      "batch: 800 loss: 0.711132  [102400/555113]\n",
      "batch: 850 loss: 0.749922  [108800/555113]\n",
      "batch: 900 loss: 0.752176  [115200/555113]\n",
      "batch: 950 loss: 0.735493  [121600/555113]\n",
      "batch: 1000 loss: 0.706795  [128000/555113]\n",
      "batch: 1050 loss: 0.661902  [134400/555113]\n",
      "batch: 1100 loss: 0.701401  [140800/555113]\n",
      "batch: 1150 loss: 0.686723  [147200/555113]\n",
      "batch: 1200 loss: 0.685770  [153600/555113]\n",
      "batch: 1250 loss: 0.721367  [160000/555113]\n",
      "batch: 1300 loss: 0.707448  [166400/555113]\n",
      "batch: 1350 loss: 0.723396  [172800/555113]\n",
      "batch: 1400 loss: 0.710599  [179200/555113]\n",
      "batch: 1450 loss: 0.673566  [185600/555113]\n",
      "batch: 1500 loss: 0.701300  [192000/555113]\n",
      "batch: 1550 loss: 0.705119  [198400/555113]\n",
      "batch: 1600 loss: 0.691576  [204800/555113]\n",
      "batch: 1650 loss: 0.716411  [211200/555113]\n",
      "batch: 1700 loss: 0.712491  [217600/555113]\n",
      "batch: 1750 loss: 0.714112  [224000/555113]\n",
      "batch: 1800 loss: 0.728041  [230400/555113]\n",
      "batch: 1850 loss: 0.727212  [236800/555113]\n",
      "batch: 1900 loss: 0.727789  [243200/555113]\n",
      "batch: 1950 loss: 0.774096  [249600/555113]\n",
      "batch: 2000 loss: 0.701392  [256000/555113]\n",
      "batch: 2050 loss: 0.747736  [262400/555113]\n",
      "batch: 2100 loss: 0.714945  [268800/555113]\n",
      "batch: 2150 loss: 0.735372  [275200/555113]\n",
      "batch: 2200 loss: 0.710455  [281600/555113]\n",
      "batch: 2250 loss: 0.693836  [288000/555113]\n",
      "batch: 2300 loss: 0.719857  [294400/555113]\n",
      "batch: 2350 loss: 0.676344  [300800/555113]\n",
      "batch: 2400 loss: 0.679324  [307200/555113]\n",
      "batch: 2450 loss: 0.691314  [313600/555113]\n",
      "batch: 2500 loss: 0.714729  [320000/555113]\n",
      "batch: 2550 loss: 0.713716  [326400/555113]\n",
      "batch: 2600 loss: 0.705255  [332800/555113]\n",
      "batch: 2650 loss: 0.720086  [339200/555113]\n",
      "batch: 2700 loss: 0.743062  [345600/555113]\n",
      "batch: 2750 loss: 0.694967  [352000/555113]\n",
      "batch: 2800 loss: 0.722376  [358400/555113]\n",
      "batch: 2850 loss: 0.702478  [364800/555113]\n",
      "batch: 2900 loss: 0.698899  [371200/555113]\n",
      "batch: 2950 loss: 0.719133  [377600/555113]\n",
      "batch: 3000 loss: 0.724396  [384000/555113]\n",
      "batch: 3050 loss: 0.701350  [390400/555113]\n",
      "batch: 3100 loss: 0.721780  [396800/555113]\n",
      "batch: 3150 loss: 0.716214  [403200/555113]\n",
      "batch: 3200 loss: 0.728082  [409600/555113]\n",
      "batch: 3250 loss: 0.710069  [416000/555113]\n",
      "batch: 3300 loss: 0.704934  [422400/555113]\n",
      "batch: 3350 loss: 0.697995  [428800/555113]\n",
      "batch: 3400 loss: 0.749829  [435200/555113]\n",
      "batch: 3450 loss: 0.706695  [441600/555113]\n",
      "batch: 3500 loss: 0.684122  [448000/555113]\n",
      "batch: 3550 loss: 0.685086  [454400/555113]\n",
      "batch: 3600 loss: 0.671374  [460800/555113]\n",
      "batch: 3650 loss: 0.705574  [467200/555113]\n",
      "batch: 3700 loss: 0.748367  [473600/555113]\n",
      "batch: 3750 loss: 0.673346  [480000/555113]\n",
      "batch: 3800 loss: 0.744085  [486400/555113]\n",
      "batch: 3850 loss: 0.673977  [492800/555113]\n",
      "batch: 3900 loss: 0.700057  [499200/555113]\n",
      "batch: 3950 loss: 0.704137  [505600/555113]\n",
      "batch: 4000 loss: 0.728049  [512000/555113]\n",
      "batch: 4050 loss: 0.751618  [518400/555113]\n",
      "batch: 4100 loss: 0.658121  [524800/555113]\n",
      "batch: 4150 loss: 0.706301  [531200/555113]\n",
      "batch: 4200 loss: 0.717593  [537600/555113]\n",
      "batch: 4250 loss: 0.682226  [544000/555113]\n",
      "batch: 4300 loss: 0.727830  [550400/555113]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.737144  [ 6400/555113]\n",
      "batch: 100 loss: 0.685008  [12800/555113]\n",
      "batch: 150 loss: 0.732408  [19200/555113]\n",
      "batch: 200 loss: 0.713952  [25600/555113]\n",
      "batch: 250 loss: 0.719287  [32000/555113]\n",
      "batch: 300 loss: 0.693203  [38400/555113]\n",
      "batch: 350 loss: 0.715754  [44800/555113]\n",
      "batch: 400 loss: 0.716713  [51200/555113]\n",
      "batch: 450 loss: 0.731070  [57600/555113]\n",
      "batch: 500 loss: 0.709777  [64000/555113]\n",
      "batch: 550 loss: 0.699962  [70400/555113]\n",
      "batch: 600 loss: 0.719516  [76800/555113]\n",
      "batch: 650 loss: 0.692430  [83200/555113]\n",
      "batch: 700 loss: 0.755919  [89600/555113]\n",
      "batch: 750 loss: 0.699097  [96000/555113]\n",
      "batch: 800 loss: 0.677844  [102400/555113]\n",
      "batch: 850 loss: 0.706557  [108800/555113]\n",
      "batch: 900 loss: 0.703260  [115200/555113]\n",
      "batch: 950 loss: 0.715964  [121600/555113]\n",
      "batch: 1000 loss: 0.706630  [128000/555113]\n",
      "batch: 1050 loss: 0.696960  [134400/555113]\n",
      "batch: 1100 loss: 0.700606  [140800/555113]\n",
      "batch: 1150 loss: 0.719438  [147200/555113]\n",
      "batch: 1200 loss: 0.692456  [153600/555113]\n",
      "batch: 1250 loss: 0.710591  [160000/555113]\n",
      "batch: 1300 loss: 0.726041  [166400/555113]\n",
      "batch: 1350 loss: 0.682507  [172800/555113]\n",
      "batch: 1400 loss: 0.711652  [179200/555113]\n",
      "batch: 1450 loss: 0.705656  [185600/555113]\n",
      "batch: 1500 loss: 0.682974  [192000/555113]\n",
      "batch: 1550 loss: 0.692961  [198400/555113]\n",
      "batch: 1600 loss: 0.703841  [204800/555113]\n",
      "batch: 1650 loss: 0.739485  [211200/555113]\n",
      "batch: 1700 loss: 0.670226  [217600/555113]\n",
      "batch: 1750 loss: 0.695830  [224000/555113]\n",
      "batch: 1800 loss: 0.726029  [230400/555113]\n",
      "batch: 1850 loss: 0.714305  [236800/555113]\n",
      "batch: 1900 loss: 0.674999  [243200/555113]\n",
      "batch: 1950 loss: 0.728055  [249600/555113]\n",
      "batch: 2000 loss: 0.724637  [256000/555113]\n",
      "batch: 2050 loss: 0.653831  [262400/555113]\n",
      "batch: 2100 loss: 0.711041  [268800/555113]\n",
      "batch: 2150 loss: 0.709541  [275200/555113]\n",
      "batch: 2200 loss: 0.719065  [281600/555113]\n",
      "batch: 2250 loss: 0.704695  [288000/555113]\n",
      "batch: 2300 loss: 0.673486  [294400/555113]\n",
      "batch: 2350 loss: 0.681569  [300800/555113]\n",
      "batch: 2400 loss: 0.699567  [307200/555113]\n",
      "batch: 2450 loss: 0.745916  [313600/555113]\n",
      "batch: 2500 loss: 0.718416  [320000/555113]\n",
      "batch: 2550 loss: 0.662913  [326400/555113]\n",
      "batch: 2600 loss: 0.712521  [332800/555113]\n",
      "batch: 2650 loss: 0.722460  [339200/555113]\n",
      "batch: 2700 loss: 0.674168  [345600/555113]\n",
      "batch: 2750 loss: 0.671360  [352000/555113]\n",
      "batch: 2800 loss: 0.697491  [358400/555113]\n",
      "batch: 2850 loss: 0.686441  [364800/555113]\n",
      "batch: 2900 loss: 0.685622  [371200/555113]\n",
      "batch: 2950 loss: 0.693203  [377600/555113]\n",
      "batch: 3000 loss: 0.721849  [384000/555113]\n",
      "batch: 3050 loss: 0.689170  [390400/555113]\n",
      "batch: 3100 loss: 0.672780  [396800/555113]\n",
      "batch: 3150 loss: 0.717556  [403200/555113]\n",
      "batch: 3200 loss: 0.665144  [409600/555113]\n",
      "batch: 3250 loss: 0.702040  [416000/555113]\n",
      "batch: 3300 loss: 0.693182  [422400/555113]\n",
      "batch: 3350 loss: 0.727639  [428800/555113]\n",
      "batch: 3400 loss: 0.733285  [435200/555113]\n",
      "batch: 3450 loss: 0.713734  [441600/555113]\n",
      "batch: 3500 loss: 0.695355  [448000/555113]\n",
      "batch: 3550 loss: 0.687352  [454400/555113]\n",
      "batch: 3600 loss: 0.705804  [460800/555113]\n",
      "batch: 3650 loss: 0.711431  [467200/555113]\n",
      "batch: 3700 loss: 0.701269  [473600/555113]\n",
      "batch: 3750 loss: 0.719703  [480000/555113]\n",
      "batch: 3800 loss: 0.724393  [486400/555113]\n",
      "batch: 3850 loss: 0.713297  [492800/555113]\n",
      "batch: 3900 loss: 0.713182  [499200/555113]\n",
      "batch: 3950 loss: 0.731927  [505600/555113]\n",
      "batch: 4000 loss: 0.703046  [512000/555113]\n",
      "batch: 4050 loss: 0.723187  [518400/555113]\n",
      "batch: 4100 loss: 0.713000  [524800/555113]\n",
      "batch: 4150 loss: 0.713102  [531200/555113]\n",
      "batch: 4200 loss: 0.687477  [537600/555113]\n",
      "batch: 4250 loss: 0.691886  [544000/555113]\n",
      "batch: 4300 loss: 0.687153  [550400/555113]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.686752  [ 6400/555113]\n",
      "batch: 100 loss: 0.691710  [12800/555113]\n",
      "batch: 150 loss: 0.697472  [19200/555113]\n",
      "batch: 200 loss: 0.688837  [25600/555113]\n",
      "batch: 250 loss: 0.691234  [32000/555113]\n",
      "batch: 300 loss: 0.681614  [38400/555113]\n",
      "batch: 350 loss: 0.712183  [44800/555113]\n",
      "batch: 400 loss: 0.712622  [51200/555113]\n",
      "batch: 450 loss: 0.695899  [57600/555113]\n",
      "batch: 500 loss: 0.677996  [64000/555113]\n",
      "batch: 550 loss: 0.727482  [70400/555113]\n",
      "batch: 600 loss: 0.675891  [76800/555113]\n",
      "batch: 650 loss: 0.692224  [83200/555113]\n",
      "batch: 700 loss: 0.672671  [89600/555113]\n",
      "batch: 750 loss: 0.694276  [96000/555113]\n",
      "batch: 800 loss: 0.729796  [102400/555113]\n",
      "batch: 850 loss: 0.676148  [108800/555113]\n",
      "batch: 900 loss: 0.706664  [115200/555113]\n",
      "batch: 950 loss: 0.700824  [121600/555113]\n",
      "batch: 1000 loss: 0.683672  [128000/555113]\n",
      "batch: 1050 loss: 0.681908  [134400/555113]\n",
      "batch: 1100 loss: 0.670760  [140800/555113]\n",
      "batch: 1150 loss: 0.739888  [147200/555113]\n",
      "batch: 1200 loss: 0.700194  [153600/555113]\n",
      "batch: 1250 loss: 0.675018  [160000/555113]\n",
      "batch: 1300 loss: 0.698330  [166400/555113]\n",
      "batch: 1350 loss: 0.688914  [172800/555113]\n",
      "batch: 1400 loss: 0.686995  [179200/555113]\n",
      "batch: 1450 loss: 0.677592  [185600/555113]\n",
      "batch: 1500 loss: 0.690962  [192000/555113]\n",
      "batch: 1550 loss: 0.699864  [198400/555113]\n",
      "batch: 1600 loss: 0.723314  [204800/555113]\n",
      "batch: 1650 loss: 0.671495  [211200/555113]\n",
      "batch: 1700 loss: 0.693663  [217600/555113]\n",
      "batch: 1750 loss: 0.702348  [224000/555113]\n",
      "batch: 1800 loss: 0.695183  [230400/555113]\n",
      "batch: 1850 loss: 0.686658  [236800/555113]\n",
      "batch: 1900 loss: 0.728370  [243200/555113]\n",
      "batch: 1950 loss: 0.689761  [249600/555113]\n",
      "batch: 2000 loss: 0.664780  [256000/555113]\n",
      "batch: 2050 loss: 0.679477  [262400/555113]\n",
      "batch: 2100 loss: 0.689462  [268800/555113]\n",
      "batch: 2150 loss: 0.691294  [275200/555113]\n",
      "batch: 2200 loss: 0.671282  [281600/555113]\n",
      "batch: 2250 loss: 0.678068  [288000/555113]\n",
      "batch: 2300 loss: 0.704999  [294400/555113]\n",
      "batch: 2350 loss: 0.676181  [300800/555113]\n",
      "batch: 2400 loss: 0.673231  [307200/555113]\n",
      "batch: 2450 loss: 0.695623  [313600/555113]\n",
      "batch: 2500 loss: 0.710496  [320000/555113]\n",
      "batch: 2550 loss: 0.682163  [326400/555113]\n",
      "batch: 2600 loss: 0.691350  [332800/555113]\n",
      "batch: 2650 loss: 0.691629  [339200/555113]\n",
      "batch: 2700 loss: 0.704994  [345600/555113]\n",
      "batch: 2750 loss: 0.689027  [352000/555113]\n",
      "batch: 2800 loss: 0.670174  [358400/555113]\n",
      "batch: 2850 loss: 0.690472  [364800/555113]\n",
      "batch: 2900 loss: 0.685531  [371200/555113]\n",
      "batch: 2950 loss: 0.712320  [377600/555113]\n",
      "batch: 3000 loss: 0.704285  [384000/555113]\n",
      "batch: 3050 loss: 0.701689  [390400/555113]\n",
      "batch: 3100 loss: 0.698247  [396800/555113]\n",
      "batch: 3150 loss: 0.695735  [403200/555113]\n",
      "batch: 3200 loss: 0.672718  [409600/555113]\n",
      "batch: 3250 loss: 0.680033  [416000/555113]\n",
      "batch: 3300 loss: 0.705541  [422400/555113]\n",
      "batch: 3350 loss: 0.690120  [428800/555113]\n",
      "batch: 3400 loss: 0.724617  [435200/555113]\n",
      "batch: 3450 loss: 0.697911  [441600/555113]\n",
      "batch: 3500 loss: 0.736775  [448000/555113]\n",
      "batch: 3550 loss: 0.673869  [454400/555113]\n",
      "batch: 3600 loss: 0.709607  [460800/555113]\n",
      "batch: 3650 loss: 0.697328  [467200/555113]\n",
      "batch: 3700 loss: 0.704135  [473600/555113]\n",
      "batch: 3750 loss: 0.699792  [480000/555113]\n",
      "batch: 3800 loss: 0.692282  [486400/555113]\n",
      "batch: 3850 loss: 0.693298  [492800/555113]\n",
      "batch: 3900 loss: 0.702759  [499200/555113]\n",
      "batch: 3950 loss: 0.695317  [505600/555113]\n",
      "batch: 4000 loss: 0.702789  [512000/555113]\n",
      "batch: 4050 loss: 0.657383  [518400/555113]\n",
      "batch: 4100 loss: 0.709577  [524800/555113]\n",
      "batch: 4150 loss: 0.676146  [531200/555113]\n",
      "batch: 4200 loss: 0.697890  [537600/555113]\n",
      "batch: 4250 loss: 0.690020  [544000/555113]\n",
      "batch: 4300 loss: 0.724613  [550400/555113]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.707954  [ 6400/555113]\n",
      "batch: 100 loss: 0.698291  [12800/555113]\n",
      "batch: 150 loss: 0.691917  [19200/555113]\n",
      "batch: 200 loss: 0.679250  [25600/555113]\n",
      "batch: 250 loss: 0.662892  [32000/555113]\n",
      "batch: 300 loss: 0.711511  [38400/555113]\n",
      "batch: 350 loss: 0.719580  [44800/555113]\n",
      "batch: 400 loss: 0.713642  [51200/555113]\n",
      "batch: 450 loss: 0.693158  [57600/555113]\n",
      "batch: 500 loss: 0.661422  [64000/555113]\n",
      "batch: 550 loss: 0.695792  [70400/555113]\n",
      "batch: 600 loss: 0.681594  [76800/555113]\n",
      "batch: 650 loss: 0.700964  [83200/555113]\n",
      "batch: 700 loss: 0.684134  [89600/555113]\n",
      "batch: 750 loss: 0.690490  [96000/555113]\n",
      "batch: 800 loss: 0.717705  [102400/555113]\n",
      "batch: 850 loss: 0.684694  [108800/555113]\n",
      "batch: 900 loss: 0.716611  [115200/555113]\n",
      "batch: 950 loss: 0.677662  [121600/555113]\n",
      "batch: 1000 loss: 0.694623  [128000/555113]\n",
      "batch: 1050 loss: 0.691369  [134400/555113]\n",
      "batch: 1100 loss: 0.689867  [140800/555113]\n",
      "batch: 1150 loss: 0.648924  [147200/555113]\n",
      "batch: 1200 loss: 0.689157  [153600/555113]\n",
      "batch: 1250 loss: 0.685080  [160000/555113]\n",
      "batch: 1300 loss: 0.706072  [166400/555113]\n",
      "batch: 1350 loss: 0.700850  [172800/555113]\n",
      "batch: 1400 loss: 0.679797  [179200/555113]\n",
      "batch: 1450 loss: 0.668384  [185600/555113]\n",
      "batch: 1500 loss: 0.693974  [192000/555113]\n",
      "batch: 1550 loss: 0.692591  [198400/555113]\n",
      "batch: 1600 loss: 0.707105  [204800/555113]\n",
      "batch: 1650 loss: 0.700493  [211200/555113]\n",
      "batch: 1700 loss: 0.672652  [217600/555113]\n",
      "batch: 1750 loss: 0.688495  [224000/555113]\n",
      "batch: 1800 loss: 0.671807  [230400/555113]\n",
      "batch: 1850 loss: 0.711954  [236800/555113]\n",
      "batch: 1900 loss: 0.687772  [243200/555113]\n",
      "batch: 1950 loss: 0.696141  [249600/555113]\n",
      "batch: 2000 loss: 0.738855  [256000/555113]\n",
      "batch: 2050 loss: 0.692017  [262400/555113]\n",
      "batch: 2100 loss: 0.672694  [268800/555113]\n",
      "batch: 2150 loss: 0.693226  [275200/555113]\n",
      "batch: 2200 loss: 0.690314  [281600/555113]\n",
      "batch: 2250 loss: 0.712690  [288000/555113]\n",
      "batch: 2300 loss: 0.714537  [294400/555113]\n",
      "batch: 2350 loss: 0.688729  [300800/555113]\n",
      "batch: 2400 loss: 0.700082  [307200/555113]\n",
      "batch: 2450 loss: 0.691660  [313600/555113]\n",
      "batch: 2500 loss: 0.677045  [320000/555113]\n",
      "batch: 2550 loss: 0.691336  [326400/555113]\n",
      "batch: 2600 loss: 0.694952  [332800/555113]\n",
      "batch: 2650 loss: 0.679066  [339200/555113]\n",
      "batch: 2700 loss: 0.671065  [345600/555113]\n",
      "batch: 2750 loss: 0.721293  [352000/555113]\n",
      "batch: 2800 loss: 0.695463  [358400/555113]\n",
      "batch: 2850 loss: 0.697212  [364800/555113]\n",
      "batch: 2900 loss: 0.689788  [371200/555113]\n",
      "batch: 2950 loss: 0.680978  [377600/555113]\n",
      "batch: 3000 loss: 0.655466  [384000/555113]\n",
      "batch: 3050 loss: 0.694008  [390400/555113]\n",
      "batch: 3100 loss: 0.678564  [396800/555113]\n",
      "batch: 3150 loss: 0.677880  [403200/555113]\n",
      "batch: 3200 loss: 0.700715  [409600/555113]\n",
      "batch: 3250 loss: 0.714643  [416000/555113]\n",
      "batch: 3300 loss: 0.714654  [422400/555113]\n",
      "batch: 3350 loss: 0.705604  [428800/555113]\n",
      "batch: 3400 loss: 0.704147  [435200/555113]\n",
      "batch: 3450 loss: 0.680158  [441600/555113]\n",
      "batch: 3500 loss: 0.679404  [448000/555113]\n",
      "batch: 3550 loss: 0.666329  [454400/555113]\n",
      "batch: 3600 loss: 0.666481  [460800/555113]\n",
      "batch: 3650 loss: 0.684008  [467200/555113]\n",
      "batch: 3700 loss: 0.686194  [473600/555113]\n",
      "batch: 3750 loss: 0.676876  [480000/555113]\n",
      "batch: 3800 loss: 0.680803  [486400/555113]\n",
      "batch: 3850 loss: 0.710972  [492800/555113]\n",
      "batch: 3900 loss: 0.694637  [499200/555113]\n",
      "batch: 3950 loss: 0.698491  [505600/555113]\n",
      "batch: 4000 loss: 0.708381  [512000/555113]\n",
      "batch: 4050 loss: 0.686011  [518400/555113]\n",
      "batch: 4100 loss: 0.705700  [524800/555113]\n",
      "batch: 4150 loss: 0.683613  [531200/555113]\n",
      "batch: 4200 loss: 0.703902  [537600/555113]\n",
      "batch: 4250 loss: 0.717724  [544000/555113]\n",
      "batch: 4300 loss: 0.726406  [550400/555113]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.668802  [ 6400/555113]\n",
      "batch: 100 loss: 0.704149  [12800/555113]\n",
      "batch: 150 loss: 0.672649  [19200/555113]\n",
      "batch: 200 loss: 0.698184  [25600/555113]\n",
      "batch: 250 loss: 0.703019  [32000/555113]\n",
      "batch: 300 loss: 0.682507  [38400/555113]\n",
      "batch: 350 loss: 0.702466  [44800/555113]\n",
      "batch: 400 loss: 0.677609  [51200/555113]\n",
      "batch: 450 loss: 0.686195  [57600/555113]\n",
      "batch: 500 loss: 0.691918  [64000/555113]\n",
      "batch: 550 loss: 0.675588  [70400/555113]\n",
      "batch: 600 loss: 0.696978  [76800/555113]\n",
      "batch: 650 loss: 0.673687  [83200/555113]\n",
      "batch: 700 loss: 0.663889  [89600/555113]\n",
      "batch: 750 loss: 0.703304  [96000/555113]\n",
      "batch: 800 loss: 0.655635  [102400/555113]\n",
      "batch: 850 loss: 0.644897  [108800/555113]\n",
      "batch: 900 loss: 0.701020  [115200/555113]\n",
      "batch: 950 loss: 0.703469  [121600/555113]\n",
      "batch: 1000 loss: 0.681532  [128000/555113]\n",
      "batch: 1050 loss: 0.670656  [134400/555113]\n",
      "batch: 1100 loss: 0.680416  [140800/555113]\n",
      "batch: 1150 loss: 0.659601  [147200/555113]\n",
      "batch: 1200 loss: 0.700573  [153600/555113]\n",
      "batch: 1250 loss: 0.728288  [160000/555113]\n",
      "batch: 1300 loss: 0.667634  [166400/555113]\n",
      "batch: 1350 loss: 0.700592  [172800/555113]\n",
      "batch: 1400 loss: 0.691189  [179200/555113]\n",
      "batch: 1450 loss: 0.706691  [185600/555113]\n",
      "batch: 1500 loss: 0.704449  [192000/555113]\n",
      "batch: 1550 loss: 0.712311  [198400/555113]\n",
      "batch: 1600 loss: 0.712644  [204800/555113]\n",
      "batch: 1650 loss: 0.690334  [211200/555113]\n",
      "batch: 1700 loss: 0.698968  [217600/555113]\n",
      "batch: 1750 loss: 0.670573  [224000/555113]\n",
      "batch: 1800 loss: 0.673761  [230400/555113]\n",
      "batch: 1850 loss: 0.691102  [236800/555113]\n",
      "batch: 1900 loss: 0.706273  [243200/555113]\n",
      "batch: 1950 loss: 0.669212  [249600/555113]\n",
      "batch: 2000 loss: 0.698127  [256000/555113]\n",
      "batch: 2050 loss: 0.668764  [262400/555113]\n",
      "batch: 2100 loss: 0.689201  [268800/555113]\n",
      "batch: 2150 loss: 0.682987  [275200/555113]\n",
      "batch: 2200 loss: 0.664316  [281600/555113]\n",
      "batch: 2250 loss: 0.683554  [288000/555113]\n",
      "batch: 2300 loss: 0.672349  [294400/555113]\n",
      "batch: 2350 loss: 0.715689  [300800/555113]\n",
      "batch: 2400 loss: 0.689742  [307200/555113]\n",
      "batch: 2450 loss: 0.681179  [313600/555113]\n",
      "batch: 2500 loss: 0.730242  [320000/555113]\n",
      "batch: 2550 loss: 0.678746  [326400/555113]\n",
      "batch: 2600 loss: 0.707010  [332800/555113]\n",
      "batch: 2650 loss: 0.659627  [339200/555113]\n",
      "batch: 2700 loss: 0.663268  [345600/555113]\n",
      "batch: 2750 loss: 0.710372  [352000/555113]\n",
      "batch: 2800 loss: 0.711859  [358400/555113]\n",
      "batch: 2850 loss: 0.691732  [364800/555113]\n",
      "batch: 2900 loss: 0.721149  [371200/555113]\n",
      "batch: 2950 loss: 0.698234  [377600/555113]\n",
      "batch: 3000 loss: 0.673847  [384000/555113]\n",
      "batch: 3050 loss: 0.689274  [390400/555113]\n",
      "batch: 3100 loss: 0.677577  [396800/555113]\n",
      "batch: 3150 loss: 0.683355  [403200/555113]\n",
      "batch: 3200 loss: 0.670777  [409600/555113]\n",
      "batch: 3250 loss: 0.660594  [416000/555113]\n",
      "batch: 3300 loss: 0.688714  [422400/555113]\n",
      "batch: 3350 loss: 0.709271  [428800/555113]\n",
      "batch: 3400 loss: 0.679301  [435200/555113]\n",
      "batch: 3450 loss: 0.708691  [441600/555113]\n",
      "batch: 3500 loss: 0.693387  [448000/555113]\n",
      "batch: 3550 loss: 0.683653  [454400/555113]\n",
      "batch: 3600 loss: 0.690746  [460800/555113]\n",
      "batch: 3650 loss: 0.697985  [467200/555113]\n",
      "batch: 3700 loss: 0.676647  [473600/555113]\n",
      "batch: 3750 loss: 0.716564  [480000/555113]\n",
      "batch: 3800 loss: 0.689542  [486400/555113]\n",
      "batch: 3850 loss: 0.681790  [492800/555113]\n",
      "batch: 3900 loss: 0.701241  [499200/555113]\n",
      "batch: 3950 loss: 0.685547  [505600/555113]\n",
      "batch: 4000 loss: 0.686114  [512000/555113]\n",
      "batch: 4050 loss: 0.708477  [518400/555113]\n",
      "batch: 4100 loss: 0.704127  [524800/555113]\n",
      "batch: 4150 loss: 0.683036  [531200/555113]\n",
      "batch: 4200 loss: 0.702559  [537600/555113]\n",
      "batch: 4250 loss: 0.697207  [544000/555113]\n",
      "batch: 4300 loss: 0.665539  [550400/555113]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.659868  [ 6400/555113]\n",
      "batch: 100 loss: 0.691093  [12800/555113]\n",
      "batch: 150 loss: 0.698507  [19200/555113]\n",
      "batch: 200 loss: 0.693971  [25600/555113]\n",
      "batch: 250 loss: 0.665769  [32000/555113]\n",
      "batch: 300 loss: 0.685690  [38400/555113]\n",
      "batch: 350 loss: 0.688770  [44800/555113]\n",
      "batch: 400 loss: 0.665326  [51200/555113]\n",
      "batch: 450 loss: 0.671058  [57600/555113]\n",
      "batch: 500 loss: 0.692784  [64000/555113]\n",
      "batch: 550 loss: 0.703498  [70400/555113]\n",
      "batch: 600 loss: 0.675770  [76800/555113]\n",
      "batch: 650 loss: 0.676079  [83200/555113]\n",
      "batch: 700 loss: 0.681905  [89600/555113]\n",
      "batch: 750 loss: 0.665104  [96000/555113]\n",
      "batch: 800 loss: 0.651858  [102400/555113]\n",
      "batch: 850 loss: 0.686446  [108800/555113]\n",
      "batch: 900 loss: 0.722052  [115200/555113]\n",
      "batch: 950 loss: 0.699785  [121600/555113]\n",
      "batch: 1000 loss: 0.684239  [128000/555113]\n",
      "batch: 1050 loss: 0.661751  [134400/555113]\n",
      "batch: 1100 loss: 0.673318  [140800/555113]\n",
      "batch: 1150 loss: 0.722322  [147200/555113]\n",
      "batch: 1200 loss: 0.688382  [153600/555113]\n",
      "batch: 1250 loss: 0.658373  [160000/555113]\n",
      "batch: 1300 loss: 0.708219  [166400/555113]\n",
      "batch: 1350 loss: 0.719157  [172800/555113]\n",
      "batch: 1400 loss: 0.661642  [179200/555113]\n",
      "batch: 1450 loss: 0.715190  [185600/555113]\n",
      "batch: 1500 loss: 0.710539  [192000/555113]\n",
      "batch: 1550 loss: 0.693999  [198400/555113]\n",
      "batch: 1600 loss: 0.690171  [204800/555113]\n",
      "batch: 1650 loss: 0.664761  [211200/555113]\n",
      "batch: 1700 loss: 0.673964  [217600/555113]\n",
      "batch: 1750 loss: 0.691781  [224000/555113]\n",
      "batch: 1800 loss: 0.669742  [230400/555113]\n",
      "batch: 1850 loss: 0.672871  [236800/555113]\n",
      "batch: 1900 loss: 0.683442  [243200/555113]\n",
      "batch: 1950 loss: 0.697309  [249600/555113]\n",
      "batch: 2000 loss: 0.709039  [256000/555113]\n",
      "batch: 2050 loss: 0.682812  [262400/555113]\n",
      "batch: 2100 loss: 0.680528  [268800/555113]\n",
      "batch: 2150 loss: 0.696992  [275200/555113]\n",
      "batch: 2200 loss: 0.716590  [281600/555113]\n",
      "batch: 2250 loss: 0.696813  [288000/555113]\n",
      "batch: 2300 loss: 0.691200  [294400/555113]\n",
      "batch: 2350 loss: 0.708654  [300800/555113]\n",
      "batch: 2400 loss: 0.695819  [307200/555113]\n",
      "batch: 2450 loss: 0.647361  [313600/555113]\n",
      "batch: 2500 loss: 0.686293  [320000/555113]\n",
      "batch: 2550 loss: 0.688038  [326400/555113]\n",
      "batch: 2600 loss: 0.681442  [332800/555113]\n",
      "batch: 2650 loss: 0.697300  [339200/555113]\n",
      "batch: 2700 loss: 0.678263  [345600/555113]\n",
      "batch: 2750 loss: 0.700900  [352000/555113]\n",
      "batch: 2800 loss: 0.678353  [358400/555113]\n",
      "batch: 2850 loss: 0.697605  [364800/555113]\n",
      "batch: 2900 loss: 0.685823  [371200/555113]\n",
      "batch: 2950 loss: 0.728732  [377600/555113]\n",
      "batch: 3000 loss: 0.687327  [384000/555113]\n",
      "batch: 3050 loss: 0.702785  [390400/555113]\n",
      "batch: 3100 loss: 0.701698  [396800/555113]\n",
      "batch: 3150 loss: 0.654003  [403200/555113]\n",
      "batch: 3200 loss: 0.690009  [409600/555113]\n",
      "batch: 3250 loss: 0.706264  [416000/555113]\n",
      "batch: 3300 loss: 0.706680  [422400/555113]\n",
      "batch: 3350 loss: 0.685776  [428800/555113]\n",
      "batch: 3400 loss: 0.685088  [435200/555113]\n",
      "batch: 3450 loss: 0.692963  [441600/555113]\n",
      "batch: 3500 loss: 0.676815  [448000/555113]\n",
      "batch: 3550 loss: 0.693009  [454400/555113]\n",
      "batch: 3600 loss: 0.670057  [460800/555113]\n",
      "batch: 3650 loss: 0.674377  [467200/555113]\n",
      "batch: 3700 loss: 0.676268  [473600/555113]\n",
      "batch: 3750 loss: 0.709257  [480000/555113]\n",
      "batch: 3800 loss: 0.674095  [486400/555113]\n",
      "batch: 3850 loss: 0.697736  [492800/555113]\n",
      "batch: 3900 loss: 0.707432  [499200/555113]\n",
      "batch: 3950 loss: 0.684947  [505600/555113]\n",
      "batch: 4000 loss: 0.650879  [512000/555113]\n",
      "batch: 4050 loss: 0.693473  [518400/555113]\n",
      "batch: 4100 loss: 0.665117  [524800/555113]\n",
      "batch: 4150 loss: 0.682814  [531200/555113]\n",
      "batch: 4200 loss: 0.716543  [537600/555113]\n",
      "batch: 4250 loss: 0.669514  [544000/555113]\n",
      "batch: 4300 loss: 0.676576  [550400/555113]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.653314  [ 6400/555113]\n",
      "batch: 100 loss: 0.685252  [12800/555113]\n",
      "batch: 150 loss: 0.690809  [19200/555113]\n",
      "batch: 200 loss: 0.732073  [25600/555113]\n",
      "batch: 250 loss: 0.675293  [32000/555113]\n",
      "batch: 300 loss: 0.688956  [38400/555113]\n",
      "batch: 350 loss: 0.672569  [44800/555113]\n",
      "batch: 400 loss: 0.662036  [51200/555113]\n",
      "batch: 450 loss: 0.703043  [57600/555113]\n",
      "batch: 500 loss: 0.678209  [64000/555113]\n",
      "batch: 550 loss: 0.711384  [70400/555113]\n",
      "batch: 600 loss: 0.698281  [76800/555113]\n",
      "batch: 650 loss: 0.672750  [83200/555113]\n",
      "batch: 700 loss: 0.705735  [89600/555113]\n",
      "batch: 750 loss: 0.696376  [96000/555113]\n",
      "batch: 800 loss: 0.666585  [102400/555113]\n",
      "batch: 850 loss: 0.663837  [108800/555113]\n",
      "batch: 900 loss: 0.707137  [115200/555113]\n",
      "batch: 950 loss: 0.694097  [121600/555113]\n",
      "batch: 1000 loss: 0.708549  [128000/555113]\n",
      "batch: 1050 loss: 0.697892  [134400/555113]\n",
      "batch: 1100 loss: 0.670130  [140800/555113]\n",
      "batch: 1150 loss: 0.653351  [147200/555113]\n",
      "batch: 1200 loss: 0.706125  [153600/555113]\n",
      "batch: 1250 loss: 0.680472  [160000/555113]\n",
      "batch: 1300 loss: 0.682920  [166400/555113]\n",
      "batch: 1350 loss: 0.673409  [172800/555113]\n",
      "batch: 1400 loss: 0.660989  [179200/555113]\n",
      "batch: 1450 loss: 0.743064  [185600/555113]\n",
      "batch: 1500 loss: 0.702332  [192000/555113]\n",
      "batch: 1550 loss: 0.668998  [198400/555113]\n",
      "batch: 1600 loss: 0.710809  [204800/555113]\n",
      "batch: 1650 loss: 0.668646  [211200/555113]\n",
      "batch: 1700 loss: 0.695924  [217600/555113]\n",
      "batch: 1750 loss: 0.673194  [224000/555113]\n",
      "batch: 1800 loss: 0.689801  [230400/555113]\n",
      "batch: 1850 loss: 0.686371  [236800/555113]\n",
      "batch: 1900 loss: 0.697139  [243200/555113]\n",
      "batch: 1950 loss: 0.698854  [249600/555113]\n",
      "batch: 2000 loss: 0.658361  [256000/555113]\n",
      "batch: 2050 loss: 0.664613  [262400/555113]\n",
      "batch: 2100 loss: 0.684864  [268800/555113]\n",
      "batch: 2150 loss: 0.692536  [275200/555113]\n",
      "batch: 2200 loss: 0.687559  [281600/555113]\n",
      "batch: 2250 loss: 0.687296  [288000/555113]\n",
      "batch: 2300 loss: 0.683756  [294400/555113]\n",
      "batch: 2350 loss: 0.723470  [300800/555113]\n",
      "batch: 2400 loss: 0.670151  [307200/555113]\n",
      "batch: 2450 loss: 0.723604  [313600/555113]\n",
      "batch: 2500 loss: 0.669759  [320000/555113]\n",
      "batch: 2550 loss: 0.693816  [326400/555113]\n",
      "batch: 2600 loss: 0.705728  [332800/555113]\n",
      "batch: 2650 loss: 0.694757  [339200/555113]\n",
      "batch: 2700 loss: 0.682574  [345600/555113]\n",
      "batch: 2750 loss: 0.663373  [352000/555113]\n",
      "batch: 2800 loss: 0.708198  [358400/555113]\n",
      "batch: 2850 loss: 0.704630  [364800/555113]\n",
      "batch: 2900 loss: 0.693817  [371200/555113]\n",
      "batch: 2950 loss: 0.706466  [377600/555113]\n",
      "batch: 3000 loss: 0.707689  [384000/555113]\n",
      "batch: 3050 loss: 0.671482  [390400/555113]\n",
      "batch: 3100 loss: 0.676140  [396800/555113]\n",
      "batch: 3150 loss: 0.698446  [403200/555113]\n",
      "batch: 3200 loss: 0.678304  [409600/555113]\n",
      "batch: 3250 loss: 0.695786  [416000/555113]\n",
      "batch: 3300 loss: 0.690983  [422400/555113]\n",
      "batch: 3350 loss: 0.700128  [428800/555113]\n",
      "batch: 3400 loss: 0.691787  [435200/555113]\n",
      "batch: 3450 loss: 0.660775  [441600/555113]\n",
      "batch: 3500 loss: 0.682404  [448000/555113]\n",
      "batch: 3550 loss: 0.666638  [454400/555113]\n",
      "batch: 3600 loss: 0.669968  [460800/555113]\n",
      "batch: 3650 loss: 0.713328  [467200/555113]\n",
      "batch: 3700 loss: 0.674045  [473600/555113]\n",
      "batch: 3750 loss: 0.694350  [480000/555113]\n",
      "batch: 3800 loss: 0.705540  [486400/555113]\n",
      "batch: 3850 loss: 0.663171  [492800/555113]\n",
      "batch: 3900 loss: 0.696869  [499200/555113]\n",
      "batch: 3950 loss: 0.693730  [505600/555113]\n",
      "batch: 4000 loss: 0.698380  [512000/555113]\n",
      "batch: 4050 loss: 0.685836  [518400/555113]\n",
      "batch: 4100 loss: 0.701266  [524800/555113]\n",
      "batch: 4150 loss: 0.697627  [531200/555113]\n",
      "batch: 4200 loss: 0.679689  [537600/555113]\n",
      "batch: 4250 loss: 0.671658  [544000/555113]\n",
      "batch: 4300 loss: 0.686271  [550400/555113]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.691956  [ 6400/555113]\n",
      "batch: 100 loss: 0.656945  [12800/555113]\n",
      "batch: 150 loss: 0.695197  [19200/555113]\n",
      "batch: 200 loss: 0.666399  [25600/555113]\n",
      "batch: 250 loss: 0.688720  [32000/555113]\n",
      "batch: 300 loss: 0.705007  [38400/555113]\n",
      "batch: 350 loss: 0.685495  [44800/555113]\n",
      "batch: 400 loss: 0.682806  [51200/555113]\n",
      "batch: 450 loss: 0.684712  [57600/555113]\n",
      "batch: 500 loss: 0.686088  [64000/555113]\n",
      "batch: 550 loss: 0.677782  [70400/555113]\n",
      "batch: 600 loss: 0.698744  [76800/555113]\n",
      "batch: 650 loss: 0.690671  [83200/555113]\n",
      "batch: 700 loss: 0.701015  [89600/555113]\n",
      "batch: 750 loss: 0.664141  [96000/555113]\n",
      "batch: 800 loss: 0.672630  [102400/555113]\n",
      "batch: 850 loss: 0.684868  [108800/555113]\n",
      "batch: 900 loss: 0.696359  [115200/555113]\n",
      "batch: 950 loss: 0.694882  [121600/555113]\n",
      "batch: 1000 loss: 0.710241  [128000/555113]\n",
      "batch: 1050 loss: 0.684001  [134400/555113]\n",
      "batch: 1100 loss: 0.688225  [140800/555113]\n",
      "batch: 1150 loss: 0.694521  [147200/555113]\n",
      "batch: 1200 loss: 0.689177  [153600/555113]\n",
      "batch: 1250 loss: 0.715420  [160000/555113]\n",
      "batch: 1300 loss: 0.671669  [166400/555113]\n",
      "batch: 1350 loss: 0.703124  [172800/555113]\n",
      "batch: 1400 loss: 0.680728  [179200/555113]\n",
      "batch: 1450 loss: 0.683025  [185600/555113]\n",
      "batch: 1500 loss: 0.692112  [192000/555113]\n",
      "batch: 1550 loss: 0.685482  [198400/555113]\n",
      "batch: 1600 loss: 0.681322  [204800/555113]\n",
      "batch: 1650 loss: 0.688860  [211200/555113]\n",
      "batch: 1700 loss: 0.709314  [217600/555113]\n",
      "batch: 1750 loss: 0.681300  [224000/555113]\n",
      "batch: 1800 loss: 0.686657  [230400/555113]\n",
      "batch: 1850 loss: 0.669983  [236800/555113]\n",
      "batch: 1900 loss: 0.703906  [243200/555113]\n",
      "batch: 1950 loss: 0.660759  [249600/555113]\n",
      "batch: 2000 loss: 0.703255  [256000/555113]\n",
      "batch: 2050 loss: 0.702674  [262400/555113]\n",
      "batch: 2100 loss: 0.709843  [268800/555113]\n",
      "batch: 2150 loss: 0.697699  [275200/555113]\n",
      "batch: 2200 loss: 0.679000  [281600/555113]\n",
      "batch: 2250 loss: 0.684702  [288000/555113]\n",
      "batch: 2300 loss: 0.712081  [294400/555113]\n",
      "batch: 2350 loss: 0.713433  [300800/555113]\n",
      "batch: 2400 loss: 0.682982  [307200/555113]\n",
      "batch: 2450 loss: 0.682328  [313600/555113]\n",
      "batch: 2500 loss: 0.672617  [320000/555113]\n",
      "batch: 2550 loss: 0.693553  [326400/555113]\n",
      "batch: 2600 loss: 0.677370  [332800/555113]\n",
      "batch: 2650 loss: 0.699416  [339200/555113]\n",
      "batch: 2700 loss: 0.661967  [345600/555113]\n",
      "batch: 2750 loss: 0.689139  [352000/555113]\n",
      "batch: 2800 loss: 0.676933  [358400/555113]\n",
      "batch: 2850 loss: 0.671636  [364800/555113]\n",
      "batch: 2900 loss: 0.666452  [371200/555113]\n",
      "batch: 2950 loss: 0.699331  [377600/555113]\n",
      "batch: 3000 loss: 0.676098  [384000/555113]\n",
      "batch: 3050 loss: 0.684202  [390400/555113]\n",
      "batch: 3100 loss: 0.667691  [396800/555113]\n",
      "batch: 3150 loss: 0.678837  [403200/555113]\n",
      "batch: 3200 loss: 0.701586  [409600/555113]\n",
      "batch: 3250 loss: 0.700098  [416000/555113]\n",
      "batch: 3300 loss: 0.693599  [422400/555113]\n",
      "batch: 3350 loss: 0.698063  [428800/555113]\n",
      "batch: 3400 loss: 0.689302  [435200/555113]\n",
      "batch: 3450 loss: 0.673248  [441600/555113]\n",
      "batch: 3500 loss: 0.675050  [448000/555113]\n",
      "batch: 3550 loss: 0.697081  [454400/555113]\n",
      "batch: 3600 loss: 0.663964  [460800/555113]\n",
      "batch: 3650 loss: 0.713645  [467200/555113]\n",
      "batch: 3700 loss: 0.676616  [473600/555113]\n",
      "batch: 3750 loss: 0.659975  [480000/555113]\n",
      "batch: 3800 loss: 0.696105  [486400/555113]\n",
      "batch: 3850 loss: 0.685451  [492800/555113]\n",
      "batch: 3900 loss: 0.697041  [499200/555113]\n",
      "batch: 3950 loss: 0.702353  [505600/555113]\n",
      "batch: 4000 loss: 0.714131  [512000/555113]\n",
      "batch: 4050 loss: 0.715531  [518400/555113]\n",
      "batch: 4100 loss: 0.684131  [524800/555113]\n",
      "batch: 4150 loss: 0.707437  [531200/555113]\n",
      "batch: 4200 loss: 0.689414  [537600/555113]\n",
      "batch: 4250 loss: 0.679720  [544000/555113]\n",
      "batch: 4300 loss: 0.704401  [550400/555113]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.665892  [ 6400/555113]\n",
      "batch: 100 loss: 0.681334  [12800/555113]\n",
      "batch: 150 loss: 0.675128  [19200/555113]\n",
      "batch: 200 loss: 0.716778  [25600/555113]\n",
      "batch: 250 loss: 0.685600  [32000/555113]\n",
      "batch: 300 loss: 0.694476  [38400/555113]\n",
      "batch: 350 loss: 0.690146  [44800/555113]\n",
      "batch: 400 loss: 0.700947  [51200/555113]\n",
      "batch: 450 loss: 0.700611  [57600/555113]\n",
      "batch: 500 loss: 0.694148  [64000/555113]\n",
      "batch: 550 loss: 0.700251  [70400/555113]\n",
      "batch: 600 loss: 0.690377  [76800/555113]\n",
      "batch: 650 loss: 0.687174  [83200/555113]\n",
      "batch: 700 loss: 0.657474  [89600/555113]\n",
      "batch: 750 loss: 0.686289  [96000/555113]\n",
      "batch: 800 loss: 0.700666  [102400/555113]\n",
      "batch: 850 loss: 0.690879  [108800/555113]\n",
      "batch: 900 loss: 0.684707  [115200/555113]\n",
      "batch: 950 loss: 0.702705  [121600/555113]\n",
      "batch: 1000 loss: 0.718952  [128000/555113]\n",
      "batch: 1050 loss: 0.704820  [134400/555113]\n",
      "batch: 1100 loss: 0.701124  [140800/555113]\n",
      "batch: 1150 loss: 0.708269  [147200/555113]\n",
      "batch: 1200 loss: 0.661502  [153600/555113]\n",
      "batch: 1250 loss: 0.691377  [160000/555113]\n",
      "batch: 1300 loss: 0.673337  [166400/555113]\n",
      "batch: 1350 loss: 0.710158  [172800/555113]\n",
      "batch: 1400 loss: 0.688508  [179200/555113]\n",
      "batch: 1450 loss: 0.681888  [185600/555113]\n",
      "batch: 1500 loss: 0.670544  [192000/555113]\n",
      "batch: 1550 loss: 0.687104  [198400/555113]\n",
      "batch: 1600 loss: 0.683545  [204800/555113]\n",
      "batch: 1650 loss: 0.698471  [211200/555113]\n",
      "batch: 1700 loss: 0.663910  [217600/555113]\n",
      "batch: 1750 loss: 0.689514  [224000/555113]\n",
      "batch: 1800 loss: 0.675769  [230400/555113]\n",
      "batch: 1850 loss: 0.690376  [236800/555113]\n",
      "batch: 1900 loss: 0.672286  [243200/555113]\n",
      "batch: 1950 loss: 0.664295  [249600/555113]\n",
      "batch: 2000 loss: 0.704520  [256000/555113]\n",
      "batch: 2050 loss: 0.676739  [262400/555113]\n",
      "batch: 2100 loss: 0.700883  [268800/555113]\n",
      "batch: 2150 loss: 0.705583  [275200/555113]\n",
      "batch: 2200 loss: 0.650594  [281600/555113]\n",
      "batch: 2250 loss: 0.714167  [288000/555113]\n",
      "batch: 2300 loss: 0.697129  [294400/555113]\n",
      "batch: 2350 loss: 0.709634  [300800/555113]\n",
      "batch: 2400 loss: 0.702899  [307200/555113]\n",
      "batch: 2450 loss: 0.675388  [313600/555113]\n",
      "batch: 2500 loss: 0.679027  [320000/555113]\n",
      "batch: 2550 loss: 0.697438  [326400/555113]\n",
      "batch: 2600 loss: 0.689760  [332800/555113]\n",
      "batch: 2650 loss: 0.698824  [339200/555113]\n",
      "batch: 2700 loss: 0.697963  [345600/555113]\n",
      "batch: 2750 loss: 0.690068  [352000/555113]\n",
      "batch: 2800 loss: 0.681654  [358400/555113]\n",
      "batch: 2850 loss: 0.689380  [364800/555113]\n",
      "batch: 2900 loss: 0.654483  [371200/555113]\n",
      "batch: 2950 loss: 0.701474  [377600/555113]\n",
      "batch: 3000 loss: 0.685326  [384000/555113]\n",
      "batch: 3050 loss: 0.684483  [390400/555113]\n",
      "batch: 3100 loss: 0.674946  [396800/555113]\n",
      "batch: 3150 loss: 0.710857  [403200/555113]\n",
      "batch: 3200 loss: 0.717141  [409600/555113]\n",
      "batch: 3250 loss: 0.692541  [416000/555113]\n",
      "batch: 3300 loss: 0.692056  [422400/555113]\n",
      "batch: 3350 loss: 0.682035  [428800/555113]\n",
      "batch: 3400 loss: 0.695323  [435200/555113]\n",
      "batch: 3450 loss: 0.683312  [441600/555113]\n",
      "batch: 3500 loss: 0.718659  [448000/555113]\n",
      "batch: 3550 loss: 0.670794  [454400/555113]\n",
      "batch: 3600 loss: 0.675613  [460800/555113]\n",
      "batch: 3650 loss: 0.646854  [467200/555113]\n",
      "batch: 3700 loss: 0.669199  [473600/555113]\n",
      "batch: 3750 loss: 0.689612  [480000/555113]\n",
      "batch: 3800 loss: 0.688813  [486400/555113]\n",
      "batch: 3850 loss: 0.683245  [492800/555113]\n",
      "batch: 3900 loss: 0.678203  [499200/555113]\n",
      "batch: 3950 loss: 0.684789  [505600/555113]\n",
      "batch: 4000 loss: 0.670613  [512000/555113]\n",
      "batch: 4050 loss: 0.674615  [518400/555113]\n",
      "batch: 4100 loss: 0.714567  [524800/555113]\n",
      "batch: 4150 loss: 0.700053  [531200/555113]\n",
      "batch: 4200 loss: 0.704624  [537600/555113]\n",
      "batch: 4250 loss: 0.689193  [544000/555113]\n",
      "batch: 4300 loss: 0.715418  [550400/555113]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.673537  [ 6400/555113]\n",
      "batch: 100 loss: 0.713316  [12800/555113]\n",
      "batch: 150 loss: 0.682085  [19200/555113]\n",
      "batch: 200 loss: 0.650254  [25600/555113]\n",
      "batch: 250 loss: 0.703633  [32000/555113]\n",
      "batch: 300 loss: 0.708754  [38400/555113]\n",
      "batch: 350 loss: 0.690936  [44800/555113]\n",
      "batch: 400 loss: 0.688590  [51200/555113]\n",
      "batch: 450 loss: 0.681319  [57600/555113]\n",
      "batch: 500 loss: 0.674699  [64000/555113]\n",
      "batch: 550 loss: 0.688944  [70400/555113]\n",
      "batch: 600 loss: 0.670859  [76800/555113]\n",
      "batch: 650 loss: 0.637531  [83200/555113]\n",
      "batch: 700 loss: 0.674126  [89600/555113]\n",
      "batch: 750 loss: 0.674975  [96000/555113]\n",
      "batch: 800 loss: 0.709982  [102400/555113]\n",
      "batch: 850 loss: 0.683068  [108800/555113]\n",
      "batch: 900 loss: 0.690198  [115200/555113]\n",
      "batch: 950 loss: 0.665796  [121600/555113]\n",
      "batch: 1000 loss: 0.654962  [128000/555113]\n",
      "batch: 1050 loss: 0.678040  [134400/555113]\n",
      "batch: 1100 loss: 0.678018  [140800/555113]\n",
      "batch: 1150 loss: 0.673256  [147200/555113]\n",
      "batch: 1200 loss: 0.697074  [153600/555113]\n",
      "batch: 1250 loss: 0.682977  [160000/555113]\n",
      "batch: 1300 loss: 0.695768  [166400/555113]\n",
      "batch: 1350 loss: 0.693366  [172800/555113]\n",
      "batch: 1400 loss: 0.671134  [179200/555113]\n",
      "batch: 1450 loss: 0.689126  [185600/555113]\n",
      "batch: 1500 loss: 0.651586  [192000/555113]\n",
      "batch: 1550 loss: 0.694501  [198400/555113]\n",
      "batch: 1600 loss: 0.687942  [204800/555113]\n",
      "batch: 1650 loss: 0.660959  [211200/555113]\n",
      "batch: 1700 loss: 0.702154  [217600/555113]\n",
      "batch: 1750 loss: 0.660910  [224000/555113]\n",
      "batch: 1800 loss: 0.700331  [230400/555113]\n",
      "batch: 1850 loss: 0.676312  [236800/555113]\n",
      "batch: 1900 loss: 0.706542  [243200/555113]\n",
      "batch: 1950 loss: 0.664161  [249600/555113]\n",
      "batch: 2000 loss: 0.656625  [256000/555113]\n",
      "batch: 2050 loss: 0.654060  [262400/555113]\n",
      "batch: 2100 loss: 0.658394  [268800/555113]\n",
      "batch: 2150 loss: 0.687076  [275200/555113]\n",
      "batch: 2200 loss: 0.662449  [281600/555113]\n",
      "batch: 2250 loss: 0.688875  [288000/555113]\n",
      "batch: 2300 loss: 0.705269  [294400/555113]\n",
      "batch: 2350 loss: 0.683843  [300800/555113]\n",
      "batch: 2400 loss: 0.648857  [307200/555113]\n",
      "batch: 2450 loss: 0.686101  [313600/555113]\n",
      "batch: 2500 loss: 0.683852  [320000/555113]\n",
      "batch: 2550 loss: 0.674829  [326400/555113]\n",
      "batch: 2600 loss: 0.689996  [332800/555113]\n",
      "batch: 2650 loss: 0.702467  [339200/555113]\n",
      "batch: 2700 loss: 0.707043  [345600/555113]\n",
      "batch: 2750 loss: 0.695658  [352000/555113]\n",
      "batch: 2800 loss: 0.686237  [358400/555113]\n",
      "batch: 2850 loss: 0.683910  [364800/555113]\n",
      "batch: 2900 loss: 0.707840  [371200/555113]\n",
      "batch: 2950 loss: 0.696069  [377600/555113]\n",
      "batch: 3000 loss: 0.691138  [384000/555113]\n",
      "batch: 3050 loss: 0.668638  [390400/555113]\n",
      "batch: 3100 loss: 0.701801  [396800/555113]\n",
      "batch: 3150 loss: 0.716493  [403200/555113]\n",
      "batch: 3200 loss: 0.694713  [409600/555113]\n",
      "batch: 3250 loss: 0.695298  [416000/555113]\n",
      "batch: 3300 loss: 0.711714  [422400/555113]\n",
      "batch: 3350 loss: 0.654448  [428800/555113]\n",
      "batch: 3400 loss: 0.677710  [435200/555113]\n",
      "batch: 3450 loss: 0.695124  [441600/555113]\n",
      "batch: 3500 loss: 0.672510  [448000/555113]\n",
      "batch: 3550 loss: 0.678419  [454400/555113]\n",
      "batch: 3600 loss: 0.685597  [460800/555113]\n",
      "batch: 3650 loss: 0.679119  [467200/555113]\n",
      "batch: 3700 loss: 0.665756  [473600/555113]\n",
      "batch: 3750 loss: 0.675782  [480000/555113]\n",
      "batch: 3800 loss: 0.693095  [486400/555113]\n",
      "batch: 3850 loss: 0.669660  [492800/555113]\n",
      "batch: 3900 loss: 0.697535  [499200/555113]\n",
      "batch: 3950 loss: 0.683963  [505600/555113]\n",
      "batch: 4000 loss: 0.694438  [512000/555113]\n",
      "batch: 4050 loss: 0.697413  [518400/555113]\n",
      "batch: 4100 loss: 0.696123  [524800/555113]\n",
      "batch: 4150 loss: 0.689110  [531200/555113]\n",
      "batch: 4200 loss: 0.693360  [537600/555113]\n",
      "batch: 4250 loss: 0.687536  [544000/555113]\n",
      "batch: 4300 loss: 0.684929  [550400/555113]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.706949  [ 6400/555113]\n",
      "batch: 100 loss: 0.695307  [12800/555113]\n",
      "batch: 150 loss: 0.680000  [19200/555113]\n",
      "batch: 200 loss: 0.654306  [25600/555113]\n",
      "batch: 250 loss: 0.713892  [32000/555113]\n",
      "batch: 300 loss: 0.673928  [38400/555113]\n",
      "batch: 350 loss: 0.686478  [44800/555113]\n",
      "batch: 400 loss: 0.651447  [51200/555113]\n",
      "batch: 450 loss: 0.673100  [57600/555113]\n",
      "batch: 500 loss: 0.701410  [64000/555113]\n",
      "batch: 550 loss: 0.669614  [70400/555113]\n",
      "batch: 600 loss: 0.683807  [76800/555113]\n",
      "batch: 650 loss: 0.671710  [83200/555113]\n",
      "batch: 700 loss: 0.679481  [89600/555113]\n",
      "batch: 750 loss: 0.672192  [96000/555113]\n",
      "batch: 800 loss: 0.699960  [102400/555113]\n",
      "batch: 850 loss: 0.681311  [108800/555113]\n",
      "batch: 900 loss: 0.675545  [115200/555113]\n",
      "batch: 950 loss: 0.698401  [121600/555113]\n",
      "batch: 1000 loss: 0.684524  [128000/555113]\n",
      "batch: 1050 loss: 0.661585  [134400/555113]\n",
      "batch: 1100 loss: 0.713768  [140800/555113]\n",
      "batch: 1150 loss: 0.684755  [147200/555113]\n",
      "batch: 1200 loss: 0.675831  [153600/555113]\n",
      "batch: 1250 loss: 0.675027  [160000/555113]\n",
      "batch: 1300 loss: 0.671757  [166400/555113]\n",
      "batch: 1350 loss: 0.694858  [172800/555113]\n",
      "batch: 1400 loss: 0.676035  [179200/555113]\n",
      "batch: 1450 loss: 0.654376  [185600/555113]\n",
      "batch: 1500 loss: 0.661050  [192000/555113]\n",
      "batch: 1550 loss: 0.695073  [198400/555113]\n",
      "batch: 1600 loss: 0.665843  [204800/555113]\n",
      "batch: 1650 loss: 0.662841  [211200/555113]\n",
      "batch: 1700 loss: 0.717044  [217600/555113]\n",
      "batch: 1750 loss: 0.693204  [224000/555113]\n",
      "batch: 1800 loss: 0.675359  [230400/555113]\n",
      "batch: 1850 loss: 0.655998  [236800/555113]\n",
      "batch: 1900 loss: 0.693145  [243200/555113]\n",
      "batch: 1950 loss: 0.638180  [249600/555113]\n",
      "batch: 2000 loss: 0.676490  [256000/555113]\n",
      "batch: 2050 loss: 0.671602  [262400/555113]\n",
      "batch: 2100 loss: 0.653463  [268800/555113]\n",
      "batch: 2150 loss: 0.717830  [275200/555113]\n",
      "batch: 2200 loss: 0.701599  [281600/555113]\n",
      "batch: 2250 loss: 0.661864  [288000/555113]\n",
      "batch: 2300 loss: 0.696876  [294400/555113]\n",
      "batch: 2350 loss: 0.691235  [300800/555113]\n",
      "batch: 2400 loss: 0.689032  [307200/555113]\n",
      "batch: 2450 loss: 0.648093  [313600/555113]\n",
      "batch: 2500 loss: 0.700829  [320000/555113]\n",
      "batch: 2550 loss: 0.660627  [326400/555113]\n",
      "batch: 2600 loss: 0.669200  [332800/555113]\n",
      "batch: 2650 loss: 0.698108  [339200/555113]\n",
      "batch: 2700 loss: 0.718304  [345600/555113]\n",
      "batch: 2750 loss: 0.693300  [352000/555113]\n",
      "batch: 2800 loss: 0.679616  [358400/555113]\n",
      "batch: 2850 loss: 0.707823  [364800/555113]\n",
      "batch: 2900 loss: 0.676225  [371200/555113]\n",
      "batch: 2950 loss: 0.670065  [377600/555113]\n",
      "batch: 3000 loss: 0.691293  [384000/555113]\n",
      "batch: 3050 loss: 0.680698  [390400/555113]\n",
      "batch: 3100 loss: 0.710264  [396800/555113]\n",
      "batch: 3150 loss: 0.690382  [403200/555113]\n",
      "batch: 3200 loss: 0.669301  [409600/555113]\n",
      "batch: 3250 loss: 0.661031  [416000/555113]\n",
      "batch: 3300 loss: 0.652912  [422400/555113]\n",
      "batch: 3350 loss: 0.668274  [428800/555113]\n",
      "batch: 3400 loss: 0.695170  [435200/555113]\n",
      "batch: 3450 loss: 0.688750  [441600/555113]\n",
      "batch: 3500 loss: 0.695823  [448000/555113]\n",
      "batch: 3550 loss: 0.690877  [454400/555113]\n",
      "batch: 3600 loss: 0.705507  [460800/555113]\n",
      "batch: 3650 loss: 0.694217  [467200/555113]\n",
      "batch: 3700 loss: 0.676271  [473600/555113]\n",
      "batch: 3750 loss: 0.683454  [480000/555113]\n",
      "batch: 3800 loss: 0.693552  [486400/555113]\n",
      "batch: 3850 loss: 0.686182  [492800/555113]\n",
      "batch: 3900 loss: 0.688913  [499200/555113]\n",
      "batch: 3950 loss: 0.718912  [505600/555113]\n",
      "batch: 4000 loss: 0.682785  [512000/555113]\n",
      "batch: 4050 loss: 0.674434  [518400/555113]\n",
      "batch: 4100 loss: 0.676886  [524800/555113]\n",
      "batch: 4150 loss: 0.697184  [531200/555113]\n",
      "batch: 4200 loss: 0.677557  [537600/555113]\n",
      "batch: 4250 loss: 0.701453  [544000/555113]\n",
      "batch: 4300 loss: 0.702648  [550400/555113]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.658382  [ 6400/555113]\n",
      "batch: 100 loss: 0.660611  [12800/555113]\n",
      "batch: 150 loss: 0.664895  [19200/555113]\n",
      "batch: 200 loss: 0.703069  [25600/555113]\n",
      "batch: 250 loss: 0.680403  [32000/555113]\n",
      "batch: 300 loss: 0.673651  [38400/555113]\n",
      "batch: 350 loss: 0.681883  [44800/555113]\n",
      "batch: 400 loss: 0.712338  [51200/555113]\n",
      "batch: 450 loss: 0.680314  [57600/555113]\n",
      "batch: 500 loss: 0.682403  [64000/555113]\n",
      "batch: 550 loss: 0.673967  [70400/555113]\n",
      "batch: 600 loss: 0.654857  [76800/555113]\n",
      "batch: 650 loss: 0.696439  [83200/555113]\n",
      "batch: 700 loss: 0.697887  [89600/555113]\n",
      "batch: 750 loss: 0.678723  [96000/555113]\n",
      "batch: 800 loss: 0.662256  [102400/555113]\n",
      "batch: 850 loss: 0.669291  [108800/555113]\n",
      "batch: 900 loss: 0.677691  [115200/555113]\n",
      "batch: 950 loss: 0.661152  [121600/555113]\n",
      "batch: 1000 loss: 0.702660  [128000/555113]\n",
      "batch: 1050 loss: 0.658931  [134400/555113]\n",
      "batch: 1100 loss: 0.664257  [140800/555113]\n",
      "batch: 1150 loss: 0.710651  [147200/555113]\n",
      "batch: 1200 loss: 0.688746  [153600/555113]\n",
      "batch: 1250 loss: 0.697120  [160000/555113]\n",
      "batch: 1300 loss: 0.672627  [166400/555113]\n",
      "batch: 1350 loss: 0.668978  [172800/555113]\n",
      "batch: 1400 loss: 0.662947  [179200/555113]\n",
      "batch: 1450 loss: 0.667811  [185600/555113]\n",
      "batch: 1500 loss: 0.671964  [192000/555113]\n",
      "batch: 1550 loss: 0.672137  [198400/555113]\n",
      "batch: 1600 loss: 0.668562  [204800/555113]\n",
      "batch: 1650 loss: 0.690171  [211200/555113]\n",
      "batch: 1700 loss: 0.688866  [217600/555113]\n",
      "batch: 1750 loss: 0.698720  [224000/555113]\n",
      "batch: 1800 loss: 0.680084  [230400/555113]\n",
      "batch: 1850 loss: 0.700185  [236800/555113]\n",
      "batch: 1900 loss: 0.690046  [243200/555113]\n",
      "batch: 1950 loss: 0.667670  [249600/555113]\n",
      "batch: 2000 loss: 0.694055  [256000/555113]\n",
      "batch: 2050 loss: 0.680264  [262400/555113]\n",
      "batch: 2100 loss: 0.698496  [268800/555113]\n",
      "batch: 2150 loss: 0.718834  [275200/555113]\n",
      "batch: 2200 loss: 0.662304  [281600/555113]\n",
      "batch: 2250 loss: 0.670534  [288000/555113]\n",
      "batch: 2300 loss: 0.690565  [294400/555113]\n",
      "batch: 2350 loss: 0.660957  [300800/555113]\n",
      "batch: 2400 loss: 0.692588  [307200/555113]\n",
      "batch: 2450 loss: 0.683034  [313600/555113]\n",
      "batch: 2500 loss: 0.675874  [320000/555113]\n",
      "batch: 2550 loss: 0.717416  [326400/555113]\n",
      "batch: 2600 loss: 0.704130  [332800/555113]\n",
      "batch: 2650 loss: 0.674959  [339200/555113]\n",
      "batch: 2700 loss: 0.666473  [345600/555113]\n",
      "batch: 2750 loss: 0.668810  [352000/555113]\n",
      "batch: 2800 loss: 0.679757  [358400/555113]\n",
      "batch: 2850 loss: 0.686203  [364800/555113]\n",
      "batch: 2900 loss: 0.698863  [371200/555113]\n",
      "batch: 2950 loss: 0.683551  [377600/555113]\n",
      "batch: 3000 loss: 0.708859  [384000/555113]\n",
      "batch: 3050 loss: 0.673339  [390400/555113]\n",
      "batch: 3100 loss: 0.691381  [396800/555113]\n",
      "batch: 3150 loss: 0.665115  [403200/555113]\n",
      "batch: 3200 loss: 0.692389  [409600/555113]\n",
      "batch: 3250 loss: 0.673509  [416000/555113]\n",
      "batch: 3300 loss: 0.692214  [422400/555113]\n",
      "batch: 3350 loss: 0.676310  [428800/555113]\n",
      "batch: 3400 loss: 0.683828  [435200/555113]\n",
      "batch: 3450 loss: 0.664184  [441600/555113]\n",
      "batch: 3500 loss: 0.692884  [448000/555113]\n",
      "batch: 3550 loss: 0.660139  [454400/555113]\n",
      "batch: 3600 loss: 0.646410  [460800/555113]\n",
      "batch: 3650 loss: 0.667860  [467200/555113]\n",
      "batch: 3700 loss: 0.696993  [473600/555113]\n",
      "batch: 3750 loss: 0.666992  [480000/555113]\n",
      "batch: 3800 loss: 0.669874  [486400/555113]\n",
      "batch: 3850 loss: 0.751302  [492800/555113]\n",
      "batch: 3900 loss: 0.668210  [499200/555113]\n",
      "batch: 3950 loss: 0.687730  [505600/555113]\n",
      "batch: 4000 loss: 0.693741  [512000/555113]\n",
      "batch: 4050 loss: 0.666260  [518400/555113]\n",
      "batch: 4100 loss: 0.658279  [524800/555113]\n",
      "batch: 4150 loss: 0.673534  [531200/555113]\n",
      "batch: 4200 loss: 0.658440  [537600/555113]\n",
      "batch: 4250 loss: 0.675964  [544000/555113]\n",
      "batch: 4300 loss: 0.692978  [550400/555113]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.697578  [ 6400/555113]\n",
      "batch: 100 loss: 0.653690  [12800/555113]\n",
      "batch: 150 loss: 0.676702  [19200/555113]\n",
      "batch: 200 loss: 0.688947  [25600/555113]\n",
      "batch: 250 loss: 0.678712  [32000/555113]\n",
      "batch: 300 loss: 0.648017  [38400/555113]\n",
      "batch: 350 loss: 0.682668  [44800/555113]\n",
      "batch: 400 loss: 0.655941  [51200/555113]\n",
      "batch: 450 loss: 0.686756  [57600/555113]\n",
      "batch: 500 loss: 0.698988  [64000/555113]\n",
      "batch: 550 loss: 0.659750  [70400/555113]\n",
      "batch: 600 loss: 0.696479  [76800/555113]\n",
      "batch: 650 loss: 0.679644  [83200/555113]\n",
      "batch: 700 loss: 0.660888  [89600/555113]\n",
      "batch: 750 loss: 0.685705  [96000/555113]\n",
      "batch: 800 loss: 0.713814  [102400/555113]\n",
      "batch: 850 loss: 0.665829  [108800/555113]\n",
      "batch: 900 loss: 0.674282  [115200/555113]\n",
      "batch: 950 loss: 0.676903  [121600/555113]\n",
      "batch: 1000 loss: 0.691809  [128000/555113]\n",
      "batch: 1050 loss: 0.690778  [134400/555113]\n",
      "batch: 1100 loss: 0.667989  [140800/555113]\n",
      "batch: 1150 loss: 0.688791  [147200/555113]\n",
      "batch: 1200 loss: 0.671378  [153600/555113]\n",
      "batch: 1250 loss: 0.656192  [160000/555113]\n",
      "batch: 1300 loss: 0.680088  [166400/555113]\n",
      "batch: 1350 loss: 0.679540  [172800/555113]\n",
      "batch: 1400 loss: 0.678218  [179200/555113]\n",
      "batch: 1450 loss: 0.679326  [185600/555113]\n",
      "batch: 1500 loss: 0.653381  [192000/555113]\n",
      "batch: 1550 loss: 0.691820  [198400/555113]\n",
      "batch: 1600 loss: 0.668032  [204800/555113]\n",
      "batch: 1650 loss: 0.687391  [211200/555113]\n",
      "batch: 1700 loss: 0.638200  [217600/555113]\n",
      "batch: 1750 loss: 0.660655  [224000/555113]\n",
      "batch: 1800 loss: 0.669739  [230400/555113]\n",
      "batch: 1850 loss: 0.660293  [236800/555113]\n",
      "batch: 1900 loss: 0.707501  [243200/555113]\n",
      "batch: 1950 loss: 0.643933  [249600/555113]\n",
      "batch: 2000 loss: 0.700040  [256000/555113]\n",
      "batch: 2050 loss: 0.666960  [262400/555113]\n",
      "batch: 2100 loss: 0.685840  [268800/555113]\n",
      "batch: 2150 loss: 0.677321  [275200/555113]\n",
      "batch: 2200 loss: 0.694195  [281600/555113]\n",
      "batch: 2250 loss: 0.680329  [288000/555113]\n",
      "batch: 2300 loss: 0.664292  [294400/555113]\n",
      "batch: 2350 loss: 0.642030  [300800/555113]\n",
      "batch: 2400 loss: 0.704966  [307200/555113]\n",
      "batch: 2450 loss: 0.670156  [313600/555113]\n",
      "batch: 2500 loss: 0.700289  [320000/555113]\n",
      "batch: 2550 loss: 0.656372  [326400/555113]\n",
      "batch: 2600 loss: 0.684838  [332800/555113]\n",
      "batch: 2650 loss: 0.669473  [339200/555113]\n",
      "batch: 2700 loss: 0.678950  [345600/555113]\n",
      "batch: 2750 loss: 0.681721  [352000/555113]\n",
      "batch: 2800 loss: 0.673271  [358400/555113]\n",
      "batch: 2850 loss: 0.681285  [364800/555113]\n",
      "batch: 2900 loss: 0.643348  [371200/555113]\n",
      "batch: 2950 loss: 0.697496  [377600/555113]\n",
      "batch: 3000 loss: 0.700813  [384000/555113]\n",
      "batch: 3050 loss: 0.668168  [390400/555113]\n",
      "batch: 3100 loss: 0.663805  [396800/555113]\n",
      "batch: 3150 loss: 0.707894  [403200/555113]\n",
      "batch: 3200 loss: 0.637752  [409600/555113]\n",
      "batch: 3250 loss: 0.703498  [416000/555113]\n",
      "batch: 3300 loss: 0.700485  [422400/555113]\n",
      "batch: 3350 loss: 0.677077  [428800/555113]\n",
      "batch: 3400 loss: 0.698476  [435200/555113]\n",
      "batch: 3450 loss: 0.652864  [441600/555113]\n",
      "batch: 3500 loss: 0.681268  [448000/555113]\n",
      "batch: 3550 loss: 0.679814  [454400/555113]\n",
      "batch: 3600 loss: 0.675165  [460800/555113]\n",
      "batch: 3650 loss: 0.668731  [467200/555113]\n",
      "batch: 3700 loss: 0.683752  [473600/555113]\n",
      "batch: 3750 loss: 0.664991  [480000/555113]\n",
      "batch: 3800 loss: 0.672425  [486400/555113]\n",
      "batch: 3850 loss: 0.655775  [492800/555113]\n",
      "batch: 3900 loss: 0.679865  [499200/555113]\n",
      "batch: 3950 loss: 0.696691  [505600/555113]\n",
      "batch: 4000 loss: 0.661563  [512000/555113]\n",
      "batch: 4050 loss: 0.685813  [518400/555113]\n",
      "batch: 4100 loss: 0.669312  [524800/555113]\n",
      "batch: 4150 loss: 0.663492  [531200/555113]\n",
      "batch: 4200 loss: 0.675929  [537600/555113]\n",
      "batch: 4250 loss: 0.683785  [544000/555113]\n",
      "batch: 4300 loss: 0.685920  [550400/555113]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net_gelu.parameters(), lr=1e-5)\n",
    "\n",
    "start_epoch = 0\n",
    "min_val_loss = 1e9\n",
    "last_min_ind = -1\n",
    "early_stopping_epoch = 5\n",
    "\n",
    "epochs = 100\n",
    "for t in range(start_epoch, epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train_loop(train_dataloader, net_gelu, loss_fn, optimizer)\n",
    "    eval_loss = eval_loop(val_dataloader, net_gelu, loss_fn)\n",
    "    torch.save(net_gelu, 'pt/'+'gelu_epoch_{}_train_{:5f}_eval_{:5f}_.pt'.format(t+1, train_loss, eval_loss)) \n",
    "    if eval_loss < min_val_loss:\n",
    "        last_min_ind = t\n",
    "        min_val_loss = eval_loss\n",
    "    elif t - last_min_ind >= early_stopping_epoch:\n",
    "        break\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
