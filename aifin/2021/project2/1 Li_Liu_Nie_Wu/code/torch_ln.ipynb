{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os.path as op\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2,3\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "IMAGE_WIDTH = {5: 15, 20: 60, 60: 180}\n",
    "IMAGE_HEIGHT = {5: 32, 20: 64, 60: 96}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = np.arange(1993,2001,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793019, 64, 60)\n",
      "(793019, 8)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "label_df = []\n",
    "for year in year_list:\n",
    "    images.append(np.memmap(op.join(\"./monthly_20d\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), dtype=np.uint8, mode='r').reshape(\n",
    "                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20])))\n",
    "    label_df.append(pd.read_feather(op.join(\"./monthly_20d\", f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\")))\n",
    "    \n",
    "images = np.concatenate(images)\n",
    "label_df = pd.concat(label_df)\n",
    "\n",
    "print(images.shape)\n",
    "print(label_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img, label):\n",
    "        self.img = torch.Tensor(img.copy())\n",
    "        self.label = torch.Tensor(label)\n",
    "        self.len = len(img)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(images, (label_df.Ret_20d > 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_ratio = 0.7\n",
    "train_dataset, val_dataset = random_split(dataset, [int(dataset.len*train_val_ratio), dataset.len-int(dataset.len*train_val_ratio)], \\\n",
    "                                           generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_ln(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.LayerNorm([64, 27, 60]),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.LayerNorm([128, 10, 60]),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.LayerNorm([256, 7, 60]),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(46080, 2),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1,64,60)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.reshape(-1,46080)\n",
    "        x = self.fc1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ln = Net_ln().cuda()\n",
    "net_ln.apply(init_weights)\n",
    "net_ln = nn.DataParallel(net_ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, net, loss_fn, optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    current = 0\n",
    "    net.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        y_pred = net(X)\n",
    "        loss = loss_fn(y_pred, y.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        total_loss = (len(X) * running_loss + total_loss * current) / (len(X) + current)\n",
    "        current += len(X)\n",
    "        if batch % 50 == 49:\n",
    "            print(f\"batch: {batch+1} loss: {running_loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        running_loss = 0.0\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(dataloader, net, loss_fn):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    current = 0\n",
    "    net.eval()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        y_pred = net(X)\n",
    "        loss = loss_fn(y_pred, y.long())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        total_loss = (len(X) * running_loss + total_loss * current) / (len(X) + current)\n",
    "        current += len(X)\n",
    "        running_loss = 0.0\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.load('/home/clidg/proj_2/pt/baseline_epoch_10_train_0.6865865240322523_eval_0.686580_.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.765934  [ 6400/555113]\n",
      "batch: 100 loss: 0.698438  [12800/555113]\n",
      "batch: 150 loss: 0.763650  [19200/555113]\n",
      "batch: 200 loss: 0.747773  [25600/555113]\n",
      "batch: 250 loss: 0.735894  [32000/555113]\n",
      "batch: 300 loss: 0.752475  [38400/555113]\n",
      "batch: 350 loss: 0.785759  [44800/555113]\n",
      "batch: 400 loss: 0.762600  [51200/555113]\n",
      "batch: 450 loss: 0.721784  [57600/555113]\n",
      "batch: 500 loss: 0.711251  [64000/555113]\n",
      "batch: 550 loss: 0.723052  [70400/555113]\n",
      "batch: 600 loss: 0.702028  [76800/555113]\n",
      "batch: 650 loss: 0.734207  [83200/555113]\n",
      "batch: 700 loss: 0.717070  [89600/555113]\n",
      "batch: 750 loss: 0.749528  [96000/555113]\n",
      "batch: 800 loss: 0.751218  [102400/555113]\n",
      "batch: 850 loss: 0.712467  [108800/555113]\n",
      "batch: 900 loss: 0.701323  [115200/555113]\n",
      "batch: 950 loss: 0.729163  [121600/555113]\n",
      "batch: 1000 loss: 0.784043  [128000/555113]\n",
      "batch: 1050 loss: 0.717567  [134400/555113]\n",
      "batch: 1100 loss: 0.750356  [140800/555113]\n",
      "batch: 1150 loss: 0.726137  [147200/555113]\n",
      "batch: 1200 loss: 0.743123  [153600/555113]\n",
      "batch: 1250 loss: 0.730526  [160000/555113]\n",
      "batch: 1300 loss: 0.737735  [166400/555113]\n",
      "batch: 1350 loss: 0.718910  [172800/555113]\n",
      "batch: 1400 loss: 0.763568  [179200/555113]\n",
      "batch: 1450 loss: 0.711478  [185600/555113]\n",
      "batch: 1500 loss: 0.696641  [192000/555113]\n",
      "batch: 1550 loss: 0.736723  [198400/555113]\n",
      "batch: 1600 loss: 0.693786  [204800/555113]\n",
      "batch: 1650 loss: 0.704251  [211200/555113]\n",
      "batch: 1700 loss: 0.707002  [217600/555113]\n",
      "batch: 1750 loss: 0.752478  [224000/555113]\n",
      "batch: 1800 loss: 0.706341  [230400/555113]\n",
      "batch: 1850 loss: 0.701311  [236800/555113]\n",
      "batch: 1900 loss: 0.693758  [243200/555113]\n",
      "batch: 1950 loss: 0.670291  [249600/555113]\n",
      "batch: 2000 loss: 0.703636  [256000/555113]\n",
      "batch: 2050 loss: 0.699103  [262400/555113]\n",
      "batch: 2100 loss: 0.688504  [268800/555113]\n",
      "batch: 2150 loss: 0.697942  [275200/555113]\n",
      "batch: 2200 loss: 0.686337  [281600/555113]\n",
      "batch: 2250 loss: 0.702802  [288000/555113]\n",
      "batch: 2300 loss: 0.688837  [294400/555113]\n",
      "batch: 2350 loss: 0.684953  [300800/555113]\n",
      "batch: 2400 loss: 0.734414  [307200/555113]\n",
      "batch: 2450 loss: 0.711026  [313600/555113]\n",
      "batch: 2500 loss: 0.736229  [320000/555113]\n",
      "batch: 2550 loss: 0.730844  [326400/555113]\n",
      "batch: 2600 loss: 0.678544  [332800/555113]\n",
      "batch: 2650 loss: 0.692411  [339200/555113]\n",
      "batch: 2700 loss: 0.712045  [345600/555113]\n",
      "batch: 2750 loss: 0.689561  [352000/555113]\n",
      "batch: 2800 loss: 0.723772  [358400/555113]\n",
      "batch: 2850 loss: 0.703332  [364800/555113]\n",
      "batch: 2900 loss: 0.726289  [371200/555113]\n",
      "batch: 2950 loss: 0.710147  [377600/555113]\n",
      "batch: 3000 loss: 0.696606  [384000/555113]\n",
      "batch: 3050 loss: 0.713269  [390400/555113]\n",
      "batch: 3100 loss: 0.655580  [396800/555113]\n",
      "batch: 3150 loss: 0.679650  [403200/555113]\n",
      "batch: 3200 loss: 0.687344  [409600/555113]\n",
      "batch: 3250 loss: 0.689198  [416000/555113]\n",
      "batch: 3300 loss: 0.719000  [422400/555113]\n",
      "batch: 3350 loss: 0.695753  [428800/555113]\n",
      "batch: 3400 loss: 0.677565  [435200/555113]\n",
      "batch: 3450 loss: 0.683070  [441600/555113]\n",
      "batch: 3500 loss: 0.695256  [448000/555113]\n",
      "batch: 3550 loss: 0.713411  [454400/555113]\n",
      "batch: 3600 loss: 0.706502  [460800/555113]\n",
      "batch: 3650 loss: 0.697193  [467200/555113]\n",
      "batch: 3700 loss: 0.699550  [473600/555113]\n",
      "batch: 3750 loss: 0.699020  [480000/555113]\n",
      "batch: 3800 loss: 0.692087  [486400/555113]\n",
      "batch: 3850 loss: 0.727119  [492800/555113]\n",
      "batch: 3900 loss: 0.712055  [499200/555113]\n",
      "batch: 3950 loss: 0.679502  [505600/555113]\n",
      "batch: 4000 loss: 0.726628  [512000/555113]\n",
      "batch: 4050 loss: 0.715806  [518400/555113]\n",
      "batch: 4100 loss: 0.713016  [524800/555113]\n",
      "batch: 4150 loss: 0.677965  [531200/555113]\n",
      "batch: 4200 loss: 0.702821  [537600/555113]\n",
      "batch: 4250 loss: 0.723820  [544000/555113]\n",
      "batch: 4300 loss: 0.718428  [550400/555113]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.718589  [ 6400/555113]\n",
      "batch: 100 loss: 0.720051  [12800/555113]\n",
      "batch: 150 loss: 0.688238  [19200/555113]\n",
      "batch: 200 loss: 0.703916  [25600/555113]\n",
      "batch: 250 loss: 0.706819  [32000/555113]\n",
      "batch: 300 loss: 0.695948  [38400/555113]\n",
      "batch: 350 loss: 0.712152  [44800/555113]\n",
      "batch: 400 loss: 0.673959  [51200/555113]\n",
      "batch: 450 loss: 0.690801  [57600/555113]\n",
      "batch: 500 loss: 0.706650  [64000/555113]\n",
      "batch: 550 loss: 0.699436  [70400/555113]\n",
      "batch: 600 loss: 0.702023  [76800/555113]\n",
      "batch: 650 loss: 0.702819  [83200/555113]\n",
      "batch: 700 loss: 0.699328  [89600/555113]\n",
      "batch: 750 loss: 0.704653  [96000/555113]\n",
      "batch: 800 loss: 0.696305  [102400/555113]\n",
      "batch: 850 loss: 0.704940  [108800/555113]\n",
      "batch: 900 loss: 0.701462  [115200/555113]\n",
      "batch: 950 loss: 0.695430  [121600/555113]\n",
      "batch: 1000 loss: 0.695403  [128000/555113]\n",
      "batch: 1050 loss: 0.687633  [134400/555113]\n",
      "batch: 1100 loss: 0.696377  [140800/555113]\n",
      "batch: 1150 loss: 0.698649  [147200/555113]\n",
      "batch: 1200 loss: 0.699704  [153600/555113]\n",
      "batch: 1250 loss: 0.701709  [160000/555113]\n",
      "batch: 1300 loss: 0.695021  [166400/555113]\n",
      "batch: 1350 loss: 0.693254  [172800/555113]\n",
      "batch: 1400 loss: 0.693137  [179200/555113]\n",
      "batch: 1450 loss: 0.692347  [185600/555113]\n",
      "batch: 1500 loss: 0.703246  [192000/555113]\n",
      "batch: 1550 loss: 0.714478  [198400/555113]\n",
      "batch: 1600 loss: 0.691358  [204800/555113]\n",
      "batch: 1650 loss: 0.699024  [211200/555113]\n",
      "batch: 1700 loss: 0.687541  [217600/555113]\n",
      "batch: 1750 loss: 0.706506  [224000/555113]\n",
      "batch: 1800 loss: 0.670896  [230400/555113]\n",
      "batch: 1850 loss: 0.712116  [236800/555113]\n",
      "batch: 1900 loss: 0.699144  [243200/555113]\n",
      "batch: 1950 loss: 0.680287  [249600/555113]\n",
      "batch: 2000 loss: 0.691157  [256000/555113]\n",
      "batch: 2050 loss: 0.699483  [262400/555113]\n",
      "batch: 2100 loss: 0.705121  [268800/555113]\n",
      "batch: 2150 loss: 0.702187  [275200/555113]\n",
      "batch: 2200 loss: 0.708362  [281600/555113]\n",
      "batch: 2250 loss: 0.695784  [288000/555113]\n",
      "batch: 2300 loss: 0.692159  [294400/555113]\n",
      "batch: 2350 loss: 0.687200  [300800/555113]\n",
      "batch: 2400 loss: 0.704845  [307200/555113]\n",
      "batch: 2450 loss: 0.685174  [313600/555113]\n",
      "batch: 2500 loss: 0.724142  [320000/555113]\n",
      "batch: 2550 loss: 0.685328  [326400/555113]\n",
      "batch: 2600 loss: 0.680379  [332800/555113]\n",
      "batch: 2650 loss: 0.703892  [339200/555113]\n",
      "batch: 2700 loss: 0.688598  [345600/555113]\n",
      "batch: 2750 loss: 0.681727  [352000/555113]\n",
      "batch: 2800 loss: 0.696324  [358400/555113]\n",
      "batch: 2850 loss: 0.695748  [364800/555113]\n",
      "batch: 2900 loss: 0.685662  [371200/555113]\n",
      "batch: 2950 loss: 0.686904  [377600/555113]\n",
      "batch: 3000 loss: 0.700744  [384000/555113]\n",
      "batch: 3050 loss: 0.685341  [390400/555113]\n",
      "batch: 3100 loss: 0.715823  [396800/555113]\n",
      "batch: 3150 loss: 0.690322  [403200/555113]\n",
      "batch: 3200 loss: 0.695138  [409600/555113]\n",
      "batch: 3250 loss: 0.676113  [416000/555113]\n",
      "batch: 3300 loss: 0.710084  [422400/555113]\n",
      "batch: 3350 loss: 0.708581  [428800/555113]\n",
      "batch: 3400 loss: 0.702300  [435200/555113]\n",
      "batch: 3450 loss: 0.704548  [441600/555113]\n",
      "batch: 3500 loss: 0.667937  [448000/555113]\n",
      "batch: 3550 loss: 0.703827  [454400/555113]\n",
      "batch: 3600 loss: 0.688217  [460800/555113]\n",
      "batch: 3650 loss: 0.701809  [467200/555113]\n",
      "batch: 3700 loss: 0.715940  [473600/555113]\n",
      "batch: 3750 loss: 0.684992  [480000/555113]\n",
      "batch: 3800 loss: 0.693883  [486400/555113]\n",
      "batch: 3850 loss: 0.678443  [492800/555113]\n",
      "batch: 3900 loss: 0.711902  [499200/555113]\n",
      "batch: 3950 loss: 0.707977  [505600/555113]\n",
      "batch: 4000 loss: 0.694997  [512000/555113]\n",
      "batch: 4050 loss: 0.714917  [518400/555113]\n",
      "batch: 4100 loss: 0.695651  [524800/555113]\n",
      "batch: 4150 loss: 0.690863  [531200/555113]\n",
      "batch: 4200 loss: 0.691199  [537600/555113]\n",
      "batch: 4250 loss: 0.682596  [544000/555113]\n",
      "batch: 4300 loss: 0.703219  [550400/555113]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.703064  [ 6400/555113]\n",
      "batch: 100 loss: 0.701174  [12800/555113]\n",
      "batch: 150 loss: 0.706126  [19200/555113]\n",
      "batch: 200 loss: 0.712076  [25600/555113]\n",
      "batch: 250 loss: 0.701866  [32000/555113]\n",
      "batch: 300 loss: 0.687626  [38400/555113]\n",
      "batch: 350 loss: 0.690835  [44800/555113]\n",
      "batch: 400 loss: 0.698410  [51200/555113]\n",
      "batch: 450 loss: 0.689917  [57600/555113]\n",
      "batch: 500 loss: 0.698943  [64000/555113]\n",
      "batch: 550 loss: 0.697197  [70400/555113]\n",
      "batch: 600 loss: 0.720164  [76800/555113]\n",
      "batch: 650 loss: 0.690724  [83200/555113]\n",
      "batch: 700 loss: 0.699106  [89600/555113]\n",
      "batch: 750 loss: 0.682272  [96000/555113]\n",
      "batch: 800 loss: 0.694625  [102400/555113]\n",
      "batch: 850 loss: 0.705885  [108800/555113]\n",
      "batch: 900 loss: 0.700040  [115200/555113]\n",
      "batch: 950 loss: 0.699842  [121600/555113]\n",
      "batch: 1000 loss: 0.681134  [128000/555113]\n",
      "batch: 1050 loss: 0.694092  [134400/555113]\n",
      "batch: 1100 loss: 0.710130  [140800/555113]\n",
      "batch: 1150 loss: 0.696413  [147200/555113]\n",
      "batch: 1200 loss: 0.679158  [153600/555113]\n",
      "batch: 1250 loss: 0.694495  [160000/555113]\n",
      "batch: 1300 loss: 0.690146  [166400/555113]\n",
      "batch: 1350 loss: 0.692022  [172800/555113]\n",
      "batch: 1400 loss: 0.690738  [179200/555113]\n",
      "batch: 1450 loss: 0.687190  [185600/555113]\n",
      "batch: 1500 loss: 0.676371  [192000/555113]\n",
      "batch: 1550 loss: 0.689712  [198400/555113]\n",
      "batch: 1600 loss: 0.665907  [204800/555113]\n",
      "batch: 1650 loss: 0.703453  [211200/555113]\n",
      "batch: 1700 loss: 0.682671  [217600/555113]\n",
      "batch: 1750 loss: 0.704583  [224000/555113]\n",
      "batch: 1800 loss: 0.699256  [230400/555113]\n",
      "batch: 1850 loss: 0.689621  [236800/555113]\n",
      "batch: 1900 loss: 0.695958  [243200/555113]\n",
      "batch: 1950 loss: 0.695176  [249600/555113]\n",
      "batch: 2000 loss: 0.695890  [256000/555113]\n",
      "batch: 2050 loss: 0.678738  [262400/555113]\n",
      "batch: 2100 loss: 0.683258  [268800/555113]\n",
      "batch: 2150 loss: 0.687460  [275200/555113]\n",
      "batch: 2200 loss: 0.721693  [281600/555113]\n",
      "batch: 2250 loss: 0.675936  [288000/555113]\n",
      "batch: 2300 loss: 0.685392  [294400/555113]\n",
      "batch: 2350 loss: 0.705101  [300800/555113]\n",
      "batch: 2400 loss: 0.680536  [307200/555113]\n",
      "batch: 2450 loss: 0.711139  [313600/555113]\n",
      "batch: 2500 loss: 0.697026  [320000/555113]\n",
      "batch: 2550 loss: 0.688100  [326400/555113]\n",
      "batch: 2600 loss: 0.699400  [332800/555113]\n",
      "batch: 2650 loss: 0.685489  [339200/555113]\n",
      "batch: 2700 loss: 0.671295  [345600/555113]\n",
      "batch: 2750 loss: 0.682385  [352000/555113]\n",
      "batch: 2800 loss: 0.683998  [358400/555113]\n",
      "batch: 2850 loss: 0.693263  [364800/555113]\n",
      "batch: 2900 loss: 0.686272  [371200/555113]\n",
      "batch: 2950 loss: 0.701610  [377600/555113]\n",
      "batch: 3000 loss: 0.700351  [384000/555113]\n",
      "batch: 3050 loss: 0.697182  [390400/555113]\n",
      "batch: 3100 loss: 0.685261  [396800/555113]\n",
      "batch: 3150 loss: 0.682060  [403200/555113]\n",
      "batch: 3200 loss: 0.676219  [409600/555113]\n",
      "batch: 3250 loss: 0.678010  [416000/555113]\n",
      "batch: 3300 loss: 0.692402  [422400/555113]\n",
      "batch: 3350 loss: 0.703735  [428800/555113]\n",
      "batch: 3400 loss: 0.708856  [435200/555113]\n",
      "batch: 3450 loss: 0.721774  [441600/555113]\n",
      "batch: 3500 loss: 0.708329  [448000/555113]\n",
      "batch: 3550 loss: 0.695749  [454400/555113]\n",
      "batch: 3600 loss: 0.691154  [460800/555113]\n",
      "batch: 3650 loss: 0.688841  [467200/555113]\n",
      "batch: 3700 loss: 0.696462  [473600/555113]\n",
      "batch: 3750 loss: 0.692445  [480000/555113]\n",
      "batch: 3800 loss: 0.693369  [486400/555113]\n",
      "batch: 3850 loss: 0.696001  [492800/555113]\n",
      "batch: 3900 loss: 0.691779  [499200/555113]\n",
      "batch: 3950 loss: 0.704903  [505600/555113]\n",
      "batch: 4000 loss: 0.706950  [512000/555113]\n",
      "batch: 4050 loss: 0.693134  [518400/555113]\n",
      "batch: 4100 loss: 0.697094  [524800/555113]\n",
      "batch: 4150 loss: 0.694161  [531200/555113]\n",
      "batch: 4200 loss: 0.692492  [537600/555113]\n",
      "batch: 4250 loss: 0.694447  [544000/555113]\n",
      "batch: 4300 loss: 0.693008  [550400/555113]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.707972  [ 6400/555113]\n",
      "batch: 100 loss: 0.694536  [12800/555113]\n",
      "batch: 150 loss: 0.689597  [19200/555113]\n",
      "batch: 200 loss: 0.689097  [25600/555113]\n",
      "batch: 250 loss: 0.697802  [32000/555113]\n",
      "batch: 300 loss: 0.682376  [38400/555113]\n",
      "batch: 350 loss: 0.687380  [44800/555113]\n",
      "batch: 400 loss: 0.702569  [51200/555113]\n",
      "batch: 450 loss: 0.686526  [57600/555113]\n",
      "batch: 500 loss: 0.688598  [64000/555113]\n",
      "batch: 550 loss: 0.703561  [70400/555113]\n",
      "batch: 600 loss: 0.674503  [76800/555113]\n",
      "batch: 650 loss: 0.689076  [83200/555113]\n",
      "batch: 700 loss: 0.695887  [89600/555113]\n",
      "batch: 750 loss: 0.688692  [96000/555113]\n",
      "batch: 800 loss: 0.686484  [102400/555113]\n",
      "batch: 850 loss: 0.687413  [108800/555113]\n",
      "batch: 900 loss: 0.677677  [115200/555113]\n",
      "batch: 950 loss: 0.672351  [121600/555113]\n",
      "batch: 1000 loss: 0.684725  [128000/555113]\n",
      "batch: 1050 loss: 0.695030  [134400/555113]\n",
      "batch: 1100 loss: 0.692512  [140800/555113]\n",
      "batch: 1150 loss: 0.721896  [147200/555113]\n",
      "batch: 1200 loss: 0.687190  [153600/555113]\n",
      "batch: 1250 loss: 0.681766  [160000/555113]\n",
      "batch: 1300 loss: 0.695351  [166400/555113]\n",
      "batch: 1350 loss: 0.681351  [172800/555113]\n",
      "batch: 1400 loss: 0.686494  [179200/555113]\n",
      "batch: 1450 loss: 0.693636  [185600/555113]\n",
      "batch: 1500 loss: 0.697613  [192000/555113]\n",
      "batch: 1550 loss: 0.698272  [198400/555113]\n",
      "batch: 1600 loss: 0.694580  [204800/555113]\n",
      "batch: 1650 loss: 0.674137  [211200/555113]\n",
      "batch: 1700 loss: 0.692156  [217600/555113]\n",
      "batch: 1750 loss: 0.697387  [224000/555113]\n",
      "batch: 1800 loss: 0.716874  [230400/555113]\n",
      "batch: 1850 loss: 0.705573  [236800/555113]\n",
      "batch: 1900 loss: 0.709022  [243200/555113]\n",
      "batch: 1950 loss: 0.688196  [249600/555113]\n",
      "batch: 2000 loss: 0.684507  [256000/555113]\n",
      "batch: 2050 loss: 0.685334  [262400/555113]\n",
      "batch: 2100 loss: 0.705964  [268800/555113]\n",
      "batch: 2150 loss: 0.705471  [275200/555113]\n",
      "batch: 2200 loss: 0.677491  [281600/555113]\n",
      "batch: 2250 loss: 0.695922  [288000/555113]\n",
      "batch: 2300 loss: 0.686554  [294400/555113]\n",
      "batch: 2350 loss: 0.697693  [300800/555113]\n",
      "batch: 2400 loss: 0.696123  [307200/555113]\n",
      "batch: 2450 loss: 0.680848  [313600/555113]\n",
      "batch: 2500 loss: 0.684470  [320000/555113]\n",
      "batch: 2550 loss: 0.676345  [326400/555113]\n",
      "batch: 2600 loss: 0.678777  [332800/555113]\n",
      "batch: 2650 loss: 0.691492  [339200/555113]\n",
      "batch: 2700 loss: 0.693213  [345600/555113]\n",
      "batch: 2750 loss: 0.692380  [352000/555113]\n",
      "batch: 2800 loss: 0.673969  [358400/555113]\n",
      "batch: 2850 loss: 0.690976  [364800/555113]\n",
      "batch: 2900 loss: 0.693072  [371200/555113]\n",
      "batch: 2950 loss: 0.713794  [377600/555113]\n",
      "batch: 3000 loss: 0.698098  [384000/555113]\n",
      "batch: 3050 loss: 0.684527  [390400/555113]\n",
      "batch: 3100 loss: 0.697690  [396800/555113]\n",
      "batch: 3150 loss: 0.684194  [403200/555113]\n",
      "batch: 3200 loss: 0.677690  [409600/555113]\n",
      "batch: 3250 loss: 0.706266  [416000/555113]\n",
      "batch: 3300 loss: 0.676953  [422400/555113]\n",
      "batch: 3350 loss: 0.707681  [428800/555113]\n",
      "batch: 3400 loss: 0.685494  [435200/555113]\n",
      "batch: 3450 loss: 0.687712  [441600/555113]\n",
      "batch: 3500 loss: 0.695154  [448000/555113]\n",
      "batch: 3550 loss: 0.680264  [454400/555113]\n",
      "batch: 3600 loss: 0.698330  [460800/555113]\n",
      "batch: 3650 loss: 0.701808  [467200/555113]\n",
      "batch: 3700 loss: 0.703047  [473600/555113]\n",
      "batch: 3750 loss: 0.699648  [480000/555113]\n",
      "batch: 3800 loss: 0.688582  [486400/555113]\n",
      "batch: 3850 loss: 0.674535  [492800/555113]\n",
      "batch: 3900 loss: 0.692004  [499200/555113]\n",
      "batch: 3950 loss: 0.695282  [505600/555113]\n",
      "batch: 4000 loss: 0.686211  [512000/555113]\n",
      "batch: 4050 loss: 0.682418  [518400/555113]\n",
      "batch: 4100 loss: 0.695149  [524800/555113]\n",
      "batch: 4150 loss: 0.675719  [531200/555113]\n",
      "batch: 4200 loss: 0.691328  [537600/555113]\n",
      "batch: 4250 loss: 0.687245  [544000/555113]\n",
      "batch: 4300 loss: 0.699590  [550400/555113]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.690128  [ 6400/555113]\n",
      "batch: 100 loss: 0.693639  [12800/555113]\n",
      "batch: 150 loss: 0.696022  [19200/555113]\n",
      "batch: 200 loss: 0.698245  [25600/555113]\n",
      "batch: 250 loss: 0.676618  [32000/555113]\n",
      "batch: 300 loss: 0.691007  [38400/555113]\n",
      "batch: 350 loss: 0.697064  [44800/555113]\n",
      "batch: 400 loss: 0.681881  [51200/555113]\n",
      "batch: 450 loss: 0.707080  [57600/555113]\n",
      "batch: 500 loss: 0.663558  [64000/555113]\n",
      "batch: 550 loss: 0.702783  [70400/555113]\n",
      "batch: 600 loss: 0.671680  [76800/555113]\n",
      "batch: 650 loss: 0.684807  [83200/555113]\n",
      "batch: 700 loss: 0.694017  [89600/555113]\n",
      "batch: 750 loss: 0.694237  [96000/555113]\n",
      "batch: 800 loss: 0.694450  [102400/555113]\n",
      "batch: 850 loss: 0.690699  [108800/555113]\n",
      "batch: 900 loss: 0.685937  [115200/555113]\n",
      "batch: 950 loss: 0.675677  [121600/555113]\n",
      "batch: 1000 loss: 0.683457  [128000/555113]\n",
      "batch: 1050 loss: 0.691976  [134400/555113]\n",
      "batch: 1100 loss: 0.708407  [140800/555113]\n",
      "batch: 1150 loss: 0.673285  [147200/555113]\n",
      "batch: 1200 loss: 0.698313  [153600/555113]\n",
      "batch: 1250 loss: 0.682483  [160000/555113]\n",
      "batch: 1300 loss: 0.682465  [166400/555113]\n",
      "batch: 1350 loss: 0.684843  [172800/555113]\n",
      "batch: 1400 loss: 0.686123  [179200/555113]\n",
      "batch: 1450 loss: 0.684085  [185600/555113]\n",
      "batch: 1500 loss: 0.678690  [192000/555113]\n",
      "batch: 1550 loss: 0.691468  [198400/555113]\n",
      "batch: 1600 loss: 0.688642  [204800/555113]\n",
      "batch: 1650 loss: 0.694416  [211200/555113]\n",
      "batch: 1700 loss: 0.681089  [217600/555113]\n",
      "batch: 1750 loss: 0.680427  [224000/555113]\n",
      "batch: 1800 loss: 0.698708  [230400/555113]\n",
      "batch: 1850 loss: 0.697177  [236800/555113]\n",
      "batch: 1900 loss: 0.683622  [243200/555113]\n",
      "batch: 1950 loss: 0.692255  [249600/555113]\n",
      "batch: 2000 loss: 0.703610  [256000/555113]\n",
      "batch: 2050 loss: 0.689570  [262400/555113]\n",
      "batch: 2100 loss: 0.698111  [268800/555113]\n",
      "batch: 2150 loss: 0.703960  [275200/555113]\n",
      "batch: 2200 loss: 0.677586  [281600/555113]\n",
      "batch: 2250 loss: 0.683044  [288000/555113]\n",
      "batch: 2300 loss: 0.704428  [294400/555113]\n",
      "batch: 2350 loss: 0.684388  [300800/555113]\n",
      "batch: 2400 loss: 0.694265  [307200/555113]\n",
      "batch: 2450 loss: 0.682174  [313600/555113]\n",
      "batch: 2500 loss: 0.670935  [320000/555113]\n",
      "batch: 2550 loss: 0.675810  [326400/555113]\n",
      "batch: 2600 loss: 0.695521  [332800/555113]\n",
      "batch: 2650 loss: 0.682885  [339200/555113]\n",
      "batch: 2700 loss: 0.685708  [345600/555113]\n",
      "batch: 2750 loss: 0.733436  [352000/555113]\n",
      "batch: 2800 loss: 0.686836  [358400/555113]\n",
      "batch: 2850 loss: 0.686359  [364800/555113]\n",
      "batch: 2900 loss: 0.675166  [371200/555113]\n",
      "batch: 2950 loss: 0.680757  [377600/555113]\n",
      "batch: 3000 loss: 0.672896  [384000/555113]\n",
      "batch: 3050 loss: 0.681605  [390400/555113]\n",
      "batch: 3100 loss: 0.693404  [396800/555113]\n",
      "batch: 3150 loss: 0.677515  [403200/555113]\n",
      "batch: 3200 loss: 0.681743  [409600/555113]\n",
      "batch: 3250 loss: 0.701051  [416000/555113]\n",
      "batch: 3300 loss: 0.720343  [422400/555113]\n",
      "batch: 3350 loss: 0.690733  [428800/555113]\n",
      "batch: 3400 loss: 0.683224  [435200/555113]\n",
      "batch: 3450 loss: 0.681065  [441600/555113]\n",
      "batch: 3500 loss: 0.686333  [448000/555113]\n",
      "batch: 3550 loss: 0.672035  [454400/555113]\n",
      "batch: 3600 loss: 0.677778  [460800/555113]\n",
      "batch: 3650 loss: 0.686193  [467200/555113]\n",
      "batch: 3700 loss: 0.704844  [473600/555113]\n",
      "batch: 3750 loss: 0.683548  [480000/555113]\n",
      "batch: 3800 loss: 0.675702  [486400/555113]\n",
      "batch: 3850 loss: 0.710442  [492800/555113]\n",
      "batch: 3900 loss: 0.688675  [499200/555113]\n",
      "batch: 3950 loss: 0.689027  [505600/555113]\n",
      "batch: 4000 loss: 0.705245  [512000/555113]\n",
      "batch: 4050 loss: 0.701734  [518400/555113]\n",
      "batch: 4100 loss: 0.692860  [524800/555113]\n",
      "batch: 4150 loss: 0.689535  [531200/555113]\n",
      "batch: 4200 loss: 0.680373  [537600/555113]\n",
      "batch: 4250 loss: 0.697238  [544000/555113]\n",
      "batch: 4300 loss: 0.694510  [550400/555113]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.671403  [ 6400/555113]\n",
      "batch: 100 loss: 0.691177  [12800/555113]\n",
      "batch: 150 loss: 0.663780  [19200/555113]\n",
      "batch: 200 loss: 0.697011  [25600/555113]\n",
      "batch: 250 loss: 0.669993  [32000/555113]\n",
      "batch: 300 loss: 0.683620  [38400/555113]\n",
      "batch: 350 loss: 0.682001  [44800/555113]\n",
      "batch: 400 loss: 0.685832  [51200/555113]\n",
      "batch: 450 loss: 0.694814  [57600/555113]\n",
      "batch: 500 loss: 0.695705  [64000/555113]\n",
      "batch: 550 loss: 0.678873  [70400/555113]\n",
      "batch: 600 loss: 0.698108  [76800/555113]\n",
      "batch: 650 loss: 0.681783  [83200/555113]\n",
      "batch: 700 loss: 0.690652  [89600/555113]\n",
      "batch: 750 loss: 0.712550  [96000/555113]\n",
      "batch: 800 loss: 0.671087  [102400/555113]\n",
      "batch: 850 loss: 0.684990  [108800/555113]\n",
      "batch: 900 loss: 0.681836  [115200/555113]\n",
      "batch: 950 loss: 0.705336  [121600/555113]\n",
      "batch: 1000 loss: 0.692116  [128000/555113]\n",
      "batch: 1050 loss: 0.683521  [134400/555113]\n",
      "batch: 1100 loss: 0.682503  [140800/555113]\n",
      "batch: 1150 loss: 0.665577  [147200/555113]\n",
      "batch: 1200 loss: 0.686525  [153600/555113]\n",
      "batch: 1250 loss: 0.700987  [160000/555113]\n",
      "batch: 1300 loss: 0.683572  [166400/555113]\n",
      "batch: 1350 loss: 0.695561  [172800/555113]\n",
      "batch: 1400 loss: 0.668667  [179200/555113]\n",
      "batch: 1450 loss: 0.696909  [185600/555113]\n",
      "batch: 1500 loss: 0.700019  [192000/555113]\n",
      "batch: 1550 loss: 0.692931  [198400/555113]\n",
      "batch: 1600 loss: 0.692966  [204800/555113]\n",
      "batch: 1650 loss: 0.689864  [211200/555113]\n",
      "batch: 1700 loss: 0.704440  [217600/555113]\n",
      "batch: 1750 loss: 0.680918  [224000/555113]\n",
      "batch: 1800 loss: 0.683167  [230400/555113]\n",
      "batch: 1850 loss: 0.683918  [236800/555113]\n",
      "batch: 1900 loss: 0.709964  [243200/555113]\n",
      "batch: 1950 loss: 0.678489  [249600/555113]\n",
      "batch: 2000 loss: 0.712991  [256000/555113]\n",
      "batch: 2050 loss: 0.692226  [262400/555113]\n",
      "batch: 2100 loss: 0.687228  [268800/555113]\n",
      "batch: 2150 loss: 0.701791  [275200/555113]\n",
      "batch: 2200 loss: 0.690746  [281600/555113]\n",
      "batch: 2250 loss: 0.678274  [288000/555113]\n",
      "batch: 2300 loss: 0.660797  [294400/555113]\n",
      "batch: 2350 loss: 0.686925  [300800/555113]\n",
      "batch: 2400 loss: 0.685947  [307200/555113]\n",
      "batch: 2450 loss: 0.686256  [313600/555113]\n",
      "batch: 2500 loss: 0.718857  [320000/555113]\n",
      "batch: 2550 loss: 0.666696  [326400/555113]\n",
      "batch: 2600 loss: 0.688041  [332800/555113]\n",
      "batch: 2650 loss: 0.677509  [339200/555113]\n",
      "batch: 2700 loss: 0.669499  [345600/555113]\n",
      "batch: 2750 loss: 0.708178  [352000/555113]\n",
      "batch: 2800 loss: 0.690852  [358400/555113]\n",
      "batch: 2850 loss: 0.709897  [364800/555113]\n",
      "batch: 2900 loss: 0.712593  [371200/555113]\n",
      "batch: 2950 loss: 0.705263  [377600/555113]\n",
      "batch: 3000 loss: 0.673739  [384000/555113]\n",
      "batch: 3050 loss: 0.700357  [390400/555113]\n",
      "batch: 3100 loss: 0.692236  [396800/555113]\n",
      "batch: 3150 loss: 0.684861  [403200/555113]\n",
      "batch: 3200 loss: 0.680910  [409600/555113]\n",
      "batch: 3250 loss: 0.680547  [416000/555113]\n",
      "batch: 3300 loss: 0.697147  [422400/555113]\n",
      "batch: 3350 loss: 0.690375  [428800/555113]\n",
      "batch: 3400 loss: 0.682882  [435200/555113]\n",
      "batch: 3450 loss: 0.700698  [441600/555113]\n",
      "batch: 3500 loss: 0.693552  [448000/555113]\n",
      "batch: 3550 loss: 0.695485  [454400/555113]\n",
      "batch: 3600 loss: 0.679600  [460800/555113]\n",
      "batch: 3650 loss: 0.698252  [467200/555113]\n",
      "batch: 3700 loss: 0.682527  [473600/555113]\n",
      "batch: 3750 loss: 0.702167  [480000/555113]\n",
      "batch: 3800 loss: 0.676846  [486400/555113]\n",
      "batch: 3850 loss: 0.679640  [492800/555113]\n",
      "batch: 3900 loss: 0.689720  [499200/555113]\n",
      "batch: 3950 loss: 0.689677  [505600/555113]\n",
      "batch: 4000 loss: 0.698135  [512000/555113]\n",
      "batch: 4050 loss: 0.681850  [518400/555113]\n",
      "batch: 4100 loss: 0.688515  [524800/555113]\n",
      "batch: 4150 loss: 0.683539  [531200/555113]\n",
      "batch: 4200 loss: 0.705802  [537600/555113]\n",
      "batch: 4250 loss: 0.697040  [544000/555113]\n",
      "batch: 4300 loss: 0.683074  [550400/555113]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.655163  [ 6400/555113]\n",
      "batch: 100 loss: 0.679614  [12800/555113]\n",
      "batch: 150 loss: 0.685036  [19200/555113]\n",
      "batch: 200 loss: 0.682596  [25600/555113]\n",
      "batch: 250 loss: 0.669948  [32000/555113]\n",
      "batch: 300 loss: 0.696376  [38400/555113]\n",
      "batch: 350 loss: 0.708752  [44800/555113]\n",
      "batch: 400 loss: 0.683974  [51200/555113]\n",
      "batch: 450 loss: 0.693047  [57600/555113]\n",
      "batch: 500 loss: 0.681427  [64000/555113]\n",
      "batch: 550 loss: 0.682365  [70400/555113]\n",
      "batch: 600 loss: 0.674627  [76800/555113]\n",
      "batch: 650 loss: 0.675955  [83200/555113]\n",
      "batch: 700 loss: 0.680649  [89600/555113]\n",
      "batch: 750 loss: 0.684358  [96000/555113]\n",
      "batch: 800 loss: 0.676115  [102400/555113]\n",
      "batch: 850 loss: 0.683196  [108800/555113]\n",
      "batch: 900 loss: 0.697104  [115200/555113]\n",
      "batch: 950 loss: 0.703186  [121600/555113]\n",
      "batch: 1000 loss: 0.690988  [128000/555113]\n",
      "batch: 1050 loss: 0.680790  [134400/555113]\n",
      "batch: 1100 loss: 0.678750  [140800/555113]\n",
      "batch: 1150 loss: 0.688467  [147200/555113]\n",
      "batch: 1200 loss: 0.677198  [153600/555113]\n",
      "batch: 1250 loss: 0.663932  [160000/555113]\n",
      "batch: 1300 loss: 0.687649  [166400/555113]\n",
      "batch: 1350 loss: 0.700404  [172800/555113]\n",
      "batch: 1400 loss: 0.667792  [179200/555113]\n",
      "batch: 1450 loss: 0.697782  [185600/555113]\n",
      "batch: 1500 loss: 0.685966  [192000/555113]\n",
      "batch: 1550 loss: 0.677810  [198400/555113]\n",
      "batch: 1600 loss: 0.682434  [204800/555113]\n",
      "batch: 1650 loss: 0.664597  [211200/555113]\n",
      "batch: 1700 loss: 0.672625  [217600/555113]\n",
      "batch: 1750 loss: 0.690595  [224000/555113]\n",
      "batch: 1800 loss: 0.688104  [230400/555113]\n",
      "batch: 1850 loss: 0.693995  [236800/555113]\n",
      "batch: 1900 loss: 0.675579  [243200/555113]\n",
      "batch: 1950 loss: 0.685758  [249600/555113]\n",
      "batch: 2000 loss: 0.692993  [256000/555113]\n",
      "batch: 2050 loss: 0.687044  [262400/555113]\n",
      "batch: 2100 loss: 0.697094  [268800/555113]\n",
      "batch: 2150 loss: 0.706818  [275200/555113]\n",
      "batch: 2200 loss: 0.700674  [281600/555113]\n",
      "batch: 2250 loss: 0.696108  [288000/555113]\n",
      "batch: 2300 loss: 0.688284  [294400/555113]\n",
      "batch: 2350 loss: 0.713088  [300800/555113]\n",
      "batch: 2400 loss: 0.696141  [307200/555113]\n",
      "batch: 2450 loss: 0.673803  [313600/555113]\n",
      "batch: 2500 loss: 0.695466  [320000/555113]\n",
      "batch: 2550 loss: 0.681101  [326400/555113]\n",
      "batch: 2600 loss: 0.692726  [332800/555113]\n",
      "batch: 2650 loss: 0.698985  [339200/555113]\n",
      "batch: 2700 loss: 0.661412  [345600/555113]\n",
      "batch: 2750 loss: 0.700442  [352000/555113]\n",
      "batch: 2800 loss: 0.675760  [358400/555113]\n",
      "batch: 2850 loss: 0.683868  [364800/555113]\n",
      "batch: 2900 loss: 0.689509  [371200/555113]\n",
      "batch: 2950 loss: 0.708857  [377600/555113]\n",
      "batch: 3000 loss: 0.675153  [384000/555113]\n",
      "batch: 3050 loss: 0.695422  [390400/555113]\n",
      "batch: 3100 loss: 0.684020  [396800/555113]\n",
      "batch: 3150 loss: 0.656549  [403200/555113]\n",
      "batch: 3200 loss: 0.683128  [409600/555113]\n",
      "batch: 3250 loss: 0.689421  [416000/555113]\n",
      "batch: 3300 loss: 0.702115  [422400/555113]\n",
      "batch: 3350 loss: 0.686852  [428800/555113]\n",
      "batch: 3400 loss: 0.702846  [435200/555113]\n",
      "batch: 3450 loss: 0.692319  [441600/555113]\n",
      "batch: 3500 loss: 0.684025  [448000/555113]\n",
      "batch: 3550 loss: 0.684681  [454400/555113]\n",
      "batch: 3600 loss: 0.700387  [460800/555113]\n",
      "batch: 3650 loss: 0.684823  [467200/555113]\n",
      "batch: 3700 loss: 0.674634  [473600/555113]\n",
      "batch: 3750 loss: 0.696666  [480000/555113]\n",
      "batch: 3800 loss: 0.671470  [486400/555113]\n",
      "batch: 3850 loss: 0.698669  [492800/555113]\n",
      "batch: 3900 loss: 0.712478  [499200/555113]\n",
      "batch: 3950 loss: 0.701979  [505600/555113]\n",
      "batch: 4000 loss: 0.673390  [512000/555113]\n",
      "batch: 4050 loss: 0.686849  [518400/555113]\n",
      "batch: 4100 loss: 0.666288  [524800/555113]\n",
      "batch: 4150 loss: 0.678134  [531200/555113]\n",
      "batch: 4200 loss: 0.688711  [537600/555113]\n",
      "batch: 4250 loss: 0.673117  [544000/555113]\n",
      "batch: 4300 loss: 0.680980  [550400/555113]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.680799  [ 6400/555113]\n",
      "batch: 100 loss: 0.690055  [12800/555113]\n",
      "batch: 150 loss: 0.690579  [19200/555113]\n",
      "batch: 200 loss: 0.686211  [25600/555113]\n",
      "batch: 250 loss: 0.703986  [32000/555113]\n",
      "batch: 300 loss: 0.693534  [38400/555113]\n",
      "batch: 350 loss: 0.696034  [44800/555113]\n",
      "batch: 400 loss: 0.685364  [51200/555113]\n",
      "batch: 450 loss: 0.687135  [57600/555113]\n",
      "batch: 500 loss: 0.688294  [64000/555113]\n",
      "batch: 550 loss: 0.697595  [70400/555113]\n",
      "batch: 600 loss: 0.689832  [76800/555113]\n",
      "batch: 650 loss: 0.682571  [83200/555113]\n",
      "batch: 700 loss: 0.695492  [89600/555113]\n",
      "batch: 750 loss: 0.714864  [96000/555113]\n",
      "batch: 800 loss: 0.666966  [102400/555113]\n",
      "batch: 850 loss: 0.666681  [108800/555113]\n",
      "batch: 900 loss: 0.693302  [115200/555113]\n",
      "batch: 950 loss: 0.685333  [121600/555113]\n",
      "batch: 1000 loss: 0.689107  [128000/555113]\n",
      "batch: 1050 loss: 0.688346  [134400/555113]\n",
      "batch: 1100 loss: 0.684953  [140800/555113]\n",
      "batch: 1150 loss: 0.657817  [147200/555113]\n",
      "batch: 1200 loss: 0.708860  [153600/555113]\n",
      "batch: 1250 loss: 0.683548  [160000/555113]\n",
      "batch: 1300 loss: 0.693447  [166400/555113]\n",
      "batch: 1350 loss: 0.680532  [172800/555113]\n",
      "batch: 1400 loss: 0.687294  [179200/555113]\n",
      "batch: 1450 loss: 0.713650  [185600/555113]\n",
      "batch: 1500 loss: 0.704811  [192000/555113]\n",
      "batch: 1550 loss: 0.676969  [198400/555113]\n",
      "batch: 1600 loss: 0.705703  [204800/555113]\n",
      "batch: 1650 loss: 0.670286  [211200/555113]\n",
      "batch: 1700 loss: 0.687205  [217600/555113]\n",
      "batch: 1750 loss: 0.672950  [224000/555113]\n",
      "batch: 1800 loss: 0.684699  [230400/555113]\n",
      "batch: 1850 loss: 0.689696  [236800/555113]\n",
      "batch: 1900 loss: 0.699376  [243200/555113]\n",
      "batch: 1950 loss: 0.701470  [249600/555113]\n",
      "batch: 2000 loss: 0.681558  [256000/555113]\n",
      "batch: 2050 loss: 0.672337  [262400/555113]\n",
      "batch: 2100 loss: 0.695732  [268800/555113]\n",
      "batch: 2150 loss: 0.679268  [275200/555113]\n",
      "batch: 2200 loss: 0.696618  [281600/555113]\n",
      "batch: 2250 loss: 0.680492  [288000/555113]\n",
      "batch: 2300 loss: 0.687058  [294400/555113]\n",
      "batch: 2350 loss: 0.700892  [300800/555113]\n",
      "batch: 2400 loss: 0.679102  [307200/555113]\n",
      "batch: 2450 loss: 0.714208  [313600/555113]\n",
      "batch: 2500 loss: 0.683728  [320000/555113]\n",
      "batch: 2550 loss: 0.690422  [326400/555113]\n",
      "batch: 2600 loss: 0.682297  [332800/555113]\n",
      "batch: 2650 loss: 0.693128  [339200/555113]\n",
      "batch: 2700 loss: 0.682482  [345600/555113]\n",
      "batch: 2750 loss: 0.675291  [352000/555113]\n",
      "batch: 2800 loss: 0.697912  [358400/555113]\n",
      "batch: 2850 loss: 0.690034  [364800/555113]\n",
      "batch: 2900 loss: 0.690165  [371200/555113]\n",
      "batch: 2950 loss: 0.697761  [377600/555113]\n",
      "batch: 3000 loss: 0.694920  [384000/555113]\n",
      "batch: 3050 loss: 0.685869  [390400/555113]\n",
      "batch: 3100 loss: 0.670587  [396800/555113]\n",
      "batch: 3150 loss: 0.699524  [403200/555113]\n",
      "batch: 3200 loss: 0.687160  [409600/555113]\n",
      "batch: 3250 loss: 0.698355  [416000/555113]\n",
      "batch: 3300 loss: 0.680904  [422400/555113]\n",
      "batch: 3350 loss: 0.678150  [428800/555113]\n",
      "batch: 3400 loss: 0.682085  [435200/555113]\n",
      "batch: 3450 loss: 0.667773  [441600/555113]\n",
      "batch: 3500 loss: 0.680419  [448000/555113]\n",
      "batch: 3550 loss: 0.669409  [454400/555113]\n",
      "batch: 3600 loss: 0.691572  [460800/555113]\n",
      "batch: 3650 loss: 0.698846  [467200/555113]\n",
      "batch: 3700 loss: 0.684267  [473600/555113]\n",
      "batch: 3750 loss: 0.685769  [480000/555113]\n",
      "batch: 3800 loss: 0.680849  [486400/555113]\n",
      "batch: 3850 loss: 0.666603  [492800/555113]\n",
      "batch: 3900 loss: 0.694699  [499200/555113]\n",
      "batch: 3950 loss: 0.698694  [505600/555113]\n",
      "batch: 4000 loss: 0.694477  [512000/555113]\n",
      "batch: 4050 loss: 0.679513  [518400/555113]\n",
      "batch: 4100 loss: 0.682365  [524800/555113]\n",
      "batch: 4150 loss: 0.693695  [531200/555113]\n",
      "batch: 4200 loss: 0.684803  [537600/555113]\n",
      "batch: 4250 loss: 0.679561  [544000/555113]\n",
      "batch: 4300 loss: 0.689241  [550400/555113]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.700438  [ 6400/555113]\n",
      "batch: 100 loss: 0.672536  [12800/555113]\n",
      "batch: 150 loss: 0.716227  [19200/555113]\n",
      "batch: 200 loss: 0.666847  [25600/555113]\n",
      "batch: 250 loss: 0.695287  [32000/555113]\n",
      "batch: 300 loss: 0.694200  [38400/555113]\n",
      "batch: 350 loss: 0.690269  [44800/555113]\n",
      "batch: 400 loss: 0.691037  [51200/555113]\n",
      "batch: 450 loss: 0.663597  [57600/555113]\n",
      "batch: 500 loss: 0.700071  [64000/555113]\n",
      "batch: 550 loss: 0.682788  [70400/555113]\n",
      "batch: 600 loss: 0.677761  [76800/555113]\n",
      "batch: 650 loss: 0.672822  [83200/555113]\n",
      "batch: 700 loss: 0.692334  [89600/555113]\n",
      "batch: 750 loss: 0.681875  [96000/555113]\n",
      "batch: 800 loss: 0.676555  [102400/555113]\n",
      "batch: 850 loss: 0.691867  [108800/555113]\n",
      "batch: 900 loss: 0.679871  [115200/555113]\n",
      "batch: 950 loss: 0.680287  [121600/555113]\n",
      "batch: 1000 loss: 0.703282  [128000/555113]\n",
      "batch: 1050 loss: 0.675525  [134400/555113]\n",
      "batch: 1100 loss: 0.698824  [140800/555113]\n",
      "batch: 1150 loss: 0.681298  [147200/555113]\n",
      "batch: 1200 loss: 0.677763  [153600/555113]\n",
      "batch: 1250 loss: 0.695698  [160000/555113]\n",
      "batch: 1300 loss: 0.689738  [166400/555113]\n",
      "batch: 1350 loss: 0.696338  [172800/555113]\n",
      "batch: 1400 loss: 0.701222  [179200/555113]\n",
      "batch: 1450 loss: 0.672988  [185600/555113]\n",
      "batch: 1500 loss: 0.693724  [192000/555113]\n",
      "batch: 1550 loss: 0.685682  [198400/555113]\n",
      "batch: 1600 loss: 0.700430  [204800/555113]\n",
      "batch: 1650 loss: 0.669777  [211200/555113]\n",
      "batch: 1700 loss: 0.698285  [217600/555113]\n",
      "batch: 1750 loss: 0.670138  [224000/555113]\n",
      "batch: 1800 loss: 0.670433  [230400/555113]\n",
      "batch: 1850 loss: 0.680758  [236800/555113]\n",
      "batch: 1900 loss: 0.681420  [243200/555113]\n",
      "batch: 1950 loss: 0.684372  [249600/555113]\n",
      "batch: 2000 loss: 0.693852  [256000/555113]\n",
      "batch: 2050 loss: 0.696245  [262400/555113]\n",
      "batch: 2100 loss: 0.679785  [268800/555113]\n",
      "batch: 2150 loss: 0.693164  [275200/555113]\n",
      "batch: 2200 loss: 0.687870  [281600/555113]\n",
      "batch: 2250 loss: 0.690181  [288000/555113]\n",
      "batch: 2300 loss: 0.702162  [294400/555113]\n",
      "batch: 2350 loss: 0.702224  [300800/555113]\n",
      "batch: 2400 loss: 0.677028  [307200/555113]\n",
      "batch: 2450 loss: 0.678934  [313600/555113]\n",
      "batch: 2500 loss: 0.682868  [320000/555113]\n",
      "batch: 2550 loss: 0.696472  [326400/555113]\n",
      "batch: 2600 loss: 0.672911  [332800/555113]\n",
      "batch: 2650 loss: 0.694180  [339200/555113]\n",
      "batch: 2700 loss: 0.664763  [345600/555113]\n",
      "batch: 2750 loss: 0.682803  [352000/555113]\n",
      "batch: 2800 loss: 0.679834  [358400/555113]\n",
      "batch: 2850 loss: 0.678839  [364800/555113]\n",
      "batch: 2900 loss: 0.664893  [371200/555113]\n",
      "batch: 2950 loss: 0.692404  [377600/555113]\n",
      "batch: 3000 loss: 0.673834  [384000/555113]\n",
      "batch: 3050 loss: 0.678058  [390400/555113]\n",
      "batch: 3100 loss: 0.675262  [396800/555113]\n",
      "batch: 3150 loss: 0.672126  [403200/555113]\n",
      "batch: 3200 loss: 0.685676  [409600/555113]\n",
      "batch: 3250 loss: 0.703779  [416000/555113]\n",
      "batch: 3300 loss: 0.679603  [422400/555113]\n",
      "batch: 3350 loss: 0.694013  [428800/555113]\n",
      "batch: 3400 loss: 0.694062  [435200/555113]\n",
      "batch: 3450 loss: 0.689049  [441600/555113]\n",
      "batch: 3500 loss: 0.669864  [448000/555113]\n",
      "batch: 3550 loss: 0.708936  [454400/555113]\n",
      "batch: 3600 loss: 0.683712  [460800/555113]\n",
      "batch: 3650 loss: 0.709337  [467200/555113]\n",
      "batch: 3700 loss: 0.669819  [473600/555113]\n",
      "batch: 3750 loss: 0.682585  [480000/555113]\n",
      "batch: 3800 loss: 0.668568  [486400/555113]\n",
      "batch: 3850 loss: 0.684541  [492800/555113]\n",
      "batch: 3900 loss: 0.689170  [499200/555113]\n",
      "batch: 3950 loss: 0.675813  [505600/555113]\n",
      "batch: 4000 loss: 0.699747  [512000/555113]\n",
      "batch: 4050 loss: 0.707790  [518400/555113]\n",
      "batch: 4100 loss: 0.686963  [524800/555113]\n",
      "batch: 4150 loss: 0.721244  [531200/555113]\n",
      "batch: 4200 loss: 0.707894  [537600/555113]\n",
      "batch: 4250 loss: 0.679811  [544000/555113]\n",
      "batch: 4300 loss: 0.698295  [550400/555113]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.672075  [ 6400/555113]\n",
      "batch: 100 loss: 0.673739  [12800/555113]\n",
      "batch: 150 loss: 0.706238  [19200/555113]\n",
      "batch: 200 loss: 0.702402  [25600/555113]\n",
      "batch: 250 loss: 0.690099  [32000/555113]\n",
      "batch: 300 loss: 0.689751  [38400/555113]\n",
      "batch: 350 loss: 0.686498  [44800/555113]\n",
      "batch: 400 loss: 0.696506  [51200/555113]\n",
      "batch: 450 loss: 0.691045  [57600/555113]\n",
      "batch: 500 loss: 0.673865  [64000/555113]\n",
      "batch: 550 loss: 0.677797  [70400/555113]\n",
      "batch: 600 loss: 0.683087  [76800/555113]\n",
      "batch: 650 loss: 0.692744  [83200/555113]\n",
      "batch: 700 loss: 0.670607  [89600/555113]\n",
      "batch: 750 loss: 0.681442  [96000/555113]\n",
      "batch: 800 loss: 0.700953  [102400/555113]\n",
      "batch: 850 loss: 0.677898  [108800/555113]\n",
      "batch: 900 loss: 0.679256  [115200/555113]\n",
      "batch: 950 loss: 0.695317  [121600/555113]\n",
      "batch: 1000 loss: 0.705761  [128000/555113]\n",
      "batch: 1050 loss: 0.670476  [134400/555113]\n",
      "batch: 1100 loss: 0.693103  [140800/555113]\n",
      "batch: 1150 loss: 0.706869  [147200/555113]\n",
      "batch: 1200 loss: 0.680870  [153600/555113]\n",
      "batch: 1250 loss: 0.682423  [160000/555113]\n",
      "batch: 1300 loss: 0.665518  [166400/555113]\n",
      "batch: 1350 loss: 0.685912  [172800/555113]\n",
      "batch: 1400 loss: 0.701193  [179200/555113]\n",
      "batch: 1450 loss: 0.685235  [185600/555113]\n",
      "batch: 1500 loss: 0.680773  [192000/555113]\n",
      "batch: 1550 loss: 0.673317  [198400/555113]\n",
      "batch: 1600 loss: 0.673107  [204800/555113]\n",
      "batch: 1650 loss: 0.693782  [211200/555113]\n",
      "batch: 1700 loss: 0.679448  [217600/555113]\n",
      "batch: 1750 loss: 0.692866  [224000/555113]\n",
      "batch: 1800 loss: 0.679816  [230400/555113]\n",
      "batch: 1850 loss: 0.693020  [236800/555113]\n",
      "batch: 1900 loss: 0.674684  [243200/555113]\n",
      "batch: 1950 loss: 0.676486  [249600/555113]\n",
      "batch: 2000 loss: 0.701845  [256000/555113]\n",
      "batch: 2050 loss: 0.674522  [262400/555113]\n",
      "batch: 2100 loss: 0.678500  [268800/555113]\n",
      "batch: 2150 loss: 0.690331  [275200/555113]\n",
      "batch: 2200 loss: 0.659624  [281600/555113]\n",
      "batch: 2250 loss: 0.707377  [288000/555113]\n",
      "batch: 2300 loss: 0.695871  [294400/555113]\n",
      "batch: 2350 loss: 0.685173  [300800/555113]\n",
      "batch: 2400 loss: 0.691539  [307200/555113]\n",
      "batch: 2450 loss: 0.674112  [313600/555113]\n",
      "batch: 2500 loss: 0.691403  [320000/555113]\n",
      "batch: 2550 loss: 0.686125  [326400/555113]\n",
      "batch: 2600 loss: 0.701065  [332800/555113]\n",
      "batch: 2650 loss: 0.701362  [339200/555113]\n",
      "batch: 2700 loss: 0.682667  [345600/555113]\n",
      "batch: 2750 loss: 0.691407  [352000/555113]\n",
      "batch: 2800 loss: 0.690094  [358400/555113]\n",
      "batch: 2850 loss: 0.689160  [364800/555113]\n",
      "batch: 2900 loss: 0.681551  [371200/555113]\n",
      "batch: 2950 loss: 0.690867  [377600/555113]\n",
      "batch: 3000 loss: 0.685460  [384000/555113]\n",
      "batch: 3050 loss: 0.679905  [390400/555113]\n",
      "batch: 3100 loss: 0.685600  [396800/555113]\n",
      "batch: 3150 loss: 0.690469  [403200/555113]\n",
      "batch: 3200 loss: 0.699705  [409600/555113]\n",
      "batch: 3250 loss: 0.700862  [416000/555113]\n",
      "batch: 3300 loss: 0.685241  [422400/555113]\n",
      "batch: 3350 loss: 0.689157  [428800/555113]\n",
      "batch: 3400 loss: 0.706746  [435200/555113]\n",
      "batch: 3450 loss: 0.683196  [441600/555113]\n",
      "batch: 3500 loss: 0.713746  [448000/555113]\n",
      "batch: 3550 loss: 0.677070  [454400/555113]\n",
      "batch: 3600 loss: 0.688405  [460800/555113]\n",
      "batch: 3650 loss: 0.662903  [467200/555113]\n",
      "batch: 3700 loss: 0.672874  [473600/555113]\n",
      "batch: 3750 loss: 0.695316  [480000/555113]\n",
      "batch: 3800 loss: 0.684749  [486400/555113]\n",
      "batch: 3850 loss: 0.679671  [492800/555113]\n",
      "batch: 3900 loss: 0.686510  [499200/555113]\n",
      "batch: 3950 loss: 0.679605  [505600/555113]\n",
      "batch: 4000 loss: 0.672140  [512000/555113]\n",
      "batch: 4050 loss: 0.687273  [518400/555113]\n",
      "batch: 4100 loss: 0.708100  [524800/555113]\n",
      "batch: 4150 loss: 0.690223  [531200/555113]\n",
      "batch: 4200 loss: 0.709171  [537600/555113]\n",
      "batch: 4250 loss: 0.685697  [544000/555113]\n",
      "batch: 4300 loss: 0.688784  [550400/555113]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.672219  [ 6400/555113]\n",
      "batch: 100 loss: 0.696692  [12800/555113]\n",
      "batch: 150 loss: 0.669056  [19200/555113]\n",
      "batch: 200 loss: 0.666639  [25600/555113]\n",
      "batch: 250 loss: 0.702742  [32000/555113]\n",
      "batch: 300 loss: 0.687385  [38400/555113]\n",
      "batch: 350 loss: 0.693229  [44800/555113]\n",
      "batch: 400 loss: 0.678827  [51200/555113]\n",
      "batch: 450 loss: 0.683944  [57600/555113]\n",
      "batch: 500 loss: 0.664998  [64000/555113]\n",
      "batch: 550 loss: 0.685201  [70400/555113]\n",
      "batch: 600 loss: 0.662840  [76800/555113]\n",
      "batch: 650 loss: 0.676900  [83200/555113]\n",
      "batch: 700 loss: 0.667004  [89600/555113]\n",
      "batch: 750 loss: 0.700364  [96000/555113]\n",
      "batch: 800 loss: 0.697640  [102400/555113]\n",
      "batch: 850 loss: 0.686045  [108800/555113]\n",
      "batch: 900 loss: 0.693236  [115200/555113]\n",
      "batch: 950 loss: 0.679427  [121600/555113]\n",
      "batch: 1000 loss: 0.679770  [128000/555113]\n",
      "batch: 1050 loss: 0.682416  [134400/555113]\n",
      "batch: 1100 loss: 0.676696  [140800/555113]\n",
      "batch: 1150 loss: 0.673199  [147200/555113]\n",
      "batch: 1200 loss: 0.685972  [153600/555113]\n",
      "batch: 1250 loss: 0.693499  [160000/555113]\n",
      "batch: 1300 loss: 0.692238  [166400/555113]\n",
      "batch: 1350 loss: 0.701102  [172800/555113]\n",
      "batch: 1400 loss: 0.677649  [179200/555113]\n",
      "batch: 1450 loss: 0.679424  [185600/555113]\n",
      "batch: 1500 loss: 0.636020  [192000/555113]\n",
      "batch: 1550 loss: 0.689548  [198400/555113]\n",
      "batch: 1600 loss: 0.681824  [204800/555113]\n",
      "batch: 1650 loss: 0.681290  [211200/555113]\n",
      "batch: 1700 loss: 0.697277  [217600/555113]\n",
      "batch: 1750 loss: 0.661081  [224000/555113]\n",
      "batch: 1800 loss: 0.672449  [230400/555113]\n",
      "batch: 1850 loss: 0.680813  [236800/555113]\n",
      "batch: 1900 loss: 0.696990  [243200/555113]\n",
      "batch: 1950 loss: 0.685736  [249600/555113]\n",
      "batch: 2000 loss: 0.653705  [256000/555113]\n",
      "batch: 2050 loss: 0.680361  [262400/555113]\n",
      "batch: 2100 loss: 0.676294  [268800/555113]\n",
      "batch: 2150 loss: 0.693106  [275200/555113]\n",
      "batch: 2200 loss: 0.661549  [281600/555113]\n",
      "batch: 2250 loss: 0.681864  [288000/555113]\n",
      "batch: 2300 loss: 0.697067  [294400/555113]\n",
      "batch: 2350 loss: 0.715048  [300800/555113]\n",
      "batch: 2400 loss: 0.667883  [307200/555113]\n",
      "batch: 2450 loss: 0.682821  [313600/555113]\n",
      "batch: 2500 loss: 0.673572  [320000/555113]\n",
      "batch: 2550 loss: 0.660230  [326400/555113]\n",
      "batch: 2600 loss: 0.697871  [332800/555113]\n",
      "batch: 2650 loss: 0.685368  [339200/555113]\n",
      "batch: 2700 loss: 0.677451  [345600/555113]\n",
      "batch: 2750 loss: 0.701375  [352000/555113]\n",
      "batch: 2800 loss: 0.683527  [358400/555113]\n",
      "batch: 2850 loss: 0.673766  [364800/555113]\n",
      "batch: 2900 loss: 0.682638  [371200/555113]\n",
      "batch: 2950 loss: 0.684047  [377600/555113]\n",
      "batch: 3000 loss: 0.700337  [384000/555113]\n",
      "batch: 3050 loss: 0.681413  [390400/555113]\n",
      "batch: 3100 loss: 0.686245  [396800/555113]\n",
      "batch: 3150 loss: 0.704760  [403200/555113]\n",
      "batch: 3200 loss: 0.680479  [409600/555113]\n",
      "batch: 3250 loss: 0.694273  [416000/555113]\n",
      "batch: 3300 loss: 0.703001  [422400/555113]\n",
      "batch: 3350 loss: 0.677287  [428800/555113]\n",
      "batch: 3400 loss: 0.695466  [435200/555113]\n",
      "batch: 3450 loss: 0.684335  [441600/555113]\n",
      "batch: 3500 loss: 0.686106  [448000/555113]\n",
      "batch: 3550 loss: 0.673549  [454400/555113]\n",
      "batch: 3600 loss: 0.674018  [460800/555113]\n",
      "batch: 3650 loss: 0.682642  [467200/555113]\n",
      "batch: 3700 loss: 0.680784  [473600/555113]\n",
      "batch: 3750 loss: 0.695818  [480000/555113]\n",
      "batch: 3800 loss: 0.711680  [486400/555113]\n",
      "batch: 3850 loss: 0.676104  [492800/555113]\n",
      "batch: 3900 loss: 0.685046  [499200/555113]\n",
      "batch: 3950 loss: 0.696846  [505600/555113]\n",
      "batch: 4000 loss: 0.697167  [512000/555113]\n",
      "batch: 4050 loss: 0.715939  [518400/555113]\n",
      "batch: 4100 loss: 0.695550  [524800/555113]\n",
      "batch: 4150 loss: 0.692510  [531200/555113]\n",
      "batch: 4200 loss: 0.668869  [537600/555113]\n",
      "batch: 4250 loss: 0.692932  [544000/555113]\n",
      "batch: 4300 loss: 0.678837  [550400/555113]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.686524  [ 6400/555113]\n",
      "batch: 100 loss: 0.680681  [12800/555113]\n",
      "batch: 150 loss: 0.687619  [19200/555113]\n",
      "batch: 200 loss: 0.687367  [25600/555113]\n",
      "batch: 250 loss: 0.693174  [32000/555113]\n",
      "batch: 300 loss: 0.666081  [38400/555113]\n",
      "batch: 350 loss: 0.676389  [44800/555113]\n",
      "batch: 400 loss: 0.652123  [51200/555113]\n",
      "batch: 450 loss: 0.670947  [57600/555113]\n",
      "batch: 500 loss: 0.697187  [64000/555113]\n",
      "batch: 550 loss: 0.679226  [70400/555113]\n",
      "batch: 600 loss: 0.675932  [76800/555113]\n",
      "batch: 650 loss: 0.654228  [83200/555113]\n",
      "batch: 700 loss: 0.666063  [89600/555113]\n",
      "batch: 750 loss: 0.670594  [96000/555113]\n",
      "batch: 800 loss: 0.702368  [102400/555113]\n",
      "batch: 850 loss: 0.666919  [108800/555113]\n",
      "batch: 900 loss: 0.682546  [115200/555113]\n",
      "batch: 950 loss: 0.684386  [121600/555113]\n",
      "batch: 1000 loss: 0.677264  [128000/555113]\n",
      "batch: 1050 loss: 0.693928  [134400/555113]\n",
      "batch: 1100 loss: 0.697268  [140800/555113]\n",
      "batch: 1150 loss: 0.686026  [147200/555113]\n",
      "batch: 1200 loss: 0.681508  [153600/555113]\n",
      "batch: 1250 loss: 0.671759  [160000/555113]\n",
      "batch: 1300 loss: 0.677341  [166400/555113]\n",
      "batch: 1350 loss: 0.700688  [172800/555113]\n",
      "batch: 1400 loss: 0.677616  [179200/555113]\n",
      "batch: 1450 loss: 0.674709  [185600/555113]\n",
      "batch: 1500 loss: 0.671897  [192000/555113]\n",
      "batch: 1550 loss: 0.700219  [198400/555113]\n",
      "batch: 1600 loss: 0.667613  [204800/555113]\n",
      "batch: 1650 loss: 0.679553  [211200/555113]\n",
      "batch: 1700 loss: 0.691648  [217600/555113]\n",
      "batch: 1750 loss: 0.692841  [224000/555113]\n",
      "batch: 1800 loss: 0.680521  [230400/555113]\n",
      "batch: 1850 loss: 0.659774  [236800/555113]\n",
      "batch: 1900 loss: 0.689449  [243200/555113]\n",
      "batch: 1950 loss: 0.650781  [249600/555113]\n",
      "batch: 2000 loss: 0.666161  [256000/555113]\n",
      "batch: 2050 loss: 0.683325  [262400/555113]\n",
      "batch: 2100 loss: 0.674558  [268800/555113]\n",
      "batch: 2150 loss: 0.693426  [275200/555113]\n",
      "batch: 2200 loss: 0.695597  [281600/555113]\n",
      "batch: 2250 loss: 0.680736  [288000/555113]\n",
      "batch: 2300 loss: 0.675896  [294400/555113]\n",
      "batch: 2350 loss: 0.682728  [300800/555113]\n",
      "batch: 2400 loss: 0.688138  [307200/555113]\n",
      "batch: 2450 loss: 0.686018  [313600/555113]\n",
      "batch: 2500 loss: 0.695600  [320000/555113]\n",
      "batch: 2550 loss: 0.671859  [326400/555113]\n",
      "batch: 2600 loss: 0.708817  [332800/555113]\n",
      "batch: 2650 loss: 0.686296  [339200/555113]\n",
      "batch: 2700 loss: 0.719715  [345600/555113]\n",
      "batch: 2750 loss: 0.684212  [352000/555113]\n",
      "batch: 2800 loss: 0.691687  [358400/555113]\n",
      "batch: 2850 loss: 0.698587  [364800/555113]\n",
      "batch: 2900 loss: 0.670289  [371200/555113]\n",
      "batch: 2950 loss: 0.666927  [377600/555113]\n",
      "batch: 3000 loss: 0.683939  [384000/555113]\n",
      "batch: 3050 loss: 0.674305  [390400/555113]\n",
      "batch: 3100 loss: 0.705449  [396800/555113]\n",
      "batch: 3150 loss: 0.688228  [403200/555113]\n",
      "batch: 3200 loss: 0.691152  [409600/555113]\n",
      "batch: 3250 loss: 0.674448  [416000/555113]\n",
      "batch: 3300 loss: 0.662105  [422400/555113]\n",
      "batch: 3350 loss: 0.684507  [428800/555113]\n",
      "batch: 3400 loss: 0.694488  [435200/555113]\n",
      "batch: 3450 loss: 0.690281  [441600/555113]\n",
      "batch: 3500 loss: 0.690187  [448000/555113]\n",
      "batch: 3550 loss: 0.687004  [454400/555113]\n",
      "batch: 3600 loss: 0.695647  [460800/555113]\n",
      "batch: 3650 loss: 0.680863  [467200/555113]\n",
      "batch: 3700 loss: 0.687845  [473600/555113]\n",
      "batch: 3750 loss: 0.663201  [480000/555113]\n",
      "batch: 3800 loss: 0.699147  [486400/555113]\n",
      "batch: 3850 loss: 0.671663  [492800/555113]\n",
      "batch: 3900 loss: 0.683462  [499200/555113]\n",
      "batch: 3950 loss: 0.687027  [505600/555113]\n",
      "batch: 4000 loss: 0.672827  [512000/555113]\n",
      "batch: 4050 loss: 0.691459  [518400/555113]\n",
      "batch: 4100 loss: 0.676411  [524800/555113]\n",
      "batch: 4150 loss: 0.713979  [531200/555113]\n",
      "batch: 4200 loss: 0.670043  [537600/555113]\n",
      "batch: 4250 loss: 0.697873  [544000/555113]\n",
      "batch: 4300 loss: 0.689923  [550400/555113]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.676992  [ 6400/555113]\n",
      "batch: 100 loss: 0.655193  [12800/555113]\n",
      "batch: 150 loss: 0.652908  [19200/555113]\n",
      "batch: 200 loss: 0.675289  [25600/555113]\n",
      "batch: 250 loss: 0.675987  [32000/555113]\n",
      "batch: 300 loss: 0.667531  [38400/555113]\n",
      "batch: 350 loss: 0.669527  [44800/555113]\n",
      "batch: 400 loss: 0.704308  [51200/555113]\n",
      "batch: 450 loss: 0.656571  [57600/555113]\n",
      "batch: 500 loss: 0.678217  [64000/555113]\n",
      "batch: 550 loss: 0.672500  [70400/555113]\n",
      "batch: 600 loss: 0.660664  [76800/555113]\n",
      "batch: 650 loss: 0.703682  [83200/555113]\n",
      "batch: 700 loss: 0.708650  [89600/555113]\n",
      "batch: 750 loss: 0.670495  [96000/555113]\n",
      "batch: 800 loss: 0.658579  [102400/555113]\n",
      "batch: 850 loss: 0.691590  [108800/555113]\n",
      "batch: 900 loss: 0.673575  [115200/555113]\n",
      "batch: 950 loss: 0.668003  [121600/555113]\n",
      "batch: 1000 loss: 0.695337  [128000/555113]\n",
      "batch: 1050 loss: 0.681895  [134400/555113]\n",
      "batch: 1100 loss: 0.674818  [140800/555113]\n",
      "batch: 1150 loss: 0.691374  [147200/555113]\n",
      "batch: 1200 loss: 0.678034  [153600/555113]\n",
      "batch: 1250 loss: 0.674064  [160000/555113]\n",
      "batch: 1300 loss: 0.670898  [166400/555113]\n",
      "batch: 1350 loss: 0.678908  [172800/555113]\n",
      "batch: 1400 loss: 0.659430  [179200/555113]\n",
      "batch: 1450 loss: 0.665448  [185600/555113]\n",
      "batch: 1500 loss: 0.670417  [192000/555113]\n",
      "batch: 1550 loss: 0.671925  [198400/555113]\n",
      "batch: 1600 loss: 0.682052  [204800/555113]\n",
      "batch: 1650 loss: 0.679176  [211200/555113]\n",
      "batch: 1700 loss: 0.696780  [217600/555113]\n",
      "batch: 1750 loss: 0.690199  [224000/555113]\n",
      "batch: 1800 loss: 0.692113  [230400/555113]\n",
      "batch: 1850 loss: 0.695038  [236800/555113]\n",
      "batch: 1900 loss: 0.692697  [243200/555113]\n",
      "batch: 1950 loss: 0.665808  [249600/555113]\n",
      "batch: 2000 loss: 0.680893  [256000/555113]\n",
      "batch: 2050 loss: 0.682003  [262400/555113]\n",
      "batch: 2100 loss: 0.682948  [268800/555113]\n",
      "batch: 2150 loss: 0.692749  [275200/555113]\n",
      "batch: 2200 loss: 0.665587  [281600/555113]\n",
      "batch: 2250 loss: 0.689174  [288000/555113]\n",
      "batch: 2300 loss: 0.691122  [294400/555113]\n",
      "batch: 2350 loss: 0.676162  [300800/555113]\n",
      "batch: 2400 loss: 0.672995  [307200/555113]\n",
      "batch: 2450 loss: 0.675803  [313600/555113]\n",
      "batch: 2500 loss: 0.685322  [320000/555113]\n",
      "batch: 2550 loss: 0.709666  [326400/555113]\n",
      "batch: 2600 loss: 0.690127  [332800/555113]\n",
      "batch: 2650 loss: 0.680695  [339200/555113]\n",
      "batch: 2700 loss: 0.679307  [345600/555113]\n",
      "batch: 2750 loss: 0.677355  [352000/555113]\n",
      "batch: 2800 loss: 0.683611  [358400/555113]\n",
      "batch: 2850 loss: 0.670251  [364800/555113]\n",
      "batch: 2900 loss: 0.705266  [371200/555113]\n",
      "batch: 2950 loss: 0.677364  [377600/555113]\n",
      "batch: 3000 loss: 0.680667  [384000/555113]\n",
      "batch: 3050 loss: 0.689051  [390400/555113]\n",
      "batch: 3100 loss: 0.694227  [396800/555113]\n",
      "batch: 3150 loss: 0.678723  [403200/555113]\n",
      "batch: 3200 loss: 0.685722  [409600/555113]\n",
      "batch: 3250 loss: 0.698433  [416000/555113]\n",
      "batch: 3300 loss: 0.672808  [422400/555113]\n",
      "batch: 3350 loss: 0.692542  [428800/555113]\n",
      "batch: 3400 loss: 0.689193  [435200/555113]\n",
      "batch: 3450 loss: 0.674284  [441600/555113]\n",
      "batch: 3500 loss: 0.670583  [448000/555113]\n",
      "batch: 3550 loss: 0.674097  [454400/555113]\n",
      "batch: 3600 loss: 0.644900  [460800/555113]\n",
      "batch: 3650 loss: 0.682419  [467200/555113]\n",
      "batch: 3700 loss: 0.712421  [473600/555113]\n",
      "batch: 3750 loss: 0.678098  [480000/555113]\n",
      "batch: 3800 loss: 0.667101  [486400/555113]\n",
      "batch: 3850 loss: 0.733358  [492800/555113]\n",
      "batch: 3900 loss: 0.681351  [499200/555113]\n",
      "batch: 3950 loss: 0.687898  [505600/555113]\n",
      "batch: 4000 loss: 0.691452  [512000/555113]\n",
      "batch: 4050 loss: 0.670486  [518400/555113]\n",
      "batch: 4100 loss: 0.666838  [524800/555113]\n",
      "batch: 4150 loss: 0.679502  [531200/555113]\n",
      "batch: 4200 loss: 0.649620  [537600/555113]\n",
      "batch: 4250 loss: 0.679879  [544000/555113]\n",
      "batch: 4300 loss: 0.676167  [550400/555113]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.691842  [ 6400/555113]\n",
      "batch: 100 loss: 0.671033  [12800/555113]\n",
      "batch: 150 loss: 0.670670  [19200/555113]\n",
      "batch: 200 loss: 0.697919  [25600/555113]\n",
      "batch: 250 loss: 0.666981  [32000/555113]\n",
      "batch: 300 loss: 0.656551  [38400/555113]\n",
      "batch: 350 loss: 0.689960  [44800/555113]\n",
      "batch: 400 loss: 0.664519  [51200/555113]\n",
      "batch: 450 loss: 0.688742  [57600/555113]\n",
      "batch: 500 loss: 0.694979  [64000/555113]\n",
      "batch: 550 loss: 0.681691  [70400/555113]\n",
      "batch: 600 loss: 0.704003  [76800/555113]\n",
      "batch: 650 loss: 0.686573  [83200/555113]\n",
      "batch: 700 loss: 0.670845  [89600/555113]\n",
      "batch: 750 loss: 0.701333  [96000/555113]\n",
      "batch: 800 loss: 0.699032  [102400/555113]\n",
      "batch: 850 loss: 0.668338  [108800/555113]\n",
      "batch: 900 loss: 0.685791  [115200/555113]\n",
      "batch: 950 loss: 0.674638  [121600/555113]\n",
      "batch: 1000 loss: 0.667807  [128000/555113]\n",
      "batch: 1050 loss: 0.677308  [134400/555113]\n",
      "batch: 1100 loss: 0.699868  [140800/555113]\n",
      "batch: 1150 loss: 0.694694  [147200/555113]\n",
      "batch: 1200 loss: 0.670112  [153600/555113]\n",
      "batch: 1250 loss: 0.655375  [160000/555113]\n",
      "batch: 1300 loss: 0.677516  [166400/555113]\n",
      "batch: 1350 loss: 0.678157  [172800/555113]\n",
      "batch: 1400 loss: 0.681510  [179200/555113]\n",
      "batch: 1450 loss: 0.683909  [185600/555113]\n",
      "batch: 1500 loss: 0.662604  [192000/555113]\n",
      "batch: 1550 loss: 0.674338  [198400/555113]\n",
      "batch: 1600 loss: 0.673679  [204800/555113]\n",
      "batch: 1650 loss: 0.671257  [211200/555113]\n",
      "batch: 1700 loss: 0.674240  [217600/555113]\n",
      "batch: 1750 loss: 0.658092  [224000/555113]\n",
      "batch: 1800 loss: 0.671210  [230400/555113]\n",
      "batch: 1850 loss: 0.669993  [236800/555113]\n",
      "batch: 1900 loss: 0.691663  [243200/555113]\n",
      "batch: 1950 loss: 0.650935  [249600/555113]\n",
      "batch: 2000 loss: 0.680144  [256000/555113]\n",
      "batch: 2050 loss: 0.675408  [262400/555113]\n",
      "batch: 2100 loss: 0.677509  [268800/555113]\n",
      "batch: 2150 loss: 0.685870  [275200/555113]\n",
      "batch: 2200 loss: 0.692472  [281600/555113]\n",
      "batch: 2250 loss: 0.675960  [288000/555113]\n",
      "batch: 2300 loss: 0.697559  [294400/555113]\n",
      "batch: 2350 loss: 0.672262  [300800/555113]\n",
      "batch: 2400 loss: 0.693315  [307200/555113]\n",
      "batch: 2450 loss: 0.670969  [313600/555113]\n",
      "batch: 2500 loss: 0.687113  [320000/555113]\n",
      "batch: 2550 loss: 0.679023  [326400/555113]\n",
      "batch: 2600 loss: 0.690094  [332800/555113]\n",
      "batch: 2650 loss: 0.659706  [339200/555113]\n",
      "batch: 2700 loss: 0.697010  [345600/555113]\n",
      "batch: 2750 loss: 0.660938  [352000/555113]\n",
      "batch: 2800 loss: 0.676206  [358400/555113]\n",
      "batch: 2850 loss: 0.656790  [364800/555113]\n",
      "batch: 2900 loss: 0.670575  [371200/555113]\n",
      "batch: 2950 loss: 0.687795  [377600/555113]\n",
      "batch: 3000 loss: 0.694747  [384000/555113]\n",
      "batch: 3050 loss: 0.661642  [390400/555113]\n",
      "batch: 3100 loss: 0.682462  [396800/555113]\n",
      "batch: 3150 loss: 0.688924  [403200/555113]\n",
      "batch: 3200 loss: 0.653433  [409600/555113]\n",
      "batch: 3250 loss: 0.691474  [416000/555113]\n",
      "batch: 3300 loss: 0.723961  [422400/555113]\n",
      "batch: 3350 loss: 0.670841  [428800/555113]\n",
      "batch: 3400 loss: 0.702964  [435200/555113]\n",
      "batch: 3450 loss: 0.678763  [441600/555113]\n",
      "batch: 3500 loss: 0.677101  [448000/555113]\n",
      "batch: 3550 loss: 0.675600  [454400/555113]\n",
      "batch: 3600 loss: 0.674359  [460800/555113]\n",
      "batch: 3650 loss: 0.669603  [467200/555113]\n",
      "batch: 3700 loss: 0.678765  [473600/555113]\n",
      "batch: 3750 loss: 0.691201  [480000/555113]\n",
      "batch: 3800 loss: 0.678090  [486400/555113]\n",
      "batch: 3850 loss: 0.679755  [492800/555113]\n",
      "batch: 3900 loss: 0.664494  [499200/555113]\n",
      "batch: 3950 loss: 0.697646  [505600/555113]\n",
      "batch: 4000 loss: 0.693280  [512000/555113]\n",
      "batch: 4050 loss: 0.678029  [518400/555113]\n",
      "batch: 4100 loss: 0.664814  [524800/555113]\n",
      "batch: 4150 loss: 0.683975  [531200/555113]\n",
      "batch: 4200 loss: 0.678447  [537600/555113]\n",
      "batch: 4250 loss: 0.675656  [544000/555113]\n",
      "batch: 4300 loss: 0.678471  [550400/555113]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.676738  [ 6400/555113]\n",
      "batch: 100 loss: 0.649067  [12800/555113]\n",
      "batch: 150 loss: 0.671501  [19200/555113]\n",
      "batch: 200 loss: 0.692225  [25600/555113]\n",
      "batch: 250 loss: 0.669876  [32000/555113]\n",
      "batch: 300 loss: 0.672408  [38400/555113]\n",
      "batch: 350 loss: 0.677414  [44800/555113]\n",
      "batch: 400 loss: 0.665489  [51200/555113]\n",
      "batch: 450 loss: 0.692369  [57600/555113]\n",
      "batch: 500 loss: 0.670003  [64000/555113]\n",
      "batch: 550 loss: 0.677704  [70400/555113]\n",
      "batch: 600 loss: 0.696574  [76800/555113]\n",
      "batch: 650 loss: 0.672042  [83200/555113]\n",
      "batch: 700 loss: 0.658593  [89600/555113]\n",
      "batch: 750 loss: 0.672949  [96000/555113]\n",
      "batch: 800 loss: 0.677665  [102400/555113]\n",
      "batch: 850 loss: 0.670984  [108800/555113]\n",
      "batch: 900 loss: 0.705308  [115200/555113]\n",
      "batch: 950 loss: 0.684247  [121600/555113]\n",
      "batch: 1000 loss: 0.673748  [128000/555113]\n",
      "batch: 1050 loss: 0.701008  [134400/555113]\n",
      "batch: 1100 loss: 0.661818  [140800/555113]\n",
      "batch: 1150 loss: 0.676704  [147200/555113]\n",
      "batch: 1200 loss: 0.692950  [153600/555113]\n",
      "batch: 1250 loss: 0.693062  [160000/555113]\n",
      "batch: 1300 loss: 0.691283  [166400/555113]\n",
      "batch: 1350 loss: 0.671777  [172800/555113]\n",
      "batch: 1400 loss: 0.668217  [179200/555113]\n",
      "batch: 1450 loss: 0.679046  [185600/555113]\n",
      "batch: 1500 loss: 0.696660  [192000/555113]\n",
      "batch: 1550 loss: 0.659289  [198400/555113]\n",
      "batch: 1600 loss: 0.681588  [204800/555113]\n",
      "batch: 1650 loss: 0.672927  [211200/555113]\n",
      "batch: 1700 loss: 0.689570  [217600/555113]\n",
      "batch: 1750 loss: 0.690833  [224000/555113]\n",
      "batch: 1800 loss: 0.665070  [230400/555113]\n",
      "batch: 1850 loss: 0.674714  [236800/555113]\n",
      "batch: 1900 loss: 0.691529  [243200/555113]\n",
      "batch: 1950 loss: 0.662914  [249600/555113]\n",
      "batch: 2000 loss: 0.692259  [256000/555113]\n",
      "batch: 2050 loss: 0.689901  [262400/555113]\n",
      "batch: 2100 loss: 0.703328  [268800/555113]\n",
      "batch: 2150 loss: 0.680197  [275200/555113]\n",
      "batch: 2200 loss: 0.669784  [281600/555113]\n",
      "batch: 2250 loss: 0.693030  [288000/555113]\n",
      "batch: 2300 loss: 0.702267  [294400/555113]\n",
      "batch: 2350 loss: 0.703122  [300800/555113]\n",
      "batch: 2400 loss: 0.674312  [307200/555113]\n",
      "batch: 2450 loss: 0.685598  [313600/555113]\n",
      "batch: 2500 loss: 0.705238  [320000/555113]\n",
      "batch: 2550 loss: 0.662447  [326400/555113]\n",
      "batch: 2600 loss: 0.680538  [332800/555113]\n",
      "batch: 2650 loss: 0.658553  [339200/555113]\n",
      "batch: 2700 loss: 0.686473  [345600/555113]\n",
      "batch: 2750 loss: 0.699317  [352000/555113]\n",
      "batch: 2800 loss: 0.699918  [358400/555113]\n",
      "batch: 2850 loss: 0.699048  [364800/555113]\n",
      "batch: 2900 loss: 0.689969  [371200/555113]\n",
      "batch: 2950 loss: 0.652801  [377600/555113]\n",
      "batch: 3000 loss: 0.668857  [384000/555113]\n",
      "batch: 3050 loss: 0.660656  [390400/555113]\n",
      "batch: 3100 loss: 0.680090  [396800/555113]\n",
      "batch: 3150 loss: 0.678958  [403200/555113]\n",
      "batch: 3200 loss: 0.655480  [409600/555113]\n",
      "batch: 3250 loss: 0.648676  [416000/555113]\n",
      "batch: 3300 loss: 0.701282  [422400/555113]\n",
      "batch: 3350 loss: 0.681870  [428800/555113]\n",
      "batch: 3400 loss: 0.661189  [435200/555113]\n",
      "batch: 3450 loss: 0.704675  [441600/555113]\n",
      "batch: 3500 loss: 0.687974  [448000/555113]\n",
      "batch: 3550 loss: 0.679872  [454400/555113]\n",
      "batch: 3600 loss: 0.646294  [460800/555113]\n",
      "batch: 3650 loss: 0.663512  [467200/555113]\n",
      "batch: 3700 loss: 0.656371  [473600/555113]\n",
      "batch: 3750 loss: 0.707355  [480000/555113]\n",
      "batch: 3800 loss: 0.681635  [486400/555113]\n",
      "batch: 3850 loss: 0.673896  [492800/555113]\n",
      "batch: 3900 loss: 0.687451  [499200/555113]\n",
      "batch: 3950 loss: 0.696236  [505600/555113]\n",
      "batch: 4000 loss: 0.677082  [512000/555113]\n",
      "batch: 4050 loss: 0.675510  [518400/555113]\n",
      "batch: 4100 loss: 0.682524  [524800/555113]\n",
      "batch: 4150 loss: 0.676477  [531200/555113]\n",
      "batch: 4200 loss: 0.658139  [537600/555113]\n",
      "batch: 4250 loss: 0.695742  [544000/555113]\n",
      "batch: 4300 loss: 0.685410  [550400/555113]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.667444  [ 6400/555113]\n",
      "batch: 100 loss: 0.671714  [12800/555113]\n",
      "batch: 150 loss: 0.676300  [19200/555113]\n",
      "batch: 200 loss: 0.654491  [25600/555113]\n",
      "batch: 250 loss: 0.681385  [32000/555113]\n",
      "batch: 300 loss: 0.681622  [38400/555113]\n",
      "batch: 350 loss: 0.682937  [44800/555113]\n",
      "batch: 400 loss: 0.690479  [51200/555113]\n",
      "batch: 450 loss: 0.681312  [57600/555113]\n",
      "batch: 500 loss: 0.694782  [64000/555113]\n",
      "batch: 550 loss: 0.681888  [70400/555113]\n",
      "batch: 600 loss: 0.670514  [76800/555113]\n",
      "batch: 650 loss: 0.676595  [83200/555113]\n",
      "batch: 700 loss: 0.650166  [89600/555113]\n",
      "batch: 750 loss: 0.667994  [96000/555113]\n",
      "batch: 800 loss: 0.657229  [102400/555113]\n",
      "batch: 850 loss: 0.708268  [108800/555113]\n",
      "batch: 900 loss: 0.676555  [115200/555113]\n",
      "batch: 950 loss: 0.670052  [121600/555113]\n",
      "batch: 1000 loss: 0.702170  [128000/555113]\n",
      "batch: 1050 loss: 0.672842  [134400/555113]\n",
      "batch: 1100 loss: 0.635211  [140800/555113]\n",
      "batch: 1150 loss: 0.663533  [147200/555113]\n",
      "batch: 1200 loss: 0.667336  [153600/555113]\n",
      "batch: 1250 loss: 0.696054  [160000/555113]\n",
      "batch: 1300 loss: 0.698408  [166400/555113]\n",
      "batch: 1350 loss: 0.710901  [172800/555113]\n",
      "batch: 1400 loss: 0.681568  [179200/555113]\n",
      "batch: 1450 loss: 0.672902  [185600/555113]\n",
      "batch: 1500 loss: 0.674697  [192000/555113]\n",
      "batch: 1550 loss: 0.689035  [198400/555113]\n",
      "batch: 1600 loss: 0.671034  [204800/555113]\n",
      "batch: 1650 loss: 0.683182  [211200/555113]\n",
      "batch: 1700 loss: 0.694391  [217600/555113]\n",
      "batch: 1750 loss: 0.663007  [224000/555113]\n",
      "batch: 1800 loss: 0.666056  [230400/555113]\n",
      "batch: 1850 loss: 0.676131  [236800/555113]\n",
      "batch: 1900 loss: 0.679686  [243200/555113]\n",
      "batch: 1950 loss: 0.674794  [249600/555113]\n",
      "batch: 2000 loss: 0.659925  [256000/555113]\n",
      "batch: 2050 loss: 0.666455  [262400/555113]\n",
      "batch: 2100 loss: 0.665896  [268800/555113]\n",
      "batch: 2150 loss: 0.700245  [275200/555113]\n",
      "batch: 2200 loss: 0.687091  [281600/555113]\n",
      "batch: 2250 loss: 0.679806  [288000/555113]\n",
      "batch: 2300 loss: 0.680039  [294400/555113]\n",
      "batch: 2350 loss: 0.689762  [300800/555113]\n",
      "batch: 2400 loss: 0.665257  [307200/555113]\n",
      "batch: 2450 loss: 0.701650  [313600/555113]\n",
      "batch: 2500 loss: 0.663178  [320000/555113]\n",
      "batch: 2550 loss: 0.661467  [326400/555113]\n",
      "batch: 2600 loss: 0.670240  [332800/555113]\n",
      "batch: 2650 loss: 0.682582  [339200/555113]\n",
      "batch: 2700 loss: 0.684739  [345600/555113]\n",
      "batch: 2750 loss: 0.655948  [352000/555113]\n",
      "batch: 2800 loss: 0.663738  [358400/555113]\n",
      "batch: 2850 loss: 0.641950  [364800/555113]\n",
      "batch: 2900 loss: 0.666140  [371200/555113]\n",
      "batch: 2950 loss: 0.668834  [377600/555113]\n",
      "batch: 3000 loss: 0.658725  [384000/555113]\n",
      "batch: 3050 loss: 0.677355  [390400/555113]\n",
      "batch: 3100 loss: 0.669263  [396800/555113]\n",
      "batch: 3150 loss: 0.674022  [403200/555113]\n",
      "batch: 3200 loss: 0.670220  [409600/555113]\n",
      "batch: 3250 loss: 0.687277  [416000/555113]\n",
      "batch: 3300 loss: 0.692895  [422400/555113]\n",
      "batch: 3350 loss: 0.676281  [428800/555113]\n",
      "batch: 3400 loss: 0.665000  [435200/555113]\n",
      "batch: 3450 loss: 0.678260  [441600/555113]\n",
      "batch: 3500 loss: 0.690210  [448000/555113]\n",
      "batch: 3550 loss: 0.667830  [454400/555113]\n",
      "batch: 3600 loss: 0.693143  [460800/555113]\n",
      "batch: 3650 loss: 0.659730  [467200/555113]\n",
      "batch: 3700 loss: 0.664806  [473600/555113]\n",
      "batch: 3750 loss: 0.674070  [480000/555113]\n",
      "batch: 3800 loss: 0.646204  [486400/555113]\n",
      "batch: 3850 loss: 0.691775  [492800/555113]\n",
      "batch: 3900 loss: 0.674286  [499200/555113]\n",
      "batch: 3950 loss: 0.695772  [505600/555113]\n",
      "batch: 4000 loss: 0.689180  [512000/555113]\n",
      "batch: 4050 loss: 0.682872  [518400/555113]\n",
      "batch: 4100 loss: 0.687900  [524800/555113]\n",
      "batch: 4150 loss: 0.678923  [531200/555113]\n",
      "batch: 4200 loss: 0.679506  [537600/555113]\n",
      "batch: 4250 loss: 0.687621  [544000/555113]\n",
      "batch: 4300 loss: 0.691986  [550400/555113]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.685447  [ 6400/555113]\n",
      "batch: 100 loss: 0.671021  [12800/555113]\n",
      "batch: 150 loss: 0.666350  [19200/555113]\n",
      "batch: 200 loss: 0.680132  [25600/555113]\n",
      "batch: 250 loss: 0.668151  [32000/555113]\n",
      "batch: 300 loss: 0.676064  [38400/555113]\n",
      "batch: 350 loss: 0.648851  [44800/555113]\n",
      "batch: 400 loss: 0.635173  [51200/555113]\n",
      "batch: 450 loss: 0.675944  [57600/555113]\n",
      "batch: 500 loss: 0.675773  [64000/555113]\n",
      "batch: 550 loss: 0.689549  [70400/555113]\n",
      "batch: 600 loss: 0.682022  [76800/555113]\n",
      "batch: 650 loss: 0.696693  [83200/555113]\n",
      "batch: 700 loss: 0.669245  [89600/555113]\n",
      "batch: 750 loss: 0.638358  [96000/555113]\n",
      "batch: 800 loss: 0.664656  [102400/555113]\n",
      "batch: 850 loss: 0.668827  [108800/555113]\n",
      "batch: 900 loss: 0.671710  [115200/555113]\n",
      "batch: 950 loss: 0.680899  [121600/555113]\n",
      "batch: 1000 loss: 0.702453  [128000/555113]\n",
      "batch: 1050 loss: 0.675134  [134400/555113]\n",
      "batch: 1100 loss: 0.677996  [140800/555113]\n",
      "batch: 1150 loss: 0.643707  [147200/555113]\n",
      "batch: 1200 loss: 0.663905  [153600/555113]\n",
      "batch: 1250 loss: 0.647287  [160000/555113]\n",
      "batch: 1300 loss: 0.669402  [166400/555113]\n",
      "batch: 1350 loss: 0.664572  [172800/555113]\n",
      "batch: 1400 loss: 0.647601  [179200/555113]\n",
      "batch: 1450 loss: 0.681097  [185600/555113]\n",
      "batch: 1500 loss: 0.681676  [192000/555113]\n",
      "batch: 1550 loss: 0.686700  [198400/555113]\n",
      "batch: 1600 loss: 0.664724  [204800/555113]\n",
      "batch: 1650 loss: 0.677220  [211200/555113]\n",
      "batch: 1700 loss: 0.683910  [217600/555113]\n",
      "batch: 1750 loss: 0.683058  [224000/555113]\n",
      "batch: 1800 loss: 0.686784  [230400/555113]\n",
      "batch: 1850 loss: 0.661157  [236800/555113]\n",
      "batch: 1900 loss: 0.685319  [243200/555113]\n",
      "batch: 1950 loss: 0.698374  [249600/555113]\n",
      "batch: 2000 loss: 0.675759  [256000/555113]\n",
      "batch: 2050 loss: 0.668130  [262400/555113]\n",
      "batch: 2100 loss: 0.690322  [268800/555113]\n",
      "batch: 2150 loss: 0.678372  [275200/555113]\n",
      "batch: 2200 loss: 0.674163  [281600/555113]\n",
      "batch: 2250 loss: 0.687231  [288000/555113]\n",
      "batch: 2300 loss: 0.678066  [294400/555113]\n",
      "batch: 2350 loss: 0.665943  [300800/555113]\n",
      "batch: 2400 loss: 0.680232  [307200/555113]\n",
      "batch: 2450 loss: 0.651171  [313600/555113]\n",
      "batch: 2500 loss: 0.683673  [320000/555113]\n",
      "batch: 2550 loss: 0.641333  [326400/555113]\n",
      "batch: 2600 loss: 0.663461  [332800/555113]\n",
      "batch: 2650 loss: 0.671398  [339200/555113]\n",
      "batch: 2700 loss: 0.679777  [345600/555113]\n",
      "batch: 2750 loss: 0.647828  [352000/555113]\n",
      "batch: 2800 loss: 0.662978  [358400/555113]\n",
      "batch: 2850 loss: 0.692927  [364800/555113]\n",
      "batch: 2900 loss: 0.665527  [371200/555113]\n",
      "batch: 2950 loss: 0.706734  [377600/555113]\n",
      "batch: 3000 loss: 0.664186  [384000/555113]\n",
      "batch: 3050 loss: 0.684532  [390400/555113]\n",
      "batch: 3100 loss: 0.694387  [396800/555113]\n",
      "batch: 3150 loss: 0.666360  [403200/555113]\n",
      "batch: 3200 loss: 0.669221  [409600/555113]\n",
      "batch: 3250 loss: 0.670034  [416000/555113]\n",
      "batch: 3300 loss: 0.664796  [422400/555113]\n",
      "batch: 3350 loss: 0.678024  [428800/555113]\n",
      "batch: 3400 loss: 0.681342  [435200/555113]\n",
      "batch: 3450 loss: 0.687533  [441600/555113]\n",
      "batch: 3500 loss: 0.678992  [448000/555113]\n",
      "batch: 3550 loss: 0.689334  [454400/555113]\n",
      "batch: 3600 loss: 0.668094  [460800/555113]\n",
      "batch: 3650 loss: 0.682268  [467200/555113]\n",
      "batch: 3700 loss: 0.679446  [473600/555113]\n",
      "batch: 3750 loss: 0.693723  [480000/555113]\n",
      "batch: 3800 loss: 0.695007  [486400/555113]\n",
      "batch: 3850 loss: 0.674173  [492800/555113]\n",
      "batch: 3900 loss: 0.675997  [499200/555113]\n",
      "batch: 3950 loss: 0.661817  [505600/555113]\n",
      "batch: 4000 loss: 0.662094  [512000/555113]\n",
      "batch: 4050 loss: 0.656307  [518400/555113]\n",
      "batch: 4100 loss: 0.700807  [524800/555113]\n",
      "batch: 4150 loss: 0.666024  [531200/555113]\n",
      "batch: 4200 loss: 0.688742  [537600/555113]\n",
      "batch: 4250 loss: 0.670931  [544000/555113]\n",
      "batch: 4300 loss: 0.702192  [550400/555113]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "batch: 50 loss: 0.655184  [ 6400/555113]\n",
      "batch: 100 loss: 0.701157  [12800/555113]\n",
      "batch: 150 loss: 0.674632  [19200/555113]\n",
      "batch: 200 loss: 0.668520  [25600/555113]\n",
      "batch: 250 loss: 0.686190  [32000/555113]\n",
      "batch: 300 loss: 0.638697  [38400/555113]\n",
      "batch: 350 loss: 0.666569  [44800/555113]\n",
      "batch: 400 loss: 0.673516  [51200/555113]\n",
      "batch: 450 loss: 0.679691  [57600/555113]\n",
      "batch: 500 loss: 0.673619  [64000/555113]\n",
      "batch: 550 loss: 0.668345  [70400/555113]\n",
      "batch: 600 loss: 0.673634  [76800/555113]\n",
      "batch: 650 loss: 0.672864  [83200/555113]\n",
      "batch: 700 loss: 0.664508  [89600/555113]\n",
      "batch: 750 loss: 0.696974  [96000/555113]\n",
      "batch: 800 loss: 0.673773  [102400/555113]\n",
      "batch: 850 loss: 0.678182  [108800/555113]\n",
      "batch: 900 loss: 0.664093  [115200/555113]\n",
      "batch: 950 loss: 0.670543  [121600/555113]\n",
      "batch: 1000 loss: 0.668359  [128000/555113]\n",
      "batch: 1050 loss: 0.668834  [134400/555113]\n",
      "batch: 1100 loss: 0.666178  [140800/555113]\n",
      "batch: 1150 loss: 0.638479  [147200/555113]\n",
      "batch: 1200 loss: 0.642413  [153600/555113]\n",
      "batch: 1250 loss: 0.645576  [160000/555113]\n",
      "batch: 1300 loss: 0.683233  [166400/555113]\n",
      "batch: 1350 loss: 0.666563  [172800/555113]\n",
      "batch: 1400 loss: 0.649028  [179200/555113]\n",
      "batch: 1450 loss: 0.689651  [185600/555113]\n",
      "batch: 1500 loss: 0.672004  [192000/555113]\n",
      "batch: 1550 loss: 0.680935  [198400/555113]\n",
      "batch: 1600 loss: 0.660451  [204800/555113]\n",
      "batch: 1650 loss: 0.676460  [211200/555113]\n",
      "batch: 1700 loss: 0.680950  [217600/555113]\n",
      "batch: 1750 loss: 0.664748  [224000/555113]\n",
      "batch: 1800 loss: 0.695828  [230400/555113]\n",
      "batch: 1850 loss: 0.658729  [236800/555113]\n",
      "batch: 1900 loss: 0.670285  [243200/555113]\n",
      "batch: 1950 loss: 0.671583  [249600/555113]\n",
      "batch: 2000 loss: 0.715727  [256000/555113]\n",
      "batch: 2050 loss: 0.695326  [262400/555113]\n",
      "batch: 2100 loss: 0.728474  [268800/555113]\n",
      "batch: 2150 loss: 0.675361  [275200/555113]\n",
      "batch: 2200 loss: 0.689982  [281600/555113]\n",
      "batch: 2250 loss: 0.668841  [288000/555113]\n",
      "batch: 2300 loss: 0.684882  [294400/555113]\n",
      "batch: 2350 loss: 0.683632  [300800/555113]\n",
      "batch: 2400 loss: 0.676920  [307200/555113]\n",
      "batch: 2450 loss: 0.670858  [313600/555113]\n",
      "batch: 2500 loss: 0.670680  [320000/555113]\n",
      "batch: 2550 loss: 0.680211  [326400/555113]\n",
      "batch: 2600 loss: 0.646410  [332800/555113]\n",
      "batch: 2650 loss: 0.700242  [339200/555113]\n",
      "batch: 2700 loss: 0.672602  [345600/555113]\n",
      "batch: 2750 loss: 0.696397  [352000/555113]\n",
      "batch: 2800 loss: 0.687608  [358400/555113]\n",
      "batch: 2850 loss: 0.670605  [364800/555113]\n",
      "batch: 2900 loss: 0.683009  [371200/555113]\n",
      "batch: 2950 loss: 0.676384  [377600/555113]\n",
      "batch: 3000 loss: 0.666805  [384000/555113]\n",
      "batch: 3050 loss: 0.657608  [390400/555113]\n",
      "batch: 3100 loss: 0.660367  [396800/555113]\n",
      "batch: 3150 loss: 0.659749  [403200/555113]\n",
      "batch: 3200 loss: 0.654591  [409600/555113]\n",
      "batch: 3250 loss: 0.680498  [416000/555113]\n",
      "batch: 3300 loss: 0.679706  [422400/555113]\n",
      "batch: 3350 loss: 0.656328  [428800/555113]\n",
      "batch: 3400 loss: 0.672929  [435200/555113]\n",
      "batch: 3450 loss: 0.644261  [441600/555113]\n",
      "batch: 3500 loss: 0.698959  [448000/555113]\n",
      "batch: 3550 loss: 0.669723  [454400/555113]\n",
      "batch: 3600 loss: 0.704588  [460800/555113]\n",
      "batch: 3650 loss: 0.679859  [467200/555113]\n",
      "batch: 3700 loss: 0.666736  [473600/555113]\n",
      "batch: 3750 loss: 0.677191  [480000/555113]\n",
      "batch: 3800 loss: 0.683570  [486400/555113]\n",
      "batch: 3850 loss: 0.671747  [492800/555113]\n",
      "batch: 3900 loss: 0.677769  [499200/555113]\n",
      "batch: 3950 loss: 0.673202  [505600/555113]\n",
      "batch: 4000 loss: 0.686124  [512000/555113]\n",
      "batch: 4050 loss: 0.700517  [518400/555113]\n",
      "batch: 4100 loss: 0.677031  [524800/555113]\n",
      "batch: 4150 loss: 0.671533  [531200/555113]\n",
      "batch: 4200 loss: 0.647608  [537600/555113]\n",
      "batch: 4250 loss: 0.689386  [544000/555113]\n",
      "batch: 4300 loss: 0.677066  [550400/555113]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net_ln.parameters(), lr=1e-5)\n",
    "\n",
    "start_epoch = 0\n",
    "min_val_loss = 1e9\n",
    "last_min_ind = -1\n",
    "early_stopping_epoch = 5\n",
    "\n",
    "epochs = 100\n",
    "for t in range(start_epoch, epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train_loop(train_dataloader, net_ln, loss_fn, optimizer)\n",
    "    eval_loss = eval_loop(val_dataloader, net_ln, loss_fn)\n",
    "    torch.save(net_ln, 'pt/'+'ln_epoch_{}_train_{:5f}_eval_{:5f}_.pt'.format(t+1, train_loss, eval_loss)) \n",
    "    if eval_loss < min_val_loss:\n",
    "        last_min_ind = t\n",
    "        min_val_loss = eval_loss\n",
    "    elif t - last_min_ind >= early_stopping_epoch:\n",
    "        break\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
