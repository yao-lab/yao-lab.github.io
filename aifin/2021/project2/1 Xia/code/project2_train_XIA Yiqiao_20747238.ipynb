{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586fb720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import functools\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "\n",
    "IMAGE_WIDTH = {5: 15, 20: 60, 60: 180}\n",
    "IMAGE_HEIGHT = {5: 32, 20: 64, 60: 96}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87d78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f4397",
   "metadata": {},
   "source": [
    "### Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a051025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 3), stride=(3, 1), padding=(16, 1), dilation=(2, 1))\n",
      "  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): LeakyReLU(negative_slope=0.01)\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): LeakyReLU(negative_slope=0.01)\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
      "  (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): LeakyReLU(negative_slope=0.01)\n",
      "  (pool3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=46080, out_features=2, bias=True)\n",
      "  (out): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "\n",
    "class CNN(Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels=64, kernel_size=(5, 3), stride = (3,1), padding= (16,1), dilation = (2,1)) \n",
    "        self.norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.LeakyReLU(0.01)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = (2,1))\n",
    "        self.conv2 = nn.Conv2d(in_channels = 64, out_channels=128, kernel_size=(5, 3), stride = 1, padding= (2,1))\n",
    "        self.norm2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.LeakyReLU(0.01)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = (2,1))\n",
    "        self.conv3 = nn.Conv2d(in_channels = 128, out_channels=256, kernel_size=(5, 3), stride = 1, padding= (2,1))\n",
    "        self.norm3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.LeakyReLU(0.01)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = (2,1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(46080, 2)\n",
    "        self.out = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.norm1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.norm2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool2(y)\n",
    "        y = self.conv3(y)\n",
    "        y = self.norm3(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.pool3(y)\n",
    "        y = y.view(y.size()[0],-1)\n",
    "        y = self.dropout(y)\n",
    "        y = self.fc1(y)\n",
    "        y = self.out(y)\n",
    "        return y\n",
    "\n",
    "net = CNN()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba97e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 30, 60]           1,024\n",
      "       BatchNorm2d-2           [-1, 64, 30, 60]             128\n",
      "         LeakyReLU-3           [-1, 64, 30, 60]               0\n",
      "         MaxPool2d-4           [-1, 64, 15, 60]               0\n",
      "            Conv2d-5          [-1, 128, 15, 60]         123,008\n",
      "       BatchNorm2d-6          [-1, 128, 15, 60]             256\n",
      "         LeakyReLU-7          [-1, 128, 15, 60]               0\n",
      "         MaxPool2d-8           [-1, 128, 7, 60]               0\n",
      "            Conv2d-9           [-1, 256, 7, 60]         491,776\n",
      "      BatchNorm2d-10           [-1, 256, 7, 60]             512\n",
      "        LeakyReLU-11           [-1, 256, 7, 60]               0\n",
      "        MaxPool2d-12           [-1, 256, 3, 60]               0\n",
      "          Dropout-13                [-1, 46080]               0\n",
      "           Linear-14                    [-1, 2]          92,162\n",
      "          Softmax-15                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 708,866\n",
      "Trainable params: 708,866\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.29\n",
      "Params size (MB): 2.70\n",
      "Estimated Total Size (MB): 12.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(net, input_size=(1,64,60), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef9873",
   "metadata": {},
   "source": [
    "### Apply xavier initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb33492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250f1d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 3), stride=(3, 1), padding=(16, 1), dilation=(2, 1))\n",
       "  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
       "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
       "  (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): LeakyReLU(negative_slope=0.01)\n",
       "  (pool3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=46080, out_features=2, bias=True)\n",
       "  (out): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0873f",
   "metadata": {},
   "source": [
    "### Adopt CrossEntropyLoss, Adam optimizer with learning rate 10-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb15fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(),lr = 0.00001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = net.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a16f5",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c21270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        print(self.path)\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9c74212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/cnn_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(path= './model/cnn_checkpoint.pt',verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67493f98",
   "metadata": {},
   "source": [
    "## Load data and split into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2706942f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(694871, 64, 60)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =[]\n",
    "y_train = pd.DataFrame()\n",
    "for year in range(1993,2000):\n",
    "    train = np.memmap(op.join(\"./img_data/monthly_20d/\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), dtype=np.uint8, mode='r+').reshape(\\\n",
    "                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20]))\n",
    "    data.append(train/255)\n",
    "    label_df_train = pd.read_feather(op.join(\"./img_data/monthly_20d/\", f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\"))['Ret_20d']\n",
    "    y_train= pd.concat([y_train,label_df_train],axis= 0)\n",
    "data = np.concatenate(data, axis=0, out=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf5c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.columns = ['Ret_20d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b1a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(694871, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46386910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(x):\n",
    "    if x>0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "y = y_train['Ret_20d'].apply(labeling)\n",
    "y = np.array(y).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7434faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, y, test_size=0.3, random_state=10, shuffle=True)\n",
    "del data,y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df514d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486409, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17800d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "x_train = torch.Tensor(x_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "x_val = torch.Tensor(x_val)\n",
    "y_val = torch.Tensor(y_val)\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=TensorDataset(x_train, y_train), \\\n",
    "                               batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = Data.DataLoader(dataset=TensorDataset(x_val, y_val), \\\n",
    "                               batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4243554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train,y_train,x_val,y_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24878e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3801"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e16e4b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1:  iteration: 1:\t loss: 0.7274898290634155\n",
      "epoch: 1:  iteration: 21:\t loss: 0.7861272692680359\n",
      "epoch: 1:  iteration: 41:\t loss: 0.7706305384635925\n",
      "epoch: 1:  iteration: 61:\t loss: 0.7629300951957703\n",
      "epoch: 1:  iteration: 81:\t loss: 0.7074761986732483\n",
      "epoch: 1:  iteration: 101:\t loss: 0.7326621413230896\n",
      "epoch: 1:  iteration: 121:\t loss: 0.8022302985191345\n",
      "epoch: 1:  iteration: 141:\t loss: 0.7791987061500549\n",
      "epoch: 1:  iteration: 161:\t loss: 0.6999830603599548\n",
      "epoch: 1:  iteration: 181:\t loss: 0.8335579633712769\n",
      "epoch: 1:  iteration: 201:\t loss: 0.7257198691368103\n",
      "Validation times:  1 | validation loss: 0.721 | validation accuracy: 0.507\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (inf --> 0.720850).  Saving model ...\n",
      "epoch: 1:  iteration: 221:\t loss: 0.7787879109382629\n",
      "epoch: 1:  iteration: 241:\t loss: 0.7453786134719849\n",
      "epoch: 1:  iteration: 261:\t loss: 0.7323696613311768\n",
      "epoch: 1:  iteration: 281:\t loss: 0.7293095588684082\n",
      "epoch: 1:  iteration: 301:\t loss: 0.7507721781730652\n",
      "epoch: 1:  iteration: 321:\t loss: 0.7331990599632263\n",
      "epoch: 1:  iteration: 341:\t loss: 0.6928297877311707\n",
      "epoch: 1:  iteration: 361:\t loss: 0.7488259077072144\n",
      "epoch: 1:  iteration: 381:\t loss: 0.7628939151763916\n",
      "epoch: 1:  iteration: 401:\t loss: 0.7560994625091553\n",
      "Validation times:  2 | validation loss: 0.713 | validation accuracy: 0.519\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.720850 --> 0.713244).  Saving model ...\n",
      "epoch: 1:  iteration: 421:\t loss: 0.7699449062347412\n",
      "epoch: 1:  iteration: 441:\t loss: 0.7332013845443726\n",
      "epoch: 1:  iteration: 461:\t loss: 0.7461798787117004\n",
      "epoch: 1:  iteration: 481:\t loss: 0.7110780477523804\n",
      "epoch: 1:  iteration: 501:\t loss: 0.7229692935943604\n",
      "epoch: 1:  iteration: 521:\t loss: 0.7628577351570129\n",
      "epoch: 1:  iteration: 541:\t loss: 0.7257547974586487\n",
      "epoch: 1:  iteration: 561:\t loss: 0.6910157203674316\n",
      "epoch: 1:  iteration: 581:\t loss: 0.6911789178848267\n",
      "epoch: 1:  iteration: 601:\t loss: 0.7228341102600098\n",
      "Validation times:  3 | validation loss: 0.710 | validation accuracy: 0.521\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.713244 --> 0.710386).  Saving model ...\n",
      "epoch: 1:  iteration: 621:\t loss: 0.6984595060348511\n",
      "epoch: 1:  iteration: 641:\t loss: 0.7287504076957703\n",
      "epoch: 1:  iteration: 661:\t loss: 0.7210038900375366\n",
      "epoch: 1:  iteration: 681:\t loss: 0.7215686440467834\n",
      "epoch: 1:  iteration: 701:\t loss: 0.7611393332481384\n",
      "epoch: 1:  iteration: 721:\t loss: 0.7588096857070923\n",
      "epoch: 1:  iteration: 741:\t loss: 0.7634269595146179\n",
      "epoch: 1:  iteration: 761:\t loss: 0.699252188205719\n",
      "epoch: 1:  iteration: 781:\t loss: 0.7654467821121216\n",
      "epoch: 1:  iteration: 801:\t loss: 0.7037999033927917\n",
      "Validation times:  4 | validation loss: 0.708 | validation accuracy: 0.522\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.710386 --> 0.708211).  Saving model ...\n",
      "epoch: 1:  iteration: 821:\t loss: 0.7095765471458435\n",
      "epoch: 1:  iteration: 841:\t loss: 0.75382399559021\n",
      "epoch: 1:  iteration: 861:\t loss: 0.7800806760787964\n",
      "epoch: 1:  iteration: 881:\t loss: 0.7486031651496887\n",
      "epoch: 1:  iteration: 901:\t loss: 0.7270534038543701\n",
      "epoch: 1:  iteration: 921:\t loss: 0.714173436164856\n",
      "epoch: 1:  iteration: 941:\t loss: 0.7375187873840332\n",
      "epoch: 1:  iteration: 961:\t loss: 0.7583195567131042\n",
      "epoch: 1:  iteration: 981:\t loss: 0.7644068002700806\n",
      "epoch: 1:  iteration: 1001:\t loss: 0.7206599116325378\n",
      "Validation times:  5 | validation loss: 0.712 | validation accuracy: 0.521\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 7\n",
      "epoch: 1:  iteration: 1021:\t loss: 0.7274302840232849\n",
      "epoch: 1:  iteration: 1041:\t loss: 0.709394097328186\n",
      "epoch: 1:  iteration: 1061:\t loss: 0.7159138917922974\n",
      "epoch: 1:  iteration: 1081:\t loss: 0.6370947360992432\n",
      "epoch: 1:  iteration: 1101:\t loss: 0.7350673675537109\n",
      "epoch: 1:  iteration: 1121:\t loss: 0.748381495475769\n",
      "epoch: 1:  iteration: 1141:\t loss: 0.7505289316177368\n",
      "epoch: 1:  iteration: 1161:\t loss: 0.7939372658729553\n",
      "epoch: 1:  iteration: 1181:\t loss: 0.7366529703140259\n",
      "epoch: 1:  iteration: 1201:\t loss: 0.7354071736335754\n",
      "Validation times:  6 | validation loss: 0.711 | validation accuracy: 0.520\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 7\n",
      "epoch: 1:  iteration: 1221:\t loss: 0.7686508297920227\n",
      "epoch: 1:  iteration: 1241:\t loss: 0.7678437232971191\n",
      "epoch: 1:  iteration: 1261:\t loss: 0.781499445438385\n",
      "epoch: 1:  iteration: 1281:\t loss: 0.7072525024414062\n",
      "epoch: 1:  iteration: 1301:\t loss: 0.7610988616943359\n",
      "epoch: 1:  iteration: 1321:\t loss: 0.6923854947090149\n",
      "epoch: 1:  iteration: 1341:\t loss: 0.6914510726928711\n",
      "epoch: 1:  iteration: 1361:\t loss: 0.7827236652374268\n",
      "epoch: 1:  iteration: 1381:\t loss: 0.7513726949691772\n",
      "epoch: 1:  iteration: 1401:\t loss: 0.756026029586792\n",
      "Validation times:  7 | validation loss: 0.709 | validation accuracy: 0.526\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 7\n",
      "epoch: 1:  iteration: 1421:\t loss: 0.7678569555282593\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-6c633c14f1d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "loss_count = []\n",
    "\n",
    "validation_loss = []\n",
    "validation_acc = []\n",
    "for epoch in range(num_epochs):\n",
    "    for step,(b_x,b_y) in enumerate(train_loader):\n",
    "        net.train()\n",
    "        b_x = b_x.to(device)\n",
    "        b_y = b_y.to(device)\n",
    "        b_y = b_y.reshape(b_y.size()[0],)\n",
    "        b_x = torch.unsqueeze(b_x,dim=1).float()\n",
    "        output = net(b_x)\n",
    "        loss = criterion(output, b_y.reshape(BATCH_SIZE,).long())\n",
    "        optimizer.zero_grad()           \n",
    "        loss.backward()                 \n",
    "        optimizer.step()                \n",
    "\n",
    "        if step%20 == 0:\n",
    "            temp = loss.cpu()\n",
    "            loss_count.append(temp.detach().numpy())\n",
    "            print('epoch: {}: '.format(epoch+1),'iteration: {}:\\t'.format(step+1),'loss:', loss.item())\n",
    "            torch.save(net.state_dict(),r'./model/cnn_checkpoint.pt')\n",
    "\n",
    "        if ((step % 200 == 0) & (step != 0)):\n",
    "            loss_val = 0\n",
    "            total_val = 0\n",
    "            correct_val = 0\n",
    "            net.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_step,(v_x,v_y) in enumerate(valid_loader):\n",
    "                    v_x = v_x.to(device)\n",
    "                    v_y = v_y.to(device)\n",
    "                    v_y = v_y.reshape(v_y.size()[0],)\n",
    "                    v_x = torch.unsqueeze(v_x,dim=1).float()\n",
    "                    validate_output = net(v_x)\n",
    "                    validate_loss_new = criterion(validate_output,v_y.long())\n",
    "                    loss_val += validate_loss_new.item()\n",
    "\n",
    "                    pred_y = torch.max(validate_output,1)[1].data\n",
    "                    total_val += v_y.size(0)\n",
    "                    correct_val += (pred_y == v_y).squeeze().sum()\n",
    "                loss_val /= len(valid_loader)\n",
    "\n",
    "            print('Validation times: ', step//200, '| validation loss: %.3f' % loss_val, '| validation accuracy: %.3f' % (correct_val / float(total_val)))\n",
    "            print('--------------------------------------------------')\n",
    "            validation_loss.append(loss_val)\n",
    "            validation_acc.append(correct_val / float(total_val))\n",
    "            early_stopping(loss_val, net)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    if early_stopping.early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7c52ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x232df48ce50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_loss,label = \"Validation Loss\")\n",
    "plt.plot(validation_acc,label = \"Validation Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ad424d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_loader, valid_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =[]\n",
    "y_test = pd.DataFrame()\n",
    "for year in range(2000,2020):\n",
    "    train = np.memmap(op.join(\"./img_data/monthly_20d/\", f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), dtype=np.uint8, mode='r+').reshape(\\\n",
    "                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20]))\n",
    "    test.append(test)\n",
    "    label_df_train = pd.read_feather(op.join(\"./img_data/monthly_20d/\", f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\"))['Ret_20d']\n",
    "    y_test= pd.concat([y_test,label_df_train],axis= 0)\n",
    "test = np.concatenate(test, axis=0, out=None)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.columns = ['Ret_20d']\n",
    "y_test = y_test['Ret_20d'].apply(labeling)\n",
    "y_test = np.array(y_test).reshape((-1,1))\n",
    "\n",
    "x_test = torch.Tensor(test)\n",
    "y_test = torch.Tensor(y)\n",
    "\n",
    "test_loader = Data.DataLoader(dataset=TensorDataset(x_test, y_test), \\\n",
    "                               batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/cnn_checkpoint.pt'))\n",
    "global_loss_test = []\n",
    "global_acc_test = []\n",
    "prediction = []\n",
    "y_res = []\n",
    "for b_x,b_y in test_loader:\n",
    "    b_x = b_x.to(device)\n",
    "    b_y = b_y.to(device)\n",
    "    b_y = b_y.reshape(b_y.size()[0],)\n",
    "    b_x = torch.unsqueeze(b_x,dim=1).float()\n",
    "    output = net(b_x)\n",
    "    loss = criterion(output, b_y.reshape(b_y.size()[0],).long())\n",
    "\n",
    "    pred_y = torch.max(output,1)[1].data\n",
    "    total_val += v_y.size(0)\n",
    "    correct_val += (pred_y == v_y).squeeze().sum()\n",
    "\n",
    "    global_loss_test.append(loss.item())\n",
    "    acc_test = torch.max(prediction_test,1)[1].cpu().numpy() == test_y.cpu().numpy()\n",
    "    global_acc_test.append(acc_test.mean())\n",
    "    prediction.extend(torch.max(prediction_test,1)[1].cpu().numpy().tolist())\n",
    "    y_res.extend(np.array(b).tolist())\n",
    "    print('|loss_test|', loss_test.cpu().item(), '|test_acc|', acc_test.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
