{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_dataset import EqDataset\n",
    "from CNNmodel import OURCNN\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "# from ten\n",
    "# sorboardX import  SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.memory_summary(device=None, abbreviated=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid:\t Epoch[000/010] Iteration_train[050/1901] Iteration[815/815] Loss: 575.7151 Acc:50.28%\n",
      "Training:Epoch[000/010] Iteration[100/1901] Loss: 0.8433 Acc:49.81% Acc_total:49.81%\n",
      "Valid:\t Epoch[000/010] Iteration_train[100/1901] Iteration[815/815] Loss: 575.2933 Acc:50.40%\n",
      "Valid:\t Epoch[000/010] Iteration_train[150/1901] Iteration[815/815] Loss: 575.0307 Acc:50.41%\n",
      "Training:Epoch[000/010] Iteration[200/1901] Loss: 0.7046 Acc:50.72% Acc_total:50.26%\n",
      "Valid:\t Epoch[000/010] Iteration_train[200/1901] Iteration[815/815] Loss: 574.9983 Acc:50.26%\n",
      "Valid:\t Epoch[000/010] Iteration_train[250/1901] Iteration[815/815] Loss: 574.6209 Acc:50.45%\n",
      "Training:Epoch[000/010] Iteration[300/1901] Loss: 0.7056 Acc:50.30% Acc_total:50.28%\n",
      "Valid:\t Epoch[000/010] Iteration_train[300/1901] Iteration[815/815] Loss: 575.9135 Acc:50.96%\n",
      "Valid:\t Epoch[000/010] Iteration_train[350/1901] Iteration[815/815] Loss: 574.7340 Acc:50.86%\n",
      "Training:Epoch[000/010] Iteration[400/1901] Loss: 0.7053 Acc:50.36% Acc_total:50.30%\n",
      "Valid:\t Epoch[000/010] Iteration_train[400/1901] Iteration[815/815] Loss: 574.2776 Acc:50.33%\n",
      "Valid:\t Epoch[000/010] Iteration_train[450/1901] Iteration[815/815] Loss: 574.5160 Acc:50.27%\n",
      "Training:Epoch[000/010] Iteration[500/1901] Loss: 0.7029 Acc:51.00% Acc_total:50.44%\n",
      "Valid:\t Epoch[000/010] Iteration_train[500/1901] Iteration[815/815] Loss: 573.7472 Acc:50.67%\n",
      "Valid:\t Epoch[000/010] Iteration_train[550/1901] Iteration[815/815] Loss: 573.6046 Acc:50.68%\n",
      "Training:Epoch[000/010] Iteration[600/1901] Loss: 0.7023 Acc:50.91% Acc_total:50.52%\n",
      "Valid:\t Epoch[000/010] Iteration_train[600/1901] Iteration[815/815] Loss: 574.0529 Acc:50.29%\n",
      "Valid:\t Epoch[000/010] Iteration_train[650/1901] Iteration[815/815] Loss: 573.5483 Acc:50.90%\n",
      "Training:Epoch[000/010] Iteration[700/1901] Loss: 0.7043 Acc:50.81% Acc_total:50.56%\n",
      "Valid:\t Epoch[000/010] Iteration_train[700/1901] Iteration[815/815] Loss: 573.2215 Acc:50.71%\n",
      "Valid:\t Epoch[000/010] Iteration_train[750/1901] Iteration[815/815] Loss: 573.1198 Acc:50.70%\n",
      "Training:Epoch[000/010] Iteration[800/1901] Loss: 0.7034 Acc:50.49% Acc_total:50.55%\n",
      "Valid:\t Epoch[000/010] Iteration_train[800/1901] Iteration[815/815] Loss: 573.5240 Acc:50.36%\n",
      "Valid:\t Epoch[000/010] Iteration_train[850/1901] Iteration[815/815] Loss: 573.0197 Acc:50.55%\n",
      "Training:Epoch[000/010] Iteration[900/1901] Loss: 0.7044 Acc:50.45% Acc_total:50.54%\n",
      "Valid:\t Epoch[000/010] Iteration_train[900/1901] Iteration[815/815] Loss: 572.8730 Acc:50.57%\n",
      "Valid:\t Epoch[000/010] Iteration_train[950/1901] Iteration[815/815] Loss: 572.7395 Acc:50.80%\n",
      "Training:Epoch[000/010] Iteration[1000/1901] Loss: 0.7029 Acc:51.01% Acc_total:50.59%\n",
      "Valid:\t Epoch[000/010] Iteration_train[1000/1901] Iteration[815/815] Loss: 572.6669 Acc:50.85%\n",
      "Valid:\t Epoch[000/010] Iteration_train[1050/1901] Iteration[815/815] Loss: 572.5177 Acc:50.71%\n",
      "Training:Epoch[000/010] Iteration[1100/1901] Loss: 0.7029 Acc:50.82% Acc_total:50.61%\n",
      "Valid:\t Epoch[000/010] Iteration_train[1100/1901] Iteration[815/815] Loss: 572.4068 Acc:50.77%\n",
      "Valid:\t Epoch[000/010] Iteration_train[1150/1901] Iteration[815/815] Loss: 572.4331 Acc:50.64%\n",
      "Training:Epoch[000/010] Iteration[1200/1901] Loss: 0.7036 Acc:50.33% Acc_total:50.59%\n",
      "Valid:\t Epoch[000/010] Iteration_train[1200/1901] Iteration[815/815] Loss: 572.8364 Acc:51.10%\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n",
      "====================================================================\n",
      "Valid[-1] Loss: 0.7029 Valid[-2] Loss: 0.7024 Valid[-3] Loss: 0.7023\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE = 256\n",
    "#256\n",
    "val_interval = 50\n",
    "log_interval = 100\n",
    "TRAIN_START = 1993\n",
    "TRAIN_END = 2000\n",
    "\n",
    "# ============================ step 1/5 data ============================\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "t_v_data = EqDataset(data_dir=\"/home/clicw/data/MAFS6010Z_Project2/data/\",sd=TRAIN_START,ed=TRAIN_END,transform=train_transform)\n",
    "train_size = int(0.7 * len(t_v_data))\n",
    "validate_size = len(t_v_data) - train_size\n",
    "train_dataset, validate_dataset = torch.utils.data.random_split(t_v_data, [train_size, validate_size])\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                                        shuffle=True)\n",
    "validateloader = torch.utils.data.DataLoader(validate_dataset, batch_size=BATCH_SIZE,\n",
    "                                        shuffle=False)\n",
    "\n",
    "# ============================ step 2/5 model ============================\n",
    "net = OURCNN()\n",
    "net.cuda()\n",
    "\n",
    "# ============================ step 3/5 loss ============================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ============================ step 4/5 optim ============================\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00005)                        # 选择优化器\n",
    "\n",
    "# ============================ step 5/5 train ============================\n",
    "train_curve = list()\n",
    "valid_curve = list()\n",
    "\n",
    "iter_count = 0\n",
    "\n",
    "# SummaryWriter\n",
    "# writer = SummaryWriter(comment='test_your_comment', filename_suffix=\"_test_your_filename_suffix\")\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "\n",
    "    loss_mean = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    correct_this_time = 0.\n",
    "    total_this_time = 0.\n",
    "\n",
    "    net.train()\n",
    "    # 遍历 train_loader 取数据\n",
    "    for i, data in enumerate(trainloader):\n",
    "        iter_count = iter_count+1\n",
    "        # forward\n",
    "        inputs, labels = data\n",
    "        labels = labels.squeeze(1).long()\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        #temp = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # get score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).squeeze().sum().cpu().numpy()\n",
    "        \n",
    "        # print\n",
    "        loss_mean += loss.item()\n",
    "        train_curve.append(loss.item())\n",
    "\n",
    "        correct_this_time = correct_this_time + (predicted == labels).squeeze().sum().cpu().numpy()\n",
    "        total_this_time = total_this_time + labels.size(0)\n",
    "\n",
    "        if (i+1) % log_interval == 0:\n",
    "            loss_mean = loss_mean / log_interval\n",
    "            print(\"Training:Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%} Acc_total:{:.2%}\".format(\n",
    "                epoch, MAX_EPOCH, i+1, len(trainloader), loss_mean,correct_this_time/total_this_time,correct / total))\n",
    "            loss_mean = 0.\n",
    "            correct_this_time = 0.\n",
    "            total_this_time = 0.\n",
    "\n",
    "        # # 记录数据，保存于event file\n",
    "        # writer.add_scalars(\"Loss\", {\"Train\": loss.item()}, iter_count)\n",
    "        # writer.add_scalars(\"Accuracy\", {\"Train\": correct / total}, iter_count)\n",
    "\n",
    "    # # Each epoch，write weights and grad\n",
    "    # for name, param in net.named_parameters():\n",
    "    #     writer.add_histogram(name + '_grad', param.grad, epoch)\n",
    "    #     writer.add_histogram(name + '_data', param, epoch)\n",
    "\n",
    "        # validate the model\n",
    "        if (i+1) % val_interval == 0:\n",
    "            correct_val = 0.\n",
    "            total_val = 0.\n",
    "            loss_val = 0.\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for j, data in enumerate(validateloader):\n",
    "                    inputs, labels = data\n",
    "                    labels = labels.squeeze(1).long()\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted == labels).squeeze().sum().cpu().numpy()\n",
    "\n",
    "                    loss_val += loss.item()\n",
    "\n",
    "                valid_curve.append(loss_val/validateloader.__len__())\n",
    "\n",
    "                print(\"Valid:\\t Epoch[{:0>3}/{:0>3}] Iteration_train[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "                    epoch, MAX_EPOCH, i+1, len(trainloader),j+1, len(validateloader), loss_val, correct_val / total_val))\n",
    "\n",
    "            if len(valid_curve)>=3 and valid_curve[-1]>valid_curve[-2] and valid_curve[-2]>valid_curve[-3]:\n",
    "                break\n",
    "\n",
    "        if len(valid_curve)>=3 and valid_curve[-1]>valid_curve[-2] and valid_curve[-2]>valid_curve[-3]:\n",
    "            print('====================================================================')\n",
    "            print('Valid[-1] Loss: {:.4f} Valid[-2] Loss: {:.4f} Valid[-3] Loss: {:.4f}'.format(\n",
    "                valid_curve[-1],valid_curve[-2],valid_curve[-3]))\n",
    "            break\n",
    "\n",
    "            # writer.add_scalars(\"Loss\", {\"Valid\": np.mean(valid_curve)}, iter_count)\n",
    "            # writer.add_scalars(\"Accuracy\", {\"Valid\": correct / total}, iter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_x = range(len(train_curve))\n",
    "train_y = train_curve\n",
    "\n",
    "train_iters = len(trainloader)\n",
    "valid_x = np.arange(1, len(valid_curve)+1) * train_iters*val_interval\n",
    "valid_y = valid_curve\n",
    "\n",
    "plt.plot(train_x, train_y, label='Train')\n",
    "# plt.plot(valid_x, valid_y, label='Valid')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('loss value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 1/5 data ============================\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_data = EqDataset(data_dir=\"/home/clicw/data/MAFS6010Z_Project2/data/\",sd=2000,ed=2020,transform=train_transform)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Iteration[100/5868] Loss: 0.7286 Acc:49.73%\n",
      "Testing: Iteration[200/5868] Loss: 0.7143 Acc:50.10%\n",
      "Testing: Iteration[300/5868] Loss: 0.7185 Acc:50.07%\n",
      "Testing: Iteration[400/5868] Loss: 0.7220 Acc:49.89%\n",
      "Testing: Iteration[500/5868] Loss: 0.7191 Acc:49.92%\n",
      "Testing: Iteration[600/5868] Loss: 0.7181 Acc:49.90%\n",
      "Testing: Iteration[700/5868] Loss: 0.7192 Acc:49.86%\n",
      "Testing: Iteration[800/5868] Loss: 0.7220 Acc:49.78%\n",
      "Testing: Iteration[900/5868] Loss: 0.7223 Acc:49.73%\n",
      "Testing: Iteration[1000/5868] Loss: 0.7221 Acc:49.69%\n",
      "Testing: Iteration[1100/5868] Loss: 0.7187 Acc:49.71%\n",
      "Testing: Iteration[1200/5868] Loss: 0.7012 Acc:49.99%\n",
      "Testing: Iteration[1300/5868] Loss: 0.7067 Acc:50.12%\n",
      "Testing: Iteration[1400/5868] Loss: 0.7068 Acc:50.25%\n",
      "Testing: Iteration[1500/5868] Loss: 0.7152 Acc:50.27%\n",
      "Testing: Iteration[1600/5868] Loss: 0.7138 Acc:50.31%\n",
      "Testing: Iteration[1700/5868] Loss: 0.7129 Acc:50.37%\n",
      "Testing: Iteration[1800/5868] Loss: 0.7129 Acc:50.39%\n",
      "Testing: Iteration[1900/5868] Loss: 0.7120 Acc:50.44%\n",
      "Testing: Iteration[2000/5868] Loss: 0.7130 Acc:50.44%\n",
      "Testing: Iteration[2100/5868] Loss: 0.7158 Acc:50.47%\n",
      "Testing: Iteration[2200/5868] Loss: 0.7158 Acc:50.48%\n",
      "Testing: Iteration[2300/5868] Loss: 0.7133 Acc:50.52%\n",
      "Testing: Iteration[2400/5868] Loss: 0.7182 Acc:50.50%\n",
      "Testing: Iteration[2500/5868] Loss: 0.7210 Acc:50.45%\n",
      "Testing: Iteration[2600/5868] Loss: 0.7212 Acc:50.41%\n",
      "Testing: Iteration[2700/5868] Loss: 0.7244 Acc:50.35%\n",
      "Testing: Iteration[2800/5868] Loss: 0.7276 Acc:50.28%\n",
      "Testing: Iteration[2900/5868] Loss: 0.7260 Acc:50.23%\n",
      "Testing: Iteration[3000/5868] Loss: 0.7144 Acc:50.24%\n",
      "Testing: Iteration[3100/5868] Loss: 0.7036 Acc:50.32%\n",
      "Testing: Iteration[3200/5868] Loss: 0.7055 Acc:50.37%\n",
      "Testing: Iteration[3300/5868] Loss: 0.7008 Acc:50.46%\n",
      "Testing: Iteration[3400/5868] Loss: 0.7062 Acc:50.52%\n",
      "Testing: Iteration[3500/5868] Loss: 0.7108 Acc:50.54%\n",
      "Testing: Iteration[3600/5868] Loss: 0.7339 Acc:50.45%\n",
      "Testing: Iteration[3700/5868] Loss: 0.7356 Acc:50.36%\n",
      "Testing: Iteration[3800/5868] Loss: 0.7233 Acc:50.32%\n",
      "Testing: Iteration[3900/5868] Loss: 0.7136 Acc:50.34%\n",
      "Testing: Iteration[4000/5868] Loss: 0.7170 Acc:50.34%\n",
      "Testing: Iteration[4100/5868] Loss: 0.7140 Acc:50.35%\n",
      "Testing: Iteration[4200/5868] Loss: 0.7183 Acc:50.35%\n",
      "Testing: Iteration[4300/5868] Loss: 0.7231 Acc:50.32%\n",
      "Testing: Iteration[4400/5868] Loss: 0.7188 Acc:50.32%\n",
      "Testing: Iteration[4500/5868] Loss: 0.7241 Acc:50.30%\n",
      "Testing: Iteration[4600/5868] Loss: 0.7222 Acc:50.29%\n",
      "Testing: Iteration[4700/5868] Loss: 0.7199 Acc:50.29%\n",
      "Testing: Iteration[4800/5868] Loss: 0.7221 Acc:50.27%\n",
      "Testing: Iteration[4900/5868] Loss: 0.7136 Acc:50.29%\n",
      "Testing: Iteration[5000/5868] Loss: 0.7080 Acc:50.33%\n",
      "Testing: Iteration[5100/5868] Loss: 0.7123 Acc:50.36%\n",
      "Testing: Iteration[5200/5868] Loss: 0.7169 Acc:50.35%\n",
      "Testing: Iteration[5300/5868] Loss: 0.7143 Acc:50.36%\n",
      "Testing: Iteration[5400/5868] Loss: 0.7195 Acc:50.36%\n",
      "Testing: Iteration[5500/5868] Loss: 0.7248 Acc:50.33%\n",
      "Testing: Iteration[5600/5868] Loss: 0.7269 Acc:50.30%\n",
      "Testing: Iteration[5700/5868] Loss: 0.7131 Acc:50.32%\n",
      "Testing: Iteration[5800/5868] Loss: 0.7093 Acc:50.35%\n"
     ]
    }
   ],
   "source": [
    "correct_test = 0.\n",
    "total_test = 0.\n",
    "loss_test = 0.\n",
    "test_curve=[]\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for j, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "        labels = labels.squeeze(1).long()\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).squeeze().sum().cpu().numpy()\n",
    "\n",
    "        loss_mean += loss.item()\n",
    "        test_curve.append(loss.item())\n",
    "\n",
    "        if (j+1) % log_interval == 0:\n",
    "                loss_mean = loss_mean / log_interval\n",
    "                print(\"Testing: Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "                    j+1, len(testloader), loss_mean, correct_test / total_test))\n",
    "                loss_mean = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5037590130768252"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_test / total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83c520eb75281188740654a4e5112c4d206c6a318206330e6bc3601aeef39461"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('liangxin': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
