{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"project2_NN1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1hcoYk4Vg650f_oFwDF0AbfWJy8roYTvu","authorship_tag":"ABX9TyPGR+OBJ45DoWlA41x4YPxq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"aKJeTLIPwii7","executionInfo":{"status":"ok","timestamp":1636808575608,"user_tz":-480,"elapsed":477,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"id":"SB-cGFpQxp7I","executionInfo":{"status":"ok","timestamp":1636808641472,"user_tz":-480,"elapsed":65413,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}},"outputId":"7e7adf2b-2fa4-44eb-ec40-7df8018bb325"},"source":["df = pd.read_csv(\"/content/drive/My Drive/datashare/GKX_20201231.csv\")\n","df = df[df[\"DATE\"] >= 19600101].reset_index(drop = True) #选取1960年之后的数据\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>permno</th>\n","      <th>DATE</th>\n","      <th>mvel1</th>\n","      <th>RET</th>\n","      <th>prc</th>\n","      <th>SHROUT</th>\n","      <th>beta</th>\n","      <th>betasq</th>\n","      <th>chmom</th>\n","      <th>dolvol</th>\n","      <th>idiovol</th>\n","      <th>indmom</th>\n","      <th>mom1m</th>\n","      <th>mom6m</th>\n","      <th>mom12m</th>\n","      <th>mom36m</th>\n","      <th>mve0</th>\n","      <th>pricedelay</th>\n","      <th>turn</th>\n","      <th>absacc</th>\n","      <th>acc</th>\n","      <th>age</th>\n","      <th>agr</th>\n","      <th>cashdebt</th>\n","      <th>cashpr</th>\n","      <th>cfp</th>\n","      <th>cfp_ia</th>\n","      <th>chatoia</th>\n","      <th>chcsho</th>\n","      <th>chempia</th>\n","      <th>chinv</th>\n","      <th>chpmia</th>\n","      <th>convind</th>\n","      <th>currat</th>\n","      <th>depr</th>\n","      <th>divi</th>\n","      <th>divo</th>\n","      <th>dy</th>\n","      <th>egr</th>\n","      <th>ep</th>\n","      <th>...</th>\n","      <th>ps</th>\n","      <th>quick</th>\n","      <th>rd</th>\n","      <th>rd_mve</th>\n","      <th>rd_sale</th>\n","      <th>realestate</th>\n","      <th>roic</th>\n","      <th>salecash</th>\n","      <th>saleinv</th>\n","      <th>salerec</th>\n","      <th>secured</th>\n","      <th>securedind</th>\n","      <th>sgr</th>\n","      <th>sin</th>\n","      <th>sp</th>\n","      <th>tang</th>\n","      <th>tb</th>\n","      <th>aeavol</th>\n","      <th>cash</th>\n","      <th>chtx</th>\n","      <th>cinvest</th>\n","      <th>ear</th>\n","      <th>nincr</th>\n","      <th>roaq</th>\n","      <th>roavol</th>\n","      <th>roeq</th>\n","      <th>rsup</th>\n","      <th>stdacc</th>\n","      <th>stdcf</th>\n","      <th>ms</th>\n","      <th>baspread</th>\n","      <th>ill</th>\n","      <th>maxret</th>\n","      <th>retvol</th>\n","      <th>std_dolvol</th>\n","      <th>std_turn</th>\n","      <th>zerotrade</th>\n","      <th>sic2</th>\n","      <th>bm</th>\n","      <th>bm_ia</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10006</td>\n","      <td>19600129</td>\n","      <td>68773.00</td>\n","      <td>0.005155</td>\n","      <td>48.750</td>\n","      <td>1418</td>\n","      <td>1.158041</td>\n","      <td>1.341058</td>\n","      <td>-0.078184</td>\n","      <td>9.474396</td>\n","      <td>0.027283</td>\n","      <td>0.136142</td>\n","      <td>0.013055</td>\n","      <td>-0.021572</td>\n","      <td>0.046317</td>\n","      <td>-0.051308</td>\n","      <td>69127.500</td>\n","      <td>-0.015614</td>\n","      <td>0.168077</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.015272</td>\n","      <td>2.059137e-07</td>\n","      <td>0.033943</td>\n","      <td>0.015149</td>\n","      <td>0.591078</td>\n","      <td>0.533983</td>\n","      <td>9.859742e-08</td>\n","      <td>37.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10014</td>\n","      <td>19600129</td>\n","      <td>9823.50</td>\n","      <td>0.138889</td>\n","      <td>5.125</td>\n","      <td>2183</td>\n","      <td>1.838109</td>\n","      <td>3.378645</td>\n","      <td>-0.506541</td>\n","      <td>7.946573</td>\n","      <td>0.067400</td>\n","      <td>0.136142</td>\n","      <td>-0.027027</td>\n","      <td>-0.139535</td>\n","      <td>0.156250</td>\n","      <td>0.523810</td>\n","      <td>11187.875</td>\n","      <td>0.271738</td>\n","      <td>0.210261</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.035918</td>\n","      <td>1.906160e-06</td>\n","      <td>0.028571</td>\n","      <td>0.021261</td>\n","      <td>0.491650</td>\n","      <td>0.481666</td>\n","      <td>8.535634e-08</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10022</td>\n","      <td>19600129</td>\n","      <td>21133.75</td>\n","      <td>-0.045455</td>\n","      <td>13.125</td>\n","      <td>1537</td>\n","      <td>1.157077</td>\n","      <td>1.338827</td>\n","      <td>-0.374534</td>\n","      <td>8.507143</td>\n","      <td>0.043777</td>\n","      <td>0.136142</td>\n","      <td>0.009091</td>\n","      <td>-0.007626</td>\n","      <td>0.365436</td>\n","      <td>0.876728</td>\n","      <td>20173.125</td>\n","      <td>-0.029163</td>\n","      <td>0.276296</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.022607</td>\n","      <td>6.754297e-07</td>\n","      <td>0.040000</td>\n","      <td>0.026199</td>\n","      <td>0.877110</td>\n","      <td>1.639491</td>\n","      <td>5.271194e-08</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10030</td>\n","      <td>19600129</td>\n","      <td>81200.00</td>\n","      <td>-0.015000</td>\n","      <td>49.250</td>\n","      <td>1624</td>\n","      <td>1.327625</td>\n","      <td>1.762587</td>\n","      <td>-0.186923</td>\n","      <td>9.550378</td>\n","      <td>0.024872</td>\n","      <td>0.136142</td>\n","      <td>0.012000</td>\n","      <td>-0.024721</td>\n","      <td>0.144885</td>\n","      <td>0.142554</td>\n","      <td>79982.000</td>\n","      <td>0.029423</td>\n","      <td>0.189860</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.014960</td>\n","      <td>4.355397e-07</td>\n","      <td>0.038462</td>\n","      <td>0.020206</td>\n","      <td>0.936132</td>\n","      <td>0.771756</td>\n","      <td>1.102852e-07</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10057</td>\n","      <td>19600129</td>\n","      <td>27062.50</td>\n","      <td>-0.020785</td>\n","      <td>53.000</td>\n","      <td>500</td>\n","      <td>1.194604</td>\n","      <td>1.427080</td>\n","      <td>-0.293635</td>\n","      <td>8.138565</td>\n","      <td>0.030824</td>\n","      <td>0.136142</td>\n","      <td>0.021028</td>\n","      <td>-0.111214</td>\n","      <td>0.067530</td>\n","      <td>-0.270734</td>\n","      <td>26500.000</td>\n","      <td>-0.065354</td>\n","      <td>0.103333</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.002941</td>\n","      <td>3.479863e-07</td>\n","      <td>0.018692</td>\n","      <td>0.006685</td>\n","      <td>0.451979</td>\n","      <td>0.190010</td>\n","      <td>9.545457e-01</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 101 columns</p>\n","</div>"],"text/plain":["   permno      DATE     mvel1       RET  ...     zerotrade  sic2  bm  bm_ia\n","0   10006  19600129  68773.00  0.005155  ...  9.859742e-08  37.0 NaN    NaN\n","1   10014  19600129   9823.50  0.138889  ...  8.535634e-08   NaN NaN    NaN\n","2   10022  19600129  21133.75 -0.045455  ...  5.271194e-08   NaN NaN    NaN\n","3   10030  19600129  81200.00 -0.015000  ...  1.102852e-07   NaN NaN    NaN\n","4   10057  19600129  27062.50 -0.020785  ...  9.545457e-01   NaN NaN    NaN\n","\n","[5 rows x 101 columns]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"0IIGREOwKx8k","executionInfo":{"status":"ok","timestamp":1636808641472,"user_tz":-480,"elapsed":13,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["#Handle NA\n","def handling_na(df):\n","  for column in df.columns:\n","    if df[column].isnull().sum() == 0:\n","      continue\n","    #缺失值多于50%，直接drop该列\n","    elif (df[column].isnull().sum()/len(df[column])) > 0.5:\n","      df.drop(column, axis = 1, inplace = True)\n","    #缺失值少于50%，填充平均值 \n","    else:\n","      df[column].fillna(df[column].mean(), inplace = True)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"KpbKomATy5Yj","executionInfo":{"status":"ok","timestamp":1636808641472,"user_tz":-480,"elapsed":13,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["#输入测试集年份，自动准备数据\n","def cleaning_data(year_of_test):\n","  end_of_test = (year_of_test+1)*10000\n","  end_of_validation = year_of_test*10000\n","  start_of_validation = (year_of_test-12)*10000\n","\n","  alldata = df[df[\"DATE\"] < end_of_test]\n","\n","  #handling na\n","  handling_na(alldata)\n","\n","  #划分train/validation/test\n","  train = alldata[alldata[\"DATE\"] < start_of_validation]\n","  valid = alldata[(alldata[\"DATE\"] > start_of_validation)&(alldata[\"DATE\"] < end_of_validation)]\n","  test = alldata[(alldata[\"DATE\"] > end_of_validation)&(alldata[\"DATE\"] < end_of_test)]\n","\n","  #x,y\n","  x_train = train.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  x_valid = valid.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  x_test = test.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  \n","  y_train = np.array(train['RET']).reshape(-1,1)\n","  y_valid = np.array(valid['RET']).reshape(-1,1)\n","  y_test = np.array(test['RET']).reshape(-1,1)\n","\n","\n","  #StandardScale\n","  scaler = StandardScaler()\n","  x_train = scaler.fit_transform(x_train)\n","  x_valid = scaler.transform(x_valid)\n","  x_test = scaler.transform(x_test)\n","\n","  return x_train, x_valid, x_test, y_train, y_valid, y_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBVxt6BWl9DB","executionInfo":{"status":"ok","timestamp":1636808641473,"user_tz":-480,"elapsed":4,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["#定义计算out of sample R square函数\n","def R_square(ypred,ytrue): \n","  dif2=np.sum(np.power(ytrue-ypred,2))\n","  return 1-(dif2/np.sum(np.power(ytrue,2)))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKu2-x65IALX","executionInfo":{"status":"ok","timestamp":1636808641473,"user_tz":-480,"elapsed":3,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["#自定义定义损失函数\n","def R_loss(y_true, y_pred):\n","  return tf.reduce_mean(tf.square(y_true-y_pred))/tf.reduce_mean(tf.square(y_true))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6YvawJjbYcF","executionInfo":{"status":"ok","timestamp":1636808647092,"user_tz":-480,"elapsed":5622,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["import tensorflow as tf\n","from tensorflow import keras"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gGTCpfdYAA6_","executionInfo":{"status":"error","timestamp":1636812146733,"user_tz":-480,"elapsed":3499650,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}},"outputId":"f997fb26-25b7-4089-faa0-3979156aca02"},"source":["rsquare_oos_valid = []\n","rsquare_oos_test = []\n","\n","#NN model\n","for year in range(1990,2021):\n","  print(\"start training the data from 1960 to \"+str(year))\n","  x_train, x_valid, x_test, y_train, y_valid, y_test = cleaning_data(year)\n","\n","  model = keras.models.Sequential()\n","  model.add(keras.layers.Dense(32, activation='relu', input_shape=x_train.shape[1:]))\n","  model.add(keras.layers.Dense(1))\n","\n","  sgd = keras.optimizers.SGD(learning_rate = 0.0002, clipnorm = 0.5)\n","\n","  model.summary()\n","  model.compile(loss = R_loss, optimizer= sgd)\n","  \n","  EarlyStop = keras.callbacks.EarlyStopping(\n","      monitor='val_loss',\n","      patience=5,\n","      verbose=1,\n","      min_delta=0.001, \n","      mode='min')\n","  \n","  Reduce = keras.callbacks.ReduceLROnPlateau(\n","      monitor='val_loss',\n","      factor=0.2,\n","      patience=3,\n","      verbose=1,\n","      mode='min',\n","      min_delta=0.001,\n","      cooldown=0,\n","      min_lr=0)\n","\n","  model.fit(\n","      x_train,\n","      y_train,\n","      validation_data = (x_valid, y_valid),\n","      epochs = 100,\n","      callbacks = [Reduce,EarlyStop])\n","  \n","  model.save('/content/drive/My Drive/NN_models/NN1_'+str(year)+'.h5')\n","\n","  rsquare_oos_valid.append(R_square(model.predict(x_valid),y_valid))\n","  print(rsquare_oos_valid)\n","  rsquare_oos_test.append(R_square(model.predict(x_test),y_test))\n","  print(rsquare_oos_test)\n","\n","  del model"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["start training the data from 1960 to 1990\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 32)                2560      \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,593\n","Trainable params: 2,593\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","19317/19317 [==============================] - 81s 4ms/step - loss: 22.2655 - val_loss: 52.2581 - lr: 2.0000e-04\n","Epoch 2/100\n","19317/19317 [==============================] - 68s 4ms/step - loss: 3.2682 - val_loss: 16.9177 - lr: 2.0000e-04\n","Epoch 3/100\n","19317/19317 [==============================] - 68s 4ms/step - loss: 1.2923 - val_loss: 3.6880 - lr: 2.0000e-04\n","Epoch 4/100\n","19317/19317 [==============================] - 68s 3ms/step - loss: 1.0217 - val_loss: 1.4759 - lr: 2.0000e-04\n","Epoch 5/100\n","19317/19317 [==============================] - 67s 3ms/step - loss: 0.9976 - val_loss: 1.1208 - lr: 2.0000e-04\n","Epoch 6/100\n","19317/19317 [==============================] - 68s 4ms/step - loss: 0.9939 - val_loss: 1.1033 - lr: 2.0000e-04\n","Epoch 7/100\n","19317/19317 [==============================] - 68s 3ms/step - loss: 0.9930 - val_loss: 1.1155 - lr: 2.0000e-04\n","Epoch 8/100\n","19317/19317 [==============================] - 68s 4ms/step - loss: 0.9917 - val_loss: 1.1100 - lr: 2.0000e-04\n","Epoch 9/100\n","19307/19317 [============================>.] - ETA: 0s - loss: 0.9911\n","Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","19317/19317 [==============================] - 67s 3ms/step - loss: 0.9910 - val_loss: 1.1202 - lr: 2.0000e-04\n","Epoch 10/100\n","19317/19317 [==============================] - 67s 3ms/step - loss: 0.9903 - val_loss: 1.1146 - lr: 4.0000e-05\n","Epoch 11/100\n","19317/19317 [==============================] - 68s 4ms/step - loss: 0.9905 - val_loss: 1.1165 - lr: 4.0000e-05\n","Epoch 00011: early stopping\n","[-0.07870800164492353]\n","[-0.09040272457698317]\n","start training the data from 1960 to 1991\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_2 (Dense)             (None, 32)                2560      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,593\n","Trainable params: 2,593\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","21136/21136 [==============================] - 73s 3ms/step - loss: 19.7842 - val_loss: 21.4527 - lr: 2.0000e-04\n","Epoch 2/100\n","21136/21136 [==============================] - 72s 3ms/step - loss: 2.2306 - val_loss: 2.2757 - lr: 2.0000e-04\n","Epoch 3/100\n","21136/21136 [==============================] - 72s 3ms/step - loss: 1.0684 - val_loss: 1.1071 - lr: 2.0000e-04\n","Epoch 4/100\n","21136/21136 [==============================] - 72s 3ms/step - loss: 1.0022 - val_loss: 1.0347 - lr: 2.0000e-04\n","Epoch 5/100\n","21136/21136 [==============================] - 73s 3ms/step - loss: 0.9973 - val_loss: 1.0249 - lr: 2.0000e-04\n","Epoch 6/100\n","21136/21136 [==============================] - 72s 3ms/step - loss: 0.9961 - val_loss: 1.0271 - lr: 2.0000e-04\n","Epoch 7/100\n","21136/21136 [==============================] - 72s 3ms/step - loss: 0.9959 - val_loss: 1.0356 - lr: 2.0000e-04\n","Epoch 8/100\n","21122/21136 [============================>.] - ETA: 0s - loss: 0.9949\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","21136/21136 [==============================] - 72s 3ms/step - loss: 0.9949 - val_loss: 1.0339 - lr: 2.0000e-04\n","Epoch 9/100\n","21136/21136 [==============================] - 73s 3ms/step - loss: 0.9937 - val_loss: 1.0338 - lr: 4.0000e-05\n","Epoch 10/100\n","21136/21136 [==============================] - 72s 3ms/step - loss: 0.9940 - val_loss: 1.0371 - lr: 4.0000e-05\n","Epoch 00010: early stopping\n","[-0.07870800164492353, -0.02447493368585918]\n","[-0.09040272457698317, -0.05027480792466843]\n","start training the data from 1960 to 1992\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_4 (Dense)             (None, 32)                2592      \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,625\n","Trainable params: 2,625\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","22939/22939 [==============================] - 78s 3ms/step - loss: 22.7121 - val_loss: 23.0023 - lr: 2.0000e-04\n","Epoch 2/100\n","22939/22939 [==============================] - 77s 3ms/step - loss: 2.4440 - val_loss: 2.6231 - lr: 2.0000e-04\n","Epoch 3/100\n","22939/22939 [==============================] - 77s 3ms/step - loss: 1.0797 - val_loss: 1.0912 - lr: 2.0000e-04\n","Epoch 4/100\n","22939/22939 [==============================] - 77s 3ms/step - loss: 1.0000 - val_loss: 1.0278 - lr: 2.0000e-04\n","Epoch 5/100\n","22939/22939 [==============================] - 77s 3ms/step - loss: 0.9962 - val_loss: 1.0247 - lr: 2.0000e-04\n","Epoch 6/100\n","22939/22939 [==============================] - 77s 3ms/step - loss: 0.9951 - val_loss: 1.0272 - lr: 2.0000e-04\n","Epoch 7/100\n","22939/22939 [==============================] - 77s 3ms/step - loss: 0.9945 - val_loss: 1.0402 - lr: 2.0000e-04\n","Epoch 8/100\n","22918/22939 [============================>.] - ETA: 0s - loss: 0.9940\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","22939/22939 [==============================] - 76s 3ms/step - loss: 0.9940 - val_loss: 1.0471 - lr: 2.0000e-04\n","Epoch 9/100\n","22939/22939 [==============================] - 76s 3ms/step - loss: 0.9931 - val_loss: 1.0441 - lr: 4.0000e-05\n","Epoch 10/100\n","22939/22939 [==============================] - 76s 3ms/step - loss: 0.9935 - val_loss: 1.0475 - lr: 4.0000e-05\n","Epoch 00010: early stopping\n","[-0.07870800164492353, -0.02447493368585918, -0.03103764685672683]\n","[-0.09040272457698317, -0.05027480792466843, -0.07407414883087982]\n","start training the data from 1960 to 1993\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 32)                2592      \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,625\n","Trainable params: 2,625\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","24756/24756 [==============================] - 82s 3ms/step - loss: 12.1185 - val_loss: 10.3192 - lr: 2.0000e-04\n","Epoch 2/100\n","24756/24756 [==============================] - 81s 3ms/step - loss: 1.3905 - val_loss: 1.6418 - lr: 2.0000e-04\n","Epoch 3/100\n","24756/24756 [==============================] - 80s 3ms/step - loss: 1.0111 - val_loss: 1.0744 - lr: 2.0000e-04\n","Epoch 4/100\n","24756/24756 [==============================] - 81s 3ms/step - loss: 0.9935 - val_loss: 1.0736 - lr: 2.0000e-04\n","Epoch 5/100\n","24756/24756 [==============================] - 80s 3ms/step - loss: 0.9921 - val_loss: 1.0579 - lr: 2.0000e-04\n","Epoch 6/100\n","24756/24756 [==============================] - 81s 3ms/step - loss: 0.9909 - val_loss: 1.0781 - lr: 2.0000e-04\n","Epoch 7/100\n","24756/24756 [==============================] - 80s 3ms/step - loss: 0.9904 - val_loss: 1.0878 - lr: 2.0000e-04\n","Epoch 8/100\n","24754/24756 [============================>.] - ETA: 0s - loss: 0.9892\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","24756/24756 [==============================] - 81s 3ms/step - loss: 0.9892 - val_loss: 1.0905 - lr: 2.0000e-04\n","Epoch 9/100\n","24756/24756 [==============================] - 80s 3ms/step - loss: 0.9880 - val_loss: 1.1046 - lr: 4.0000e-05\n","Epoch 10/100\n","24756/24756 [==============================] - 80s 3ms/step - loss: 0.9882 - val_loss: 1.1115 - lr: 4.0000e-05\n","Epoch 00010: early stopping\n","[-0.07870800164492353, -0.02447493368585918, -0.03103764685672683, -0.057067023928255134]\n","[-0.09040272457698317, -0.05027480792466843, -0.07407414883087982, -0.26369377076850253]\n","start training the data from 1960 to 1994\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 32)                2560      \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,593\n","Trainable params: 2,593\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","26695/26695 [==============================] - 86s 3ms/step - loss: 17.6926 - val_loss: 84.3661 - lr: 2.0000e-04\n","Epoch 2/100\n","26695/26695 [==============================] - 84s 3ms/step - loss: 1.6818 - val_loss: 4.8746 - lr: 2.0000e-04\n","Epoch 3/100\n","26695/26695 [==============================] - 84s 3ms/step - loss: 1.0252 - val_loss: 1.3285 - lr: 2.0000e-04\n","Epoch 4/100\n","13685/26695 [==============>...............] - ETA: 24s - loss: 0.9970"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-42b08b7666b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       callbacks = [Reduce,EarlyStop])\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/NN_models/NN1_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}