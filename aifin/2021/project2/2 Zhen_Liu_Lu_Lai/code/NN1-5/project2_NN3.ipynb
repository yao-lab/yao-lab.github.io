{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project2_NN3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1Fh6cYarZWZfEn_cELpD-Vdq6yGRoo65O","authorship_tag":"ABX9TyO2lDPx006A3n/UhNYgA3xx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"UY9TrfhGiKZS","executionInfo":{"status":"ok","timestamp":1636875156545,"user_tz":-480,"elapsed":726,"user":{"displayName":"Lai Cong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13592941909926457419"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"id":"0aPto3QCiO7S","executionInfo":{"status":"ok","timestamp":1636875239678,"user_tz":-480,"elapsed":82540,"user":{"displayName":"Lai Cong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13592941909926457419"}},"outputId":"df616614-a9b7-45eb-c4ff-848ba71dd27e"},"source":["df = pd.read_csv(\"/content/drive/My Drive/datashare/GKX_20201231.csv\")\n","df = df[df[\"DATE\"] >= 19600101].reset_index(drop = True) #选取1960年之后的数据\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>permno</th>\n","      <th>DATE</th>\n","      <th>mvel1</th>\n","      <th>RET</th>\n","      <th>prc</th>\n","      <th>SHROUT</th>\n","      <th>beta</th>\n","      <th>betasq</th>\n","      <th>chmom</th>\n","      <th>dolvol</th>\n","      <th>idiovol</th>\n","      <th>indmom</th>\n","      <th>mom1m</th>\n","      <th>mom6m</th>\n","      <th>mom12m</th>\n","      <th>mom36m</th>\n","      <th>mve0</th>\n","      <th>pricedelay</th>\n","      <th>turn</th>\n","      <th>absacc</th>\n","      <th>acc</th>\n","      <th>age</th>\n","      <th>agr</th>\n","      <th>cashdebt</th>\n","      <th>cashpr</th>\n","      <th>cfp</th>\n","      <th>cfp_ia</th>\n","      <th>chatoia</th>\n","      <th>chcsho</th>\n","      <th>chempia</th>\n","      <th>chinv</th>\n","      <th>chpmia</th>\n","      <th>convind</th>\n","      <th>currat</th>\n","      <th>depr</th>\n","      <th>divi</th>\n","      <th>divo</th>\n","      <th>dy</th>\n","      <th>egr</th>\n","      <th>ep</th>\n","      <th>...</th>\n","      <th>ps</th>\n","      <th>quick</th>\n","      <th>rd</th>\n","      <th>rd_mve</th>\n","      <th>rd_sale</th>\n","      <th>realestate</th>\n","      <th>roic</th>\n","      <th>salecash</th>\n","      <th>saleinv</th>\n","      <th>salerec</th>\n","      <th>secured</th>\n","      <th>securedind</th>\n","      <th>sgr</th>\n","      <th>sin</th>\n","      <th>sp</th>\n","      <th>tang</th>\n","      <th>tb</th>\n","      <th>aeavol</th>\n","      <th>cash</th>\n","      <th>chtx</th>\n","      <th>cinvest</th>\n","      <th>ear</th>\n","      <th>nincr</th>\n","      <th>roaq</th>\n","      <th>roavol</th>\n","      <th>roeq</th>\n","      <th>rsup</th>\n","      <th>stdacc</th>\n","      <th>stdcf</th>\n","      <th>ms</th>\n","      <th>baspread</th>\n","      <th>ill</th>\n","      <th>maxret</th>\n","      <th>retvol</th>\n","      <th>std_dolvol</th>\n","      <th>std_turn</th>\n","      <th>zerotrade</th>\n","      <th>sic2</th>\n","      <th>bm</th>\n","      <th>bm_ia</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10006</td>\n","      <td>19600129</td>\n","      <td>68773.00</td>\n","      <td>0.005155</td>\n","      <td>48.750</td>\n","      <td>1418</td>\n","      <td>1.158041</td>\n","      <td>1.341058</td>\n","      <td>-0.078184</td>\n","      <td>9.474396</td>\n","      <td>0.027283</td>\n","      <td>0.136142</td>\n","      <td>0.013055</td>\n","      <td>-0.021572</td>\n","      <td>0.046317</td>\n","      <td>-0.051308</td>\n","      <td>69127.500</td>\n","      <td>-0.015614</td>\n","      <td>0.168077</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.015272</td>\n","      <td>2.059137e-07</td>\n","      <td>0.033943</td>\n","      <td>0.015149</td>\n","      <td>0.591078</td>\n","      <td>0.533983</td>\n","      <td>9.859742e-08</td>\n","      <td>37.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10014</td>\n","      <td>19600129</td>\n","      <td>9823.50</td>\n","      <td>0.138889</td>\n","      <td>5.125</td>\n","      <td>2183</td>\n","      <td>1.838109</td>\n","      <td>3.378645</td>\n","      <td>-0.506541</td>\n","      <td>7.946573</td>\n","      <td>0.067400</td>\n","      <td>0.136142</td>\n","      <td>-0.027027</td>\n","      <td>-0.139535</td>\n","      <td>0.156250</td>\n","      <td>0.523810</td>\n","      <td>11187.875</td>\n","      <td>0.271738</td>\n","      <td>0.210261</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.035918</td>\n","      <td>1.906160e-06</td>\n","      <td>0.028571</td>\n","      <td>0.021261</td>\n","      <td>0.491650</td>\n","      <td>0.481666</td>\n","      <td>8.535634e-08</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10022</td>\n","      <td>19600129</td>\n","      <td>21133.75</td>\n","      <td>-0.045455</td>\n","      <td>13.125</td>\n","      <td>1537</td>\n","      <td>1.157077</td>\n","      <td>1.338827</td>\n","      <td>-0.374534</td>\n","      <td>8.507143</td>\n","      <td>0.043777</td>\n","      <td>0.136142</td>\n","      <td>0.009091</td>\n","      <td>-0.007626</td>\n","      <td>0.365436</td>\n","      <td>0.876728</td>\n","      <td>20173.125</td>\n","      <td>-0.029163</td>\n","      <td>0.276296</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.022607</td>\n","      <td>6.754297e-07</td>\n","      <td>0.040000</td>\n","      <td>0.026199</td>\n","      <td>0.877110</td>\n","      <td>1.639491</td>\n","      <td>5.271194e-08</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10030</td>\n","      <td>19600129</td>\n","      <td>81200.00</td>\n","      <td>-0.015000</td>\n","      <td>49.250</td>\n","      <td>1624</td>\n","      <td>1.327625</td>\n","      <td>1.762587</td>\n","      <td>-0.186923</td>\n","      <td>9.550378</td>\n","      <td>0.024872</td>\n","      <td>0.136142</td>\n","      <td>0.012000</td>\n","      <td>-0.024721</td>\n","      <td>0.144885</td>\n","      <td>0.142554</td>\n","      <td>79982.000</td>\n","      <td>0.029423</td>\n","      <td>0.189860</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.014960</td>\n","      <td>4.355397e-07</td>\n","      <td>0.038462</td>\n","      <td>0.020206</td>\n","      <td>0.936132</td>\n","      <td>0.771756</td>\n","      <td>1.102852e-07</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10057</td>\n","      <td>19600129</td>\n","      <td>27062.50</td>\n","      <td>-0.020785</td>\n","      <td>53.000</td>\n","      <td>500</td>\n","      <td>1.194604</td>\n","      <td>1.427080</td>\n","      <td>-0.293635</td>\n","      <td>8.138565</td>\n","      <td>0.030824</td>\n","      <td>0.136142</td>\n","      <td>0.021028</td>\n","      <td>-0.111214</td>\n","      <td>0.067530</td>\n","      <td>-0.270734</td>\n","      <td>26500.000</td>\n","      <td>-0.065354</td>\n","      <td>0.103333</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.002941</td>\n","      <td>3.479863e-07</td>\n","      <td>0.018692</td>\n","      <td>0.006685</td>\n","      <td>0.451979</td>\n","      <td>0.190010</td>\n","      <td>9.545457e-01</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 101 columns</p>\n","</div>"],"text/plain":["   permno      DATE     mvel1       RET  ...     zerotrade  sic2  bm  bm_ia\n","0   10006  19600129  68773.00  0.005155  ...  9.859742e-08  37.0 NaN    NaN\n","1   10014  19600129   9823.50  0.138889  ...  8.535634e-08   NaN NaN    NaN\n","2   10022  19600129  21133.75 -0.045455  ...  5.271194e-08   NaN NaN    NaN\n","3   10030  19600129  81200.00 -0.015000  ...  1.102852e-07   NaN NaN    NaN\n","4   10057  19600129  27062.50 -0.020785  ...  9.545457e-01   NaN NaN    NaN\n","\n","[5 rows x 101 columns]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"NsHLsAxMiPw6","executionInfo":{"status":"ok","timestamp":1636875239679,"user_tz":-480,"elapsed":5,"user":{"displayName":"Lai Cong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13592941909926457419"}}},"source":["#Handle NA\n","def handling_na(df):\n","  for column in df.columns:\n","    if df[column].isnull().sum() == 0:\n","      continue\n","    #缺失值多于50%，直接drop该列\n","    elif (df[column].isnull().sum()/len(df[column])) > 0.5:\n","      df.drop(column, axis = 1, inplace = True)\n","    #缺失值少于50%，填充平均值 \n","    else:\n","      df[column].fillna(df[column].mean(), inplace = True)\n","\n","#输入测试集年份，自动准备数据\n","def cleaning_data(year_of_test):\n","  end_of_test = (year_of_test+1)*10000\n","  end_of_validation = year_of_test*10000\n","  start_of_validation = (year_of_test-12)*10000\n","\n","  alldata = df[df[\"DATE\"] < end_of_test]\n","\n","  #handling na\n","  handling_na(alldata)\n","\n","  #划分train/validation/test\n","  train = alldata[alldata[\"DATE\"] < start_of_validation]\n","  valid = alldata[(alldata[\"DATE\"] > start_of_validation)&(alldata[\"DATE\"] < end_of_validation)]\n","  test = alldata[(alldata[\"DATE\"] > end_of_validation)&(alldata[\"DATE\"] < end_of_test)]\n","\n","  #x,y\n","  x_train = train.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  x_valid = valid.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  x_test = test.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  \n","  y_train = np.array(train['RET']).reshape(-1,1)\n","  y_valid = np.array(valid['RET']).reshape(-1,1)\n","  y_test = np.array(test['RET']).reshape(-1,1)\n","\n","\n","  #StandardScale\n","  scaler = StandardScaler()\n","  x_train = scaler.fit_transform(x_train)\n","  x_valid = scaler.transform(x_valid)\n","  x_test = scaler.transform(x_test)\n","\n","  return x_train, x_valid, x_test, y_train, y_valid, y_test\n","\n","\n","#定义计算out of sample R square函数\n","def R_square(ypred,ytrue): \n","  dif2=np.sum(np.power(ytrue-ypred,2))\n","  return 1-(dif2/np.sum(np.power(ytrue,2)))\n","\n","\n","#自定义定义损失函数\n","def R_loss(y_true, y_pred):\n","  return tf.reduce_mean(tf.square(y_true-y_pred))/tf.reduce_mean(tf.square(y_true))\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4xH8GTmis4L","executionInfo":{"status":"ok","timestamp":1636875242315,"user_tz":-480,"elapsed":2640,"user":{"displayName":"Lai Cong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13592941909926457419"}}},"source":["import tensorflow as tf\n","from tensorflow import keras"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Isi-0PAdkZ6e","outputId":"ca66f2ad-0726-4303-957b-fad80437f4f1"},"source":["rsquare_oos_valid = []\n","rsquare_oos_test = []\n","\n","#NN3\n","for year in range(2004,2021):\n","  print(\"start training the data from 1960 to \"+str(year))\n","  x_train, x_valid, x_test, y_train, y_valid, y_test = cleaning_data(year)\n","\n","  model = keras.models.Sequential()\n","  model.add(keras.layers.Dense(32, activation='relu', input_shape=x_train.shape[1:]))\n","  model.add(keras.layers.Dense(16, activation='relu'))\n","  model.add(keras.layers.Dense(8, activation='relu'))\n","  model.add(keras.layers.Dense(1))\n","\n","  sgd = keras.optimizers.SGD(learning_rate = 0.0002, clipnorm = 0.5)\n","\n","  model.summary()\n","  model.compile(loss = R_loss, optimizer= sgd)\n","  \n","  EarlyStop = keras.callbacks.EarlyStopping(\n","      monitor='val_loss',\n","      patience=5,\n","      verbose=1,\n","      min_delta=0.001, \n","      mode='min')\n","  \n","  Reduce = keras.callbacks.ReduceLROnPlateau(\n","      monitor='val_loss',\n","      factor=0.2,\n","      patience=3,\n","      verbose=1,\n","      mode='min',\n","      min_delta=0.001,\n","      cooldown=0,\n","      min_lr=0)\n","\n","  model.fit(\n","      x_train,\n","      y_train,\n","      validation_data = (x_valid, y_valid),\n","      epochs = 100,\n","      callbacks = [Reduce,EarlyStop])\n","  \n","  model.save('/content/drive/My Drive/NN_models/NN3_'+str(year)+'.h5')\n","\n","  rsquare_oos_valid.append(R_square(model.predict(x_valid),y_valid))\n","  print(rsquare_oos_valid)\n","  rsquare_oos_test.append(R_square(model.predict(x_test),y_test))\n","  print(rsquare_oos_test)\n","\n","  del model\n","  del x_train, x_valid, x_test, y_train, y_valid, y_test"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["start training the data from 1960 to 2004\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 32)                2848      \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_2 (Dense)             (None, 8)                 136       \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,521\n","Trainable params: 3,521\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","50830/50830 [==============================] - 114s 2ms/step - loss: 1.5504 - val_loss: 1.0144 - lr: 2.0000e-04\n","Epoch 2/100\n","50830/50830 [==============================] - 112s 2ms/step - loss: 1.0039 - val_loss: 1.0039 - lr: 2.0000e-04\n","Epoch 3/100\n","50830/50830 [==============================] - 112s 2ms/step - loss: 0.9998 - val_loss: 1.0014 - lr: 2.0000e-04\n","Epoch 4/100\n","50830/50830 [==============================] - 112s 2ms/step - loss: 1.0006 - val_loss: 0.9994 - lr: 2.0000e-04\n","Epoch 5/100\n","50830/50830 [==============================] - 120s 2ms/step - loss: 1.0000 - val_loss: 0.9983 - lr: 2.0000e-04\n","Epoch 6/100\n","50830/50830 [==============================] - 121s 2ms/step - loss: 0.9987 - val_loss: 0.9977 - lr: 2.0000e-04\n","Epoch 7/100\n","50830/50830 [==============================] - 119s 2ms/step - loss: 0.9978 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 8/100\n","50830/50830 [==============================] - ETA: 0s - loss: 0.9980\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","50830/50830 [==============================] - 112s 2ms/step - loss: 0.9980 - val_loss: 0.9986 - lr: 2.0000e-04\n","Epoch 9/100\n","50830/50830 [==============================] - 112s 2ms/step - loss: 0.9976 - val_loss: 0.9973 - lr: 4.0000e-05\n","Epoch 10/100\n","50830/50830 [==============================] - 111s 2ms/step - loss: 0.9973 - val_loss: 0.9973 - lr: 4.0000e-05\n","Epoch 00010: early stopping\n","[-0.00022459280232189904]\n","[-0.0018143749979813162]\n","start training the data from 1960 to 2005\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_4 (Dense)             (None, 32)                2848      \n","                                                                 \n"," dense_5 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_6 (Dense)             (None, 8)                 136       \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,521\n","Trainable params: 3,521\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","53394/53394 [==============================] - 118s 2ms/step - loss: 1.2308 - val_loss: 1.0157 - lr: 2.0000e-04\n","Epoch 2/100\n","53394/53394 [==============================] - 116s 2ms/step - loss: 1.0074 - val_loss: 1.0041 - lr: 2.0000e-04\n","Epoch 3/100\n","53394/53394 [==============================] - 117s 2ms/step - loss: 1.0014 - val_loss: 1.0015 - lr: 2.0000e-04\n","Epoch 4/100\n","53394/53394 [==============================] - 116s 2ms/step - loss: 0.9991 - val_loss: 1.0003 - lr: 2.0000e-04\n","Epoch 5/100\n","53394/53394 [==============================] - 115s 2ms/step - loss: 0.9980 - val_loss: 0.9993 - lr: 2.0000e-04\n","Epoch 6/100\n","53394/53394 [==============================] - 116s 2ms/step - loss: 0.9977 - val_loss: 0.9978 - lr: 2.0000e-04\n","Epoch 7/100\n","53394/53394 [==============================] - 115s 2ms/step - loss: 0.9975 - val_loss: 0.9979 - lr: 2.0000e-04\n","Epoch 8/100\n","53394/53394 [==============================] - 123s 2ms/step - loss: 0.9973 - val_loss: 0.9977 - lr: 2.0000e-04\n","Epoch 9/100\n","53383/53394 [============================>.] - ETA: 0s - loss: 0.9971\n","Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","53394/53394 [==============================] - 124s 2ms/step - loss: 0.9971 - val_loss: 0.9997 - lr: 2.0000e-04\n","Epoch 10/100\n","53394/53394 [==============================] - 116s 2ms/step - loss: 0.9972 - val_loss: 0.9959 - lr: 4.0000e-05\n","Epoch 11/100\n","53394/53394 [==============================] - 118s 2ms/step - loss: 0.9972 - val_loss: 0.9962 - lr: 4.0000e-05\n","Epoch 12/100\n","53394/53394 [==============================] - 116s 2ms/step - loss: 0.9971 - val_loss: 0.9959 - lr: 4.0000e-05\n","Epoch 13/100\n","53394/53394 [==============================] - ETA: 0s - loss: 0.9968\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n","53394/53394 [==============================] - 116s 2ms/step - loss: 0.9968 - val_loss: 0.9962 - lr: 4.0000e-05\n","Epoch 14/100\n","53394/53394 [==============================] - 117s 2ms/step - loss: 0.9971 - val_loss: 0.9957 - lr: 8.0000e-06\n","Epoch 15/100\n","53394/53394 [==============================] - 117s 2ms/step - loss: 0.9967 - val_loss: 0.9957 - lr: 8.0000e-06\n","Epoch 00015: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582]\n","[-0.0018143749979813162, -0.0017895914367884735]\n","start training the data from 1960 to 2006\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 32)                2912      \n","                                                                 \n"," dense_9 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_10 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_11 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,585\n","Trainable params: 3,585\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","56108/56108 [==============================] - 122s 2ms/step - loss: 1.1331 - val_loss: 1.0028 - lr: 2.0000e-04\n","Epoch 2/100\n","56108/56108 [==============================] - 119s 2ms/step - loss: 0.9993 - val_loss: 0.9999 - lr: 2.0000e-04\n","Epoch 3/100\n","56108/56108 [==============================] - 121s 2ms/step - loss: 0.9990 - val_loss: 0.9998 - lr: 2.0000e-04\n","Epoch 4/100\n","56108/56108 [==============================] - 120s 2ms/step - loss: 0.9986 - val_loss: 1.0008 - lr: 2.0000e-04\n","Epoch 5/100\n","56089/56108 [============================>.] - ETA: 0s - loss: 0.9982\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","56108/56108 [==============================] - 120s 2ms/step - loss: 0.9982 - val_loss: 1.0020 - lr: 2.0000e-04\n","Epoch 6/100\n","56108/56108 [==============================] - 120s 2ms/step - loss: 0.9977 - val_loss: 1.0035 - lr: 4.0000e-05\n","Epoch 7/100\n","56108/56108 [==============================] - 127s 2ms/step - loss: 0.9977 - val_loss: 1.0019 - lr: 4.0000e-05\n","Epoch 00007: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054]\n","start training the data from 1960 to 2007\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_12 (Dense)            (None, 32)                2912      \n","                                                                 \n"," dense_13 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_14 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_15 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,585\n","Trainable params: 3,585\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","59108/59108 [==============================] - 126s 2ms/step - loss: 1.0546 - val_loss: 1.0051 - lr: 2.0000e-04\n","Epoch 2/100\n","59108/59108 [==============================] - 125s 2ms/step - loss: 1.0000 - val_loss: 1.0059 - lr: 2.0000e-04\n","Epoch 3/100\n","59108/59108 [==============================] - 125s 2ms/step - loss: 0.9994 - val_loss: 1.0033 - lr: 2.0000e-04\n","Epoch 4/100\n","59108/59108 [==============================] - 125s 2ms/step - loss: 0.9992 - val_loss: 1.0051 - lr: 2.0000e-04\n","Epoch 5/100\n","59108/59108 [==============================] - 132s 2ms/step - loss: 0.9989 - val_loss: 1.0122 - lr: 2.0000e-04\n","Epoch 6/100\n","59085/59108 [============================>.] - ETA: 0s - loss: 0.9988\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","59108/59108 [==============================] - 125s 2ms/step - loss: 0.9988 - val_loss: 1.0066 - lr: 2.0000e-04\n","Epoch 7/100\n","59108/59108 [==============================] - 125s 2ms/step - loss: 0.9984 - val_loss: 1.0061 - lr: 4.0000e-05\n","Epoch 8/100\n","59108/59108 [==============================] - 133s 2ms/step - loss: 0.9985 - val_loss: 1.0055 - lr: 4.0000e-05\n","Epoch 00008: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413, 0.00047269853171938436]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054, -0.024388621188249138]\n","start training the data from 1960 to 2008\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_16 (Dense)            (None, 32)                2912      \n","                                                                 \n"," dense_17 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_18 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_19 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,585\n","Trainable params: 3,585\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","62198/62198 [==============================] - 130s 2ms/step - loss: 1.7164 - val_loss: 1.3734 - lr: 2.0000e-04\n","Epoch 2/100\n","62198/62198 [==============================] - 130s 2ms/step - loss: 1.0090 - val_loss: 1.0445 - lr: 2.0000e-04\n","Epoch 3/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 1.0021 - val_loss: 1.0324 - lr: 2.0000e-04\n","Epoch 4/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 1.0008 - val_loss: 1.0173 - lr: 2.0000e-04\n","Epoch 5/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9999 - val_loss: 1.0081 - lr: 2.0000e-04\n","Epoch 6/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9980 - val_loss: 1.0032 - lr: 2.0000e-04\n","Epoch 7/100\n","62198/62198 [==============================] - 130s 2ms/step - loss: 0.9975 - val_loss: 1.0012 - lr: 2.0000e-04\n","Epoch 8/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9973 - val_loss: 0.9997 - lr: 2.0000e-04\n","Epoch 9/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9970 - val_loss: 1.0002 - lr: 2.0000e-04\n","Epoch 10/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9968 - val_loss: 0.9982 - lr: 2.0000e-04\n","Epoch 11/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9968 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 12/100\n","62198/62198 [==============================] - 130s 2ms/step - loss: 0.9964 - val_loss: 0.9988 - lr: 2.0000e-04\n","Epoch 13/100\n","62175/62198 [============================>.] - ETA: 0s - loss: 0.9962\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9963 - val_loss: 0.9981 - lr: 2.0000e-04\n","Epoch 14/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9955 - val_loss: 0.9978 - lr: 4.0000e-05\n","Epoch 15/100\n","62198/62198 [==============================] - 129s 2ms/step - loss: 0.9957 - val_loss: 0.9981 - lr: 4.0000e-05\n","Epoch 00015: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413, 0.00047269853171938436, -0.00042404143815288897]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054, -0.024388621188249138, -0.009369382633298118]\n","start training the data from 1960 to 2009\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_20 (Dense)            (None, 32)                2912      \n","                                                                 \n"," dense_21 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_22 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_23 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,585\n","Trainable params: 3,585\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","65463/65463 [==============================] - 135s 2ms/step - loss: 5.1468 - val_loss: 1.0188 - lr: 2.0000e-04\n","Epoch 2/100\n","65463/65463 [==============================] - 134s 2ms/step - loss: 1.0018 - val_loss: 1.0076 - lr: 2.0000e-04\n","Epoch 3/100\n","65463/65463 [==============================] - 143s 2ms/step - loss: 0.9992 - val_loss: 1.0061 - lr: 2.0000e-04\n","Epoch 4/100\n","65463/65463 [==============================] - 134s 2ms/step - loss: 0.9983 - val_loss: 1.0032 - lr: 2.0000e-04\n","Epoch 5/100\n","65463/65463 [==============================] - 134s 2ms/step - loss: 0.9978 - val_loss: 1.0044 - lr: 2.0000e-04\n","Epoch 6/100\n","65463/65463 [==============================] - 134s 2ms/step - loss: 0.9973 - val_loss: 1.0077 - lr: 2.0000e-04\n","Epoch 7/100\n","65463/65463 [==============================] - 135s 2ms/step - loss: 0.9970 - val_loss: 1.0016 - lr: 2.0000e-04\n","Epoch 8/100\n","65463/65463 [==============================] - 133s 2ms/step - loss: 0.9969 - val_loss: 1.0003 - lr: 2.0000e-04\n","Epoch 9/100\n","65463/65463 [==============================] - 133s 2ms/step - loss: 0.9967 - val_loss: 1.0041 - lr: 2.0000e-04\n","Epoch 10/100\n","65463/65463 [==============================] - 133s 2ms/step - loss: 0.9967 - val_loss: 0.9991 - lr: 2.0000e-04\n","Epoch 11/100\n","65463/65463 [==============================] - 133s 2ms/step - loss: 0.9963 - val_loss: 1.0022 - lr: 2.0000e-04\n","Epoch 12/100\n","65463/65463 [==============================] - 133s 2ms/step - loss: 0.9964 - val_loss: 1.0124 - lr: 2.0000e-04\n","Epoch 13/100\n","65452/65463 [============================>.] - ETA: 0s - loss: 0.9962\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","65463/65463 [==============================] - 133s 2ms/step - loss: 0.9962 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 14/100\n","65463/65463 [==============================] - 144s 2ms/step - loss: 0.9954 - val_loss: 1.0044 - lr: 4.0000e-05\n","Epoch 15/100\n","65463/65463 [==============================] - 134s 2ms/step - loss: 0.9953 - val_loss: 0.9994 - lr: 4.0000e-05\n","Epoch 00015: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413, 0.00047269853171938436, -0.00042404143815288897, -0.001800623277775415]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054, -0.024388621188249138, -0.009369382633298118, -0.01058911721804856]\n","start training the data from 1960 to 2010\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_24 (Dense)            (None, 32)                2912      \n","                                                                 \n"," dense_25 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_26 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_27 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,585\n","Trainable params: 3,585\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","68861/68861 [==============================] - 139s 2ms/step - loss: 2.5460 - val_loss: 1.0127 - lr: 2.0000e-04\n","Epoch 2/100\n","68861/68861 [==============================] - 139s 2ms/step - loss: 1.0071 - val_loss: 1.0050 - lr: 2.0000e-04\n","Epoch 3/100\n","68861/68861 [==============================] - 139s 2ms/step - loss: 0.9989 - val_loss: 1.0033 - lr: 2.0000e-04\n","Epoch 4/100\n","68861/68861 [==============================] - 147s 2ms/step - loss: 0.9983 - val_loss: 1.0005 - lr: 2.0000e-04\n","Epoch 5/100\n","68861/68861 [==============================] - 138s 2ms/step - loss: 0.9972 - val_loss: 1.0020 - lr: 2.0000e-04\n","Epoch 6/100\n","68861/68861 [==============================] - 137s 2ms/step - loss: 0.9969 - val_loss: 0.9995 - lr: 2.0000e-04\n","Epoch 7/100\n","68861/68861 [==============================] - 149s 2ms/step - loss: 0.9963 - val_loss: 0.9982 - lr: 2.0000e-04\n","Epoch 8/100\n","68861/68861 [==============================] - 149s 2ms/step - loss: 0.9960 - val_loss: 0.9976 - lr: 2.0000e-04\n","Epoch 9/100\n","68861/68861 [==============================] - 149s 2ms/step - loss: 0.9958 - val_loss: 0.9968 - lr: 2.0000e-04\n","Epoch 10/100\n","68861/68861 [==============================] - 137s 2ms/step - loss: 0.9959 - val_loss: 1.0016 - lr: 2.0000e-04\n","Epoch 11/100\n","68861/68861 [==============================] - 138s 2ms/step - loss: 0.9958 - val_loss: 0.9984 - lr: 2.0000e-04\n","Epoch 12/100\n","68852/68861 [============================>.] - ETA: 0s - loss: 0.9957\n","Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","68861/68861 [==============================] - 138s 2ms/step - loss: 0.9957 - val_loss: 0.9979 - lr: 2.0000e-04\n","Epoch 13/100\n","68861/68861 [==============================] - 149s 2ms/step - loss: 0.9952 - val_loss: 0.9975 - lr: 4.0000e-05\n","Epoch 14/100\n","68861/68861 [==============================] - 137s 2ms/step - loss: 0.9952 - val_loss: 0.9978 - lr: 4.0000e-05\n","Epoch 00014: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413, 0.00047269853171938436, -0.00042404143815288897, -0.001800623277775415, -0.0019277057729980562]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054, -0.024388621188249138, -0.009369382633298118, -0.01058911721804856, 0.009543322614161354]\n","start training the data from 1960 to 2011\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_28 (Dense)            (None, 32)                2944      \n","                                                                 \n"," dense_29 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_30 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_31 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,617\n","Trainable params: 3,617\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","72226/72226 [==============================] - 143s 2ms/step - loss: 1.2015 - val_loss: 1.0120 - lr: 2.0000e-04\n","Epoch 2/100\n","72226/72226 [==============================] - 153s 2ms/step - loss: 0.9998 - val_loss: 1.0036 - lr: 2.0000e-04\n","Epoch 3/100\n","72226/72226 [==============================] - 142s 2ms/step - loss: 0.9991 - val_loss: 1.0029 - lr: 2.0000e-04\n","Epoch 4/100\n","72226/72226 [==============================] - 142s 2ms/step - loss: 0.9988 - val_loss: 1.0021 - lr: 2.0000e-04\n","Epoch 5/100\n","72226/72226 [==============================] - 142s 2ms/step - loss: 0.9985 - val_loss: 1.0006 - lr: 2.0000e-04\n","Epoch 6/100\n","72226/72226 [==============================] - 153s 2ms/step - loss: 0.9984 - val_loss: 1.0049 - lr: 2.0000e-04\n","Epoch 7/100\n","72226/72226 [==============================] - 143s 2ms/step - loss: 0.9983 - val_loss: 1.0014 - lr: 2.0000e-04\n","Epoch 8/100\n","72194/72226 [============================>.] - ETA: 0s - loss: 0.9980\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","72226/72226 [==============================] - 141s 2ms/step - loss: 0.9980 - val_loss: 1.0010 - lr: 2.0000e-04\n","Epoch 9/100\n","72226/72226 [==============================] - 142s 2ms/step - loss: 0.9977 - val_loss: 1.0008 - lr: 4.0000e-05\n","Epoch 10/100\n","72226/72226 [==============================] - 142s 2ms/step - loss: 0.9976 - val_loss: 1.0010 - lr: 4.0000e-05\n","Epoch 00010: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413, 0.00047269853171938436, -0.00042404143815288897, -0.001800623277775415, -0.0019277057729980562, -0.001358951570837652]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054, -0.024388621188249138, -0.009369382633298118, -0.01058911721804856, 0.009543322614161354, -0.0042037230770126666]\n","start training the data from 1960 to 2012\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_32 (Dense)            (None, 32)                2944      \n","                                                                 \n"," dense_33 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_34 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_35 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,617\n","Trainable params: 3,617\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","75410/75410 [==============================] - 147s 2ms/step - loss: 1.2077 - val_loss: 1.0046 - lr: 2.0000e-04\n","Epoch 2/100\n","75410/75410 [==============================] - 146s 2ms/step - loss: 1.0009 - val_loss: 1.0037 - lr: 2.0000e-04\n","Epoch 3/100\n","75410/75410 [==============================] - 160s 2ms/step - loss: 1.0001 - val_loss: 1.0012 - lr: 2.0000e-04\n","Epoch 4/100\n","75410/75410 [==============================] - 146s 2ms/step - loss: 0.9993 - val_loss: 1.0010 - lr: 2.0000e-04\n","Epoch 5/100\n","75410/75410 [==============================] - 146s 2ms/step - loss: 0.9990 - val_loss: 1.0025 - lr: 2.0000e-04\n","Epoch 6/100\n","75403/75410 [============================>.] - ETA: 0s - loss: 0.9989\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","75410/75410 [==============================] - 147s 2ms/step - loss: 0.9989 - val_loss: 1.0016 - lr: 2.0000e-04\n","Epoch 7/100\n","75410/75410 [==============================] - 146s 2ms/step - loss: 0.9986 - val_loss: 1.0003 - lr: 4.0000e-05\n","Epoch 8/100\n","75410/75410 [==============================] - 148s 2ms/step - loss: 0.9985 - val_loss: 0.9996 - lr: 4.0000e-05\n","Epoch 9/100\n","75410/75410 [==============================] - 147s 2ms/step - loss: 0.9984 - val_loss: 0.9999 - lr: 4.0000e-05\n","Epoch 10/100\n","75410/75410 [==============================] - 147s 2ms/step - loss: 0.9985 - val_loss: 0.9998 - lr: 4.0000e-05\n","Epoch 11/100\n","75406/75410 [============================>.] - ETA: 0s - loss: 0.9984\n","Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n","75410/75410 [==============================] - 148s 2ms/step - loss: 0.9984 - val_loss: 1.0003 - lr: 4.0000e-05\n","Epoch 12/100\n","75410/75410 [==============================] - 147s 2ms/step - loss: 0.9984 - val_loss: 0.9998 - lr: 8.0000e-06\n","Epoch 13/100\n","75410/75410 [==============================] - 147s 2ms/step - loss: 0.9984 - val_loss: 1.0000 - lr: 8.0000e-06\n","Epoch 00013: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413, 0.00047269853171938436, -0.00042404143815288897, -0.001800623277775415, -0.0019277057729980562, -0.001358951570837652, 0.0006409408560846819]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054, -0.024388621188249138, -0.009369382633298118, -0.01058911721804856, 0.009543322614161354, -0.0042037230770126666, 0.006293100216760217]\n","start training the data from 1960 to 2013\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_36 (Dense)            (None, 32)                2944      \n","                                                                 \n"," dense_37 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_38 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_39 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,617\n","Trainable params: 3,617\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","78525/78525 [==============================] - 151s 2ms/step - loss: 1.1335 - val_loss: 1.0184 - lr: 2.0000e-04\n","Epoch 2/100\n","78525/78525 [==============================] - 150s 2ms/step - loss: 0.9988 - val_loss: 1.0183 - lr: 2.0000e-04\n","Epoch 3/100\n","78525/78525 [==============================] - 150s 2ms/step - loss: 0.9978 - val_loss: 1.0107 - lr: 2.0000e-04\n","Epoch 4/100\n","78525/78525 [==============================] - 150s 2ms/step - loss: 0.9974 - val_loss: 1.0040 - lr: 2.0000e-04\n","Epoch 5/100\n","78525/78525 [==============================] - 150s 2ms/step - loss: 0.9970 - val_loss: 1.0007 - lr: 2.0000e-04\n","Epoch 6/100\n","78525/78525 [==============================] - 151s 2ms/step - loss: 0.9967 - val_loss: 0.9998 - lr: 2.0000e-04\n","Epoch 7/100\n","78525/78525 [==============================] - 151s 2ms/step - loss: 0.9963 - val_loss: 0.9960 - lr: 2.0000e-04\n","Epoch 8/100\n","78525/78525 [==============================] - 151s 2ms/step - loss: 0.9962 - val_loss: 0.9992 - lr: 2.0000e-04\n","Epoch 9/100\n","78525/78525 [==============================] - 151s 2ms/step - loss: 0.9961 - val_loss: 0.9978 - lr: 2.0000e-04\n","Epoch 10/100\n","78508/78525 [============================>.] - ETA: 0s - loss: 0.9958\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","78525/78525 [==============================] - 151s 2ms/step - loss: 0.9958 - val_loss: 0.9999 - lr: 2.0000e-04\n","Epoch 11/100\n","78525/78525 [==============================] - 150s 2ms/step - loss: 0.9955 - val_loss: 0.9983 - lr: 4.0000e-05\n","Epoch 12/100\n","78525/78525 [==============================] - 152s 2ms/step - loss: 0.9954 - val_loss: 0.9981 - lr: 4.0000e-05\n","Epoch 00012: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413, 0.00047269853171938436, -0.00042404143815288897, -0.001800623277775415, -0.0019277057729980562, -0.001358951570837652, 0.0006409408560846819, -0.0036265689647743127]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054, -0.024388621188249138, -0.009369382633298118, -0.01058911721804856, 0.009543322614161354, -0.0042037230770126666, 0.006293100216760217, 0.002516835978198406]\n","start training the data from 1960 to 2014\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_40 (Dense)            (None, 32)                2944      \n","                                                                 \n"," dense_41 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_42 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_43 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,617\n","Trainable params: 3,617\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","81435/81435 [==============================] - 155s 2ms/step - loss: 1.4075 - val_loss: 1.2001 - lr: 2.0000e-04\n","Epoch 2/100\n","81435/81435 [==============================] - 154s 2ms/step - loss: 1.0008 - val_loss: 1.1072 - lr: 2.0000e-04\n","Epoch 3/100\n","81435/81435 [==============================] - 169s 2ms/step - loss: 0.9997 - val_loss: 1.0709 - lr: 2.0000e-04\n","Epoch 4/100\n","81435/81435 [==============================] - 153s 2ms/step - loss: 0.9994 - val_loss: 1.0502 - lr: 2.0000e-04\n","Epoch 5/100\n","81435/81435 [==============================] - 155s 2ms/step - loss: 0.9989 - val_loss: 1.0356 - lr: 2.0000e-04\n","Epoch 6/100\n","81435/81435 [==============================] - 154s 2ms/step - loss: 0.9989 - val_loss: 1.0329 - lr: 2.0000e-04\n","Epoch 7/100\n","81435/81435 [==============================] - 154s 2ms/step - loss: 0.9986 - val_loss: 1.0226 - lr: 2.0000e-04\n","Epoch 8/100\n","81435/81435 [==============================] - 153s 2ms/step - loss: 0.9983 - val_loss: 1.0177 - lr: 2.0000e-04\n","Epoch 9/100\n","81435/81435 [==============================] - 156s 2ms/step - loss: 0.9981 - val_loss: 1.0122 - lr: 2.0000e-04\n","Epoch 10/100\n","81435/81435 [==============================] - 153s 2ms/step - loss: 0.9974 - val_loss: 1.0140 - lr: 2.0000e-04\n","Epoch 11/100\n","81435/81435 [==============================] - 168s 2ms/step - loss: 0.9970 - val_loss: 1.0185 - lr: 2.0000e-04\n","Epoch 12/100\n","81410/81435 [============================>.] - ETA: 0s - loss: 0.9970\n","Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","81435/81435 [==============================] - 153s 2ms/step - loss: 0.9970 - val_loss: 1.0199 - lr: 2.0000e-04\n","Epoch 13/100\n","81435/81435 [==============================] - 153s 2ms/step - loss: 0.9965 - val_loss: 1.0208 - lr: 4.0000e-05\n","Epoch 14/100\n","81435/81435 [==============================] - 154s 2ms/step - loss: 0.9963 - val_loss: 1.0222 - lr: 4.0000e-05\n","Epoch 00014: early stopping\n","[-0.00022459280232189904, 0.0008368194875607582, 0.0007144704134638413, 0.00047269853171938436, -0.00042404143815288897, -0.001800623277775415, -0.0019277057729980562, -0.001358951570837652, 0.0006409408560846819, -0.0036265689647743127, -0.009882240876175619]\n","[-0.0018143749979813162, -0.0017895914367884735, -0.002533075103271054, -0.024388621188249138, -0.009369382633298118, -0.01058911721804856, 0.009543322614161354, -0.0042037230770126666, 0.006293100216760217, 0.002516835978198406, -0.18992538272164228]\n","start training the data from 1960 to 2015\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_44 (Dense)            (None, 32)                2944      \n","                                                                 \n"," dense_45 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_46 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_47 (Dense)            (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,617\n","Trainable params: 3,617\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","84141/84141 [==============================] - 160s 2ms/step - loss: 1.3609 - val_loss: 1.1914 - lr: 2.0000e-04\n","Epoch 2/100\n","84141/84141 [==============================] - 159s 2ms/step - loss: 1.0042 - val_loss: 1.0730 - lr: 2.0000e-04\n","Epoch 3/100\n","84132/84141 [============================>.] - ETA: 0s - loss: 0.9999"]}]}]}