{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"project2_NN5.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1ah2h50abJplS0bqhOYC79x9b30Dznc91","authorship_tag":"ABX9TyMI31exygrqMIUmUMn9Di7y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"aKJeTLIPwii7","executionInfo":{"status":"ok","timestamp":1636812398425,"user_tz":-480,"elapsed":472,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"SB-cGFpQxp7I","executionInfo":{"status":"ok","timestamp":1636812471579,"user_tz":-480,"elapsed":73156,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}},"outputId":"950b2371-83e0-45bf-9ac8-a3fbc1d5bc1f"},"source":["df = pd.read_csv(\"/content/drive/My Drive/datashare/GKX_20201231.csv\")\n","df = df[df[\"DATE\"] >= 19600101].reset_index(drop = True) #选取1960年之后的数据\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>permno</th>\n","      <th>DATE</th>\n","      <th>mvel1</th>\n","      <th>RET</th>\n","      <th>prc</th>\n","      <th>SHROUT</th>\n","      <th>beta</th>\n","      <th>betasq</th>\n","      <th>chmom</th>\n","      <th>dolvol</th>\n","      <th>idiovol</th>\n","      <th>indmom</th>\n","      <th>mom1m</th>\n","      <th>mom6m</th>\n","      <th>mom12m</th>\n","      <th>mom36m</th>\n","      <th>mve0</th>\n","      <th>pricedelay</th>\n","      <th>turn</th>\n","      <th>absacc</th>\n","      <th>acc</th>\n","      <th>age</th>\n","      <th>agr</th>\n","      <th>cashdebt</th>\n","      <th>cashpr</th>\n","      <th>cfp</th>\n","      <th>cfp_ia</th>\n","      <th>chatoia</th>\n","      <th>chcsho</th>\n","      <th>chempia</th>\n","      <th>chinv</th>\n","      <th>chpmia</th>\n","      <th>convind</th>\n","      <th>currat</th>\n","      <th>depr</th>\n","      <th>divi</th>\n","      <th>divo</th>\n","      <th>dy</th>\n","      <th>egr</th>\n","      <th>ep</th>\n","      <th>...</th>\n","      <th>ps</th>\n","      <th>quick</th>\n","      <th>rd</th>\n","      <th>rd_mve</th>\n","      <th>rd_sale</th>\n","      <th>realestate</th>\n","      <th>roic</th>\n","      <th>salecash</th>\n","      <th>saleinv</th>\n","      <th>salerec</th>\n","      <th>secured</th>\n","      <th>securedind</th>\n","      <th>sgr</th>\n","      <th>sin</th>\n","      <th>sp</th>\n","      <th>tang</th>\n","      <th>tb</th>\n","      <th>aeavol</th>\n","      <th>cash</th>\n","      <th>chtx</th>\n","      <th>cinvest</th>\n","      <th>ear</th>\n","      <th>nincr</th>\n","      <th>roaq</th>\n","      <th>roavol</th>\n","      <th>roeq</th>\n","      <th>rsup</th>\n","      <th>stdacc</th>\n","      <th>stdcf</th>\n","      <th>ms</th>\n","      <th>baspread</th>\n","      <th>ill</th>\n","      <th>maxret</th>\n","      <th>retvol</th>\n","      <th>std_dolvol</th>\n","      <th>std_turn</th>\n","      <th>zerotrade</th>\n","      <th>sic2</th>\n","      <th>bm</th>\n","      <th>bm_ia</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10006</td>\n","      <td>19600129</td>\n","      <td>68773.00</td>\n","      <td>0.005155</td>\n","      <td>48.750</td>\n","      <td>1418</td>\n","      <td>1.158041</td>\n","      <td>1.341058</td>\n","      <td>-0.078184</td>\n","      <td>9.474396</td>\n","      <td>0.027283</td>\n","      <td>0.136142</td>\n","      <td>0.013055</td>\n","      <td>-0.021572</td>\n","      <td>0.046317</td>\n","      <td>-0.051308</td>\n","      <td>69127.500</td>\n","      <td>-0.015614</td>\n","      <td>0.168077</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.015272</td>\n","      <td>2.059137e-07</td>\n","      <td>0.033943</td>\n","      <td>0.015149</td>\n","      <td>0.591078</td>\n","      <td>0.533983</td>\n","      <td>9.859742e-08</td>\n","      <td>37.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10014</td>\n","      <td>19600129</td>\n","      <td>9823.50</td>\n","      <td>0.138889</td>\n","      <td>5.125</td>\n","      <td>2183</td>\n","      <td>1.838109</td>\n","      <td>3.378645</td>\n","      <td>-0.506541</td>\n","      <td>7.946573</td>\n","      <td>0.067400</td>\n","      <td>0.136142</td>\n","      <td>-0.027027</td>\n","      <td>-0.139535</td>\n","      <td>0.156250</td>\n","      <td>0.523810</td>\n","      <td>11187.875</td>\n","      <td>0.271738</td>\n","      <td>0.210261</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.035918</td>\n","      <td>1.906160e-06</td>\n","      <td>0.028571</td>\n","      <td>0.021261</td>\n","      <td>0.491650</td>\n","      <td>0.481666</td>\n","      <td>8.535634e-08</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10022</td>\n","      <td>19600129</td>\n","      <td>21133.75</td>\n","      <td>-0.045455</td>\n","      <td>13.125</td>\n","      <td>1537</td>\n","      <td>1.157077</td>\n","      <td>1.338827</td>\n","      <td>-0.374534</td>\n","      <td>8.507143</td>\n","      <td>0.043777</td>\n","      <td>0.136142</td>\n","      <td>0.009091</td>\n","      <td>-0.007626</td>\n","      <td>0.365436</td>\n","      <td>0.876728</td>\n","      <td>20173.125</td>\n","      <td>-0.029163</td>\n","      <td>0.276296</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.022607</td>\n","      <td>6.754297e-07</td>\n","      <td>0.040000</td>\n","      <td>0.026199</td>\n","      <td>0.877110</td>\n","      <td>1.639491</td>\n","      <td>5.271194e-08</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10030</td>\n","      <td>19600129</td>\n","      <td>81200.00</td>\n","      <td>-0.015000</td>\n","      <td>49.250</td>\n","      <td>1624</td>\n","      <td>1.327625</td>\n","      <td>1.762587</td>\n","      <td>-0.186923</td>\n","      <td>9.550378</td>\n","      <td>0.024872</td>\n","      <td>0.136142</td>\n","      <td>0.012000</td>\n","      <td>-0.024721</td>\n","      <td>0.144885</td>\n","      <td>0.142554</td>\n","      <td>79982.000</td>\n","      <td>0.029423</td>\n","      <td>0.189860</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.014960</td>\n","      <td>4.355397e-07</td>\n","      <td>0.038462</td>\n","      <td>0.020206</td>\n","      <td>0.936132</td>\n","      <td>0.771756</td>\n","      <td>1.102852e-07</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10057</td>\n","      <td>19600129</td>\n","      <td>27062.50</td>\n","      <td>-0.020785</td>\n","      <td>53.000</td>\n","      <td>500</td>\n","      <td>1.194604</td>\n","      <td>1.427080</td>\n","      <td>-0.293635</td>\n","      <td>8.138565</td>\n","      <td>0.030824</td>\n","      <td>0.136142</td>\n","      <td>0.021028</td>\n","      <td>-0.111214</td>\n","      <td>0.067530</td>\n","      <td>-0.270734</td>\n","      <td>26500.000</td>\n","      <td>-0.065354</td>\n","      <td>0.103333</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.002941</td>\n","      <td>3.479863e-07</td>\n","      <td>0.018692</td>\n","      <td>0.006685</td>\n","      <td>0.451979</td>\n","      <td>0.190010</td>\n","      <td>9.545457e-01</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 101 columns</p>\n","</div>"],"text/plain":["   permno      DATE     mvel1       RET  ...     zerotrade  sic2  bm  bm_ia\n","0   10006  19600129  68773.00  0.005155  ...  9.859742e-08  37.0 NaN    NaN\n","1   10014  19600129   9823.50  0.138889  ...  8.535634e-08   NaN NaN    NaN\n","2   10022  19600129  21133.75 -0.045455  ...  5.271194e-08   NaN NaN    NaN\n","3   10030  19600129  81200.00 -0.015000  ...  1.102852e-07   NaN NaN    NaN\n","4   10057  19600129  27062.50 -0.020785  ...  9.545457e-01   NaN NaN    NaN\n","\n","[5 rows x 101 columns]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"0IIGREOwKx8k","executionInfo":{"status":"ok","timestamp":1636812471580,"user_tz":-480,"elapsed":8,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["#Handle NA\n","def handling_na(df):\n","  for column in df.columns:\n","    if df[column].isnull().sum() == 0:\n","      continue\n","    #缺失值多于50%，直接drop该列\n","    elif (df[column].isnull().sum()/len(df[column])) > 0.5:\n","      df.drop(column, axis = 1, inplace = True)\n","    #缺失值少于50%，填充平均值 \n","    else:\n","      df[column].fillna(df[column].mean(), inplace = True)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"KpbKomATy5Yj","executionInfo":{"status":"ok","timestamp":1636812471580,"user_tz":-480,"elapsed":7,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["#输入测试集年份，自动准备数据\n","def cleaning_data(year_of_test):\n","  end_of_test = (year_of_test+1)*10000\n","  end_of_validation = year_of_test*10000\n","  start_of_validation = (year_of_test-12)*10000\n","\n","  alldata = df[df[\"DATE\"] < end_of_test]\n","\n","  #handling na\n","  handling_na(alldata)\n","\n","  #划分train/validation/test\n","  train = alldata[alldata[\"DATE\"] < start_of_validation]\n","  valid = alldata[(alldata[\"DATE\"] > start_of_validation)&(alldata[\"DATE\"] < end_of_validation)]\n","  test = alldata[(alldata[\"DATE\"] > end_of_validation)&(alldata[\"DATE\"] < end_of_test)]\n","\n","  #x,y\n","  x_train = train.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  x_valid = valid.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  x_test = test.drop([\"permno\",\"DATE\",'RET'],axis = 1)\n","  \n","  y_train = np.array(train['RET']).reshape(-1,1)\n","  y_valid = np.array(valid['RET']).reshape(-1,1)\n","  y_test = np.array(test['RET']).reshape(-1,1)\n","\n","\n","  #StandardScale\n","  scaler = StandardScaler()\n","  x_train = scaler.fit_transform(x_train)\n","  x_valid = scaler.transform(x_valid)\n","  x_test = scaler.transform(x_test)\n","\n","  return x_train, x_valid, x_test, y_train, y_valid, y_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBVxt6BWl9DB","executionInfo":{"status":"ok","timestamp":1636812471581,"user_tz":-480,"elapsed":7,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["#定义计算out of sample R square函数\n","def R_square(ypred,ytrue): \n","  dif2=np.sum(np.power(ytrue-ypred,2))\n","  return 1-(dif2/np.sum(np.power(ytrue,2)))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKu2-x65IALX","executionInfo":{"status":"ok","timestamp":1636812471581,"user_tz":-480,"elapsed":7,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["#自定义定义损失函数\n","def R_loss(y_true, y_pred):\n","  return tf.reduce_mean(tf.square(y_true-y_pred))/tf.reduce_mean(tf.square(y_true))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6YvawJjbYcF","executionInfo":{"status":"ok","timestamp":1636812473781,"user_tz":-480,"elapsed":2206,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}}},"source":["import tensorflow as tf\n","from tensorflow import keras"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGTCpfdYAA6_","executionInfo":{"status":"ok","timestamp":1636852239515,"user_tz":-480,"elapsed":4530385,"user":{"displayName":"MAFM HKUST","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10894348893487959051"}},"outputId":"60c7cbac-08ee-44f0-b156-405ff6f43373"},"source":["rsquare_oos_valid = []\n","rsquare_oos_test = []\n","\n","#NN5\n","for year in range(1990,2021):\n","  print(\"start training the data from 1960 to \"+str(year))\n","  x_train, x_valid, x_test, y_train, y_valid, y_test = cleaning_data(year)\n","\n","  model = keras.models.Sequential()\n","  model.add(keras.layers.Dense(32, activation='relu', input_shape=x_train.shape[1:]))\n","  model.add(keras.layers.Dense(16, activation='relu'))\n","  model.add(keras.layers.Dense(8, activation='relu'))\n","  model.add(keras.layers.Dense(4, activation='relu'))\n","  model.add(keras.layers.Dense(2, activation='relu'))\n","  model.add(keras.layers.Dense(1))\n","\n","  sgd = keras.optimizers.SGD(learning_rate = 0.0002, clipnorm = 0.5)\n","\n","  model.summary()\n","  model.compile(loss = R_loss, optimizer= sgd)\n","  \n","  EarlyStop = keras.callbacks.EarlyStopping(\n","      monitor='val_loss',\n","      patience=5,\n","      verbose=1,\n","      min_delta=0.001, \n","      mode='min')\n","  \n","  Reduce = keras.callbacks.ReduceLROnPlateau(\n","      monitor='val_loss',\n","      factor=0.2,\n","      patience=3,\n","      verbose=1,\n","      mode='min',\n","      min_delta=0.001,\n","      cooldown=0,\n","      min_lr=0)\n","\n","  model.fit(\n","      x_train,\n","      y_train,\n","      validation_data = (x_valid, y_valid),\n","      epochs = 100,\n","      callbacks = [Reduce,EarlyStop])\n","  \n","  model.save('/content/drive/My Drive/NN_models/NN5_'+str(year)+'.h5')\n","\n","  rsquare_oos_valid.append(R_square(model.predict(x_valid),y_valid))\n","  print(rsquare_oos_valid)\n","  rsquare_oos_test.append(R_square(model.predict(x_test),y_test))\n","  print(rsquare_oos_test)\n","\n","  del model"],"execution_count":8,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["start training the data from 1960 to 1990\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 32)                2560      \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_2 (Dense)             (None, 8)                 136       \n","                                                                 \n"," dense_3 (Dense)             (None, 4)                 36        \n","                                                                 \n"," dense_4 (Dense)             (None, 2)                 10        \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,273\n","Trainable params: 3,273\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","19317/19317 [==============================] - 58s 3ms/step - loss: 1.0094 - val_loss: 1.0369 - lr: 2.0000e-04\n","Epoch 2/100\n","19317/19317 [==============================] - 55s 3ms/step - loss: 1.0002 - val_loss: 1.0150 - lr: 2.0000e-04\n","Epoch 3/100\n","19317/19317 [==============================] - 54s 3ms/step - loss: 0.9999 - val_loss: 1.0067 - lr: 2.0000e-04\n","Epoch 4/100\n","19317/19317 [==============================] - 53s 3ms/step - loss: 0.9996 - val_loss: 1.0030 - lr: 2.0000e-04\n","Epoch 5/100\n","19317/19317 [==============================] - 51s 3ms/step - loss: 0.9998 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 6/100\n","19317/19317 [==============================] - 53s 3ms/step - loss: 0.9998 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 7/100\n","19317/19317 [==============================] - 51s 3ms/step - loss: 0.9997 - val_loss: 1.0008 - lr: 2.0000e-04\n","Epoch 8/100\n","19317/19317 [==============================] - 52s 3ms/step - loss: 0.9997 - val_loss: 0.9995 - lr: 2.0000e-04\n","Epoch 9/100\n","19317/19317 [==============================] - 51s 3ms/step - loss: 0.9998 - val_loss: 0.9998 - lr: 2.0000e-04\n","Epoch 10/100\n","19317/19317 [==============================] - 51s 3ms/step - loss: 0.9997 - val_loss: 0.9993 - lr: 2.0000e-04\n","Epoch 11/100\n","19284/19317 [============================>.] - ETA: 0s - loss: 0.9998\n","Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","19317/19317 [==============================] - 51s 3ms/step - loss: 0.9998 - val_loss: 1.0005 - lr: 2.0000e-04\n","Epoch 12/100\n","19317/19317 [==============================] - 51s 3ms/step - loss: 0.9998 - val_loss: 0.9991 - lr: 4.0000e-05\n","Epoch 13/100\n","19317/19317 [==============================] - 50s 3ms/step - loss: 0.9996 - val_loss: 0.9992 - lr: 4.0000e-05\n","Epoch 00013: early stopping\n","[0.004740899494446116]\n","[-0.01050932320707032]\n","start training the data from 1960 to 1991\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 32)                2560      \n","                                                                 \n"," dense_7 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_8 (Dense)             (None, 8)                 136       \n","                                                                 \n"," dense_9 (Dense)             (None, 4)                 36        \n","                                                                 \n"," dense_10 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_11 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,273\n","Trainable params: 3,273\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 1.0698 - val_loss: 1.2385 - lr: 2.0000e-04\n","Epoch 2/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 1.0041 - val_loss: 1.1451 - lr: 2.0000e-04\n","Epoch 3/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 1.0016 - val_loss: 1.1058 - lr: 2.0000e-04\n","Epoch 4/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 1.0004 - val_loss: 1.0868 - lr: 2.0000e-04\n","Epoch 5/100\n","21136/21136 [==============================] - 54s 3ms/step - loss: 1.0002 - val_loss: 1.0786 - lr: 2.0000e-04\n","Epoch 6/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 0.9998 - val_loss: 1.0695 - lr: 2.0000e-04\n","Epoch 7/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 0.9995 - val_loss: 1.0647 - lr: 2.0000e-04\n","Epoch 8/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 0.9995 - val_loss: 1.0587 - lr: 2.0000e-04\n","Epoch 9/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 0.9994 - val_loss: 1.0580 - lr: 2.0000e-04\n","Epoch 10/100\n","21136/21136 [==============================] - 54s 3ms/step - loss: 0.9992 - val_loss: 1.0518 - lr: 2.0000e-04\n","Epoch 11/100\n","21136/21136 [==============================] - 54s 3ms/step - loss: 0.9992 - val_loss: 1.0502 - lr: 2.0000e-04\n","Epoch 12/100\n","21136/21136 [==============================] - 56s 3ms/step - loss: 0.9993 - val_loss: 1.0486 - lr: 2.0000e-04\n","Epoch 13/100\n","21136/21136 [==============================] - 56s 3ms/step - loss: 0.9992 - val_loss: 1.0459 - lr: 2.0000e-04\n","Epoch 14/100\n","21136/21136 [==============================] - 55s 3ms/step - loss: 0.9992 - val_loss: 1.0468 - lr: 2.0000e-04\n","Epoch 15/100\n","21136/21136 [==============================] - 54s 3ms/step - loss: 0.9992 - val_loss: 1.0444 - lr: 2.0000e-04\n","Epoch 16/100\n","21136/21136 [==============================] - 54s 3ms/step - loss: 0.9991 - val_loss: 1.0457 - lr: 2.0000e-04\n","Epoch 17/100\n","21136/21136 [==============================] - 53s 3ms/step - loss: 0.9990 - val_loss: 1.0440 - lr: 2.0000e-04\n","Epoch 18/100\n","21105/21136 [============================>.] - ETA: 0s - loss: 0.9991\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","21136/21136 [==============================] - 53s 3ms/step - loss: 0.9992 - val_loss: 1.0437 - lr: 2.0000e-04\n","Epoch 19/100\n","21136/21136 [==============================] - 52s 2ms/step - loss: 0.9991 - val_loss: 1.0422 - lr: 4.0000e-05\n","Epoch 20/100\n","21136/21136 [==============================] - 53s 2ms/step - loss: 0.9992 - val_loss: 1.0428 - lr: 4.0000e-05\n","Epoch 21/100\n","21136/21136 [==============================] - 53s 3ms/step - loss: 0.9991 - val_loss: 1.0426 - lr: 4.0000e-05\n","Epoch 22/100\n","21101/21136 [============================>.] - ETA: 0s - loss: 0.9988\n","Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n","21136/21136 [==============================] - 52s 2ms/step - loss: 0.9988 - val_loss: 1.0425 - lr: 4.0000e-05\n","Epoch 23/100\n","21136/21136 [==============================] - 53s 3ms/step - loss: 0.9988 - val_loss: 1.0428 - lr: 8.0000e-06\n","Epoch 24/100\n","21136/21136 [==============================] - 52s 2ms/step - loss: 0.9990 - val_loss: 1.0429 - lr: 8.0000e-06\n","Epoch 00024: early stopping\n","[0.004740899494446116, -0.01990755362820562]\n","[-0.01050932320707032, 0.008184161731769724]\n","start training the data from 1960 to 1992\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_12 (Dense)            (None, 32)                2592      \n","                                                                 \n"," dense_13 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_14 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_15 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_16 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_17 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,305\n","Trainable params: 3,305\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","22939/22939 [==============================] - 56s 2ms/step - loss: 1.0948 - val_loss: 1.0900 - lr: 2.0000e-04\n","Epoch 2/100\n","22939/22939 [==============================] - 55s 2ms/step - loss: 1.0216 - val_loss: 1.0517 - lr: 2.0000e-04\n","Epoch 3/100\n","22939/22939 [==============================] - 56s 2ms/step - loss: 1.0096 - val_loss: 1.0370 - lr: 2.0000e-04\n","Epoch 4/100\n","22939/22939 [==============================] - 56s 2ms/step - loss: 1.0064 - val_loss: 1.0309 - lr: 2.0000e-04\n","Epoch 5/100\n","22939/22939 [==============================] - 56s 2ms/step - loss: 1.0041 - val_loss: 1.0256 - lr: 2.0000e-04\n","Epoch 6/100\n","22939/22939 [==============================] - 56s 2ms/step - loss: 1.0022 - val_loss: 1.0244 - lr: 2.0000e-04\n","Epoch 7/100\n","22939/22939 [==============================] - 56s 2ms/step - loss: 1.0008 - val_loss: 1.0194 - lr: 2.0000e-04\n","Epoch 8/100\n","22939/22939 [==============================] - 55s 2ms/step - loss: 1.0004 - val_loss: 1.0169 - lr: 2.0000e-04\n","Epoch 9/100\n","22939/22939 [==============================] - 55s 2ms/step - loss: 0.9993 - val_loss: 1.0160 - lr: 2.0000e-04\n","Epoch 10/100\n","22939/22939 [==============================] - 56s 2ms/step - loss: 0.9988 - val_loss: 1.0135 - lr: 2.0000e-04\n","Epoch 11/100\n","22939/22939 [==============================] - 60s 3ms/step - loss: 0.9984 - val_loss: 1.0125 - lr: 2.0000e-04\n","Epoch 12/100\n","22939/22939 [==============================] - 57s 2ms/step - loss: 0.9980 - val_loss: 1.0146 - lr: 2.0000e-04\n","Epoch 13/100\n","22939/22939 [==============================] - 56s 2ms/step - loss: 0.9982 - val_loss: 1.0114 - lr: 2.0000e-04\n","Epoch 14/100\n","22939/22939 [==============================] - 63s 3ms/step - loss: 0.9979 - val_loss: 1.0113 - lr: 2.0000e-04\n","Epoch 15/100\n","22939/22939 [==============================] - 61s 3ms/step - loss: 0.9980 - val_loss: 1.0124 - lr: 2.0000e-04\n","Epoch 16/100\n","22918/22939 [============================>.] - ETA: 0s - loss: 0.9980\n","Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","22939/22939 [==============================] - 59s 3ms/step - loss: 0.9980 - val_loss: 1.0130 - lr: 2.0000e-04\n","Epoch 17/100\n","22939/22939 [==============================] - 62s 3ms/step - loss: 0.9978 - val_loss: 1.0137 - lr: 4.0000e-05\n","Epoch 18/100\n","22939/22939 [==============================] - 68s 3ms/step - loss: 0.9980 - val_loss: 1.0129 - lr: 4.0000e-05\n","Epoch 00018: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814]\n","start training the data from 1960 to 1993\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_18 (Dense)            (None, 32)                2592      \n","                                                                 \n"," dense_19 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_20 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_21 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_22 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_23 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,305\n","Trainable params: 3,305\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","24756/24756 [==============================] - 66s 3ms/step - loss: 1.0007 - val_loss: 1.0100 - lr: 2.0000e-04\n","Epoch 2/100\n","24756/24756 [==============================] - 62s 3ms/step - loss: 0.9972 - val_loss: 1.0081 - lr: 2.0000e-04\n","Epoch 3/100\n","24756/24756 [==============================] - 59s 2ms/step - loss: 0.9970 - val_loss: 1.0137 - lr: 2.0000e-04\n","Epoch 4/100\n","24756/24756 [==============================] - 66s 3ms/step - loss: 0.9971 - val_loss: 1.0036 - lr: 2.0000e-04\n","Epoch 5/100\n","24756/24756 [==============================] - 66s 3ms/step - loss: 0.9968 - val_loss: 1.0140 - lr: 2.0000e-04\n","Epoch 6/100\n","24756/24756 [==============================] - 65s 3ms/step - loss: 0.9970 - val_loss: 1.0077 - lr: 2.0000e-04\n","Epoch 7/100\n","24744/24756 [============================>.] - ETA: 0s - loss: 0.9968\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","24756/24756 [==============================] - 65s 3ms/step - loss: 0.9968 - val_loss: 1.0073 - lr: 2.0000e-04\n","Epoch 8/100\n","24756/24756 [==============================] - 57s 2ms/step - loss: 0.9969 - val_loss: 1.0089 - lr: 4.0000e-05\n","Epoch 9/100\n","24756/24756 [==============================] - 63s 3ms/step - loss: 0.9968 - val_loss: 1.0089 - lr: 4.0000e-05\n","Epoch 00009: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932]\n","start training the data from 1960 to 1994\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_24 (Dense)            (None, 32)                2560      \n","                                                                 \n"," dense_25 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_26 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_27 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_28 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_29 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,273\n","Trainable params: 3,273\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","26695/26695 [==============================] - 69s 3ms/step - loss: 1.2641 - val_loss: 1.8441 - lr: 2.0000e-04\n","Epoch 2/100\n","26695/26695 [==============================] - 65s 2ms/step - loss: 1.0023 - val_loss: 1.2173 - lr: 2.0000e-04\n","Epoch 3/100\n","26695/26695 [==============================] - 65s 2ms/step - loss: 0.9990 - val_loss: 1.0984 - lr: 2.0000e-04\n","Epoch 4/100\n","26695/26695 [==============================] - 65s 2ms/step - loss: 0.9981 - val_loss: 1.0485 - lr: 2.0000e-04\n","Epoch 5/100\n","26695/26695 [==============================] - 68s 3ms/step - loss: 0.9978 - val_loss: 1.0304 - lr: 2.0000e-04\n","Epoch 6/100\n","26695/26695 [==============================] - 69s 3ms/step - loss: 0.9977 - val_loss: 1.0236 - lr: 2.0000e-04\n","Epoch 7/100\n","26695/26695 [==============================] - 78s 3ms/step - loss: 0.9976 - val_loss: 1.0224 - lr: 2.0000e-04\n","Epoch 8/100\n","26695/26695 [==============================] - 97s 4ms/step - loss: 0.9977 - val_loss: 1.0150 - lr: 2.0000e-04\n","Epoch 9/100\n","26695/26695 [==============================] - 67s 3ms/step - loss: 0.9977 - val_loss: 1.0109 - lr: 2.0000e-04\n","Epoch 10/100\n","26695/26695 [==============================] - 94s 4ms/step - loss: 0.9977 - val_loss: 1.0111 - lr: 2.0000e-04\n","Epoch 11/100\n","26695/26695 [==============================] - 105s 4ms/step - loss: 0.9977 - val_loss: 1.0108 - lr: 2.0000e-04\n","Epoch 12/100\n","26687/26695 [============================>.] - ETA: 0s - loss: 0.9976\n","Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","26695/26695 [==============================] - 101s 4ms/step - loss: 0.9976 - val_loss: 1.0106 - lr: 2.0000e-04\n","Epoch 13/100\n","26695/26695 [==============================] - 100s 4ms/step - loss: 0.9975 - val_loss: 1.0116 - lr: 4.0000e-05\n","Epoch 14/100\n","26695/26695 [==============================] - 95s 4ms/step - loss: 0.9976 - val_loss: 1.0091 - lr: 4.0000e-05\n","Epoch 15/100\n","26695/26695 [==============================] - 74s 3ms/step - loss: 0.9976 - val_loss: 1.0110 - lr: 4.0000e-05\n","Epoch 16/100\n","26695/26695 [==============================] - 67s 3ms/step - loss: 0.9974 - val_loss: 1.0106 - lr: 4.0000e-05\n","Epoch 17/100\n","26665/26695 [============================>.] - ETA: 0s - loss: 0.9976\n","Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n","26695/26695 [==============================] - 67s 3ms/step - loss: 0.9976 - val_loss: 1.0092 - lr: 4.0000e-05\n","Epoch 18/100\n","26695/26695 [==============================] - 68s 3ms/step - loss: 0.9976 - val_loss: 1.0092 - lr: 8.0000e-06\n","Epoch 19/100\n","26695/26695 [==============================] - 69s 3ms/step - loss: 0.9975 - val_loss: 1.0099 - lr: 8.0000e-06\n","Epoch 00019: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552]\n","start training the data from 1960 to 1995\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_30 (Dense)            (None, 32)                2560      \n","                                                                 \n"," dense_31 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_32 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_33 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_34 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_35 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,273\n","Trainable params: 3,273\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","28704/28704 [==============================] - 70s 2ms/step - loss: 1.0229 - val_loss: 1.1414 - lr: 2.0000e-04\n","Epoch 2/100\n","28704/28704 [==============================] - 69s 2ms/step - loss: 0.9997 - val_loss: 1.0674 - lr: 2.0000e-04\n","Epoch 3/100\n","28704/28704 [==============================] - 70s 2ms/step - loss: 0.9991 - val_loss: 1.0446 - lr: 2.0000e-04\n","Epoch 4/100\n","28704/28704 [==============================] - 69s 2ms/step - loss: 0.9984 - val_loss: 1.0333 - lr: 2.0000e-04\n","Epoch 5/100\n","28704/28704 [==============================] - 69s 2ms/step - loss: 0.9984 - val_loss: 1.0287 - lr: 2.0000e-04\n","Epoch 6/100\n","28704/28704 [==============================] - 72s 3ms/step - loss: 0.9986 - val_loss: 1.0254 - lr: 2.0000e-04\n","Epoch 7/100\n","28704/28704 [==============================] - 72s 3ms/step - loss: 0.9979 - val_loss: 1.0208 - lr: 2.0000e-04\n","Epoch 8/100\n","28704/28704 [==============================] - 85s 3ms/step - loss: 0.9984 - val_loss: 1.0179 - lr: 2.0000e-04\n","Epoch 9/100\n","28704/28704 [==============================] - 70s 2ms/step - loss: 0.9977 - val_loss: 1.0182 - lr: 2.0000e-04\n","Epoch 10/100\n","28704/28704 [==============================] - 72s 3ms/step - loss: 0.9981 - val_loss: 1.0179 - lr: 2.0000e-04\n","Epoch 11/100\n","28690/28704 [============================>.] - ETA: 0s - loss: 0.9979\n","Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","28704/28704 [==============================] - 77s 3ms/step - loss: 0.9979 - val_loss: 1.0189 - lr: 2.0000e-04\n","Epoch 12/100\n","28704/28704 [==============================] - 62s 2ms/step - loss: 0.9978 - val_loss: 1.0160 - lr: 4.0000e-05\n","Epoch 13/100\n","28704/28704 [==============================] - 63s 2ms/step - loss: 0.9980 - val_loss: 1.0165 - lr: 4.0000e-05\n","Epoch 14/100\n","28704/28704 [==============================] - 62s 2ms/step - loss: 0.9980 - val_loss: 1.0173 - lr: 4.0000e-05\n","Epoch 15/100\n","28701/28704 [============================>.] - ETA: 0s - loss: 0.9977\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n","28704/28704 [==============================] - 62s 2ms/step - loss: 0.9977 - val_loss: 1.0153 - lr: 4.0000e-05\n","Epoch 16/100\n","28704/28704 [==============================] - 62s 2ms/step - loss: 0.9975 - val_loss: 1.0164 - lr: 8.0000e-06\n","Epoch 17/100\n","28704/28704 [==============================] - 62s 2ms/step - loss: 0.9976 - val_loss: 1.0161 - lr: 8.0000e-06\n","Epoch 00017: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605]\n","start training the data from 1960 to 1996\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_36 (Dense)            (None, 32)                2592      \n","                                                                 \n"," dense_37 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_38 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_39 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_40 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_41 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,305\n","Trainable params: 3,305\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","30851/30851 [==============================] - 74s 2ms/step - loss: 0.9987 - val_loss: 1.0067 - lr: 2.0000e-04\n","Epoch 2/100\n","30851/30851 [==============================] - 74s 2ms/step - loss: 0.9968 - val_loss: 1.0064 - lr: 2.0000e-04\n","Epoch 3/100\n","30851/30851 [==============================] - 89s 3ms/step - loss: 0.9965 - val_loss: 1.0048 - lr: 2.0000e-04\n","Epoch 4/100\n","30851/30851 [==============================] - 85s 3ms/step - loss: 0.9966 - val_loss: 1.0075 - lr: 2.0000e-04\n","Epoch 5/100\n","30851/30851 [==============================] - 72s 2ms/step - loss: 0.9965 - val_loss: 1.0080 - lr: 2.0000e-04\n","Epoch 6/100\n","30829/30851 [============================>.] - ETA: 0s - loss: 0.9962\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","30851/30851 [==============================] - 74s 2ms/step - loss: 0.9962 - val_loss: 1.0050 - lr: 2.0000e-04\n","Epoch 7/100\n","30851/30851 [==============================] - 71s 2ms/step - loss: 0.9962 - val_loss: 1.0072 - lr: 4.0000e-05\n","Epoch 8/100\n","30851/30851 [==============================] - 68s 2ms/step - loss: 0.9962 - val_loss: 1.0068 - lr: 4.0000e-05\n","Epoch 00008: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583]\n","start training the data from 1960 to 1997\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_42 (Dense)            (None, 32)                2592      \n","                                                                 \n"," dense_43 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_44 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_45 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_46 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_47 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,305\n","Trainable params: 3,305\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","33206/33206 [==============================] - 79s 2ms/step - loss: 1.0074 - val_loss: 1.0079 - lr: 2.0000e-04\n","Epoch 2/100\n","33206/33206 [==============================] - 83s 2ms/step - loss: 0.9990 - val_loss: 1.0078 - lr: 2.0000e-04\n","Epoch 3/100\n","33206/33206 [==============================] - 80s 2ms/step - loss: 0.9987 - val_loss: 1.0061 - lr: 2.0000e-04\n","Epoch 4/100\n","33206/33206 [==============================] - 78s 2ms/step - loss: 0.9987 - val_loss: 1.0040 - lr: 2.0000e-04\n","Epoch 5/100\n","33206/33206 [==============================] - 78s 2ms/step - loss: 0.9985 - val_loss: 1.0055 - lr: 2.0000e-04\n","Epoch 6/100\n","33206/33206 [==============================] - 78s 2ms/step - loss: 0.9985 - val_loss: 1.0032 - lr: 2.0000e-04\n","Epoch 7/100\n","33187/33206 [============================>.] - ETA: 0s - loss: 0.9985\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","33206/33206 [==============================] - 77s 2ms/step - loss: 0.9985 - val_loss: 1.0036 - lr: 2.0000e-04\n","Epoch 8/100\n","33206/33206 [==============================] - 77s 2ms/step - loss: 0.9983 - val_loss: 1.0050 - lr: 4.0000e-05\n","Epoch 9/100\n","33206/33206 [==============================] - 78s 2ms/step - loss: 0.9983 - val_loss: 1.0042 - lr: 4.0000e-05\n","Epoch 00009: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898]\n","start training the data from 1960 to 1998\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_48 (Dense)            (None, 32)                2592      \n","                                                                 \n"," dense_49 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_50 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_51 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_52 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_53 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,305\n","Trainable params: 3,305\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","35560/35560 [==============================] - 92s 3ms/step - loss: 1.0980 - val_loss: 1.2780 - lr: 2.0000e-04\n","Epoch 2/100\n","35560/35560 [==============================] - 78s 2ms/step - loss: 1.0020 - val_loss: 1.0926 - lr: 2.0000e-04\n","Epoch 3/100\n","35560/35560 [==============================] - 76s 2ms/step - loss: 1.0001 - val_loss: 1.0432 - lr: 2.0000e-04\n","Epoch 4/100\n","35560/35560 [==============================] - 80s 2ms/step - loss: 0.9994 - val_loss: 1.0280 - lr: 2.0000e-04\n","Epoch 5/100\n","35560/35560 [==============================] - 76s 2ms/step - loss: 0.9989 - val_loss: 1.0219 - lr: 2.0000e-04\n","Epoch 6/100\n","35560/35560 [==============================] - 77s 2ms/step - loss: 0.9989 - val_loss: 1.0176 - lr: 2.0000e-04\n","Epoch 7/100\n","35560/35560 [==============================] - 87s 2ms/step - loss: 0.9984 - val_loss: 1.0180 - lr: 2.0000e-04\n","Epoch 8/100\n","35560/35560 [==============================] - 85s 2ms/step - loss: 0.9983 - val_loss: 1.0159 - lr: 2.0000e-04\n","Epoch 9/100\n","35560/35560 [==============================] - 81s 2ms/step - loss: 0.9983 - val_loss: 1.0165 - lr: 2.0000e-04\n","Epoch 10/100\n","35560/35560 [==============================] - 79s 2ms/step - loss: 0.9981 - val_loss: 1.0145 - lr: 2.0000e-04\n","Epoch 11/100\n","35560/35560 [==============================] - 79s 2ms/step - loss: 0.9980 - val_loss: 1.0145 - lr: 2.0000e-04\n","Epoch 12/100\n","35560/35560 [==============================] - 79s 2ms/step - loss: 0.9979 - val_loss: 1.0142 - lr: 2.0000e-04\n","Epoch 13/100\n","35560/35560 [==============================] - 78s 2ms/step - loss: 0.9980 - val_loss: 1.0123 - lr: 2.0000e-04\n","Epoch 14/100\n","35560/35560 [==============================] - 90s 3ms/step - loss: 0.9977 - val_loss: 1.0128 - lr: 2.0000e-04\n","Epoch 15/100\n","35560/35560 [==============================] - 100s 3ms/step - loss: 0.9978 - val_loss: 1.0134 - lr: 2.0000e-04\n","Epoch 16/100\n","35540/35560 [============================>.] - ETA: 0s - loss: 0.9978\n","Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","35560/35560 [==============================] - 114s 3ms/step - loss: 0.9978 - val_loss: 1.0123 - lr: 2.0000e-04\n","Epoch 17/100\n","35560/35560 [==============================] - 91s 3ms/step - loss: 0.9977 - val_loss: 1.0128 - lr: 4.0000e-05\n","Epoch 18/100\n","35560/35560 [==============================] - 90s 3ms/step - loss: 0.9977 - val_loss: 1.0128 - lr: 4.0000e-05\n","Epoch 00018: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378]\n","start training the data from 1960 to 1999\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_54 (Dense)            (None, 32)                2656      \n","                                                                 \n"," dense_55 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_56 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_57 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_58 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_59 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,369\n","Trainable params: 3,369\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","37966/37966 [==============================] - 95s 2ms/step - loss: 1.0177 - val_loss: 2.6461 - lr: 2.0000e-04\n","Epoch 2/100\n","37966/37966 [==============================] - 92s 2ms/step - loss: 1.0017 - val_loss: 1.9470 - lr: 2.0000e-04\n","Epoch 3/100\n","37966/37966 [==============================] - 96s 3ms/step - loss: 1.0018 - val_loss: 1.6119 - lr: 2.0000e-04\n","Epoch 4/100\n","37966/37966 [==============================] - 96s 3ms/step - loss: 1.0001 - val_loss: 1.4208 - lr: 2.0000e-04\n","Epoch 5/100\n","37966/37966 [==============================] - 95s 2ms/step - loss: 1.0000 - val_loss: 1.3113 - lr: 2.0000e-04\n","Epoch 6/100\n","37966/37966 [==============================] - 98s 3ms/step - loss: 0.9984 - val_loss: 1.2487 - lr: 2.0000e-04\n","Epoch 7/100\n","37966/37966 [==============================] - 90s 2ms/step - loss: 0.9992 - val_loss: 1.2178 - lr: 2.0000e-04\n","Epoch 8/100\n","37966/37966 [==============================] - 89s 2ms/step - loss: 0.9988 - val_loss: 1.1991 - lr: 2.0000e-04\n","Epoch 9/100\n","37966/37966 [==============================] - 84s 2ms/step - loss: 0.9983 - val_loss: 1.1819 - lr: 2.0000e-04\n","Epoch 10/100\n","37966/37966 [==============================] - 83s 2ms/step - loss: 0.9984 - val_loss: 1.1710 - lr: 2.0000e-04\n","Epoch 11/100\n","37966/37966 [==============================] - 79s 2ms/step - loss: 0.9986 - val_loss: 1.1629 - lr: 2.0000e-04\n","Epoch 12/100\n","37966/37966 [==============================] - 78s 2ms/step - loss: 0.9983 - val_loss: 1.1552 - lr: 2.0000e-04\n","Epoch 13/100\n","37966/37966 [==============================] - 83s 2ms/step - loss: 0.9983 - val_loss: 1.1530 - lr: 2.0000e-04\n","Epoch 14/100\n","37966/37966 [==============================] - 87s 2ms/step - loss: 0.9981 - val_loss: 1.1507 - lr: 2.0000e-04\n","Epoch 15/100\n","37966/37966 [==============================] - 89s 2ms/step - loss: 0.9981 - val_loss: 1.1472 - lr: 2.0000e-04\n","Epoch 16/100\n","37966/37966 [==============================] - 92s 2ms/step - loss: 0.9979 - val_loss: 1.1487 - lr: 2.0000e-04\n","Epoch 17/100\n","37966/37966 [==============================] - 92s 2ms/step - loss: 0.9983 - val_loss: 1.1496 - lr: 2.0000e-04\n","Epoch 18/100\n","37960/37966 [============================>.] - ETA: 0s - loss: 0.9979\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","37966/37966 [==============================] - 88s 2ms/step - loss: 0.9979 - val_loss: 1.1484 - lr: 2.0000e-04\n","Epoch 19/100\n","37966/37966 [==============================] - 85s 2ms/step - loss: 0.9981 - val_loss: 1.1487 - lr: 4.0000e-05\n","Epoch 20/100\n","37966/37966 [==============================] - 88s 2ms/step - loss: 0.9977 - val_loss: 1.1501 - lr: 4.0000e-05\n","Epoch 00020: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215]\n","start training the data from 1960 to 2000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_60 (Dense)            (None, 32)                2720      \n","                                                                 \n"," dense_61 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_62 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_63 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_64 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_65 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,433\n","Trainable params: 3,433\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","40569/40569 [==============================] - 97s 2ms/step - loss: 1.2718 - val_loss: 1.0079 - lr: 2.0000e-04\n","Epoch 2/100\n","40569/40569 [==============================] - 95s 2ms/step - loss: 1.0035 - val_loss: 1.0030 - lr: 2.0000e-04\n","Epoch 3/100\n","40569/40569 [==============================] - 98s 2ms/step - loss: 1.0007 - val_loss: 1.0029 - lr: 2.0000e-04\n","Epoch 4/100\n","40569/40569 [==============================] - 98s 2ms/step - loss: 0.9995 - val_loss: 1.0035 - lr: 2.0000e-04\n","Epoch 5/100\n","40569/40569 [==============================] - 106s 3ms/step - loss: 0.9992 - val_loss: 1.0017 - lr: 2.0000e-04\n","Epoch 6/100\n","40569/40569 [==============================] - 100s 2ms/step - loss: 0.9990 - val_loss: 1.0014 - lr: 2.0000e-04\n","Epoch 7/100\n","40569/40569 [==============================] - 111s 3ms/step - loss: 0.9989 - val_loss: 1.0023 - lr: 2.0000e-04\n","Epoch 8/100\n","40563/40569 [============================>.] - ETA: 0s - loss: 0.9990\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","40569/40569 [==============================] - 100s 2ms/step - loss: 0.9990 - val_loss: 1.0012 - lr: 2.0000e-04\n","Epoch 9/100\n","40569/40569 [==============================] - 96s 2ms/step - loss: 0.9986 - val_loss: 1.0014 - lr: 4.0000e-05\n","Epoch 10/100\n","40569/40569 [==============================] - 98s 2ms/step - loss: 0.9988 - val_loss: 1.0011 - lr: 4.0000e-05\n","Epoch 00010: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546]\n","start training the data from 1960 to 2001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_66 (Dense)            (None, 32)                2784      \n","                                                                 \n"," dense_67 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_68 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_69 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_70 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_71 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,497\n","Trainable params: 3,497\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","43217/43217 [==============================] - 94s 2ms/step - loss: 1.0035 - val_loss: 1.0120 - lr: 2.0000e-04\n","Epoch 2/100\n","43217/43217 [==============================] - 101s 2ms/step - loss: 0.9989 - val_loss: 1.0057 - lr: 2.0000e-04\n","Epoch 3/100\n","43217/43217 [==============================] - 100s 2ms/step - loss: 0.9987 - val_loss: 1.0031 - lr: 2.0000e-04\n","Epoch 4/100\n","43217/43217 [==============================] - 102s 2ms/step - loss: 0.9987 - val_loss: 1.0050 - lr: 2.0000e-04\n","Epoch 5/100\n","43217/43217 [==============================] - 104s 2ms/step - loss: 0.9986 - val_loss: 1.0046 - lr: 2.0000e-04\n","Epoch 6/100\n","43186/43217 [============================>.] - ETA: 0s - loss: 0.9987\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","43217/43217 [==============================] - 106s 2ms/step - loss: 0.9987 - val_loss: 1.0040 - lr: 2.0000e-04\n","Epoch 7/100\n","43217/43217 [==============================] - 109s 3ms/step - loss: 0.9985 - val_loss: 1.0024 - lr: 4.0000e-05\n","Epoch 8/100\n","43217/43217 [==============================] - 101s 2ms/step - loss: 0.9986 - val_loss: 1.0021 - lr: 4.0000e-05\n","Epoch 9/100\n","43217/43217 [==============================] - 105s 2ms/step - loss: 0.9985 - val_loss: 1.0031 - lr: 4.0000e-05\n","Epoch 10/100\n","43217/43217 [==============================] - 104s 2ms/step - loss: 0.9987 - val_loss: 1.0024 - lr: 4.0000e-05\n","Epoch 11/100\n","43207/43217 [============================>.] - ETA: 0s - loss: 0.9986\n","Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n","43217/43217 [==============================] - 105s 2ms/step - loss: 0.9986 - val_loss: 1.0025 - lr: 4.0000e-05\n","Epoch 12/100\n","43217/43217 [==============================] - 99s 2ms/step - loss: 0.9985 - val_loss: 1.0022 - lr: 8.0000e-06\n","Epoch 13/100\n","43217/43217 [==============================] - 98s 2ms/step - loss: 0.9985 - val_loss: 1.0023 - lr: 8.0000e-06\n","Epoch 00013: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044]\n","start training the data from 1960 to 2002\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_72 (Dense)            (None, 32)                2816      \n","                                                                 \n"," dense_73 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_74 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_75 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_76 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_77 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,529\n","Trainable params: 3,529\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","45789/45789 [==============================] - 100s 2ms/step - loss: 1.1307 - val_loss: 1.0631 - lr: 2.0000e-04\n","Epoch 2/100\n","45789/45789 [==============================] - 93s 2ms/step - loss: 1.0136 - val_loss: 1.0320 - lr: 2.0000e-04\n","Epoch 3/100\n","45789/45789 [==============================] - 91s 2ms/step - loss: 1.0078 - val_loss: 1.0249 - lr: 2.0000e-04\n","Epoch 4/100\n","45789/45789 [==============================] - 97s 2ms/step - loss: 1.0067 - val_loss: 1.0177 - lr: 2.0000e-04\n","Epoch 5/100\n","45789/45789 [==============================] - 101s 2ms/step - loss: 1.0032 - val_loss: 1.0171 - lr: 2.0000e-04\n","Epoch 6/100\n","45789/45789 [==============================] - 102s 2ms/step - loss: 1.0019 - val_loss: 1.0136 - lr: 2.0000e-04\n","Epoch 7/100\n","45789/45789 [==============================] - 99s 2ms/step - loss: 1.0012 - val_loss: 1.0114 - lr: 2.0000e-04\n","Epoch 8/100\n","45789/45789 [==============================] - 93s 2ms/step - loss: 1.0000 - val_loss: 1.0091 - lr: 2.0000e-04\n","Epoch 9/100\n","45789/45789 [==============================] - 93s 2ms/step - loss: 1.0003 - val_loss: 1.0087 - lr: 2.0000e-04\n","Epoch 10/100\n","45789/45789 [==============================] - 100s 2ms/step - loss: 1.0003 - val_loss: 1.0077 - lr: 2.0000e-04\n","Epoch 11/100\n","45789/45789 [==============================] - 100s 2ms/step - loss: 0.9997 - val_loss: 1.0080 - lr: 2.0000e-04\n","Epoch 12/100\n","45789/45789 [==============================] - 90s 2ms/step - loss: 1.0000 - val_loss: 1.0073 - lr: 2.0000e-04\n","Epoch 13/100\n","45782/45789 [============================>.] - ETA: 0s - loss: 0.9996\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","45789/45789 [==============================] - 100s 2ms/step - loss: 0.9996 - val_loss: 1.0072 - lr: 2.0000e-04\n","Epoch 14/100\n","45789/45789 [==============================] - 96s 2ms/step - loss: 0.9992 - val_loss: 1.0071 - lr: 4.0000e-05\n","Epoch 15/100\n","45789/45789 [==============================] - 97s 2ms/step - loss: 0.9993 - val_loss: 1.0070 - lr: 4.0000e-05\n","Epoch 00015: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926]\n","start training the data from 1960 to 2003\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_78 (Dense)            (None, 32)                2848      \n","                                                                 \n"," dense_79 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_80 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_81 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_82 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_83 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,561\n","Trainable params: 3,561\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","48326/48326 [==============================] - 98s 2ms/step - loss: 1.9969 - val_loss: 1.0413 - lr: 2.0000e-04\n","Epoch 2/100\n","48326/48326 [==============================] - 97s 2ms/step - loss: 1.0000 - val_loss: 1.0202 - lr: 2.0000e-04\n","Epoch 3/100\n","48326/48326 [==============================] - 103s 2ms/step - loss: 0.9996 - val_loss: 1.0214 - lr: 2.0000e-04\n","Epoch 4/100\n","48326/48326 [==============================] - 117s 2ms/step - loss: 0.9991 - val_loss: 1.0189 - lr: 2.0000e-04\n","Epoch 5/100\n","48326/48326 [==============================] - 113s 2ms/step - loss: 0.9986 - val_loss: 1.0030 - lr: 2.0000e-04\n","Epoch 6/100\n","48326/48326 [==============================] - 109s 2ms/step - loss: 0.9981 - val_loss: 1.0038 - lr: 2.0000e-04\n","Epoch 7/100\n","48326/48326 [==============================] - 122s 3ms/step - loss: 0.9978 - val_loss: 1.0011 - lr: 2.0000e-04\n","Epoch 8/100\n","48326/48326 [==============================] - 128s 3ms/step - loss: 0.9975 - val_loss: 1.0016 - lr: 2.0000e-04\n","Epoch 9/100\n","48326/48326 [==============================] - 117s 2ms/step - loss: 0.9973 - val_loss: 0.9993 - lr: 2.0000e-04\n","Epoch 10/100\n","48326/48326 [==============================] - 116s 2ms/step - loss: 0.9971 - val_loss: 0.9989 - lr: 2.0000e-04\n","Epoch 11/100\n","48326/48326 [==============================] - 95s 2ms/step - loss: 0.9968 - val_loss: 0.9995 - lr: 2.0000e-04\n","Epoch 12/100\n","48326/48326 [==============================] - 108s 2ms/step - loss: 0.9968 - val_loss: 0.9979 - lr: 2.0000e-04\n","Epoch 13/100\n","48326/48326 [==============================] - 110s 2ms/step - loss: 0.9966 - val_loss: 0.9973 - lr: 2.0000e-04\n","Epoch 14/100\n","48326/48326 [==============================] - 107s 2ms/step - loss: 0.9965 - val_loss: 0.9978 - lr: 2.0000e-04\n","Epoch 15/100\n","48319/48326 [============================>.] - ETA: 0s - loss: 0.9964\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","48326/48326 [==============================] - 119s 2ms/step - loss: 0.9964 - val_loss: 0.9981 - lr: 2.0000e-04\n","Epoch 16/100\n","48326/48326 [==============================] - 124s 3ms/step - loss: 0.9960 - val_loss: 0.9970 - lr: 4.0000e-05\n","Epoch 17/100\n","48326/48326 [==============================] - 121s 3ms/step - loss: 0.9961 - val_loss: 0.9982 - lr: 4.0000e-05\n","Epoch 00017: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233]\n","start training the data from 1960 to 2004\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_14\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_84 (Dense)            (None, 32)                2848      \n","                                                                 \n"," dense_85 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_86 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_87 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_88 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_89 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,561\n","Trainable params: 3,561\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","50830/50830 [==============================] - 111s 2ms/step - loss: 1.0041 - val_loss: 1.0050 - lr: 2.0000e-04\n","Epoch 2/100\n","50830/50830 [==============================] - 118s 2ms/step - loss: 0.9993 - val_loss: 1.0024 - lr: 2.0000e-04\n","Epoch 3/100\n","50830/50830 [==============================] - 122s 2ms/step - loss: 0.9994 - val_loss: 1.0023 - lr: 2.0000e-04\n","Epoch 4/100\n","50830/50830 [==============================] - 122s 2ms/step - loss: 0.9993 - val_loss: 1.0019 - lr: 2.0000e-04\n","Epoch 5/100\n","50823/50830 [============================>.] - ETA: 0s - loss: 0.9993\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","50830/50830 [==============================] - 122s 2ms/step - loss: 0.9993 - val_loss: 1.0019 - lr: 2.0000e-04\n","Epoch 6/100\n","50830/50830 [==============================] - 118s 2ms/step - loss: 0.9992 - val_loss: 1.0026 - lr: 4.0000e-05\n","Epoch 7/100\n","50830/50830 [==============================] - 130s 3ms/step - loss: 0.9992 - val_loss: 1.0025 - lr: 4.0000e-05\n","Epoch 00007: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248]\n","start training the data from 1960 to 2005\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_15\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_90 (Dense)            (None, 32)                2848      \n","                                                                 \n"," dense_91 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_92 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_93 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_94 (Dense)            (None, 2)                 10        \n","                                                                 \n"," dense_95 (Dense)            (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,561\n","Trainable params: 3,561\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","53394/53394 [==============================] - 112s 2ms/step - loss: 1.0227 - val_loss: 1.0047 - lr: 2.0000e-04\n","Epoch 2/100\n","53394/53394 [==============================] - 127s 2ms/step - loss: 0.9997 - val_loss: 1.0020 - lr: 2.0000e-04\n","Epoch 3/100\n","53394/53394 [==============================] - 126s 2ms/step - loss: 0.9994 - val_loss: 1.0015 - lr: 2.0000e-04\n","Epoch 4/100\n","53394/53394 [==============================] - 113s 2ms/step - loss: 0.9992 - val_loss: 1.0011 - lr: 2.0000e-04\n","Epoch 5/100\n","53394/53394 [==============================] - 132s 2ms/step - loss: 0.9992 - val_loss: 1.0005 - lr: 2.0000e-04\n","Epoch 6/100\n","53394/53394 [==============================] - 129s 2ms/step - loss: 0.9992 - val_loss: 1.0001 - lr: 2.0000e-04\n","Epoch 7/100\n","53394/53394 [==============================] - 123s 2ms/step - loss: 0.9991 - val_loss: 1.0005 - lr: 2.0000e-04\n","Epoch 8/100\n","53369/53394 [============================>.] - ETA: 0s - loss: 0.9991\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","53394/53394 [==============================] - 126s 2ms/step - loss: 0.9991 - val_loss: 0.9997 - lr: 2.0000e-04\n","Epoch 9/100\n","53394/53394 [==============================] - 106s 2ms/step - loss: 0.9991 - val_loss: 1.0003 - lr: 4.0000e-05\n","Epoch 10/100\n","53394/53394 [==============================] - 121s 2ms/step - loss: 0.9991 - val_loss: 0.9999 - lr: 4.0000e-05\n","Epoch 00010: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05]\n","start training the data from 1960 to 2006\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_96 (Dense)            (None, 32)                2912      \n","                                                                 \n"," dense_97 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_98 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_99 (Dense)            (None, 4)                 36        \n","                                                                 \n"," dense_100 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_101 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,625\n","Trainable params: 3,625\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","56108/56108 [==============================] - 149s 3ms/step - loss: 1.0093 - val_loss: 1.0052 - lr: 2.0000e-04\n","Epoch 2/100\n","56108/56108 [==============================] - 122s 2ms/step - loss: 0.9997 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 3/100\n","56108/56108 [==============================] - 133s 2ms/step - loss: 0.9994 - val_loss: 1.0019 - lr: 2.0000e-04\n","Epoch 4/100\n","56108/56108 [==============================] - 142s 3ms/step - loss: 0.9992 - val_loss: 1.0020 - lr: 2.0000e-04\n","Epoch 5/100\n","56083/56108 [============================>.] - ETA: 0s - loss: 0.9992\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","56108/56108 [==============================] - 139s 2ms/step - loss: 0.9992 - val_loss: 1.0019 - lr: 2.0000e-04\n","Epoch 6/100\n","56108/56108 [==============================] - 132s 2ms/step - loss: 0.9991 - val_loss: 1.0013 - lr: 4.0000e-05\n","Epoch 7/100\n","56108/56108 [==============================] - 123s 2ms/step - loss: 0.9991 - val_loss: 1.0011 - lr: 4.0000e-05\n","Epoch 00007: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563]\n","start training the data from 1960 to 2007\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_17\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_102 (Dense)           (None, 32)                2912      \n","                                                                 \n"," dense_103 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_104 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_105 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_106 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_107 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,625\n","Trainable params: 3,625\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","59108/59108 [==============================] - 130s 2ms/step - loss: 1.0359 - val_loss: 1.0071 - lr: 2.0000e-04\n","Epoch 2/100\n","59108/59108 [==============================] - 138s 2ms/step - loss: 0.9995 - val_loss: 1.0051 - lr: 2.0000e-04\n","Epoch 3/100\n","59108/59108 [==============================] - 136s 2ms/step - loss: 0.9995 - val_loss: 1.0035 - lr: 2.0000e-04\n","Epoch 4/100\n","59108/59108 [==============================] - 136s 2ms/step - loss: 0.9994 - val_loss: 0.9978 - lr: 2.0000e-04\n","Epoch 5/100\n","59108/59108 [==============================] - 160s 3ms/step - loss: 0.9994 - val_loss: 1.0011 - lr: 2.0000e-04\n","Epoch 6/100\n","59108/59108 [==============================] - 158s 3ms/step - loss: 0.9993 - val_loss: 1.0003 - lr: 2.0000e-04\n","Epoch 7/100\n","59100/59108 [============================>.] - ETA: 0s - loss: 0.9991\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","59108/59108 [==============================] - 159s 3ms/step - loss: 0.9991 - val_loss: 1.0017 - lr: 2.0000e-04\n","Epoch 8/100\n","59108/59108 [==============================] - 139s 2ms/step - loss: 0.9991 - val_loss: 1.0021 - lr: 4.0000e-05\n","Epoch 9/100\n","59108/59108 [==============================] - 135s 2ms/step - loss: 0.9989 - val_loss: 1.0001 - lr: 4.0000e-05\n","Epoch 00009: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144]\n","start training the data from 1960 to 2008\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_18\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_108 (Dense)           (None, 32)                2912      \n","                                                                 \n"," dense_109 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_110 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_111 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_112 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_113 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,625\n","Trainable params: 3,625\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","62198/62198 [==============================] - 155s 2ms/step - loss: 1.0042 - val_loss: 1.0031 - lr: 2.0000e-04\n","Epoch 2/100\n","62198/62198 [==============================] - 153s 2ms/step - loss: 0.9992 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 3/100\n","62198/62198 [==============================] - 125s 2ms/step - loss: 0.9990 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 4/100\n","62198/62198 [==============================] - 122s 2ms/step - loss: 0.9991 - val_loss: 1.0008 - lr: 2.0000e-04\n","Epoch 5/100\n","62194/62198 [============================>.] - ETA: 0s - loss: 0.9991\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","62198/62198 [==============================] - 123s 2ms/step - loss: 0.9991 - val_loss: 1.0004 - lr: 2.0000e-04\n","Epoch 6/100\n","62198/62198 [==============================] - 122s 2ms/step - loss: 0.9990 - val_loss: 1.0007 - lr: 4.0000e-05\n","Epoch 7/100\n","62198/62198 [==============================] - 118s 2ms/step - loss: 0.9989 - val_loss: 1.0005 - lr: 4.0000e-05\n","Epoch 00007: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606]\n","start training the data from 1960 to 2009\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_19\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_114 (Dense)           (None, 32)                2912      \n","                                                                 \n"," dense_115 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_116 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_117 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_118 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_119 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,625\n","Trainable params: 3,625\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","65463/65463 [==============================] - 120s 2ms/step - loss: 0.9990 - val_loss: 1.0031 - lr: 2.0000e-04\n","Epoch 2/100\n","65463/65463 [==============================] - 125s 2ms/step - loss: 0.9988 - val_loss: 1.0023 - lr: 2.0000e-04\n","Epoch 3/100\n","65463/65463 [==============================] - 124s 2ms/step - loss: 0.9985 - val_loss: 1.0017 - lr: 2.0000e-04\n","Epoch 4/100\n","65463/65463 [==============================] - 129s 2ms/step - loss: 0.9984 - val_loss: 1.0027 - lr: 2.0000e-04\n","Epoch 5/100\n","65463/65463 [==============================] - 127s 2ms/step - loss: 0.9984 - val_loss: 1.0036 - lr: 2.0000e-04\n","Epoch 6/100\n","65442/65463 [============================>.] - ETA: 0s - loss: 0.9983\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","65463/65463 [==============================] - 122s 2ms/step - loss: 0.9983 - val_loss: 1.0031 - lr: 2.0000e-04\n","Epoch 7/100\n","65463/65463 [==============================] - 123s 2ms/step - loss: 0.9979 - val_loss: 1.0016 - lr: 4.0000e-05\n","Epoch 8/100\n","65463/65463 [==============================] - 122s 2ms/step - loss: 0.9980 - val_loss: 1.0013 - lr: 4.0000e-05\n","Epoch 00008: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768]\n","start training the data from 1960 to 2010\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_20\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_120 (Dense)           (None, 32)                2912      \n","                                                                 \n"," dense_121 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_122 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_123 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_124 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_125 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,625\n","Trainable params: 3,625\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","68861/68861 [==============================] - 121s 2ms/step - loss: 1.0073 - val_loss: 1.0067 - lr: 2.0000e-04\n","Epoch 2/100\n","68861/68861 [==============================] - 119s 2ms/step - loss: 0.9994 - val_loss: 1.0035 - lr: 2.0000e-04\n","Epoch 3/100\n","68861/68861 [==============================] - 119s 2ms/step - loss: 0.9989 - val_loss: 1.0018 - lr: 2.0000e-04\n","Epoch 4/100\n","68861/68861 [==============================] - 142s 2ms/step - loss: 0.9986 - val_loss: 1.0038 - lr: 2.0000e-04\n","Epoch 5/100\n","68861/68861 [==============================] - 144s 2ms/step - loss: 0.9986 - val_loss: 1.0024 - lr: 2.0000e-04\n","Epoch 6/100\n","68841/68861 [============================>.] - ETA: 0s - loss: 0.9987\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","68861/68861 [==============================] - 138s 2ms/step - loss: 0.9987 - val_loss: 1.0022 - lr: 2.0000e-04\n","Epoch 7/100\n","68861/68861 [==============================] - 135s 2ms/step - loss: 0.9987 - val_loss: 1.0028 - lr: 4.0000e-05\n","Epoch 8/100\n","68861/68861 [==============================] - 135s 2ms/step - loss: 0.9987 - val_loss: 1.0028 - lr: 4.0000e-05\n","Epoch 00008: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246]\n","start training the data from 1960 to 2011\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_21\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_126 (Dense)           (None, 32)                2944      \n","                                                                 \n"," dense_127 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_128 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_129 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_130 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_131 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,657\n","Trainable params: 3,657\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","72226/72226 [==============================] - 141s 2ms/step - loss: 1.0093 - val_loss: 1.0006 - lr: 2.0000e-04\n","Epoch 2/100\n","72226/72226 [==============================] - 140s 2ms/step - loss: 0.9993 - val_loss: 0.9997 - lr: 2.0000e-04\n","Epoch 3/100\n","72226/72226 [==============================] - 148s 2ms/step - loss: 0.9993 - val_loss: 1.0013 - lr: 2.0000e-04\n","Epoch 4/100\n","72206/72226 [============================>.] - ETA: 0s - loss: 0.9994\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","72226/72226 [==============================] - 145s 2ms/step - loss: 0.9994 - val_loss: 1.0044 - lr: 2.0000e-04\n","Epoch 5/100\n","72226/72226 [==============================] - 135s 2ms/step - loss: 0.9998 - val_loss: 1.0050 - lr: 4.0000e-05\n","Epoch 6/100\n","72226/72226 [==============================] - 147s 2ms/step - loss: 1.0002 - val_loss: 1.0071 - lr: 4.0000e-05\n","Epoch 00006: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919]\n","start training the data from 1960 to 2012\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_22\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_132 (Dense)           (None, 32)                2944      \n","                                                                 \n"," dense_133 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_134 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_135 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_136 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_137 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,657\n","Trainable params: 3,657\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","75410/75410 [==============================] - 147s 2ms/step - loss: 1.0103 - val_loss: 1.0144 - lr: 2.0000e-04\n","Epoch 2/100\n","75410/75410 [==============================] - 137s 2ms/step - loss: 1.0015 - val_loss: 1.0103 - lr: 2.0000e-04\n","Epoch 3/100\n","75410/75410 [==============================] - 140s 2ms/step - loss: 1.0003 - val_loss: 1.0043 - lr: 2.0000e-04\n","Epoch 4/100\n","75410/75410 [==============================] - 149s 2ms/step - loss: 0.9995 - val_loss: 1.0042 - lr: 2.0000e-04\n","Epoch 5/100\n","75410/75410 [==============================] - 161s 2ms/step - loss: 0.9993 - val_loss: 1.0047 - lr: 2.0000e-04\n","Epoch 6/100\n","75396/75410 [============================>.] - ETA: 0s - loss: 0.9991\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","75410/75410 [==============================] - 164s 2ms/step - loss: 0.9991 - val_loss: 1.0059 - lr: 2.0000e-04\n","Epoch 7/100\n","75410/75410 [==============================] - 164s 2ms/step - loss: 0.9991 - val_loss: 1.0037 - lr: 4.0000e-05\n","Epoch 8/100\n","75410/75410 [==============================] - 180s 2ms/step - loss: 0.9991 - val_loss: 1.0039 - lr: 4.0000e-05\n","Epoch 00008: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948]\n","start training the data from 1960 to 2013\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_23\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_138 (Dense)           (None, 32)                2944      \n","                                                                 \n"," dense_139 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_140 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_141 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_142 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_143 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,657\n","Trainable params: 3,657\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","78525/78525 [==============================] - 150s 2ms/step - loss: 1.0031 - val_loss: 0.9996 - lr: 2.0000e-04\n","Epoch 2/100\n","78525/78525 [==============================] - 147s 2ms/step - loss: 0.9996 - val_loss: 1.0010 - lr: 2.0000e-04\n","Epoch 3/100\n","78525/78525 [==============================] - 150s 2ms/step - loss: 0.9995 - val_loss: 0.9998 - lr: 2.0000e-04\n","Epoch 4/100\n","78516/78525 [============================>.] - ETA: 0s - loss: 0.9995\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","78525/78525 [==============================] - 143s 2ms/step - loss: 0.9995 - val_loss: 0.9995 - lr: 2.0000e-04\n","Epoch 5/100\n","78525/78525 [==============================] - 137s 2ms/step - loss: 0.9994 - val_loss: 0.9995 - lr: 4.0000e-05\n","Epoch 6/100\n","78525/78525 [==============================] - 139s 2ms/step - loss: 0.9994 - val_loss: 0.9996 - lr: 4.0000e-05\n","Epoch 00006: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947, 0.002944938011426812]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948, 0.021227531341382555]\n","start training the data from 1960 to 2014\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_24\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_144 (Dense)           (None, 32)                2944      \n","                                                                 \n"," dense_145 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_146 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_147 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_148 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_149 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,657\n","Trainable params: 3,657\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","81435/81435 [==============================] - 151s 2ms/step - loss: 1.0560 - val_loss: 0.9986 - lr: 2.0000e-04\n","Epoch 2/100\n","81435/81435 [==============================] - 156s 2ms/step - loss: 1.0010 - val_loss: 0.9987 - lr: 2.0000e-04\n","Epoch 3/100\n","81435/81435 [==============================] - 154s 2ms/step - loss: 1.0004 - val_loss: 0.9992 - lr: 2.0000e-04\n","Epoch 4/100\n","81433/81435 [============================>.] - ETA: 0s - loss: 1.0000\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","81435/81435 [==============================] - 154s 2ms/step - loss: 1.0000 - val_loss: 0.9982 - lr: 2.0000e-04\n","Epoch 5/100\n","81435/81435 [==============================] - 148s 2ms/step - loss: 0.9998 - val_loss: 0.9989 - lr: 4.0000e-05\n","Epoch 6/100\n","81435/81435 [==============================] - 153s 2ms/step - loss: 0.9998 - val_loss: 0.9982 - lr: 4.0000e-05\n","Epoch 00006: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947, 0.002944938011426812, 0.003306365791320265]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948, 0.021227531341382555, -0.0014506481512879255]\n","start training the data from 1960 to 2015\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_25\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_150 (Dense)           (None, 32)                2944      \n","                                                                 \n"," dense_151 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_152 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_153 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_154 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_155 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,657\n","Trainable params: 3,657\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","84141/84141 [==============================] - 151s 2ms/step - loss: 1.0566 - val_loss: 1.0123 - lr: 2.0000e-04\n","Epoch 2/100\n","84141/84141 [==============================] - 145s 2ms/step - loss: 1.0007 - val_loss: 1.0044 - lr: 2.0000e-04\n","Epoch 3/100\n","84141/84141 [==============================] - 144s 2ms/step - loss: 1.0002 - val_loss: 1.0020 - lr: 2.0000e-04\n","Epoch 4/100\n","84141/84141 [==============================] - 145s 2ms/step - loss: 1.0000 - val_loss: 1.0010 - lr: 2.0000e-04\n","Epoch 5/100\n","84141/84141 [==============================] - 145s 2ms/step - loss: 0.9999 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 6/100\n","84141/84141 [==============================] - 158s 2ms/step - loss: 0.9999 - val_loss: 0.9999 - lr: 2.0000e-04\n","Epoch 7/100\n","84141/84141 [==============================] - 165s 2ms/step - loss: 0.9999 - val_loss: 0.9994 - lr: 2.0000e-04\n","Epoch 8/100\n","84141/84141 [==============================] - 163s 2ms/step - loss: 0.9999 - val_loss: 0.9995 - lr: 2.0000e-04\n","Epoch 9/100\n","84140/84141 [============================>.] - ETA: 0s - loss: 0.9999\n","Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","84141/84141 [==============================] - 156s 2ms/step - loss: 0.9999 - val_loss: 0.9994 - lr: 2.0000e-04\n","Epoch 10/100\n","84141/84141 [==============================] - 160s 2ms/step - loss: 0.9998 - val_loss: 0.9985 - lr: 4.0000e-05\n","Epoch 11/100\n","84141/84141 [==============================] - 163s 2ms/step - loss: 0.9998 - val_loss: 0.9987 - lr: 4.0000e-05\n","Epoch 12/100\n","84141/84141 [==============================] - 164s 2ms/step - loss: 0.9998 - val_loss: 0.9987 - lr: 4.0000e-05\n","Epoch 13/100\n","84113/84141 [============================>.] - ETA: 0s - loss: 0.9998\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n","84141/84141 [==============================] - 162s 2ms/step - loss: 0.9998 - val_loss: 0.9983 - lr: 4.0000e-05\n","Epoch 14/100\n","84141/84141 [==============================] - 162s 2ms/step - loss: 0.9998 - val_loss: 0.9986 - lr: 8.0000e-06\n","Epoch 15/100\n","84141/84141 [==============================] - 170s 2ms/step - loss: 0.9998 - val_loss: 0.9983 - lr: 8.0000e-06\n","Epoch 00015: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947, 0.002944938011426812, 0.003306365791320265, 0.0033697184481581433]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948, 0.021227531341382555, -0.0014506481512879255, -0.007203511587160261]\n","start training the data from 1960 to 2016\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_26\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_156 (Dense)           (None, 32)                2944      \n","                                                                 \n"," dense_157 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_158 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_159 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_160 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_161 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,657\n","Trainable params: 3,657\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","86693/86693 [==============================] - 168s 2ms/step - loss: 1.0004 - val_loss: 1.0017 - lr: 2.0000e-04\n","Epoch 2/100\n","86693/86693 [==============================] - 154s 2ms/step - loss: 0.9992 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 3/100\n","86693/86693 [==============================] - 163s 2ms/step - loss: 0.9988 - val_loss: 1.0010 - lr: 2.0000e-04\n","Epoch 4/100\n","86693/86693 [==============================] - 177s 2ms/step - loss: 0.9987 - val_loss: 1.0007 - lr: 2.0000e-04\n","Epoch 5/100\n","86693/86693 [==============================] - 186s 2ms/step - loss: 0.9986 - val_loss: 1.0014 - lr: 2.0000e-04\n","Epoch 6/100\n","86693/86693 [==============================] - 177s 2ms/step - loss: 0.9984 - val_loss: 1.0000 - lr: 2.0000e-04\n","Epoch 7/100\n","86693/86693 [==============================] - 184s 2ms/step - loss: 0.9984 - val_loss: 0.9996 - lr: 2.0000e-04\n","Epoch 8/100\n","86693/86693 [==============================] - 168s 2ms/step - loss: 0.9983 - val_loss: 1.0037 - lr: 2.0000e-04\n","Epoch 9/100\n","86693/86693 [==============================] - 196s 2ms/step - loss: 0.9982 - val_loss: 1.0027 - lr: 2.0000e-04\n","Epoch 10/100\n","86676/86693 [============================>.] - ETA: 0s - loss: 0.9981\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","86693/86693 [==============================] - 216s 2ms/step - loss: 0.9981 - val_loss: 0.9988 - lr: 2.0000e-04\n","Epoch 11/100\n","86693/86693 [==============================] - 204s 2ms/step - loss: 0.9976 - val_loss: 0.9996 - lr: 4.0000e-05\n","Epoch 12/100\n","86693/86693 [==============================] - 210s 2ms/step - loss: 0.9975 - val_loss: 1.0006 - lr: 4.0000e-05\n","Epoch 00012: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947, 0.002944938011426812, 0.003306365791320265, 0.0033697184481581433, 2.7666044636553977e-05]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948, 0.021227531341382555, -0.0014506481512879255, -0.007203511587160261, -0.21983425573173565]\n","start training the data from 1960 to 2017\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_27\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_162 (Dense)           (None, 32)                2976      \n","                                                                 \n"," dense_163 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_164 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_165 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_166 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_167 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,689\n","Trainable params: 3,689\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","89202/89202 [==============================] - 230s 3ms/step - loss: 1.0003 - val_loss: 1.0031 - lr: 2.0000e-04\n","Epoch 2/100\n","89202/89202 [==============================] - 213s 2ms/step - loss: 0.9993 - val_loss: 1.0039 - lr: 2.0000e-04\n","Epoch 3/100\n","89202/89202 [==============================] - 207s 2ms/step - loss: 0.9994 - val_loss: 0.9999 - lr: 2.0000e-04\n","Epoch 4/100\n","89202/89202 [==============================] - 180s 2ms/step - loss: 0.9993 - val_loss: 1.0064 - lr: 2.0000e-04\n","Epoch 5/100\n","89202/89202 [==============================] - 168s 2ms/step - loss: 0.9993 - val_loss: 1.0023 - lr: 2.0000e-04\n","Epoch 6/100\n","89173/89202 [============================>.] - ETA: 0s - loss: 0.9993\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","89202/89202 [==============================] - 163s 2ms/step - loss: 0.9993 - val_loss: 1.0030 - lr: 2.0000e-04\n","Epoch 7/100\n","89202/89202 [==============================] - 158s 2ms/step - loss: 0.9992 - val_loss: 1.0018 - lr: 4.0000e-05\n","Epoch 8/100\n","89202/89202 [==============================] - 169s 2ms/step - loss: 0.9993 - val_loss: 1.0021 - lr: 4.0000e-05\n","Epoch 00008: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947, 0.002944938011426812, 0.003306365791320265, 0.0033697184481581433, 2.7666044636553977e-05, 0.001069931641804689]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948, 0.021227531341382555, -0.0014506481512879255, -0.007203511587160261, -0.21983425573173565, 0.005613187580069234]\n","start training the data from 1960 to 2018\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_28\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_168 (Dense)           (None, 32)                2976      \n","                                                                 \n"," dense_169 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_170 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_171 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_172 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_173 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,689\n","Trainable params: 3,689\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","91725/91725 [==============================] - 188s 2ms/step - loss: 1.0521 - val_loss: 1.0008 - lr: 2.0000e-04\n","Epoch 2/100\n","91725/91725 [==============================] - 203s 2ms/step - loss: 0.9994 - val_loss: 1.0021 - lr: 2.0000e-04\n","Epoch 3/100\n","91725/91725 [==============================] - 206s 2ms/step - loss: 0.9993 - val_loss: 0.9992 - lr: 2.0000e-04\n","Epoch 4/100\n","91725/91725 [==============================] - 204s 2ms/step - loss: 0.9993 - val_loss: 1.0024 - lr: 2.0000e-04\n","Epoch 5/100\n","91725/91725 [==============================] - 187s 2ms/step - loss: 0.9993 - val_loss: 1.0002 - lr: 2.0000e-04\n","Epoch 6/100\n","91702/91725 [============================>.] - ETA: 0s - loss: 0.9994\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","91725/91725 [==============================] - 239s 3ms/step - loss: 0.9994 - val_loss: 1.0003 - lr: 2.0000e-04\n","Epoch 7/100\n","91725/91725 [==============================] - 200s 2ms/step - loss: 0.9993 - val_loss: 1.0006 - lr: 4.0000e-05\n","Epoch 8/100\n","91725/91725 [==============================] - 202s 2ms/step - loss: 0.9993 - val_loss: 1.0022 - lr: 4.0000e-05\n","Epoch 00008: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947, 0.002944938011426812, 0.003306365791320265, 0.0033697184481581433, 2.7666044636553977e-05, 0.001069931641804689, 0.0013224930872204332]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948, 0.021227531341382555, -0.0014506481512879255, -0.007203511587160261, -0.21983425573173565, 0.005613187580069234, -0.016963555505612904]\n","start training the data from 1960 to 2019\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  downcast=downcast,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_29\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_174 (Dense)           (None, 32)                2976      \n","                                                                 \n"," dense_175 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_176 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_177 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_178 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_179 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,689\n","Trainable params: 3,689\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","94257/94257 [==============================] - 181s 2ms/step - loss: 1.0093 - val_loss: 1.0058 - lr: 2.0000e-04\n","Epoch 2/100\n","94257/94257 [==============================] - 177s 2ms/step - loss: 0.9986 - val_loss: 1.0048 - lr: 2.0000e-04\n","Epoch 3/100\n","94257/94257 [==============================] - 185s 2ms/step - loss: 0.9978 - val_loss: 1.0078 - lr: 2.0000e-04\n","Epoch 4/100\n","94257/94257 [==============================] - 189s 2ms/step - loss: 0.9971 - val_loss: 1.0009 - lr: 2.0000e-04\n","Epoch 5/100\n","94257/94257 [==============================] - 177s 2ms/step - loss: 0.9969 - val_loss: 1.0036 - lr: 2.0000e-04\n","Epoch 6/100\n","94257/94257 [==============================] - 191s 2ms/step - loss: 0.9968 - val_loss: 1.0012 - lr: 2.0000e-04\n","Epoch 7/100\n","94238/94257 [============================>.] - ETA: 0s - loss: 0.9966\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","94257/94257 [==============================] - 196s 2ms/step - loss: 0.9966 - val_loss: 1.0015 - lr: 2.0000e-04\n","Epoch 8/100\n","94257/94257 [==============================] - 195s 2ms/step - loss: 0.9961 - val_loss: 1.0028 - lr: 4.0000e-05\n","Epoch 9/100\n","94257/94257 [==============================] - 216s 2ms/step - loss: 0.9961 - val_loss: 1.0035 - lr: 4.0000e-05\n","Epoch 00009: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947, 0.002944938011426812, 0.003306365791320265, 0.0033697184481581433, 2.7666044636553977e-05, 0.001069931641804689, 0.0013224930872204332, -0.003086866090181939]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948, 0.021227531341382555, -0.0014506481512879255, -0.007203511587160261, -0.21983425573173565, 0.005613187580069234, -0.016963555505612904, 0.0021439675914139977]\n","start training the data from 1960 to 2020\n","Model: \"sequential_30\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_180 (Dense)           (None, 32)                2976      \n","                                                                 \n"," dense_181 (Dense)           (None, 16)                528       \n","                                                                 \n"," dense_182 (Dense)           (None, 8)                 136       \n","                                                                 \n"," dense_183 (Dense)           (None, 4)                 36        \n","                                                                 \n"," dense_184 (Dense)           (None, 2)                 10        \n","                                                                 \n"," dense_185 (Dense)           (None, 1)                 3         \n","                                                                 \n","=================================================================\n","Total params: 3,689\n","Trainable params: 3,689\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","96828/96828 [==============================] - 237s 2ms/step - loss: 0.9995 - val_loss: 1.0000 - lr: 2.0000e-04\n","Epoch 2/100\n","96828/96828 [==============================] - 220s 2ms/step - loss: 0.9993 - val_loss: 1.0010 - lr: 2.0000e-04\n","Epoch 3/100\n","96828/96828 [==============================] - 213s 2ms/step - loss: 0.9993 - val_loss: 1.0001 - lr: 2.0000e-04\n","Epoch 4/100\n","96809/96828 [============================>.] - ETA: 0s - loss: 0.9993\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n","96828/96828 [==============================] - 209s 2ms/step - loss: 0.9993 - val_loss: 1.0007 - lr: 2.0000e-04\n","Epoch 5/100\n","96828/96828 [==============================] - 204s 2ms/step - loss: 0.9993 - val_loss: 1.0017 - lr: 4.0000e-05\n","Epoch 6/100\n","96828/96828 [==============================] - 210s 2ms/step - loss: 0.9993 - val_loss: 1.0022 - lr: 4.0000e-05\n","Epoch 00006: early stopping\n","[0.004740899494446116, -0.01990755362820562, -0.002979077242985184, 0.002401600746988808, 0.0013163587192990267, -0.0026339896388907214, 0.0018413891867173904, 0.001882953198110604, -0.004225838671306326, -0.0578501631211259, 0.003666529954870823, 0.0027282313834607885, 0.0006864159407380388, -0.0056849623207888555, 0.002422262921245144, 0.0032918917206739007, 0.003003728687805074, 0.0022142475301629716, 0.0031494099143339893, 0.0004294782260743091, 0.0014676364218989546, 3.114958323002792e-05, 0.000911152310269947, 0.002944938011426812, 0.003306365791320265, 0.0033697184481581433, 2.7666044636553977e-05, 0.001069931641804689, 0.0013224930872204332, -0.003086866090181939, 0.0010136277359955592]\n","[-0.01050932320707032, 0.008184161731769724, -0.010963071482562814, 0.010048646491933932, -0.012361203082080552, 0.0052061333399061605, 0.004987858110824583, 0.005196810589558898, -0.0033290998171371378, -0.20298985650468215, -0.0038676022208059546, 0.004160251232682044, -0.019190829695050926, -0.029757389490066233, 0.006735120519862248, -1.4995648611737522e-05, 0.011237149225918563, -0.014057248020752144, -0.024916534280856606, 0.004205930924860768, 0.014154109717855246, -0.01970229424243919, 0.008151022370043948, 0.021227531341382555, -0.0014506481512879255, -0.007203511587160261, -0.21983425573173565, 0.005613187580069234, -0.016963555505612904, 0.0021439675914139977, 0.006587768234081248]\n"]}]}]}