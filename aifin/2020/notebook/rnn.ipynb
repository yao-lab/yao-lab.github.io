{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-based RNN for generating Shakespear's poems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# implementation of a character-based RNN to generate sonnets\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.callbacks import LambdaCallback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename=\"shakespeare.txt\", seq_length=40, step=5):\n",
    "    '''\n",
    "    returns semi-redundant sequences their outputs \n",
    "    seq_length: number of characters in each sequence\n",
    "    step: gets every [step] sequence  \n",
    "    '''\n",
    "\n",
    "    # puts all data into text string  \n",
    "    file = open(filename, \"r\")\n",
    "    text = \"\"\n",
    "    for line in file:\n",
    "        line = line.lstrip(' ').rstrip(' ')\n",
    "        if line != '\\n' and not line[0].isdigit():\n",
    "            line.translate(str.maketrans('', '', string.punctuation))\n",
    "            text += line.lower()\n",
    "\n",
    "    # make char to index and index to char dictionary \n",
    "    characters = sorted(list(set(text)))\n",
    "    char_indices_dict = dict((c, i) for i, c in enumerate(characters))\n",
    "    indices_char_dict = dict((i, c) for i, c in enumerate(characters))\n",
    "    #print(char_indices_dict)\n",
    "\n",
    "    # makes every [step] char sequences of length seq_length and their outputs\n",
    "    sequences = []\n",
    "    next_chars = [] # next char that seq in sequences generates\n",
    "    #print(repr(text[len(text) - 200:]))\n",
    "    for i in range(0, len(text) - seq_length, step):\n",
    "        #print(i, seq, text[i : i + seq_length])\n",
    "        sequences.append(text[i : i + seq_length])\n",
    "        next_chars.append(text[i + seq_length])\n",
    "\n",
    "    # put sequences and outputs into np array\n",
    "    x = np.zeros((len(sequences), seq_length, len(characters)))\n",
    "    y = np.zeros((len(sequences), len(characters)), dtype=np.bool)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for t, char in enumerate(sequence):\n",
    "            x[i, t, char_indices_dict[char]] = 1\n",
    "        y[i, char_indices_dict[next_chars[i]]] = 1\n",
    "\n",
    "    return x, y, sequences, indices_char_dict, char_indices_dict, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_length: number of characters in each sequence\n",
    "#step: gets every [step] sequence  \n",
    "\n",
    "seq_length=40\n",
    "step=5    \n",
    "filename=\"shakespeare.txt\"\n",
    "# puts all data into text string  \n",
    "file = open(filename, \"r\")\n",
    "text = \"\"\n",
    "for line in file:\n",
    "    line = line.lstrip(' ').rstrip(' ')\n",
    "    if line != '\\n' and not line[0].isdigit():\n",
    "        line.translate(str.maketrans('', '', string.punctuation))\n",
    "        text += line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37}\n"
     ]
    }
   ],
   "source": [
    "# make char to index and index to char dictionary \n",
    "characters = sorted(list(set(text)))\n",
    "char_indices_dict = dict((c, i) for i, c in enumerate(characters))\n",
    "indices_char_dict = dict((i, c) for i, c in enumerate(characters))\n",
    "print(char_indices_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fire took heat perpetual,\\ngrowing a bath and healthful remedy,\\nfor men discased, but i my mistress' thrall,\\ncame there for cure and this by that i prove,\\nlove's fire heats water, water cools not love.\"\n"
     ]
    }
   ],
   "source": [
    "# makes every [step] char sequences of length seq_length and their outputs\n",
    "sequences = []\n",
    "next_chars = [] # next char that seq in sequences generates\n",
    "print(repr(text[len(text) - 200:]))\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    sequences.append(text[i : i + seq_length])\n",
    "    next_chars.append(text[i + seq_length])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put sequences and outputs into np array\n",
    "x = np.zeros((len(sequences), seq_length, len(characters)))\n",
    "y = np.zeros((len(sequences), len(characters)), dtype=np.bool)\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i, t, char_indices_dict[char]] = 1\n",
    "    y[i, char_indices_dict[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using rnn to build model\n",
    "def make_model(temperature=1.0):\n",
    "    x, y, sequences, indices_char_dict, char_indices_dict, text = preprocess()\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(100))\n",
    "    # add temperature (controls variance)\n",
    "    model.add(Lambda(lambda x: x / temperature))\n",
    "    model.add(Dense(len(indices_char_dict), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    earlyStopping = EarlyStopping(monitor='loss', patience=3, verbose=1, mode='auto')\n",
    "    model.fit(x, y, epochs=50, verbose=1, callbacks=[earlyStopping])\n",
    "    model.save('rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sonnet():\n",
    "    x, y, sequences, indices_char_dict, char_indices_dict, text = preprocess()\n",
    "\n",
    "    model = load_model('rnn.h5')\n",
    "    sonnet = []\n",
    "\n",
    "\n",
    "    seq = \"shall i compare thee to a summer's day?\\n\"\n",
    "    sonnet.append(seq)\n",
    "    for _ in range(13):\n",
    "        line = \"\"\n",
    "        for i in range(40):\n",
    "            x = np.zeros((1, len(seq), len(indices_char_dict)))\n",
    "            for t, index in enumerate(seq):\n",
    "                x[0, t, char_indices_dict[index]] = 1.\n",
    "\n",
    "            prediction = model.predict(x, verbose=0)[0]\n",
    "            index = np.argmax(prediction)\n",
    "            char = indices_char_dict[index]\n",
    "            line += char\n",
    "            seq = seq[1:] + char\n",
    "\n",
    "        sonnet.append(line)\n",
    "    return sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18727/18727 [==============================] - 15s 787us/step - loss: 2.6778 - accuracy: 0.2595\n",
      "Epoch 2/50\n",
      "18727/18727 [==============================] - 14s 730us/step - loss: 2.3007 - accuracy: 0.3369\n",
      "Epoch 3/50\n",
      "18727/18727 [==============================] - 13s 708us/step - loss: 2.1920 - accuracy: 0.3557\n",
      "Epoch 4/50\n",
      "18727/18727 [==============================] - 13s 706us/step - loss: 2.1518 - accuracy: 0.3636\n",
      "Epoch 5/50\n",
      "18727/18727 [==============================] - 13s 702us/step - loss: 2.1264 - accuracy: 0.3673\n",
      "Epoch 6/50\n",
      "18727/18727 [==============================] - 13s 697us/step - loss: 2.1087 - accuracy: 0.3675\n",
      "Epoch 7/50\n",
      "18727/18727 [==============================] - 13s 713us/step - loss: 2.0943 - accuracy: 0.3745\n",
      "Epoch 8/50\n",
      "18727/18727 [==============================] - 13s 685us/step - loss: 2.0785 - accuracy: 0.3806\n",
      "Epoch 9/50\n",
      "18727/18727 [==============================] - 13s 708us/step - loss: 2.0705 - accuracy: 0.3811\n",
      "Epoch 10/50\n",
      "18727/18727 [==============================] - 13s 705us/step - loss: 2.0638 - accuracy: 0.3835\n",
      "Epoch 11/50\n",
      "18727/18727 [==============================] - 13s 701us/step - loss: 2.0551 - accuracy: 0.3821\n",
      "Epoch 12/50\n",
      "18727/18727 [==============================] - 13s 700us/step - loss: 2.0454 - accuracy: 0.3882\n",
      "Epoch 13/50\n",
      "18727/18727 [==============================] - 13s 706us/step - loss: 2.0359 - accuracy: 0.3913\n",
      "Epoch 14/50\n",
      "18727/18727 [==============================] - 13s 683us/step - loss: 2.0310 - accuracy: 0.3919\n",
      "Epoch 15/50\n",
      "18727/18727 [==============================] - 13s 688us/step - loss: 2.0226 - accuracy: 0.3916\n",
      "Epoch 16/50\n",
      "18727/18727 [==============================] - 13s 696us/step - loss: 2.0090 - accuracy: 0.3978\n",
      "Epoch 17/50\n",
      "18727/18727 [==============================] - 13s 691us/step - loss: 1.9978 - accuracy: 0.3982\n",
      "Epoch 18/50\n",
      "18727/18727 [==============================] - 13s 700us/step - loss: 1.9833 - accuracy: 0.4022\n",
      "Epoch 19/50\n",
      "18727/18727 [==============================] - 13s 674us/step - loss: 1.9700 - accuracy: 0.4025\n",
      "Epoch 20/50\n",
      "18727/18727 [==============================] - 14s 728us/step - loss: 1.9540 - accuracy: 0.4130\n",
      "Epoch 21/50\n",
      "18727/18727 [==============================] - 13s 716us/step - loss: 1.9397 - accuracy: 0.4168\n",
      "Epoch 22/50\n",
      "18727/18727 [==============================] - 13s 706us/step - loss: 1.9269 - accuracy: 0.4148\n",
      "Epoch 23/50\n",
      "18727/18727 [==============================] - 13s 693us/step - loss: 1.9098 - accuracy: 0.4206\n",
      "Epoch 24/50\n",
      "18727/18727 [==============================] - 13s 696us/step - loss: 1.8960 - accuracy: 0.4231\n",
      "Epoch 25/50\n",
      "18727/18727 [==============================] - 13s 702us/step - loss: 1.8814 - accuracy: 0.4266\n",
      "Epoch 26/50\n",
      "18727/18727 [==============================] - 13s 701us/step - loss: 1.8681 - accuracy: 0.4373\n",
      "Epoch 27/50\n",
      "18727/18727 [==============================] - 13s 688us/step - loss: 1.8542 - accuracy: 0.4355\n",
      "Epoch 28/50\n",
      "18727/18727 [==============================] - 13s 687us/step - loss: 1.8349 - accuracy: 0.4413\n",
      "Epoch 29/50\n",
      "18727/18727 [==============================] - 13s 706us/step - loss: 1.8237 - accuracy: 0.4465\n",
      "Epoch 30/50\n",
      "18727/18727 [==============================] - 13s 701us/step - loss: 1.8086 - accuracy: 0.4488\n",
      "Epoch 31/50\n",
      "18727/18727 [==============================] - 13s 677us/step - loss: 1.7948 - accuracy: 0.4545\n",
      "Epoch 32/50\n",
      "18727/18727 [==============================] - 13s 695us/step - loss: 1.7780 - accuracy: 0.4561\n",
      "Epoch 33/50\n",
      "18727/18727 [==============================] - 13s 705us/step - loss: 1.7653 - accuracy: 0.4590\n",
      "Epoch 34/50\n",
      "18727/18727 [==============================] - 13s 704us/step - loss: 1.7491 - accuracy: 0.4621\n",
      "Epoch 35/50\n",
      "18727/18727 [==============================] - 13s 676us/step - loss: 1.7360 - accuracy: 0.4710\n",
      "Epoch 36/50\n",
      "18727/18727 [==============================] - 13s 703us/step - loss: 1.7244 - accuracy: 0.4730\n",
      "Epoch 37/50\n",
      "18727/18727 [==============================] - 13s 671us/step - loss: 1.7127 - accuracy: 0.4778\n",
      "Epoch 38/50\n",
      "18727/18727 [==============================] - 13s 689us/step - loss: 1.6992 - accuracy: 0.4808\n",
      "Epoch 39/50\n",
      "18727/18727 [==============================] - 13s 691us/step - loss: 1.6829 - accuracy: 0.4873\n",
      "Epoch 40/50\n",
      "18727/18727 [==============================] - 13s 695us/step - loss: 1.6763 - accuracy: 0.4922\n",
      "Epoch 41/50\n",
      "18727/18727 [==============================] - 13s 717us/step - loss: 1.6598 - accuracy: 0.4897\n",
      "Epoch 42/50\n",
      "18727/18727 [==============================] - 13s 698us/step - loss: 1.6480 - accuracy: 0.4950\n",
      "Epoch 43/50\n",
      "18727/18727 [==============================] - 13s 716us/step - loss: 1.6398 - accuracy: 0.4941\n",
      "Epoch 44/50\n",
      "18727/18727 [==============================] - 13s 686us/step - loss: 1.6199 - accuracy: 0.5048\n",
      "Epoch 45/50\n",
      "18727/18727 [==============================] - 13s 709us/step - loss: 1.6072 - accuracy: 0.5055\n",
      "Epoch 46/50\n",
      "18727/18727 [==============================] - 13s 673us/step - loss: 1.5986 - accuracy: 0.5089\n",
      "Epoch 47/50\n",
      "18727/18727 [==============================] - 13s 679us/step - loss: 1.5846 - accuracy: 0.5129\n",
      "Epoch 48/50\n",
      "18727/18727 [==============================] - 13s 711us/step - loss: 1.5677 - accuracy: 0.5186\n",
      "Epoch 49/50\n",
      "18727/18727 [==============================] - 13s 718us/step - loss: 1.5641 - accuracy: 0.5222\n",
      "Epoch 50/50\n",
      "18727/18727 [==============================] - 13s 677us/step - loss: 1.5478 - accuracy: 0.5234\n"
     ]
    }
   ],
   "source": [
    "make_model(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "\n",
      "when i for at i sathere sheed:\n",
      "the betur\n",
      "ye but thy swerek shene,\n",
      "and the of hen \n",
      "then amp tited o the piend,\n",
      "the then wha\n",
      "t i same king the belut the stepe doth d\n",
      "oth dothe,\n",
      "and the every shat i nother a\n",
      "nd therefring,\n",
      "thee hime is the beauty s\n",
      "hould a ave.\n",
      "but when i am a and dather \n",
      "ine,\n",
      "and the erought at lespere,\n",
      "and the\n",
      " of the with the withe but the rees,\n",
      "the\n",
      " worded thee in the withe beauty dite,\n",
      "t\n",
      "he will and the will the will the will g\n",
      "ive.\n",
      "when the will my semere ast love,\n",
      "w\n",
      "hene hou art when in thee fion as lively\n"
     ]
    }
   ],
   "source": [
    "sonnet=generate_sonnet()\n",
    "\n",
    "for line in sonnet:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
