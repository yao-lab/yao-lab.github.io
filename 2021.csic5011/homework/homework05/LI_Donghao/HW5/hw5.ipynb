{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "aadc15ccfa55b3c7752c8eb752e76ec48f8af494a24e97ed047d72d0a2edb086"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Homework 5\n",
    "Li Donghao 20653877\n",
    "\n",
    "## Problem 1\n",
    "### 1.a\n",
    "\n",
    "The code are follows:\n",
    "\n",
    "```matlab\n",
    "function [success] = problem1(p,r)\n",
    "    R = randn(20,20);\n",
    "    [U,S,V] = svds(R,10);\n",
    "    \n",
    "    A = U(:,1:r)*V(:,1:r)';\n",
    "\n",
    "    E0 = rand(20);\n",
    "    E = 1*abs(E0>(1-p));\n",
    "    X = A + E;\n",
    "\n",
    "    lambda = 0.25;\n",
    "    cvx_begin\n",
    "    variable L(20,20);\n",
    "    variable S(20,20);\n",
    "    variable W1(20,20);\n",
    "    variable W2(20,20);\n",
    "    variable Y(40,40) symmetric;\n",
    "    Y == semidefinite(40); \n",
    "    minimize(.5*trace(W1)+0.5*trace(W2)+lambda*sum(sum(abs(S)))); \n",
    "    subject to\n",
    "    L + S >= X-1e-5;\n",
    "    L + S <= X + 1e-5; Y == [W1, L';L W2];\n",
    "    cvx_end\n",
    "    % The difference between sparse solution S and E\n",
    "    disp('$\\—S-E\\— \\infty$:') ;\n",
    "    norm(S-E,'inf');\n",
    "    % The difference between the low rank solution L and A\n",
    "    disp('\\—A-L\\—') ;\n",
    "    norm(A-L);\n",
    "    success=norm(S-E,'inf')<1e-4;\n",
    "end\n",
    "\n",
    "```\n",
    "### 1.b \n",
    "\n",
    "Changing p from 0.1 to 0.5, I find the success rete will decrease.\n",
    "When p=0.1 succes rate=0.7,\n",
    "When p=0.15 succes rate=0.3,\n",
    "When p>0.15 succes rate=0.\n",
    "\n",
    "### 1.c \n",
    "Changing r from 1 to 5, I find the success rete will decrease.\n",
    "When r=1 succes rate=0.7,\n",
    "When r=2 succes rate=0.2,\n",
    "When r>2 succes rate=0.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problem 2 \n",
    "### 2.a\n",
    "\n",
    "The covariance matrix is shown in the code:\n",
    "```matlab\n",
    "V9=290*0.09+300*0.925*0.925+2;\n",
    "V9V5=0.925*300;\n",
    "V9V1=-0.3*290;\n",
    "True_sigma=[\n",
    "    291 , 290 , 290 , 290 , 0   , 0  , 0  , 0   , V9V1 , V9V1 ,\n",
    "    290 , 291 , 290 , 290 , 0   , 0  , 0  , 0   , V9V1 , V9V1 ,\n",
    "    290 , 290 , 291 , 290 , 0   , 0  , 0  , 0   , V9V1 , V9V1 ,\n",
    "    290 , 290 , 290 , 291 , 0   , 0  , 0  , 0   , V9V1 , V9V1 ,\n",
    "    0   , 0   , 0   , 0   , 301 , 300, 300, 300 , V9V5 , V9V5 ,\n",
    "    0   , 0   , 0   , 0   , 300 , 301, 300, 300 , V9V5 , V9V5 ,\n",
    "    0   , 0   , 0   , 0   , 300 , 300, 301, 300 , V9V5 , V9V5 ,\n",
    "    0   , 0   , 0   , 0   , 300 , 300, 300, 301 , V9V5 , V9V5 ,\n",
    "    V9V1, V9V1, V9V1, V9V1, V9V5,V9V5,V9V5, V9V5,V9    , V9-1 ,\n",
    "    V9V1, V9V1, V9V1, V9V1, V9V5,V9V5,V9V5, V9V5,V9-1  , V9   ,\n",
    "];\n",
    "```\n",
    "I have compared it with sample covariance matrix with sample size 1000 and found the difference is quite large.\n",
    "$||\\Sigma-\\hat\\Sigma||_F=51.4$ . This large gap may due to number of sample is small. If we increase the number of sample to 100000, $||\\Sigma-\\hat\\Sigma||_F=3.27$.\n",
    "\n",
    "### 2.b\n",
    "\n",
    "I computed largetest four eigenvectors using matlab.\n",
    "\n",
    "### 2.c\n",
    "\n",
    "Code for sovling the SDP problem is:\n",
    "\n",
    "```matlab\n",
    "function X=sPCA_(sigma,lambda)\n",
    "R = sigma;\n",
    "d = 10;\n",
    "e = ones(d,1);\n",
    "cvx_begin\n",
    "variable X(d,d) symmetric;\n",
    "X == semidefinite(d); \n",
    "minimize(-trace(R*X)+lambda*(e'*abs(X)*e)); \n",
    "subject to \n",
    "    trace(X)==1; \n",
    "cvx_end\n",
    "end\n",
    "```\n",
    "\n",
    "Comparing with PCA, when $\\lambda=0$, $||X_{PCA}-X_{SPCA}||_{inf}=8.8620e-12$ which means the results are similiar. When $\\lambda>0$, $||X_{PCA}-X_{SPCA}||_{inf}=7.4320e-4$ the results are slighly different. So the comclusion is that when $\\lambda=0$, Sparse PCA is the same with PCA. Which means my implimentation is correct.\n",
    "\n",
    "### 2.d,e\n",
    "\n",
    "Comparing the 1st 2nd 3rd and 4th principal components, I find the first two are similiar between $\\lambda=0$ and $\\lambda>0$. For the first pricipal component, $||X_{PCA}-X_{SPCA}||_{inf}=7.4320e-4$. And $||X_{PCA}-X_{SPCA}||_{inf}=0.0015$ for the second component.  but the 3rd and 4th principal components are quite different. ( $||X_{PCA}-X_{SPCA}||_{inf}=0.2826$ and $||X_{PCA}-X_{SPCA}||_{inf}=1.7568$ respectively) That may due to the Sparse PCA could handle sparse problems better and give accurate esimation. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}