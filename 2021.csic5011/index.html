<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
   <META http-equiv=Content-Type content="text/html; charset=gb2312">
   <title>CSIC 5011: Topological and Geometric Data Reduction and Visualization</title>
</head>
<body background="../images/crysback.jpg">

<!-- PAGE HEADER -->

<div class="Section1">
<table border="0" cellpadding="0" width="100%" style="width: 100%;">
      <tbody>
        <tr>

       <td style="padding: 0.75pt;" width="80" align="center">

      <p class="MsoNormal">&nbsp;<img width="64"
 id="_x0000_i1025"
 src="../images/HKUST_logo.jpg" alt="HKUST">
          </p>
       </td>
       <td style="padding: 0.75pt;">
      <p>
<span style="font-size: 18pt;">
<b><big>CSIC 5011: Topological and Geometric Data Reduction and Visualization<br>
   Spring 2020</big></b>
<br>
</p>
</td>
</tr>

</tbody>
</table>

<div class="MsoNormal" align="center" style="text-align: center;">
<hr size="2" width="100%" align="center">  </div>

<ul type="disc">

</ul>

<!-- COURSE INFORMATION BANNER -->

<table border="0" cellpadding="0" width="100%" bgcolor="#990000"
 style="background: rgb(153,0,0) none repeat scroll 0% 50%; width: 100%;">
      <tbody>

        <tr>
       <td style="padding: 2.25pt;">
      <p class="MsoNormal"><b><span
 style="font-size: 13.5pt; color: white;">Course Information</span></b></p>
       </td>
      </tr>

  </tbody>
</table>

<!-- COURSE INFORMATION -->

<!-- 
    <p style="margin-left: 0.5in;">
    <img height="200" src="boya_starry.png">
    <img height="200" src="boya_wreck.png">
    <img height="200" src="boya_twilight.png">
    </p>
-->

<h3>Synopsis (&#25688;&#35201;)</h3>
<p style="margin-left: 0.5in;">
<big> This course is open to graduates and senior undergraduates in applied mathematics, statistics, and engineering, who are interested in learning from data.
Students with other backgrounds such as life sciences are also welcome, provided you have certain maturity of mathematics. It will cover wide topics in geometric (principal component analysis and manifold learning, etc.) and topological data reduction (clustering and computational homology group, etc.). 
<br>
Prerequisite: linear and abstract algebra, basic probability and multivariate statistics, basic stochastic process (Markov chains), convex optimization; familiarity with Matlab, R, and/or Python, etc.
</big>
</p>


<h3>Reference (&#21442;&#32771;&#25945;&#26448;)</h3>
<p style="margin-left: 0.5in;">
 <big> <a href="https://yao-lab.github.io/book_datasci/"> [pdf download] </a> <img src="../images/new.jpg" height="40">
 </big>
 </p>
<br>
<p style="margin-left: 0.5in;">
 <big> Topological Data Analysis for Genomics and Evolution: Topology in Biology. By Raul Rabadan and Andrew J. Blumberg [<a href="https://www.amazon.com/gp/product/1107159547/ref=ox_sc_act_title_2?smid=ATVPDKIKX0DER&psc=1"> Amazon </a>] <img src="../images/new.jpg" height="40">
 </big>
 </p>	


<h3>Instructors: </h3>
<p style="margin-left: 0.5in;">
<big>
<em><a href="http://yao-lab.github.io/">Yuan YAO</a>  </em>
</big>
</p>

<h3>Time and Place:</h3>
<p style="margin-left: 0.5in;">
	<big><em>Wednesday 3:00-5:50pm, Zoom Webinar (<a href="https://hkust.zoom.com.cn/j/237158553"> link </a>) and LSK Rm1027 </em> <br> </big>
<!--- <big><em>This term we will be using Piazza for class discussion. The system is highly catered to getting you help fast and efficiently 
	from classmates and myself. Rather than emailing questions to the teaching staff, I encourage you to post your 
	questions on Piazza. If you have any problems or feedback for the developers, email team@piazza.com. <br>
Find our class page at: <a href="https://piazza.com/ust.hk/spring2019/csic5011/home">https://piazza.com/ust.hk/spring2019/csic5011/home</a></em></big> <br>
--->
</p>

<h3>Homework and Projects:</h3>

<p style="margin-left: 0.5in;">
<big><em> Weekly homeworks (no grader, but I'll read your submissions and give bonus credits), mini-projects, and a final major project. No final exam. </em>
<br>
	Email: <em> datascience.hw (add "AT gmail DOT com" afterwards) </em>
</big></p>

<!-- <h3>Teaching Assistant (&#21161;&#25945;):</h3>
    <p style="margin-left: 0.5in;">
    <big>SUN, Xinwei; XIONG, Jiechao; YUAN, Huizhuo; WU, Bingzhe. <br>
    Email:<em> statlearning_hw (add "@ 126 DOT com" afterwards) </em>
    </big>
    </p>
-->
				
<h3>Schedule (&#26102;&#38388;&#34920;)</h3>

<table border="1" cellspacing="0">
<tbody>

<tr>
<td align="left"><strong>Date</strong></td>
<td align="left"><strong>Topic</strong></td>
<td align="left"><strong>Instructor</strong></td>
<td align="left"><strong>Scriber</strong></td>
</tr>

<tr>
<td>02/19/2020, Wed </td>
<td>Lecture 01: Syllabus, Principal Component Analysis, and Multidimensional Scaling 
[<a href="slides/Lecture01_syllabus.pdf"> syllabus </a>] 
[<a href="slides/Lecture01_PCA&MDS.key"> PCA-MDS in keynote slides </a>]
[<a href=" "> video </a>]
<br>
<ul> [Reference]:
<li> To view .jpynb files below, you may try <a href="https://nbviewer.jupyter.org/"> [ Jupyter NBViewer] </a> </li> 
<li> PCA in iPython Notebook <a href="slides/pca.ipynb"> [ pca.ipynb ] </a> <a href="slides/pca.py"> [ pca.py ] </a> </li>
<li> MDS in Python <a href="http://scikit-learn.org/stable/auto_examples/manifold/plot_mds.html#sphx-glr-auto-examples-manifold-plot-mds-py"> [ scikit-learn MDS] </a> </li>
<!--<li> PCA with Logistic regression for digit classification: <a href="slides/pca_logistic.ipynb"> [ pca_logistic.ipynb ] </a> <a href="slides/pca_logistic.py"> [ pca_logistic.py ] </a> </li>
-->
</ul>
<ul>[Homework 1]:
<li> <a href="slides/homework01.pdf">Homework 1 [pdf]</a>. Just for fun, no grading; but I'll read your submissions and give your bonus credits. </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>
	
<tr>
<td>02/26/2020, Wed </td>
<td>Lecture 02: Horn's Parallel Analysis and Random Matrix Theory for PCA (Chap 3: 3)
[<a href="slides/Lecture02_RMT.pdf"> slides </a>] 
[<a href="https://hkust.zoom.us/rec/share/69BtKZzc2ntJZo31tkzwar95N4jVX6a80HVIq_oIyEtDrsN410lmqCH7p69e0LiE"> video </a>]
<br>

	<ul>[Reference]:
<li> Horn's Parallel Analysis in R: <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/paran.R"> [ paran.R ] </a> </li> 
<li> Parallel Analysis in Matlab: <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/papca.m"> [ papca.m ] </a> </li>
<li> Parallel Analysis in Python by LI, Zhen: <a href="slides/paPCA_curve.py"> [ paPCA_curve.py ] </a> <a href="slides/paPCA_image.py"> [ paPCA_image.py ] </a> </li>
<li> Marcenko-Pastur Law of Wishart matrices in Matlab: <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/mp.m"> [ mp.m ] </a> </li> 
<li> S&P500 dataset in class: <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/snp500.Rda"> [ snp500.Rda ] </a> <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/snp452-data.mat"> [ snp452-data.mat ] </a> <a href="http://math.stanford.edu/~yuany/course/data/snp500.txt"> [ snp500.txt ] </a> </li> 
<li>  <a href="http://www.icm2006.org/proceedings/Vol_I/17.pdf">[Johnstone06]</a> High dimensional statistical inference and random
matrices, ICM2006.</li>
<li>  <a href="https://arxiv.org/abs/0910.2120">Florent Benaych-Georges and Raj Rao Nadakuditi (2009) The eigenvalues and eigenvectors of finite, low rank perturbations of large random matrices.</a> </li>
<li>  <a href="https://link.springer.com/article/10.1007/BF02289447">[Parallel Analysis: Horn (1965) original paper]</a> 
<li>  <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.3813&rep=rep1&type=pdf">[Parallel Analysis: Buja-Eyuboglu (1992) with random permutation]</a> 
<li> <a href="https://www.biorxiv.org/content/early/2018/10/05/426239">[Raul Rabadan (2018)]</a>: applications of RMT in single cell data analysis</li>
</ul>
	
	<ul>[Homework 2]:
<li> <a href="homework/homework02.pdf">Homework 2 [pdf]</a>. Just for fun, no grading; but I'll read your submissions and give your bonus credits </li>
</ul>
	
</td>
<td>Y.Y.</td>
<td>LI, Zhen</td>
</tr>

<tr>
<td>03/04/2020, Wed </td>
<td>Lecture 03: Sample Mean as MLE? James-Stein Estimator and Shrinkages (Chap 3: 1-2) [<a href="slides/Lecture03_JSE.pdf"> slides </a>]<br>

	<ul>[Reference]:
<li> Comparing Maximum Likelihood Estimator and James-Stein Estimator in R: <a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/slides/JSE.R"> [ JSE.R ] </a> </li> 
</ul>

	<ul>[Homework 3]:
<li> <a href="homework/homework03.pdf">Homework 3 [pdf]</a>. Just for fun, no grading; but I'll read your submissions and give your bonus credits </li>
</ul>
	
</td>
<td>Y.Y.</td>
<td></td>
</tr>

	<tr>
<td>03/11/2020, Wed </td>
<td>Lecture 04: Random Projections, Johnson-Lindenstrauss Lemma, and Applications in Compressed Sensing etc. (Chap 2) <a href="slides/Lecture04_RP.pdf">[ Lecture04.pdf ]</a><br>
<ul>[Reference]:
	<li> Joseph Salmon's lecture on Johnson-Lindenstrauss Theory <a href="slides/JLlemma.pdf"> [ JLlemma.pdf ] </a> </li>
	<li> Random Projections in Scikit-learn: [<a href="https://scikit-learn.org/stable/modules/random_projection.html"> link </a>]</li> 
</ul>
	<ul>[Homework 4]:
<li> <a href="homework/homework04.pdf">Homework 4 [pdf]</a>. Just for fun, no grading; but I'll read your submissions and give your bonus credits </li>
</ul>

</td>
<td>Y.Y.</td>
<td></td>
</tr>
	<tr>
<td>03/18/2020, Wed </td>
<td>Lecture 05: SDP Relaxations: Robust PCA, Sparse PCA, and MDS with Uncertainty <a href="slides/Lecture05_SDP.pdf">[ slides ]</a><br>
<ul>[Reference]:
<li> You need Matlab <a href="http://cvxr.com/cvx/">CVX</a> optimization toolbox to run the following demo codes.
<li> Robust PCA demo: <a href="slides/testRPCA.m"> [ testRPCA.m ] </a> </li>
<li> Robust PCA via ADMM by Stephen Boyd et al.: [<a href="http://web.stanford.edu/~boyd/papers/prox_algs/matrix_decomp.html"> link </a>] </li>
<li> Robust PCA via ADMM in Python <a href="https://jeremykarnowski.wordpress.com/2015/08/31/robust-principal-component-analysis-via-admm-in-python/"> [ weblink ] </a> </li>
<li> Sparse PCA demo: <a href="slides/testSPCA.m"> [ testSPCA.m ] </a> </li>
<li> Sparse PCA in Python <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html"> [ sklearn ] </a></li>
<li> Sensor Network Localization in Matlab: this old link is broken <a href="http://www.math.nus.edu.sg/~mattohkc/SNLSDP.html"> [ SNLSDP ] </a>! But here is a new link [<a href="https://github.com/AlasGarn/CSIC5011_prj/tree/master/prj1/SNLSDP-0"> SNLSDP-0 </a>] from previous CSIC5011, 2017. </li>
<li> Sensor Network Localization with Facial Reduction in Matlab: <a href="http://www.math.uwaterloo.ca/~hwolkowi//henry/reports/ABSTRACTS.html#krislockwolkSNL"> [ SNLSDPclique ]</a></li>
<li> Teng ZHANG's Tyler's M-estimator <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/tyler_m_estimator.m"> [ Matlab: tyler_m_estimator.m ] </a></li>
<li> Duembgen, Nordhausen and Schuhmacher (2016): R package for M-scatter estimates <a href="https://cran.r-project.org/web/packages/fastM/index.html"> [ R package fastM ] </a></li>
	</ul>
	<ul>[Homework 5]:
<li> <a href="homework/homework05.pdf">Homework 5 [pdf]</a>. Just for fun, no grading; but I'll read and give bonus credits if you submitted. </li>
</ul>

</td>
<td>Y.Y.</td>
<td></td>
</tr>
	
	<tr>
<td>03/25/2020, Wed </td>
<td> Seminars and Mini-Project 1 <a href="project1/project1.pdf">[ project1.pdf ]</a>  <br>
	
	<ul>[ Title ]: <B>Accelerated Outlier Detection in Low-Rank and Structured Data: Robust PCA and Extensions </B> [<a href="slides/CAI_HanQin_talk.pdf"> slides </a>]
	<li>[ Speaker ]: <a href="https://www.math.ucla.edu/~hqcai/">HanQin CAI</a>, University of California at Los Angeles </li>
	<li>[ Abstract ]: We study robust PCA for the fully observed setting, which is about separating a low rank matrix L and a sparse matrix S from their sum D=L+S. In this talk, a new algorithm, dubbed accelerated alternating projections, is introduced for robust PCA which significantly improves the computational efficiency of the existing non-convex algorithms. Exact recovery guarantee has been established which shows linear convergence of the proposed algorithm. Empirical performance evaluations confirm the advantage of our algorithm over other state-of-the-art algorithms for robust PCA. Furthermore, we extend our method to the low-rank Hankel matrix, with its application to the spectrally sparse signals.
		</li>
	<li>[ Bio ]: HanQin Cai is an Assistant Adjunct Professor in the Department of Math at UCLA. He earned his Ph.D. degree from the University of Iowa in 2018, under guidance of Professor Jian-Feng Cai and Prof. Weiyu Xu. His research interests lie at image processing, data analysis, optimization, and machine learning. Currently, he is focusing the projects of outlier detection and zero-order optimization.
		</li>
	</ul>
	
	<ul>[ Title ]: <B> Online robust matrix factorization for dependent data streams </B>[<a href="slides/LYU_Hanbaek_talk.pdf"> slides </a>]
	<li>[ Speaker ]: <a href="https://hanbaeklyu.com/">Hanbaek Lyu</a>, University of California at Los Angeles </li>
	<li>[ Abstract ]: Online Robust Matrix Factorization (ORMF) algorithms seek to learn a reduced number of latent features as well as outliers from streaming data sets. It is important to understand stability of online algorithms for dependent data streams since these are often generated by Markov chain Monte Carlo (MCMC) algorithms, but rigorous convergence analysis of most online algorithms were limited to independently obtained data samples. In this talk, we propose an algorithm for ORMF and prove its almost sure convergence to the set of critical points of the expected loss function, even when the data matrices are functions of some underlying Markov chain satisfying a mild mixing condition. We illustrate our results through dictionary learning and outlier detection problem for images and networks. 
		</li>
	<li>[ Bio ]: Hanbaek Lyu is a Hedrick Assistant Professor in the Department of Math at UCLA. He earned his Ph.D. degree from the Ohio State University in 2018, under guidance of Professor David Sivakoff. His research interests lie at probability, combinatorics, complex systems, and machine learning. Recently, he is focusing the projects on online optimization algorithms and dictionary learning problems on networks. 
		</li>
	</ul>
	<ul> [<a href="https://hkust.zoom.us/rec/share/-5YycY7p_0VOTKPqsE7eVq54N6e1T6a8gyVL_fJYzxz9S67r1HpbSdYP7N4p24jD"> video </a>]
	</ul>
	
<ul>[Project 1 Report Repository] 		<img src="../images/new.jpg" height="40">
	<li> GitHub Repository for reports of Project 1 
		<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1"> [ GitHub ] </a>
	<p>
	</li>
	<li> 01. <B> CAO, Yang and ZENG, Wenqi.</B>
		<br> Dimension Reduction and Classification on Hand-written Digits.
	 	<br> 
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project1/CaoZeng/CSIC%205011%20Project%201_poster_CaoYang%26ZengWenqi.pdf"> poster </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project1/CaoZeng/"> source (.py) </a>] 
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.peer_review/CAO_Yang/"> peer review </a>]
	<p>
	</li>
	<li> 02. <B> CHEN, Zhixian and WU, Yue. </B> 
		<br> Explore NIPS papers dataset. 
		<br>
		[<a href="project1/ChenWu/CSIC5011_Project1__Explore_NIPS_dataset.pdf"> poster </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project1/ChenWu/nips_paper.ipynb"> source (.ipynb) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.peer_review/Chen_Wu/"> peer review </a>]
	<p>
	</li>
	<li> 03. <B>CHEN, Zhenghui.</B> 
		<br> Visualization and Classification on Finance Data.
		<br> 
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project1/ChenZH/Mini-Project%201.pdf"> poster (pdf) </a>]
		[<a href="project1/ChenZH/project1.py"> source (.py) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.peer_review/CHEN_Zhenghui/"> peer review </a>]
	<p>
	</li>
	<li> 04. <B>José Vinícius de Miranda Cardoso, Yixin Men, Shunkang Zhang.</B> 
		<br> Learning Stock Networks with Robust PCA. 
		<br>
		[<a href="project1/JoseMenZhang/submitted-poster.pdf"> poster (pdf) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/JoseMenZhang/sp500.ipynb"> source (ipynb) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.peer_review/Jose/"> peer review </a>]		
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.rebuttal/jose-yixin-shukang_rebuttal.docx"> rebuttal </a>]		
		<p>
	</li>
	<li> 05. <B> Neel Kanth KUNDU and Avik Kumar Das</B>. 
		<br> Performance Improvement of FNN based Image Classification using PCA.
		<br>
		[<a href="project1/KunduDas/Kundu_Das_Project1_final_v2.pdf"> report </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/KunduDas/"> source </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.peer_review/Kunduh/"> peer review </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.rebuttal/Kundu_Das_Rebuttal_Project-1.docx"> rebuttal </a>]	
		<p>
	</li>
	<li> 06. <B>WONG, Kwan Long Kyle.</B> 
		<br>
		Visualizing Random Forest Classification for Breast Cancer Diagnosis. 
		<br>
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project1/Wong/CSIC5011-Project%201-%20WONG%2C%20Kwan%20Long%20Kyle%20Poster%201.pdf"> poster (pdf) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project1/Wong/CSIC5011%20Mini-Project%20-%20Wong%2C%20Kwan%20Long%20Kyle.ipynb"> source (ipynb) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.peer_review/Wong/"> peer review </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.rebuttal/Wong_Rebuttal.docx"> rebuttal </a>]	
		<p>
	</li>
	<li> 07. <B>YANG, Yingxi and Hanli HUANG</B>. 
		<br> Deciphering Regional Variations Using SNPs. 
		<br>
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/YangHuang"> poster (pptx) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/YangHuang/SNP_CSIC5011_project.ipynb"> source (ipynb) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.peer_review/Yang/"> peer review </a>]	
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project1/0.rebuttal/HUANG-Hanli_YANG-Yingxi_Rebuttal.docx"> rebuttal </a>]	
		<p>
	</li>
	</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>
	
<!---




	
<tr>
<td>03/01/2019, Fri </td>
<td>Lecture 07: Lasso, Nonconvex shrinkage, differential inclusions (Chap 3: 1-2)<a href="https://yao-lab.github.io/book_datasci/">[ new lecture notes updated ]</a><br>
<ul>[Reference]:
<li> Comparing Maximum Likelihood Estimator and James-Stein Estimator in R: <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/JSE.R"> [ JSE.R ] </a> </li> 
</ul>
<ul>[Homework 3]:
<li> <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/homework03.pdf">Homework 3 [pdf]</a>. Just for fun, no grading. </li>
</ul>
<ul>[Project 1 Report Repository]
<li> GitHub Repository for reports of Project 1 <a href="project1"> [ GitHub ] </a></li>
	<li> 01. HAN, Xu. PCA analysis and prediction on return of SNP500 dataset. 
		[<a href="project1/01.HANXu_poster.pdf"> poster </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2019_csic5011/project1/01.HANXu_source.ipynb"> source (ipynb) </a>][<a href="project1/Project1_Report01_Review.docx"> peer review (docx) </a>]
	</li>
	<li> 02. LEI, Kang. Characters and Events Analysis of Journey to the West by PCA and SPCA. 
		[<a href="project1/02.LEIKang_report.pdf"> poster </a>]
		[<a href="project1/02.LEIKang_source_PCA%codes%for%Journey%to%the%West.py"> Python PCA </a>]
		[<a href="project1/02.LEIKang_source_SPCA%codes%for%Journey%to%the%West.py"> Python SPCA </a>]
		[<a href="project1/Project1_Report02_Review.docx"> peer review (docx) </a>]
	</li>
	<li> 03. LUI, Go Nam. Principle Component Analysis on Finance Data. 
		[<a href="project1/03.LuiGoNam_poster.pdf"> poster (pdf) </a>]
		[<a href="project1/03.LuiGoNam_poster.pptx"> poster (pptx) </a>]
		[<a href="project1/03.LUIGoNam_source.zip"> source (zip) </a>]
		[<a href="project1/Project1_Report03_Review.docx"> peer review (docx) </a>]
	</li>
	<li> 04. SHEN, Xinwei and YANG, Yunfei. Dimension reduction methods to improve image classification. 
		[<a href="project1/04.SHENXinwei-YANGYunfei_report.pdf"> report </a>]
		[<a href="project1/04.SHENXinwei-YANGYunfei_poster+.pdf"> poster revision </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2019_csic5011/project1/04.SHENXinwei-YANGYunfei_source"> source </a>]
		[<a href="project1/Project1_Report04_Review.docx"> peer review (docx) </a>]
		[<a href="project1/Project1_Rebuttal04_SHENXinwei-YANGYunfei.docx"> rebuttal (docx) </a>]
	</li>
	<li> 05. SUN, Jing and LUO, Shuang. Principal Component Analysis of Crime Data in USA.
		[<a href="project1/05.SUNJing-LUOShuang_report.pdf"> report </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2019_csic5011/project1/05.SUNJing-LUOShuang_source"> source </a>]
		[<a href="project1/Project1_Report05_Review.docx"> peer review (docx) </a>]
	</li>
	<li> 06. WANG, Meilan and LIU, Di. Finance Data PCA, Parallel Analysis. 
		[<a href="project1/06.WANGMeilan-LIUDi_poster.pdf"> poster (pdf) </a>]
		[<a href="project1/06.WANGMeilan-LIUDi_poster.pptx"> poster (pptx) </a>]
		[<a href="project1/06.WANGMeilan-LIUDi_source_MatLab_DiLIU.docx"> source (matlab) </a>]
		[<a href="project1/06.WANGMeilan-LIUDi_source_MeilanWANG.ipynb"> source (ipynb) </a>]
		[<a href="project1/Project1_Report06_Review.docx"> peer review (docx) </a>]
	</li>
	<li> 07. Ziming WU, Feng HAN, and Song LIU. Whether and why are people feeling happy? Mining Affective Events Based on Text-based Information. 
		[<a href="project1/07.WUZiming-HANFeng-LIUSong_poster.pdf"> poster </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2019_csic5011/project1/07.WUZiming-HANFeng-LIUSong_source"> source </a>]
		[<a href="project1/Project1_Report07_Review.docx"> peer review (docx) </a>]
	</li>
	<li> 08. YU, Zhijie. Dream of Red Mansion Analysis. 
		[<a href="project1/08.YUZhijie_report.pdf"> poster </a>]
		[<a href="project1/08.YUZhijie_source.ipynb"> source (ipynb) </a>]
		[<a href="project1/Project1_Report08_Review.docx"> peer review (docx) </a>]
	</li>
	<li> 09. CHAN, Lok Chun. Realization of Recent Trends in Machine Learning Community in Recent Years by Pattern Mining of NIPS Words. 
		[<a href="project1/09.CHANLokChun_poster.pdf"> poster (pdf) </a>]
		[<a href="project1/09.CHANLokChun_poster.pptx"> poster (pptx) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2019_csic5011/project1/09.CHANLokChun_source"> source (ipynb) </a>]
		[<a href="project1/Project1_Report09_Review.docx"> peer review (docx) </a>]
	</li>
	<li> 10. LIANG, Zhicong. Exploring High Dimension Data with MDS, PCA, AutoEncoder and VAE.
		[<a href="project1/10.LIANG_Zhicong_poster.pdf"> poster (pdf) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2019_csic5011/project1/10.LIANG_Zhicong_source/"> source </a>]
	</li>
	<li> 11. CHENG, Wei. Dimension Reduction Visualization and Classification on Hand Writing Data.
		[<a href="project1/11.CHENG_Wei_poster.pdf"> poster (pdf) </a>]
		[<a href="https://github.com/wchengad/course_2019_spring/tree/master/CSIC5011/Project1"> Github link </a>]
	</li>
</ul>
<ul>[ Project 1 Open Peer Review ]
	<li> <a href="project1/project1_openreview.pdf"> Description </a> </li>
	<li> <B>Deadline: 11:59pm April 16 2019</B> </li>
</ul>
<ul>[ Project 1 Rebuttal ]
	<li> <a href="project1/project1_rebuttal.pdf"> Description </a> </li>
	<li> <B>Deadline: 11:59pm April 21 2019</B> </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>
	

<tr>
<td>03/08/2019, Fri </td>
<td>Lecture 08: Supervised PCA -- LDA and SIR <a href="https://yao-lab.github.io/book_datasci/">[ Chapter 1, Section 7 in new update on Mar 1, 2019 ]</a><br>
<ul>[Reference]:
<li> Dennis Cook, <span class="bibbook"> <a href="http://arxiv.org/pdf/0708.3774.pdf">Fisher Lecture: Dimensionality Reduction in Regression</a>. Statistical Science, 22(1):1-26, 2007. </span>
</li>
<li> Ker-Chau Li, <a href="http://www.tandfonline.com/doi/abs/10.1080/01621459.1991.10475035"> Sliced Inverse Regression for Dimension Reduction </a>. Journal of the American Statistical Association, 86(414):316-327, 1991 
</li>
<li> Wu, Liang, and Mukherjee. <span class="bibbook"> <a href="http://www2.stat.duke.edu/~km68/files/Wu-LSIR.pdf">Localized Sliced Inverse Regression</a>. NIPS 2009. <a href="http://www2.stat.duke.edu/~km68/lsir.htm"> [Matlab codes]</a></span>
</li>
<li> Jiang B and Liu JS. (2014) <span class="bibbook"> <a href="http://www.people.fas.harvard.edu/~junliu/SIRI/">Variable selection for general index models via sliced inverse regression</a>. Annals of Statistics, 42:1751-1786. <a href="http://www.people.fas.harvard.edu/~junliu/SIRI/SIRI.zip">[ R codes ]</a></span>
</li> 
<li> Wolfgang Hardle and Leopold Simar. Applied Multivariate Statistical Analysis. <span class="bibbook"> <a href="slides/SIR_chapter.pdf">Chapter 18.3: Sliced Inverse Regression</a>.</span>
</li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

	
<tr>
<td>03/15/2019, Fri </td>
<td>Lecture 10: Sparse PCA and MDS with Uncertainty (Chap 4: 5-7)<a href="https://yao-lab.github.io/book_datasci">[ new update on Sep 27, 2017 ]</a><br>
<ul>[Reference]:
<li> You need Matlab <a href="http://cvxr.com/cvx/">CVX</a> optimization toolbox to run the following demo codes.
<li> Robust PCA demo: <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/testRPCA.m"> [ testRPCA.m ] </a> </li>
<li> Sparse PCA demo: <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/testSPCA.m"> [ testSPCA.m ] </a> </li>
<li> Robust PCA via ADMM in Python <a href="https://jeremykarnowski.wordpress.com/2015/08/31/robust-principal-component-analysis-via-admm-in-python/"> [ weblink ] </a> </li>
<li> Sparse PCA in Python <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html"> [ sklearn ] </a></li>
<li> Sensor Network Localization in Matlab: <a href="http://www.math.nus.edu.sg/~mattohkc/SNLSDP.html"> [ SNLSDP ] </a> </li>
</ul>
<ul>[Homework 4]:
<li> <a href="slides/homework04.pdf">Homework 4 [pdf]</a>. Just for fun, no grading; but I'll read and give bonus credits if you submitted. </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>03/20/2019, Wed </td>
<td>Lecture 11: Project 1 and An Introduction to Libra: Linearized Bregman Algorithms in High Dimensional Statistics <br>
<ul>[ Reference ]:
<li> <a href="slides/project1.pdf">  Project 1 [pdf] </a>.  </li>
<li> <a href="slides/PKU_2018b.pdf">  Page 1-17: Introduction to Libra for high dimensional statistics [slides] </a>.  </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>03/22/2019, Wed </td>
<td>Lecture 12: Differential Inclusion Methods in High Dimensional Statistics <br>
<ul>[ Reference ]:
<li> <a href="slides/PKU_2018b.pdf">  Page 18-60: how does it work? [slides] </a>.  </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>


--->

<tr>
<td>04/01/2019, Wed </td>
<td>Lecture 06: Manifold Learning I: ISOMAP and LLE (with Modified LLE, LTSA) <a href="slides/Lecture06_ISOMAP-LLE.pdf">[ slides ]</a> <br>
<ul>[Reference]:
<li>  <a href="http://web.mit.edu/cocosci/isomap/isomap.html">[ISOMAP]</a>: Tenenbaum's website on science paper with datasets; 
</li>
<li>  <a href="https://www.cs.nyu.edu/~roweis/lle/">[LLE]</a>: Roweis' website on science paper; 
</li>
<li><cite>Zhang, Z. &amp; Wang, J. MLLE: Modified Locally Linear
Embedding Using Multiple Weights. </cite> [<a class="reference external" href="https://papers.nips.cc/paper/3132-mlle-modified-locally-linear-embedding-using-multiple-weights"> NIPS 2006 </a>]</li>
<li><cite>Zhang, Z. &amp; Zha, H. (2005) Principal manifolds and nonlinear
dimensionality reduction via tangent space alignment. 
	SIAM Journal on Scientific Computing. 26 (1): 313-338. </cite> 
	[<a href="https://doi.org/10.1137/S1064827502419154">doi:10.1137/s1064827502419154</a>] </li>
	</ul>
<ul>[Python]: 
<li> <a href="https://nbviewer.jupyter.org/url/github.com/yuany-pku/2017_CSIC5011/blob/master/slides/plot_mani_digits.ipynb"> plot_mani_digits.ipynb </a>: demo of digits in class </li>
<li> <a href="http://scikit-learn.org/stable/modules/manifold.html#manifold"> scikit-learn manifold module </a> </li>
</ul>
<ul>[Matlab]:
<li> <a href="https://yao-lab.github.io/data/IsomapR1/"> IsomapR1 </a>: isomap codes by Tennenbaum, de Silva (isomapII.m with sparsity, fast mex with dijkstra.cpp and fibheap.h </li>
</li> 
<li> <a href="https://yao-lab.github.io/data/lle.m"> lle.m </a>: lle with k-nearest neighbors
</li>
<li> <a href="https://yao-lab.github.io/data/kcenter.m"> kcenter.m </a>: k-center algorithm to find 'landmarks' in a metric space
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>04/08/2020, Wed </td>
<td>Lecture 07: Manifold Learning II: Hessian LLE, Laplacian Eigenmap, Diffusion Map, and Stochastic Neighbor Embedding <a href="slides/Lecture07_manifold2.pdf">[ slides ]</a><br>
<ul>[Homework 6]:
<li> <a href="homework/homework06.pdf">Homework 6 [pdf]</a>. Just for fun, no grading. </li>
</ul>
<ul>[Reference]:
<li><cite>Mikhail Belkin &amp; Partha Niyogi, Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering, Advances in Neural Information Processing Systems (NIPS) 14, 2001, p. 586-691, MIT Press</cite>
<a href="https://papers.nips.cc/paper/1961-laplacian-eigenmaps-and-spectral-techniques-for-embedding-and-clustering">
	[nips link] </a> </li>
<li>  <cite>Donoho, D. &amp; Grimes, C. Hessian eigenmaps: Locally
linear embedding techniques for high-dimensional data.
Proc Natl Acad Sci U S A.  100:5591 (2003).</cite> [<a href="http://www.pnas.org/content/100/10/5591.full">doi: 10.1073/pnas.1031596100</a>] </li>
<li> R. R. Coifman, S. Lafon, A. B. Lee, M. Maggioni, B. Nadler, F. Warner, and S. W. Zucker. Geometric diffusions as a tool for harmonic analysis and structure definition of data: Diffusion maps. PNAS 102 (21):7426-7431, 2005 <a href="http://www.pnas.org/content/102/21/7426.long"> [doi: 10.1073/pnas.0500334102] </a> </li>
<li> <cite>Nadler, Boaz; Stéphane Lafon; Ronald R. Coifman; Ioannis G. Kevrekidis (2005). <a href="http://www.wisdom.weizmann.ac.il/~nadler/Publications/dm_nips05.pdf">"Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker–Planck Operators"</a> <span>(PDF)</span> <i>in Advances in Neural Information Processing Systems (NIPS) 18, 2005</i>.</cite></li>
<li> <cite>Coifman, R.R.; S. Lafon. (2006). "Diffusion maps". <i>Applied and Computational Harmonic Analysis.</i> 21: 5–30. <a href="//doi.org/10.1016%2Fj.acha.2006.04.006">10.1016/j.acha.2006.04.006</a>.</cite></li>
<li> Stochastic Neighbor Embedding <a href="http://www.cs.toronto.edu/~hinton/absps/sne.pdf"> [ .pdf ] </a></li>
<li> Visualizing Data using t-SNE <a href="http://www.cs.toronto.edu/~hinton/absps/tsnefinal.pdf"> [ .pdf ] </a></li>
<li> A paper that relates SNE to Laplacian Eigenmaps <a href="http://www.cs.toronto.edu/~hinton/csc2535/readings/miguel.pdf"> [ .pdf ] </a></li>
<li> A helpful website: How to use t-SNE effectively? <a href="https://distill.pub/2016/misread-tsne/"> [ link ]</a></li>
</ul>
<ul>[Matlab]
<li> Matlab code to compare manifold learning algorithms <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/mani.m"> [ mani.m ] </a>: PCA, MDS, ISOMAP, LLE, Hessian LLE, LTSA, Laplacian, Diffusion (no SNE!)</li>
</ul>
<ul>[Python]: 
<li> <a href="https://nbviewer.jupyter.org/url/github.com/yuany-pku/2017_CSIC5011/blob/master/slides/plot_compare_methods.ipynb"> plot_compare_methods.ipynb </a>: demo in class </li>
<li> <a href="https://nbviewer.jupyter.org/url/github.com/yuany-pku/2017_CSIC5011/blob/master/slides/plot_mani_digits.ipynb"> plot_mani_digits.ipynb </a>: demo of digits in class </li>
<li> <a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.locally_linear_embedding.html#sklearn.manifold.locally_linear_embedding"> scikit-learn manifold LLE </a>: PCA/MDS, ISOMAP, LLE/MLLE, Hessian, LTSA, Laplacian (Spectral), t-SNE (no Diffusion map)</li>
<li> <a href="http://lvdmaaten.github.io/tsne/"> Laurens van der Maaten's website for t-SNE codes </a></li>
	</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>04/15/2020, Wed </td>
<td>Lecture 08: Random Walk on Graphs and Spectral Graph Theory: Perron-Frobenius (PageRank), Fiedler (Algebraic Connectivity), Cheeger Inequality (Spectral bi-partition), Lumpability (Spectral Clustering) and Transition Path Theory (Semi-supervised Learning) [<a href="slides/Lecture08_graph.pdf"> slides </a>]  <br>
<ul>[Homework 7]:
<li> <a href="homework/homework07.pdf">Homework 7 [pdf]</a>. Just for fun, no grading. </li>
</ul>
<ul>[Reference]:
<li> Amy N. Langville and Carl D. Meyer's book: <a href="http://geza.kzoo.edu/~erdi/patent/langvillebook.pdf"> Google's PageRank and Beyond </a> </li>
<li> Jim Demmel's courseweb at UC Berkeley for Fiedler Theory and Graph Bipartition: <a href="https://people.eecs.berkeley.edu/~demmel/cs267/lecture20/lecture20.html"> [ link ] </a></li>
<li> T. Buehler, M. Hein. <span class="bibbook"> <a href="http://www.ml.uni-saarland.de/Publications/BueHei-pSpectralClustering2009.pdf">Spectral Clustering based on the graph p-Laplacian</a>. Proceedings of the 26th International Conference on Machine Learning (ICML 2009), 81-88. </span> 
</li>
<li> James R. Lee, Shayan Oveis Gharan, Luca Trevisan. <span class="bibbook"> <a href="https://arxiv.org/abs/1111.1055">Multi-way spectral partitioning and higher-order Cheeger inequalities</a>. Proceeding STOC'12 Proceedings of the forty-fourth annual ACM symposium on Theory of computing, Pages 1117-1130. arXiv:1111.1055. </span>
</li>
<li> Weinan E, Jianfeng Lu, and Yuan Yao. 
<span class="bibbook"> <a href="http://arxiv.org/abs/1204.6376"> The Landscape of Complex Networks: Critical Nodes and A Hierarchical Decomposition. </a>
Methods and Applications of Analysis, special issue in honor of Professor Stanley Osher on his 70th birthday, 20(4):383-404, 2013.
</li>
</ul>

</td>
<td>Y.Y.</td>
<td></td>
</tr>

	<tr>
<td>04/22/2020, Wed </td>
<td>Lecture 09: Introduction to Topological Data Analysis. 
[<a href="slides/Lecture09_TDA.pdf"> slides </a>] 
[<a href="https://hkust.zoom.us/rec/share/1JR7N5Xhq1JJa9LvxnzmAYkqJ4_Caaa81HJM8_UIyUrVGKlXiMJxa-4MWNrYPG4Y"> video </a>]
<br>
<ul>[Reference]:
	<li>
<B>Topological Methods for Exploring Low-density States in Biomolecular Folding Pathways.</B>
<br>
Yuan Yao, Jian Sun, Xuhui Huang, Gregory Bowman, Gurjeet Singh, Michael Lesnick, <a href="http://folding.stanford.edu/Pande/Main">Vijay Pande</a>, <a href="http://www-graphics.stanford.edu/~guibas/ ">Leonidas Guibas</a> and  <a href="http://math.stanford.edu/~gunnar/">Gunnar Carlsson</a>.
<br>
 <i>J. Chem. Phys</i>. <B>130</B>, 144115 (2009).
<br>
[<a href="publications/RNA_mapper_JCP2009.pdf">pdf</a>][<a href="http://link.aip.org/link/?JCP/130/144115">Online Publication</a>][<a href="https://simtk.org/home/rna-mapper">SimTK Link: Data and Mapper Matlab Codes</a>] [Selected by <a href="http://www.vjbio.org/">Virtual Journal of Biological Physics Research, 04/15/2009</a>]. 
<p>
	</li>

	<li>
<B>Structural insight into RNA hairpin folding intermediates.</B>
<br>
Bowman, Gregory R., <a href="http://csb.stanford.edu/~xhuang/">Xuhui Huang</a>, Yuan Yao, <a href="http://www.stanford.edu/~sunjian/">Jian Sun</a>, <a href="http://math.stanford.edu/~gunnar/">Gunnar Carlsson</a>, <a href="http://www-graphics.stanford.edu/~guibas/ ">Leonidas Guibas</a> and <a href="http://folding.stanford.edu/Pande/Main">Vijay Pande</a>. 
<br>
<i>Journal of American Chemistry Society</i>, 2008, 130 (30): 9676-9678. 
<br> 
[<a href="http://pubs.acs.org/cgi-bin/abstract.cgi/jacsat/2008/130/i30/abs/ja8032857.html">link</a>]
<p>
	</li>


	<li> <B> Single-cell topological RNA-seq analysis reveals insights into cellular differentiation and development. </B>
<br>
Abbas H Rizvi, Pablo G Camara, Elena K Kandror, Thomas J Roberts, Ira Schieren, Tom Maniatis & Raul Rabadan.
<br>
<i>Nature Biotechnology</i>. 2017 May. doi:10.1038/nbt.3854
<p>
	</li>

	<li>
<B>Spatiotemporal genomic architecture informs precision oncology in glioblastoma.</B>
<br> Lee JK, Wang J, Sa JK, Ladewig E, Lee HO, Lee IH, Kang HJ, Rosenbloom DS, Camara PG, Liu Z, van Nieuwenhuizen P, Jung SW, Choi SW, Kim J, Chen A, Kim KT, Shin S, Seo YJ, Oh JM, Shin YJ, Park CK, Kong DS, Seol HJ, Blumberg A, Lee JI, Iavarone A, Park WY, Rabadan R, Nam DH.
<br>
<I>Nat Genet.</I> 2017 Apr. doi: 10.1038/ng.3806.
<p>
	</li>
<li> A Python Implementation of Mapper <a href="https://github.com/szairis/sakmapper"> [ sakmapper ] </a> in single cell data analysis. 
<li> Single Cell TDA <a href="https://github.com/pcamara/scTDA"> [ scTDA ] </a> with <a href="https://github.com/pcamara/scTDA/blob/master/doc/scTDA%20Tutorial.html"> [ tutorial in html ]</a>
<li> A Java package for persistent homology and barcodes: <span class="bibbook"> <a href="https://github.com/appliedtopology/javaplex/wiki/Tutorial">Javaplex Tutorial</a>. </span>
<p>
	</li>

	<li>
<B>Persistent Homology Analysis of Biomolecular Data</B> 
		<br>
	Guo-Wei Wei. <br>
		<a href="http://users.math.msu.edu/users/wei/SIAM_News2017.pdf"> SIAM News 2017</a>
<br><p>
	</li>


	<li> <B> Topological Data Analysis Generates High-Resolution, Genome-wide Maps of Human Recombination. </B>
<br>
Pablo G. Camara, Daniel I.S. Rosenbloom, Kevin J. Emmett, Arnold J. Levine, Raul Rabadan.
<br>
<i>Cell Systems</i>. 2016 June. doi: 10.1016/j.cels.2016.05.008.
<p>
	</li>

	<li> <B> Topology of viral evolution.</B>
<br>
Chan JM, Carlsson G, Rabadan R.
<br>
<i></i>Proc Natl Acad Sci USA</i> 2013 Oct 29. doi: 10.1073/pnas.1313480110.
<p>
	</li>

	<li> Robert Ghrist's monograph on applied Topology <B> <a href="https://www.math.upenn.edu/~ghrist/notes.html"> Elementary Applied Topology </a> </B> 
<p>
	</li>
	</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>


<tr>
<td>04/29/2020, Wed </td>
<td>Lecture 10: Hodge Theory and Applications: Social Choice, Crowdsourced Ranking, and Game Theory 
[<a href="slides/Lecture10_Hodge.pdf"> slides </a>]
[<a href="https://hkust.zoom.us/rec/share/xMV1HaGh72BIfYXv5WbBeY0RLpu6X6a8hygZ_fsKz05MuW5XscI9M5NoiVFJjsta"> video </a>]
<br>
<ul>[ Reference ]:
<li>
<B>Statistical Ranking and Combinatorial Hodge Theory.</B>
<br>
<a href="http://graphics.stanford.edu/projects/lgl/person.php?id=xiaoyej">Xiaoye Jiang</a>, <a href="https://www.stat.uchicago.edu/~lekheng/">Lek-Heng Lim</a>, Yuan Yao and <a href="http://www.stanford.edu/~yyye/">Yinyu Ye</a>. 
<br>
<i>Mathematical Programming</i>, Volume 127, Number 1, Pages 203-244, 2011. 
<br>
[<a href="http://math.stanford.edu/~yuany/publications/HodgeRank.MathProg.B.2010.pdf">pdf</a>][<a href=" http://arxiv.org/abs/0811.1067"> arxiv.org/abs/0811.1067</a>][<a href="http://math.stanford.edu/~yuany/publications//MathProg.zip"> Matlab Codes</a>]
<p>
</li>
<li> 
<B>Flows and Decompositions of Games: Harmonic and Potential Games</B>
<br>
Ozan Candogan, Ishai Menache, Asuman Ozdaglar, and Pablo A. Parrilo
<br> 
<a href=""> </a>Mathematics of Operations Research, 36(3): 474 - 503, 2011
<br>
[<a href="https://arxiv.org/abs/1005.2405">arXiv.org/abs/1005.2405</a>][<a href="http://pubsonline.informs.org/doi/abs/10.1287/moor.1110.0500"> doi:10.1287/moor.1110.0500 </a>]
<p> 
</li>
<li> 
<B>HodgeRank on Random Graphs for Subjective Video Quality Assessment.</B>
<br>
Qianqian Xu, Qingming Huang, Tingting Jiang, Bowei Yan, Weisi Lin, and Yuan Yao.
<br> 
<a href=""> </a> IEEE Transactions on Multimedia, 14(3):844-857, 2012 
<br>
[<a href="http://math.stanford.edu/~yuany/publications/TMM12-final.pdf">pdf</a>][<a href="http://math.stanford.edu/~yuany/publications/BatchHodge.zip"> Matlab codes in zip </a>]
<p> 
</li>
<li>
<B>Robust Evaluation for Quality of Experience in Crowdsourcing.
</B>
<br>
Qianqian Xu, Jiechao Xiong, Qingming Huang, and Yuan Yao
<br> 
<a href="http://www.acmmm13.org/"> <I>ACM Multimedia 2013</I>.</a>
<br>
[<a href="publications/ACMMM13.pdf">pdf</a>]
<p> 
</li>
<li>
<B>Online HodgeRank on Random Graphs for Crowdsourceable QoE Evaluation.
</B>
<br>
Qianqian Xu, Jiechao Xiong, Qingming Huang, and Yuan Yao
<br> 
<I>IEEE Transactions on Multimedia</I>, 16(2):373-386, Feb. 2014.
<br>
[<a href="http://math.stanford.edu/~yuany/publications/TMM13.pdf">pdf</a>]
<p> 
</li>
<li>
<B>Analysis of Crowdsourced Sampling Strategies for HodgeRank with Sparse Random Graphs
</B>
<br>
Braxton Osting, Jiechao Xiong, Qianqian Xu, and Yuan Yao
<br>
<I>Applied and Computational Harmonic Analysis</I>, 41 (2): 540-560, 2016
<br>
[<a href="http://arxiv.org/abs/1503.00164"> arXiv:1503.00164 </a>] [<a href="http://authors.elsevier.com/sd/article/S1063520316000300
"> ACHA online </a>] [<a href="http://math.stanford.edu/~yuany/data/TIP_matlab.zip">Matlab codes to reproduce our results</a>] 
<p> 
</li>
<li>
<B>
False Discovery Rate Control and Statistical Quality Assessment of Annotators in Crowdsourced Ranking
</B>
<br>
Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Yuan Yao
<br>
<I>Proceedings of The 33rd International Conference on Machine Learning (ICML)</I>, New York, June 19-24, 2016.
<br>
[<a href="http://arxiv.org/abs/1605.05860"> arXiv:1605.05860 </a>] [<a href="http://math.stanford.edu/~yuany/publications/ICML2016_cameraready_ID_600.pdf"> pdf </a>] [<a href="http://math.stanford.edu/~yuany/publications/ICML2016_camerareadySI_ID_600.pdf"> supplementary </a>]
<p> 
</li>
<li>
<B>
Parsimonious Mixed-Effects HodgeRank for Crowdsourced Preference Aggregation
</B>
<br>
Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Yuan Yao
<br>
<I>ACM Multimedia Conference (ACMMM)</I>, Amsterdam, Netherlands, October 15-19, 2016.
<br>
[<a href="http://arxiv.org/abs/1607.03401"> arXiv:1607.03401 </a>] [<a href="http://math.stanford.edu/~yuany/publications/AMM-20160712.pdf"> pdf </a>] 
<p> 
</li>
<li>
<B>
HodgeRank with Information Maximization for Crowdsourced Pairwise Ranking Aggregation
</B>
<br>
Qianqian Xu, Jiechao Xiong, Xi Chen, Qingming Huang, Yuan Yao
<br>
<I>The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)</I>, New Orleans, Louisiana, USA, February 2–7, 2018.
<br>
[<a href="https://arxiv.org/abs/1711.05957"> arXiv:1711.05957 </a>] [<a href="https://github.com/yuany-pku/activesample"> Matlab Source Codes </a>] 
<p> 
</li>
<li>
<B>
From Social to Individuals: a Parsimonious Path of Multi-level Models for Crowdsourced Preference Aggregation
</B>
<br>
Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Qingming Huang, Yuan Yao
<br>
<I>IEEE Transactions on Pattern Analysis and Machine Intelligence</I>, 41(4):844-856, 2019. Extended from MM'16 in [<a href="https://arxiv.org/abs/1607.03401"> arXiv:1607.03401 </a>].
<br>
[<a href="https://arxiv.org/abs/1804.11177"> arXiv:1804.11177 </a>] [<a href="https://ieeexplore.ieee.org/document/8319957/"> doi: 10.1109/TPAMI.2018.2817205 </a>][<a href="https://github.com/yao-lab/TPAMI2018"> GitHub source</a>]
<p> 
	</li>
<li> Professor Don Saari: <span class="bibbook"> <a href="https://www.math.uci.edu/~dsaari/">[ UCI homepage ]</a> <a href="https://ac.els-cdn.com/S0895717708001738/1-s2.0-S0895717708001738-main.pdf?_tid=019776d4-cdd3-11e7-b9af-00000aab0f6b&acdnat=1511169360_f28a9308e65cf0032e95525053dcb3a3"> [ Book Info: Disposing Dictators, Demstifying Voting Paradoxes ] </a> <a href="https://www.amazon.com/Disposing-Dictators-Demystifying-Voting-Paradoxes/dp/0521731607"> [ Amazon link ]</a> </span>
</li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>




<tr>
<td>05/06/2020, Wed </td>
<td>Lecture 11: Seminars.
	<ul> [Title]: <B>Robust Statistics and Generative Adversarial Networks</B>
	[<a href="slides/Lecture11_robustGAN.pdf"> slides </a>] [<a href="https://hkust.zoom.us/rec/share/7t02BJzq60hOX7Pk6lDjU64TQqPFeaa813cW_fFfzk8u1wZ04VKc11eGcTHZ3jXg"> video </a>] 

	</ul>
<ul>[Reference]:
<li><cite>Chao Gao, Jiyi Liu, Yuan Yao, &amp; Weizhi Zhu, Robust Estimate and Generative Adversarial Networks, ICLR 2019. </cite> [<a href="https://arxiv.org/abs/1810.02030">arXiv:1810.02030</a>]</li>
<li><cite>Chao Gao, Yuan Yao, &amp; Weizhi Zhu, Generative Adversarial Nets for Robust Scatter Estimation: A Proper Scoring Rule Perspective. </cite> [<a href="https://arxiv.org/abs/1903.01944"> arXiv:1903.01944 </a>] </li>
</ul>
<ul>[Python]: 
<li> <a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/data/RobustGAN/Robust_GAN.ipynb"> Robust_GAN.ipynb </a>: Jupyter Notebook for demonstration </li>
<li> <a href="https://github.com/yao-lab/Robust-GAN-Center"> Robust-GAN-Center </a>: robust center (mean) estimate via GANs </li>
<li> <a href="https://github.com/zhuwzh/Robust-GAN-Scatter"> Robust-GAN-Scatter </a>: robust scatter (covariance) estimate via GANs </li>
</ul>
<br>
<ul>[ Title ]: <B>Spectral methods for latent variable models</B> [<a href="slides/WANG_Kaizheng_HKUST.pdf"> slides </a>]
</ul>
<ul>[ Speaker ]: Dr. <a href="https://kaizheng.mycpanel.princeton.edu/default.html">WANG, Kaizheng</a>, Princeton University and Columbia University
</ul>
<ul>[ Abstract ]
Latent variable models lay the statistical foundation for data science problems with unstructured, incomplete and heterogeneous information. 
Spectral methods extract low dimensional geometric structures for downstream tasks in a computationally efficient way. Despite their conceptual simplicity and wide applicability, 
theoretical understanding is lagging far behind and that hinders development of principled approaches. In this talk, I will first talk about the bias and variance of PCA, and apply the results to distributed estimation of principal eigenspaces. 
Then I will present an $\ell_p$ theory of eigenvector analysis that yields optimal recovery guarantees for spectral methods in many challenging problems. 
The results find applications in dimensionality reduction, mixture models, network analysis, recommendation systems, ranking and beyond.
</ul>
<ul>[ Bio ] Kaizheng Wang got his PhD Degree in Operations Research and Financial Engineering at Princeton University and 
will join Columbia University as Assistant Professor in the fall of 2020. 
His research interests lie at the intersection of statistics, machine learning and optimization, with special focus on development and 
analysis of efficient algorithms for unsupervised learning.
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>



<tr>
<td>05/13/2020, Fri </td>
	<td>Lecture 12: Final Project. [<a href="project2/project2.pdf"> project2.pdf </a>] [<a href="https://hkust.zoom.us/rec/share/tM5aPp7v00FOTY2Wz3zzAJM-QqfpT6a82ilMq_UIxBrRfbA7n4JAO1ynl5UH26Qe"> video </a>] <br>
	
	<ul>[ Title ]: <B>Clustering via Uncoupled REgression (CURE)</B> [<a href="slides/WANG_Kaizheng_CURE.pdf"> slides </a>]
</ul>
<ul>[ Speaker ]: Dr. <a href="https://kaizheng.mycpanel.princeton.edu/default.html">WANG, Kaizheng</a>, Princeton University and Columbia University
</ul>
<ul>[ Abstract ]
In this talk, we first consider a canonical clustering problem where one receives unlabeled samples drawn from a balanced mixture of two elliptical distributions 
and aims for a classifier to estimate the labels. Many popular methods including PCA and k-means require individual components of the mixture to be somewhat 
spherical, and perform poorly when they are stretched. To overcome this issue, we propose a non-convex program seeking for an affine transform to turn the data 
into a one-dimensional point cloud concentrating around -1 and 1, after which clustering becomes easy. Our theoretical contributions are two-fold: (1) we show 
that the non-convex loss function exhibits desirable landscape properties as long as the sample size exceeds some constant multiple of the dimension, and 
(2) we leverage this to prove that an efficient first-order algorithm achieves near-optimal statistical precision even without good initialization. 
We also propose a general methodology for multi-class clustering tasks with flexible choices of feature transforms and loss objectives.
<li> Paper: [<a href="https://arxiv.org/abs/2003.09960"> arXiv:2003.09960 </a>] </li>
</ul>

<ul>[Project 2 Report Repository] 		<img src="../images/new.jpg" height="40">
	<p>
	<li> GitHub Repository for reports of Project 2 
		<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2"> [ GitHub ] </a>
	<p>
	</li>
	<li> 1. <B> CAO, Yang and ZENG, Wenqi.</B>
		<br> Report for Robust Mean and Covariance Estimate by GAN.
	 	<br> 
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project2/CaoZeng/report/"> report </a>]
		[<a href="https://www.youtube.com/watch?v=klTzzxa4xNI"> video (youtube) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project2/CaoZeng/report/code/"> source </a>] 
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/0.peer-review/CaoZeng/"> peer review </a>]
	<p>
	</li>
	<li> 2. <B> CHEN, Zhixian and WU, Yue. </B> 
		<br> Transition Paths of Karate Club Network. 
		<br>
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project2/ChenWu/report/Project2.ipynb"> Project2.ipynb </a>]
		[<a href="https://hkust.zoom.us/rec/share/5-12IoDg3XFIc6vxxB_wHYB9Rpq-T6a813dPrqJYn0h2iOpUytQAXjmq-FpvZz75"> video </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/0.peer-review/ChenWu/"> peer review </a>]
	<p>
	</li>
	<li> 3. <B>CHEN, Zhenghui.</B> 
		<br> Order the Faces by Manifold Learning.
		<br> 
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project2/ChenZH/report/report/Final%20Project.pdf"> report (pdf) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2020.csic5011/project2/ChenZH/report/presentation/Final%20Project.pptx"> slides (pptx) </a>]
		[<a href="https://youtu.be/bQaeK81evHo"> video (youtube) </a>]
		[<a href="project2/ChenZH/report/code/"> source (.py) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/0.peer-review/ChenZH/"> peer review </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/ChenZH/rebuttal"> rebuttal </a>]
	<p>
	</li>
	<li> 4. <B> Avik Kumar DAS and Neel Kanth KUNDU</B>. 
		<br> Segmenting Cracks using classification algorithms on the low dimensional embedding of data.
		<br>
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/DasKundu/report/Das_Kundu_final_Project_Report.pdf"> report (pdf) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/DasKundu/report/FInal%20Presentation%20Slides.pdf"> slides (pdf) </a>]
		[<a href="https://youtu.be/z2LLNTQGVY8"> video (youtube) </a>]
		[<a href="https://github.com/AVKDAS/Crack-Segmentation/tree/master"> source (github) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/0.peer-review/DasKundu/"> peer review </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/DasKundu/rebuttal/"> rebuttal </a>]	
	<p>
	</li>
	<li> 5. <B>HUANG, Hanli, WONG, Kwan Long Kyle, and YANG, Yingxi</B>. 
		<br> Tissue classification in primary colorectal tumors. 
		<br>
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/HuangWongYang/report/Poster/CSIC5011_project2_Kyle%20Kwan%20Long%20Wong_Yingxi%20YANG_Hanli%20Huang.pptx"> poster (pptx) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/HuangWongYang/report/Presentation/"> slides (pptx) </a>]
		[<a href="https://youtu.be/s8MoRJWRdMA"> video (youtube) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/HuangWongYang/report/Code/"> source (ipynb) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/0.peer-review/HuangWongYang/"> peer review </a>]	
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/BestFinal.pdf"> Best Final Project Award!! </a> <img src="../images/new.jpg" height="40">]
	<p>
	</li>

	<li> 6. <B>José Vinícius de Miranda Cardoso, Yixin Men, Shunkang Zhang.</B> 
		<br> Generative Adversarial Networks: A Review. 
		<br>
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/JoseMenZhang/report/final-project-poster.pdf"> poster (pdf) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/JoseMenZhang/report/presentation.pdf"> slides (pdf) </a>]
		[<a href="https://www.youtube.com/watch?v=AwKo-cTHXXM"> video (youtube) </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/0.peer-review/JoseMenZhang/"> peer review </a>]		
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2020.csic5011/project2/JoseMenZhang/rebuttal/"> rebuttal </a>]		
	<p>
	</li>
	</ul>
	<!---
<ul>[ Project 2 Report Repository ]
<li> GitHub Repository for reports of Project 2 <a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2019_csic5011/project2"> [ GitHub ] </a></li>
	<li> 01. KANG, Lei. Order the faces by Diffusion Map, ISOMAP and LLE. 
		[<a href="project2/01.KANG-Lei_project2_report.pdf"> poster </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/blob/master/2019_csic5011/project2/01.KANG-Lei.Project2_python_code.py"> source (.py) </a>]
		[<a href="https://youtu.be/BOpHZNrusrQ"> presentation video </a>]
		[<a href="project2/Review01.pdf"> peer review </a>]
	</li>
	<li> 02. LIANG, Zhicong. Finding Trend in Stock Market with RobustPCA.
		[<a href="project2/02.LIANG-Zhicong-poster.pdf"> poster (pdf) </a>]
		[<a href="project2/02.LIANG-Zhicong_presentation.pptx"> slides (pptx) </a>]
		[<a href="project2/https://www.youtube.com/watch?v=IPq3USTavZA&feature=youtu.be"> presentation video </a>]
		[<a href="project2/Review02.pdf"> peer review </a>]
	</li>
	
	<li> 03. <B> LIU, Di, Meilan WANG, Xu HAN. </B> [<a href="project2/BestWriting.pdf"> Best Writing Award! </a>][<a href="project2/BestPresentation.pdf"> Best Presentation Award! </a>]<img src="../images/new.jpg" height="40">
		<br>
		<I> Order the Faces via Manifold Learning. </I>
		<br>
		[<a href="project2/03.LIUdi_MeilanWANG_XuHAN_report.pdf"> report (pdf) </a>]
		[<a href="project2/03.LIUdi_MeilanWANG_XuHAN_presentation.pptx"> slides (pptx) </a>]
		[<a href="https://www.dropbox.com/s/0xqy0m6tbx714fx/Project2_DiLIU_MeilanWANG_Xuhan.mp4?dl=0"> presentation video </a>]
		[<a href="project2/03.LIU-WANG-HAN_source"> source </a>]
		[<a href="project2/Review03.pdf"> peer review </a>]
	</li>
	
	<li> 04. LUI, Go Nam. Human age ranking from pairwise comparison data via HodgeRank. 
		[<a href="project2/04.LUI-GoNam_poster.pdf"> poster (pdf) </a>]
		[<a href="project2/04.LUI-GoNam_presentation.pptx"> slides (pptx) </a>]
		[<a href="https://youtu.be/JMtOLLqyhu0"> presentation video </a>]
		[<a href="project2/Review04.pdf"> peer review  </a>]
	</li>
	<li> 05. <B> SHEN, Xinwei and YANG, Yunfei. </B> [<a href="project2/BestCreativity.pdf"> Best Creativity Award!! </a>]
		<br>
		<I> Representation learning on gene expression data. </I>
		<br>
		[<a href="project2/05.SHEN_YANG_report.pdf"> report (pdf) </a>]
		[<a href="project2/05.SHEN_YANG_slides.pdf"> slides (pdf) </a>]
		[<a href="https://github.com/xwshen51/csic-pj2"> source </a>]
		[<a href="https://drive.google.com/file/d/1E9eV7nxrHzQHtggUArANgV-JiybKTajs/view?usp=sharing"> presentation video </a>]
		[<a href="project2/Review05.pdf"> peer review </a>]
		
	</li>
	<li> 06. SUN, Jing, Shuang LUO, Zhijie YU.  Dimensionality Reduction of Face Order ProblemUsing Nonlinear Embedding Methods.
		[<a href="project2/06.SUN_LUO_YU_project2_poster.pdf"> poster (pdf) </a>]
		[<a href="project2/06.SUN_LUO_YU_slides.pptx"> slides (pptx) </a>]
		[<a href="https://youtu.be/0B3ywTWL40g"> presentation video </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2019_csic5011/project2/06.SUN_LUO_YU-project2-source"> source </a>]
		[<a href="project2/Review06.pdf"> peer review </a>]
	</li>
	<li> 07.  WU, Ziming, Feng HAN, Song LIU.  Whether and why are people feeling happy? Multi-Task Mining Based on Text-based Information. 
		[<a href="project2/07.WU-HAN-LIU_poster.pdf"> poster (pdf) </a>]
		[<a href="project2/07.WU-HAN-LIU_slides.pdf"> slides (pdf) </a>]
		[<a href="https://www.youtube.com/watch?v=SNzrx1tZxkE"> presentation video </a>]
		[<a href="https://github.com/jimmy-ng/happy_project2"> source </a>]
		[<a href="project2/Review07.pdf"> peer review </a>]
	</li>
	<li> 08. CHAN, Lok Chun. Human Age Ranking Using Hodge Rank. 
		[<a href="project2/08.CHAN-LokChun_report.pdf"> poster (pdf) </a>]
		[<a href="project2/08.CHAN-LokChun_report.pptx"> poster (pptx) </a>]
		[<a href="https://www.youtube.com/watch?v=_y-owdTcCsA&feature=youtu.be"> presentation video </a>]
		[<a href="https://github.com/yao-lab/yao-lab.github.io/tree/master/2019_csic5011/project2/08.Chan-LokChun_source"> source </a>]
		[<a href="project2/Review08.pdf"> peer review </a>]
	</li>
	<li> 09. CHENG, Wei. Spectral Clustering and Transition Paths Analysis of Karate Club Network. 
		[<a href="https://github.com/wchengad/course_2019_spring/blob/master/CSIC5011/Project2/CSIC5011_Project2_Report.pdf"> poster (pdf) </a>]
		[<a href="https://github.com/wchengad/course_2019_spring/blob/master/CSIC5011/Project2/CSIS5011_Slides.pdf"> slides (pdf) </a>]
		[<a href="https://github.com/wchengad/course_2019_spring/tree/master/CSIC5011/Project2"> source </a>]
		[<a href="https://youtu.be/0OsWrUkH4Yg"> presentation video </a>]
		[<a href="project2/Review09.pdf"> peer review </a>]
	</li>

</ul>
--->
</td>
<td> Y.Y. <br> </td>
<td></td>
</tr>


<!--

<tr>
<td>05/08/2019, Wed </td>
<td>Seminar: Learning Deep Generative Models via Variational Gradient Flow and Its Applications  <br>
	<ul>
		<li>[ Invited Speaker ]: Prof. Can Yang, Department of Mathematics, The Hong Kong University of Science and Technology
		</li>
		<li> [ Abstract ]:
			Learning the generative model, i.e., the underlying data generating distribution, based on large amounts of data is one of the fundamental tasks in machine learning and statistics. Recent progresses in deep generative models have provided novel techniques for unsupervised and semi-supervised learning, with broad application varying from image synthesis, semantic image editing, image-to-image translation to low-level image processing. However, statistical understanding of deep generative models is still lacking, e.g., why the logD trick works well in training generative adversarial networks (GAN). 

In this talk, we introduce a general framework, variational gradient flow (VGrow), to learn a deep generative model to sample from the target distribution via combing the strengths of variational gradient flow on probability space, particle optimization and deep neural network. The proposed framework is applied to minimize the f-divergence between the evolving distribution and the target distribution. We prove that the particles driven by VGrow are guaranteed to converge to the target distribution asymptotically. Connections of our proposed VGrow method with other popular methods, such as VAE, GAN and flow-based methods, have been established in this framework, gaining new insights of deep generative learning. We also evaluated several commonly used f-divergences, including Kullback-Leibler, Jensen-Shannon, Jeffrey divergences as well as our newly discovered “logD” divergence which serves as the objective function of the logD-trick GAN. 

Besides the above theoretical understanding, we emphasize the practical issues in training GAN. Through a systematic design of the generator and the discriminator, much of the efforts on parameter tuning can be avoided. Using a pre-defined network structure rather than case-by-case parameter tuning, VGrow can generate high-fidelity images in a stable and efficient manner. Its results on those benchmark data sets (e.g., CIFAR10, CelebA) show Its competitive performance with state-of-the-art GANs. We have also applied VGrow to the portrait data from The Wikipedia Art Project, generating realistic portraits without extra editing. This is a joint work with Yuan Gao, Yuling Jiao, Yao Wang, Gefei Wang, Yang Wang and Shunkang Zhang.
		</li>
		<li> [<a href="https://drive.google.com/file/d/1qiwqNrMOZU7UQl3YK0d0kUh2xh5dDNlF/view"> slides </a>] </li>
	<li> [<a href="https://github.com/eeyangc/VGrowGAN"> GitHub source </a>]</li>
	<li> [<a href="https://arxiv.org/abs/1901.08469"> arXiv:1901.08469 </a>]</li>
	</ul>
</td>
<td>Can Yang<br> </td>
<td></td>
</tr>


<ul>[Project 2 Description]
<li> <a href="project2.pdf">  Mini Project 2 [pdf]</a>.  
</li>
</ul>




<tr>
<td>09/10/2017, Fri </td>
<td>Lecture 11: Manifold Learning II: Extended LLEs (Chap 5: 3-6) <a href="https://yao-lab.github.io/book_datasci/">[ new update on Oct 9, 2017 ]</a><a href="lecture11_key.pdf">[ slides ]</a><br>
<ul>[Reference]:
<li><cite>Mikhail Belkin &amp; Partha Niyogi, Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering, Advances in Neural Information Processing Systems 14, 2001, p. 586?691, MIT Press</cite>
<a href="https://papers.nips.cc/paper/1961-laplacian-eigenmaps-and-spectral-techniques-for-embedding-and-clustering"> [nips link] </a> </li>
<li><cite>Zhang, Z. &amp; Wang, J. MLLE: Modified Locally Linear
Embedding Using Multiple Weights.</cite> <a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382</a></li>
<li>  <cite>Donoho, D. &amp; Grimes, C. Hessian eigenmaps: Locally
linear embedding techniques for high-dimensional data.
Proc Natl Acad Sci U S A.  100:5591 (2003).</cite> <a href="http://www.pnas.org/content/100/10/5591.full">doi: 10.1073/pnas.1031596100</a> </li>
<li><cite>Zhang, Z. &amp; Zha, H. (2005) Principal manifolds and nonlinear
dimensionality reduction via tangent space alignment.
SIAM Journal on Scientific Computing. 26 (1): 313?338. </cite> <a href="https://doi.org/10.1137/S1064827502419154"> doi:10.1137/s1064827502419154</a> </li>
</ul>
<ul>[Python]: 
<li> <a href="https://nbviewer.jupyter.org/url/github.com/yuany-pku/2017_CSIC5011/blob/master/slides/plot_compare_methods.ipynb"> plot_compare_methods.ipynb </a>: demo in class </li>
<li> <a href="https://nbviewer.jupyter.org/url/github.com/yuany-pku/2017_CSIC5011/blob/master/slides/plot_mani_digits.ipynb"> plot_mani_digits.ipynb </a>: demo of digits in class </li>
<li> <a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.locally_linear_embedding.html#sklearn.manifold.locally_linear_embedding"> scikit-learn manifold LLE </a>: MLLE, Hessian, LTSA, Laplacian (Spectral) </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>13/10/2017, Fri </td>
<td>Lecture 12: Diffusion Map and Stochastic Neighbour Embedding <a href="lecture12.pdf">[ slides ]</a><br>
<ul>[Reference]:
<li> R. R. Coifman, S. Lafon, A. B. Lee, M. Maggioni, B. Nadler, F. Warner, and S. W. Zucker. Geometric diffusions as a tool for harmonic analysis and structure definition of data: Diffusion maps. PNAS 102 (21):7426-7431, 2005 <a href="http://www.pnas.org/content/102/21/7426.long"> [doi: 10.1073/pnas.0500334102] </a> </li>
<li> <cite>Nadler, Boaz; Stéphane Lafon; Ronald R. Coifman; Ioannis G. Kevrekidis (2005). <a href="http://www.wisdom.weizmann.ac.il/~nadler/Publications/dm_nips05.pdf">"Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker–Planck Operators"</a> <span>(PDF)</span> <i>in Advances in Neural Information Processing Systems (NIPS) 18</i>.</cite></li>
<li> <cite>Coifman, R.R.; S. Lafon. (2006). "Diffusion maps". <i>Applied and Computational Harmonic Analysis.</i> 21: 5–30. <a href="//doi.org/10.1016%2Fj.acha.2006.04.006">10.1016/j.acha.2006.04.006</a>.</cite></li>
<li> Stochastic Neighbor Embedding <a href="http://www.cs.toronto.edu/~hinton/absps/sne.pdf"> [ .pdf ] </a></li>
<li> Visualizing Data using t-SNE <a href="http://www.cs.toronto.edu/~hinton/absps/tsnefinal.pdf"> [ .pdf ] </a></li>
<li> A paper that relates SNE to Laplacian Eigenmaps <a href="http://www.cs.toronto.edu/~hinton/csc2535/readings/miguel.pdf"> [ .pdf ] </a></li>
<li> A helpful website: How to use t-SNE effectively? <a href="https://distill.pub/2016/misread-tsne/"> [ link ]</a></li>
</ul>
<ul>[Matlab]
<li> Matlab code to compare manifold learning algorithms <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/mani.m"> [ mani.m ] </a>: PCA, MDS, ISOMAP, LLE, Hessian LLE, LTSA, Laplacian, Diffusion (no SNE!)</li>
</ul>
<ul>[Python]: 
<li> <a href="https://nbviewer.jupyter.org/url/github.com/yuany-pku/2017_CSIC5011/blob/master/slides/plot_compare_methods.ipynb"> plot_compare_methods.ipynb </a>: demo in class </li>
<li> <a href="https://nbviewer.jupyter.org/url/github.com/yuany-pku/2017_CSIC5011/blob/master/slides/plot_mani_digits.ipynb"> plot_mani_digits.ipynb </a>: demo of digits in class </li>
<li> <a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.locally_linear_embedding.html#sklearn.manifold.locally_linear_embedding"> scikit-learn manifold LLE </a>: PCA/MDS, ISOMAP, LLE/MLLE, Hessian, LTSA, Laplacian (Spectral), t-SNE (no Diffusion)</li>
<li> <a href="http://lvdmaaten.github.io/tsne/"> Laurens van der Maaten's website for t-SNE codes </a></li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>16/10/2017, Mon </td>
<td>Lecture 13: Random Walk on Graphs: Perron-Frobenius Theory vs. PageRank and Fiedler Theory <br>
<ul>[Reference]:
<li> Amy N. Langville and Carl D. Meyer's book: <a href="http://geza.kzoo.edu/~erdi/patent/langvillebook.pdf"> Google's PageRank and Beyond </a> </li>
</ul>
<ul>[Project 1 Report Repository]
<li> GitHub Repository for reports of Project 1 <a href="https://github.com/yuany-pku/2017_CSIC5011/tree/master/project1"> [ GitHub ] </a></li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>


<tr>
<td>20/10/2017, Mon </td>
<td>Lecture 15: Poster workshop on project 1.<br>
<ul>[ Reference ]
<li> Doodle voting for top 3 posters <a href="https://doodle.com/poll/7n9x4qcvf478d9yz"> [ link ]</a>
</li>
<li> GitHub Repository of report collection for Project 1 <a href="https://github.com/yuany-pku/2017_CSIC5011/tree/master/project1"> [ GitHub ] </a>
</li>
</ul>
</td>
<td>Jinshan ZENG<br> Haixia LIU</td>
<td></td>
</tr>

<tr>
<td>27/10/2017, Fri </td>
<td>Lecture 16: Stochastic semidefinite optimization via low-rank factorization:
algorithms, theory and applications <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/lecture16.Zeng.SDP_SGD.pdf">[ slides ]</a><br>
</td>
<td>Jinshan ZENG</td>
<td></td>
</tr>

<tr>
<td>30/10/2017, Mon </td>
<td>Lecture 17: Restricted Boltzmann Machine and Deep Belief Nets <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/lecture17.LI-Zhen.RBM.pdf">[ slides ]</a><br>
<ul>[Reference]:
<li> Hinton, G. E.; Salakhutdinov, R. R. (2006). <a href="http://www.cs.toronto.edu/~hinton/science.pdf"> Reducing the Dimensionality of Data with Neural Networks</a>, <span style="font-size:85%;">(PDF)</span>. <i>Science</i>. <b>313</b> (5786): 504–507. 
</li>
<li> Hinton's web of matlab codes <a href="http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html">[ Matlab for science paper ]</a>
</li>
</ul>
</td>
<td>Zhen LI</td>
<td></td>
</tr>



<tr>
<td>6/11/2017, Mon </td>
<td>Lecture 19: Introduction to Topological Data Analysis I - Simplicial Complexes, Nerve, Reeb Graph, and Mapper <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/lecture19.pdf">[ slides ]</a> <br>
<ul>[Reference]:
<li>
<B>Topological Methods for Exploring Low-density States in Biomolecular Folding Pathways.</B>
<br>
Yuan Yao, Jian Sun, Xuhui Huang, Gregory Bowman, Gurjeet Singh, Michael Lesnick, <a href="http://folding.stanford.edu/Pande/Main">Vijay Pande</a>, <a href="http://www-graphics.stanford.edu/~guibas/ ">Leonidas Guibas</a> and  <a href="http://math.stanford.edu/~gunnar/">Gunnar Carlsson</a>.
<br>
 <i>J. Chem. Phys</i>. <B>130</B>, 144115 (2009).
<br>
[<a href="publications/RNA_mapper_JCP2009.pdf">pdf</a>][<a href="http://link.aip.org/link/?JCP/130/144115">Online Publication</a>][<a href="https://simtk.org/home/rna-mapper">SimTK Link: Data and Mapper Matlab Codes</a>] [Selected by <a href="http://www.vjbio.org/">Virtual Journal of Biological Physics Research, 04/15/2009</a>]. 
</li>
<li>
<B>Structural insight into RNA hairpin folding intermediates.</B>
<br>
Bowman, Gregory R., <a href="http://csb.stanford.edu/~xhuang/">Xuhui Huang</a>, Yuan Yao, <a href="http://www.stanford.edu/~sunjian/">Jian Sun</a>, <a href="http://math.stanford.edu/~gunnar/">Gunnar Carlsson</a>, <a href="http://www-graphics.stanford.edu/~guibas/ ">Leonidas Guibas</a> and <a href="http://folding.stanford.edu/Pande/Main">Vijay Pande</a>. 
<br>
<i>Journal of American Chemistry Society</i>, 2008, 130 (30): 9676-9678. 
<br> 
[<a href="http://pubs.acs.org/cgi-bin/abstract.cgi/jacsat/2008/130/i30/abs/ja8032857.html">link</a>]
</li>
</li>
<li> <B> Single-cell topological RNA-seq analysis reveals insights into cellular differentiation and development. </B>
<br>
Abbas H Rizvi, Pablo G Camara, Elena K Kandror, Thomas J Roberts, Ira Schieren, Tom Maniatis & Raul Rabadan.
<br>
<i>Nature Biotechnology</i>. 2017 May. doi:10.1038/nbt.3854
</li>
<li>
<B>Spatiotemporal genomic architecture informs precision oncology in glioblastoma.</B>
<br> Lee JK, Wang J, Sa JK, Ladewig E, Lee HO, Lee IH, Kang HJ, Rosenbloom DS, Camara PG, Liu Z, van Nieuwenhuizen P, Jung SW, Choi SW, Kim J, Chen A, Kim KT, Shin S, Seo YJ, Oh JM, Shin YJ, Park CK, Kong DS, Seol HJ, Blumberg A, Lee JI, Iavarone A, Park WY, Rabadan R, Nam DH.
<br>
<I>Nat Genet.</I> 2017 Apr. doi: 10.1038/ng.3806.
</li>
<li> A Python Implementation of Mapper <a href="https://github.com/szairis/sakmapper"> [ sakmapper ] </a> in single cell data analysis. 
<li> Single Cell TDA <a href="https://github.com/pcamara/scTDA"> [ scTDA ] </a> with <a href="https://github.com/pcamara/scTDA/blob/master/doc/scTDA%20Tutorial.html"> [ tutorial in html ]</a>
</ul>
<ul>[Seminar]
<li> Speaker: <B>Prof. Raul RABADAN</B>, 
Department of Systems Biology, 
Department of Biomedical Informatics, 
Center for Computational Biology & Bioinformatics, 
Columbia University
</li>
<li> Title: <B>Exploring biological dynamical processes using Topological Data Analysis applied to Single Cell Expression Data </B>
 <a href="http://math.stanford.edu/~yuany/course/reference/"> [ slides? ]</a> </li>
<li> Time: 5:00-6:00pm </li>
<li> Venue: LTK (Lift 31/32) </li>
<li> Abstract: Transcriptional programs control cellular lineage commitment and differentiation during development. Understanding of cell fate has been advanced by studying single-cell RNA-sequencing (RNA-seq) but is limited by the assumptions of current analytic methods regarding the structure of data. We present single-cell topological data analysis (scTDA), an algorithm for topology-based computational analyses to study temporal, unbiased transcriptional regulation. Unlike other methods, scTDA is a nonlinear, model-independent, unsupervised statistical framework that can characterize transient cellular states. We applied scTDA to the analysis of murine embryonic stem cell (mESC) differentiation in vitro in response to inducers of motor neuron differentiation. scTDA resolved asynchrony and continuity in cellular identity over time and identified four transient states (pluripotent, precursor, progenitor, and fully differentiated cells) based on changes in stage-dependent combinations of transcription factors, RNA-binding proteins, and long noncoding RNAs (lncRNAs). scTDA can be applied to study asynchronous cellular responses to either developmental cues or environmental perturbations.
</li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>10/11/2017, Fri </td>
<td>Lecture 20: Introduction to Topological Data Analysis II: Persistent Homology <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/lecture20.pdf">[ slides ]</a><br>
<ul>[Reference]:
<li> A Java package for persistent homology and barcodes: <span class="bibbook"> <a href="https://github.com/appliedtopology/javaplex/wiki/Tutorial">Javaplex Tutorial</a>. </span>
</li>
<li>
Guo-Wei Wei, <B>Persistent Homology Analysis of Biomolecular Data</B>, <a href="http://users.math.msu.edu/users/wei/SIAM_News2017.pdf"> SIAM News 2017</a>
</li>
<li> <B> Topological Data Analysis Generates High-Resolution, Genome-wide Maps of Human Recombination. </B>
<br>
Pablo G. Camara, Daniel I.S. Rosenbloom, Kevin J. Emmett, Arnold J. Levine, Raul Rabadan.
<br>
<i>Cell Systems</i>. 2016 June. doi: 10.1016/j.cels.2016.05.008.
</li>
<li> <B> Topology of viral evolution.</B>
<br>
Chan JM, Carlsson G, Rabadan R.
<br>
<i></i>Proc Natl Acad Sci USA</i> 2013 Oct 29. doi: 10.1073/pnas.1313480110.
</li>
<li> Robert Ghrist's monograph on applied Topology <B> <a href="https://www.math.upenn.edu/~ghrist/notes.html"> Elementary Applied Topology </a> </B> 
</li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>17/11/2017, Fri </td>
<td>Lecture 21: Applied Hodge Theory I: Social Choice, Crowdsourced Ranking, and Hodge Decomposition <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/lecture21.pdf">[ slides ]</a><br>
<ul>[Reference]:
<li> Professor Don Saari: <span class="bibbook"> <a href="https://www.math.uci.edu/~dsaari/">[ UCI homepage ]</a> <a href="https://ac.els-cdn.com/S0895717708001738/1-s2.0-S0895717708001738-main.pdf?_tid=019776d4-cdd3-11e7-b9af-00000aab0f6b&acdnat=1511169360_f28a9308e65cf0032e95525053dcb3a3"> [ Book Info: Disposing Dictators, Demstifying Voting Paradoxes ] </a> <a href="https://www.amazon.com/Disposing-Dictators-Demystifying-Voting-Paradoxes/dp/0521731607"> [ Amazon link ]</a> </span>
</li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>18/11/2017, Sat </td>
<td>Lecture 22: Tutorial on Single Cell TDA <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/scTDA_tutorial.pptx">[ pptx ]</a><br>
<ul>[Reference]:
<li> Raul Rabadan's website: <a href="https://github.com/pcamara/scTDA">[ scTDA ]</a>
</li>
<li> Tutorial data and ipynb: <a href="https://www.dropbox.com/s/ma80a641miteyxf/scTDA%20Tutorial.tar.gz?dl=1">[ scTDA Tutorial ]</a>
</li>
</ul>
</td>
<td>Quanhua MU</td>
<td></td>
</tr>


<tr>
<td>20/11/2017, Mon </td>
<td>Lecture 23: Applied Hodge Theory II: Hodge Decomposition for Pairwise Ranking and Game Theory <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/lecture22.pdf">[ slides ]</a> and a Tutorial on Word Embedding <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/project2/08.MaoYe_report.pdf"> [ MaoYe Report ] </a> <br>
<ul>[Project 2]
<li> <a href="https://github.com/yuany-pku/2017_CSIC5011/tree/master/project2">[ Report Repository ] </a>.  
</li>
<li> <a href="https://doodle.com/poll/r84hneqzd4sqbubp"> [ Doodle Voting for Peer Review ] </a>: Vote your top 3 favourite reports, excluding your own team
</li>
<li> Just for fun: <a href="http://allourideas.org/csic5011-project2"> [ Allourideas Crowdsourced Ranking ] </a>: Which report do you prefer? If one report is from your own team, choose 'I can't decide' to avoid conflict of interests. Data will be released to you in final project.
</li>
<li> Just for fun: <a href="http://allourideas.org/worldcollege"> [ World college ranking ] </a>: Which university would you rather attend? Data will be released to you in final project. 
</li>
</ul>
<ul>[Reference]:
<li>
<B>Statistical Ranking and Combinatorial Hodge Theory.</B>
<br>
<a href="http://graphics.stanford.edu/projects/lgl/person.php?id=xiaoyej">Xiaoye Jiang</a>, <a href="https://www.stat.uchicago.edu/~lekheng/">Lek-Heng Lim</a>, Yuan Yao and <a href="http://www.stanford.edu/~yyye/">Yinyu Ye</a>. 
<br>
<i>Mathematical Programming</i>, Volume 127, Number 1, Pages 203-244, 2011. 
<br>
[<a href="http://math.stanford.edu/~yuany/publications/HodgeRank.MathProg.B.2010.pdf">pdf</a>][<a href=" http://arxiv.org/abs/0811.1067"> arxiv.org/abs/0811.1067</a>][<a href="http://math.stanford.edu/~yuany/publications//MathProg.zip"> Matlab Codes</a>]
<p>
</li>
<li> 
<B>Flows and Decompositions of Games: Harmonic and Potential Games</B>
<br>
Ozan Candogan, Ishai Menache, Asuman Ozdaglar, and Pablo A. Parrilo
<br> 
<a href=""> </a>Mathematics of Operations Research, 36(3): 474 - 503, 2011
<br>
[<a href="https://arxiv.org/abs/1005.2405">arXiv.org/abs/1005.2405</a>][<a href="http://pubsonline.informs.org/doi/abs/10.1287/moor.1110.0500"> doi:10.1287/moor.1110.0500 </a>]
<p> 
</li>
<li> 
<B>HodgeRank on Random Graphs for Subjective Video Quality Assessment.</B>
<br>
Qianqian Xu, Qingming Huang, Tingting Jiang, Bowei Yan, Weisi Lin, and Yuan Yao.
<br> 
<a href=""> </a> IEEE Transactions on Multimedia, 14(3):844-857, 2012 
<br>
[<a href="http://math.stanford.edu/~yuany/publications/TMM12-final.pdf">pdf</a>][<a href="http://math.stanford.edu/~yuany/publications/BatchHodge.zip"> Matlab codes in zip </a>]
<p> 
</li>
<li>
<B>Robust Evaluation for Quality of Experience in Crowdsourcing.
</B>
<br>
Qianqian Xu, Jiechao Xiong, Qingming Huang, and Yuan Yao
<br> 
<a href="http://www.acmmm13.org/"> <I>ACM Multimedia 2013</I>.</a>
<br>
[<a href="publications/ACMMM13.pdf">pdf</a>]
<p> 
</li>
<li>
<B>Online HodgeRank on Random Graphs for Crowdsourceable QoE Evaluation.
</B>
<br>
Qianqian Xu, Jiechao Xiong, Qingming Huang, and Yuan Yao
<br> 
<I>IEEE Transactions on Multimedia</I>, 16(2):373-386, Feb. 2014.
<br>
[<a href="http://math.stanford.edu/~yuany/publications/TMM13.pdf">pdf</a>]
<p> 
</li>
<li>
<B>Analysis of Crowdsourced Sampling Strategies for HodgeRank with Sparse Random Graphs
</B>
<br>
Braxton Osting, Jiechao Xiong, Qianqian Xu, and Yuan Yao
<br>
<I>Applied and Computational Harmonic Analysis</I>, 41 (2): 540-560, 2016
<br>
[<a href="http://arxiv.org/abs/1503.00164"> arXiv:1503.00164 </a>] [<a href="http://authors.elsevier.com/sd/article/S1063520316000300
"> ACHA online </a>] [<a href="http://math.stanford.edu/~yuany/data/TIP_matlab.zip">Matlab codes to reproduce our results</a>] 
<p> 
</li>
<li>
<B>
False Discovery Rate Control and Statistical Quality Assessment of Annotators in Crowdsourced Ranking
</B>
<br>
Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Yuan Yao
<br>
<I>Proceedings of The 33rd International Conference on Machine Learning (ICML)</I>, New York, June 19-24, 2016.
<br>
[<a href="http://arxiv.org/abs/1605.05860"> arXiv:1605.05860 </a>] [<a href="http://math.stanford.edu/~yuany/publications/ICML2016_cameraready_ID_600.pdf"> pdf </a>] [<a href="http://math.stanford.edu/~yuany/publications/ICML2016_camerareadySI_ID_600.pdf"> supplementary </a>]
<p> 
</li>
<li>
<B>
Parsimonious Mixed-Effects HodgeRank for Crowdsourced Preference Aggregation
</B>
<br>
Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Yuan Yao
<br>
<I>ACM Multimedia Conference (ACMMM)</I>, Amsterdam, Netherlands, October 15-19, 2016.
<br>
[<a href="http://arxiv.org/abs/1607.03401"> arXiv:1607.03401 </a>] [<a href="http://math.stanford.edu/~yuany/publications/AMM-20160712.pdf"> pdf </a>] 
<p> 
</li>
<li>
<B>
HodgeRank with Information Maximization for Crowdsourced Pairwise Ranking Aggregation
</B>
<br>
Qianqian Xu, Jiechao Xiong, Xi Chen, Qingming Huang, Yuan Yao
<br>
to appear in <I>AAAI</I>, 2018.
<br>
[<a href="https://arxiv.org/abs/1711.05957"> arXiv:1711.05957 </a>] [<a href="https://github.com/yuany-pku/activesample"> Matlab Source Codes </a>] 
<p> 
</li>
</ul>
</td>
<td>Y.Y.<br> Hongyu MAO </td>
<td></td>
</tr>

<tr>
<td>24/11/2017, Fri </td>
<td>Lecture 24: Clustering Methods <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/lecture23.pdf">[ slides in pdf ]</a> and Presentation on Bayesian Deep Learning <br>
<ul>[Reference]:
<li> Furthest-First Traversal algorithm for k-center in matlab: <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/kcenter.m"> kcenter.m </a>: a.k.a. 'landmarks' in ISOMAP 
</li>
<li> Cover Tree in Python <a href="https://github.com/patvarilly/CoverTree"> https://github.com/patvarilly/CoverTree </a> </li>
<li> Ye and Mao's presentation on Bayesian Deep Learning <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/BayesianDeepLearning.pptx">[ pptx ]</a>
</li>
</ul>
</td>
<td>Y.Y. <br> Yushi Ye</td>
<td></td>
</tr>


<tr>
<td>27/11/2017, Mon </td>
<td>Lecture 25: Final Project <a href="https://github.com/yuany-pku/2017_CSIC5011/blob/master/slides/project3.pdf">[ pdf ]</a><br>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

--->
</tbody>
</table>

<br>

<h3><a name="data">Datasets (to-be-updated)</a></h3>

<ul>
<br>
<li> [Animal Sleep Data] <a href="http://math.stanford.edu/~yuany/course/data/sleep1.csv"> Animal species sleeping hours vs. other features </a>
</li>
<br>
<li> [Anzhen Heart Data] <a href="http://math.stanford.edu/~yuany/course/data/heartData_20140401.xlsx"> Heart Operation Effect Prediction</a>, provided by Dr. Jinwen Wang, Anzhen Hospital
</li>
<br>
<li> [Beer Data] <a href="http://math.stanford.edu/~yuany/course/data/Beers_20140514.xlsx"> 877 beers dataset </a>, provided by Mr. Richard Sun, Shanghai
</li>
<br>
<li> [Crime Data] <a href="http://math.stanford.edu/~yuany/course/data/crime.zip"> Crime rates in 59 US cities during 1970-1992 </a>
</li>
<br>
<li> [Real-Time-Bidding Algorithm Competition Data] <a href="http://contest.ipinyou.com/"> Contest Website </a>
</li>
<br>
<li> <a name="hongloumeng">[&#32418;&#27004;&#26790;&#20154;&#29289;&#20107;&#20214;&#30697;&#38453;]</a> a 376-by-475 matrix (374-by-475 updated by WAN, Mengting) for character-event appearance in A Dream of Red Mansion (Xueqin Cao) <a href="https://yao-lab.github.io/dream-of-the-red-chamber">[ Dataset in Github ]</a> <a href="http://math.stanford.edu/~yuany/course/data/dream.RData"> [374 Characters dream.RData (for R load)] </a><a href="http://math.stanford.edu/~yuany/course/data/dream.Rd"> [dream.Rd (for R manual)] </a>  <a href="http://math.stanford.edu/~yuany/course/data/HongLouMeng374.txt"> [HongLouMeng374.txt] </a>  <a href="http://math.stanford.edu/~yuany/course/data/HongLouMeng376.csv"> [HongLouMeng376.csv] </a> <a href="http://math.stanford.edu/~yuany/course/data/hongloumeng376.mat"> [.mat] </a>
<a href="http://math.stanford.edu/~yuany/course/data/readme.m"> [readme.m] </a>
</li>
<br>
<li> <a name="data_xiyouji">[&#35199;&#28216;&#35760;]</a> characters-scene occurance matrices for 100 chapters <a href="https://yao-lab.github.io/journey-to-the-west">[ Dataset in GitHub ]</a> <a href="http://math.stanford.edu/~yuany/course/data/west.RData">[data in RData]</a> <a href="http://math.stanford.edu/~yuany/course/data/xiyouji.mat"> [data in matlab (302-by-408 matrix)] </a>
<br>
<table border="1" cellspacing="0">
<tbody>
<tr>
<td align="left"><strong><a href="http://math.stanford.edu/~yuany/course/data/xiyouji/chap001-005.xls">chap001-005</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap006-009.xls">chap006-009</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap010-013.xls">chap010-013</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap014-017.xls">chap014-017</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap018-021.xls">chap018-021</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap022-025.xls">chap022-025</a></strong></td>
</tr>
<tr>
<td align="left"><strong><a href="../data/xiyouji/chap026-029.xls">chap026-029</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap030-033.xls">chap030-033</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap034-037.xls">chap034-037</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap038-041.xls">chap038-041</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap042-045.xls">chap042-045</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap046-049.xls">chap046-049</a></strong></td>
</tr>
<tr>
<td align="left"><strong><a href="../data/xiyouji/chap050-053.xls">chap050-053</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap054-057.xls">chap054-057</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap058-061.xls">chap058-061</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap062-065.xls">chap062-065</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap066-069.xls">chap066-069</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap070-073.xls">chap070-073</a></strong></td>
</tr>
<tr>
<td align="left"><strong><a href="../data/xiyouji/chap074-077.xls">chap074-077</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap078-081.xls">chap078-081</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap082-085.xls">chap082-085</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap086-088.xls">chap086-088</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap089-091.xls">chap089-091</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap092-094.xls">chap092-094</a></strong></td>
</tr>
<tr>
<td align="left"><strong><a href="../data/xiyouji/chap095-097.xls">chap095-097</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap098-100.xls">chap098-100</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap001-100_txt.zip">All in TXT</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/readData.m">readData.m</a></strong></td>
</tr>
</tbody>
</table>
</li>
<br>
<li> <a name="keywords">[Keywords Pricing]</a> Keywords and profit index in paid search advertising, by Hansheng Wang (Guanghua, PKU). <a href="http://math.stanford.edu/~yuany/course/2010.spring/Keyword/SE_slice.jpg"> [sample file] </a> <a href="http://math.stanford.edu/~yuany/course/2010.spring/Keyword/readme.txt"> [readme.txt] </a>  <a href="http://math.stanford.edu/~yuany/course/2010.spring/Keyword/SE.csv"> [data in csv] </a>
</li>
<br>
<li> [Radon Data] <a href="http://math.stanford.edu/~yuany/course/data/radon.csv"> Radon measurements of 12,687 houses in US </a>
</li>
<br>
<li> [Wells Data] <a href="http://math.stanford.edu/~yuany/course/data/wells.csv"> Switch unsafe wells for arsenic pollution in Bangladesh </a>
</li>
<br>
<li> to-be-done...
</li>
</ul>

<hr>

<address>
by <a href="http://www.math.pku.edu.cn/teachers/yaoy">YAO, Yuan</a>.
</address>

</body>
</html>
© 2019 GitHub, Inc.
Terms
Privacy
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
